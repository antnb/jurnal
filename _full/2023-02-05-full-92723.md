---
layout: full_article
title: "Penerapan Algoritma Decision Tree dalam Segmentasi Customer"
author: "Ni Putu Vina Amandari, Ngurah Agus Sanjaya ER"
categories: jik
canonical_url: https://jurnal.harianregional.com/jik/full-92723 
citation_abstract_html_url: "https://jurnal.harianregional.com/jik/id-92723"
citation_pdf_url: "https://jurnal.harianregional.com/jik/full-92723"  
comments: true
---

<p><span class="font2">Jurnal Elektronik Ilmu Komputer Udayana</span></p>
<p><span class="font2">Volume 12, No 2. November 2023</span></p>
<p><span class="font2">p-ISSN: 2301-5373</span></p>
<p><span class="font2">e-ISSN: 2654-5101</span></p><a name="caption1"></a>
<h1><a name="bookmark0"></a><span class="font3" style="font-weight:bold;"><a name="bookmark1"></a>Penerapan Algoritma Decision Tree dalam Segmentasi Customer</span></h1>
<p><span class="font2">Ni Putu Vina Amandari</span><span class="font6"><sup>1</sup></span><span class="font2">, Dr. Ngurah Agus Sanjaya ER</span><span class="font6"><sup>2</sup></span></p>
<ul style="list-style:none;"><li>
<p><span class="font6"><sup>1,2</sup></span><span class="font2">Program Studi Informatika</span></p></li></ul>
<p><span class="font2">Fakultas Matematika dan Ilmu Pengetahuan Alam</span></p>
<p><span class="font2">Universitas Udayana</span></p>
<p><a href="mailto:1vinamandari1@gmail.com"><span class="font6"><sup>1</sup></span><span class="font2">vinamandari1@gmail.com</span></a><span class="font2">, </span><a href="mailto:2agus_sanjaya@unud.ac.id"><span class="font4"><sup>2</sup></span><span class="font2">agus_sanjaya@unud.ac.id</span></a></p>
<p><span class="font2" style="font-weight:bold;font-style:italic;">Abstract</span></p>
<p><span class="font2" style="font-style:italic;">Segmentasi customer merupakan proses pembagian customer yang dilakukan oleh suatu bisnis guna mengetahui target pasar yang sesuai dengan usaha yang dijalankan. Customer akan dibagi menjadi beberapa kelompok sesuai dengan karakteristiknya seperti usia, frekuensi pembelian, jenis kelamin, pekerjaan, dan lain sebagainya. Tujuan dilakukannya segmentasi customer yaitu mengembangkan hubungan yang lebih baik dengan cara memahami kebutuhan setiap segmen pelanggan, meningkatkan profitabilitas dengan cara membuat strategi pemasaran yang lebih efektif, serta mengidentifikasi customer yang kemungkinan dapat meningkatkan pendapatan suatu usaha. Pada penelitian ini akan dilakukan klasifikasi customer menggunakan algoritma decision tree dengan tujuan untuk mengetahui tingkat akurasi dari algoritma decision tree ketika digunakan untuk mengklasifikasi customer menjadi beberapa segmen. Dataset yang digunakan pada penelitian kali ini didapatkan dari website Kaggle.com dimana dataset ini terdiri dari data training dan data testing.</span></p>
<p><span class="font2" style="font-weight:bold;font-style:italic;">Keywords: </span><span class="font2" style="font-style:italic;">Decision Tree, Segmentasi Customer</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark2"></a><span class="font2" style="font-weight:bold;"><a name="bookmark3"></a>1. &nbsp;&nbsp;&nbsp;Pendahuluan</span></h2></li></ul>
<p><span class="font2">Perkembangan teknologi yang semakin pesat menyebabkan hampir seluruh aspek kehidupan seperti aspek ekonomi, kesehatan, industri, dan aspek lainnya bergantung pada teknologi. Dalam persaingan antar bisnis, suatu perusahaan dituntut agar dapat memanfaatkan semaksimal mungkin sumber daya yang ada agar mampu bersaing dengan perusahaan lain. Sejalan dengan peradaban manusia, terjadi perubahan terhadap kebutuhan pelanggan. Dengan berubahnya kebutuhan pelanggan maka diiperlukan perubahan juga dalam bidang pemasaran. Bagian marketing dalam suatu perusahaan sangat berperan besar tehadap keberhasilan suatu perusahaan dalam mendapatkan customer. Ditambah lagi ketatnya persaingan antara perusahaan satu dengan perusahaan lainnya membuat suatu perusahaan harus memiliki strategi pemasaran yang baik. Untuk menciptakan strategi pemasaran yang baik kita perlu mengetahui target pasar kita serta mempertimbangkan karakteristik dari setiap customer, maka dari itu segmentasi customer sangat penting dilakukan. Customer segmentation merupakan membagi-bagi pasar menjadi beberapa kelompok pembeli berbeda yang mungkin memerlukan produk atau jasa yang berbeda pula [1]. Dengan melakukan segmentasi customer kegiatan pemasaran suatu perusahaan lebih terarah mengingat banyaknya customer yang memiliki keinginan dan kebutuhan yang berbeda. Adapun beberapa tujuan dilakukannya segmentasi customer yaitu mengembangkan hubungan yang lebih baik dengan cara memahami kebutuhan setiap segmen pelanggan, meningkatkan profitabilitas dengan cara membuat strategi pemasaran yang lebih efektif, serta mengidentifikasi customer yang kemungkinan dapat meningkatkan pendapatan suatu usaha. Untuk melakukan segmentasi customer dibutuhkan suatu algoritma yang dapat membantu dalam mengklasifikasikan customer ke dalam beberapa kelompok.</span></p>
<p><span class="font2">Pada penelitian yang Alkahfi Madani, dkk (2022) dengan judul Segmentasi Pelanggan pada BC HNI 2 Pekanbaru dengan Menerapkan Algoritma K-Medoids dan Model Recency, Frequency, Monetery (RFM), dilakukan segmentasi pelanggan pada BC HNI 2 Pekanbaru dengan menerapkan algoritma K-Medoids dan Model RFM. Setelah melakukan klasifikasi didapatkan 2 kelompok customer dimana customer pada kelompok 1 merupakan pelanggan dengan kategori pelanggan utama yang recent</span></p>
<p><span class="font2">transaction time yang rendah dengan artian bahwa baru-baru ini dan frekuensinya juga tinggi hal ini diartikan bahwa pelanggan sering bertransaksi antara pelanggan dan perusahaan serta rendahnya nilai monetary yang berarti total uang yang dipakai tidak terlalu besar [2]. Sedangkan customer pada kelompok 2 merupakan customer yang tergolong bertransaksi hanya pada awal bulan dan betransaksi ketika sangat membutuhkan barang tersebut. Kemudian pada penelitian yang dilakukan oleh Nana Suryana (2017) dengan judul penelitian Prediksi Churn dan Segmentasi Pelanggan TV Berlangganan (Studi Kasus Transvision Jawa Barat), dilakukan prediksi churn rate dan segmentasi pelanggan menggunakan algoritma K-Means. Berdasarkan penelitian tersebut tingkat akurasi yang didapatkan sebesar 90,89%.</span></p>
<p><span class="font2">Pada penelitian ini, proses klasifikasi dilakukan dengan menggunakan algoritma Decision Tree pada suatu dataset. Dataset yang digunakan diperoleh dari website Kaggle.com dengan nama dataset “</span><span class="font2" style="font-style:italic;">Customer Segmentation Classification</span><span class="font2">”. Dataset ini terdiri dari data training dan data testing dimana masing-masing set data memiliki 11 atribut. Tujuan dari penelitian ini yaitu untuk mengetahui akurasi dari algoritma Decision Tree jika digunakan untuk mengklasifikasikan customer menjadi beberapa segmen.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark4"></a><span class="font2" style="font-weight:bold;"><a name="bookmark5"></a>2. &nbsp;&nbsp;&nbsp;Metode Penelitian</span></h2></li></ul>
<p><span class="font2">Pada penelitian ini akan menggunakan library python mulai dari tahap data preparation sampai model evaluation. Berikut ini tahapan dalam penelitian ini :</span></p><img src="https://jurnal.harianregional.com/media/92723-1.png" alt="" style="width:96pt;height:232pt;">
<p><span class="font2" style="font-weight:bold;">Gambar 1</span><span class="font2">. Tahapan Penelitian</span></p>
<ul style="list-style:none;"><li>
<p><span class="font2">2.1 &nbsp;&nbsp;&nbsp;Data Preparation</span></p></li></ul>
<p><span class="font2">Pada tahap ini dilakukan proses pengumpulan data serta informasi yang berkaitan dengan penelitian yang akan dilakukan. Dataset yang digunakan dalam penelitian yaitu </span><span class="font2" style="font-style:italic;">“Customer Segmentation Classification”</span><span class="font2"> yang didapatkan dari website </span><span class="font2" style="font-style:italic;">Kaggle.com</span><span class="font2">. Dataset ini terdiri dari data training dan data testing dimana masing-masing data terdiri dari 11 atribut. Data training digunakan untuk melatih algoritma dalam mencari model yang sesuai sedangkan data testing digunakan untuk menguji performa dari algoritma yang sudah dilatih sebelumnya.</span></p>
<p><span class="font2" style="font-weight:bold;">Tabel 1</span><span class="font2">. Atribut Dataset</span></p>
<table border="1">
<tr><td style="vertical-align:bottom;">
<p><span class="font2">No</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">Atribut</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">Penjelasan</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2">1.</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">ID</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">Unique ID</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2">2.</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">Gender</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">Gender dari customer</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2">3.</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">Ever_Married</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">Status pernikahan customer (sudah atau belum)</span></p></td></tr>
</table>
<table border="1">
<tr><td style="vertical-align:bottom;">
<p><span class="font2">4.</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">Age</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">Usia customer</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2">5.</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">Graduated</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">Sudah lulus sekolah atau belum</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2">6.</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">Profession</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">Profesi customer</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2">7.</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">Work_Experience</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">Pengalaman kerja</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2">8.</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">Spending_Score</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">Skor yang diberikan customer</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2">9</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">Family_Size</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">Jumlah anggota keluarga customer</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2">10.</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">Var_1</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">Kategori anonim customer</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2">11.</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">Segmentation</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">Segmentasi pelanggan (A,B,C,D)</span></p></td></tr>
</table>
<ul style="list-style:none;"><li>
<p><span class="font2">2.2 &nbsp;&nbsp;&nbsp;Data Preprocessing</span></p>
<ul style="list-style:none;">
<li>
<p><span class="font2">2.2.1 &nbsp;&nbsp;&nbsp;Cleaning Dataset</span></p></li></ul></li></ul>
<p><span class="font2">Cleaning dataset dilakukan dengan tujuan memastikan bahwa tidak terdapat missing value dalam dataset sehingga tidak menimbulkan error ketika tahap klasifikasi berlansung. Missing value merupakan informasi yang tidak tersedia dalam suatu data dimana hal ini dapat terjadi karena beberapa hal diantaranya responden menolak untuk menjawab, informasi tidak tersedia atau sulit untuk dicari, kesalahan ketika mengumpulkan data, dan lain sebagainya. Pada penelitian ini ketika ditemukan missing value pada dataset maka data tersebut nantinya akan dihapus.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font2">2.2.2 &nbsp;&nbsp;&nbsp;Encoding Nominal Data</span></p></li></ul>
<p><span class="font2">Model machine learning hanya dapat memahami data berupa data numerikal sedangkan dataset yang digunakan terdiri dari data numerikal dan data kategorikal. Maka dari itu dibutuhkan sebuah metode yang dapat mengubah data kategorikal menjadi data numerikal. Encoding nominal data merupakan transformasi data kategorikal menjadi data numerikal. Bentuk transformasi data menggunakan mekanisme sederhana yaitu mengubah semua data kategorikal dengan kode numerik 0 - n, dimana n adalah varian terakhir dari data kategorikal pada atribut tersebut [3].Tahap ini dapat dilakukan dengan menggunakan salah satu library python yaitu </span><span class="font2" style="font-style:italic;">sci-kit LabelEncoder </span><span class="font2">kemudian dilakukan proses </span><span class="font2" style="font-style:italic;">fit_transform()</span><span class="font2"> terhadap kolom yang ingin dirubah.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font2">2.2.3 &nbsp;&nbsp;&nbsp;Handle Unwanted Column</span></p></li></ul>
<p><span class="font2">Unwanted Column merupakan kolom atau fitur yang tidak relevan dengan hasil klasifikasi nantinya. Maka dari itu untuk meningkatkan kinerja dari model klasifikasi maka fitur-fitur yang tidak relevan akan dihapus dengan cara melihat korelasinya terlebih dahulu dengan fitur lainnya.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font2">2.2.4 &nbsp;&nbsp;&nbsp;Handle Outliers</span></p></li></ul>
<p><span class="font2">Outlier merupakan data yang memiliki nilai-nilai yang jauh berbeda dibandingkan dengan kelompoknya baik itu terlalu tinggi maupun terlalu rendah. Pada penelitian ini data outlier dideteksi menggunakan metode boxplot. Konsep metode ini adalah menggunakan nilai dari jangkauan interkuartil atau </span><span class="font2" style="font-style:italic;">Interquartile Range (IQR)</span><span class="font2"> yang merupakan selisih antara kuartil 1 terhadap kuartil 3 [4]. Data yang dapat dikatakan outlier adalah data yang nilainya lebih dari Q3+1.5*IQR dan data yang nilainya kurang dari Q1+1.5*IQR dimana Q3 adalah kuartil 3 dan Q1 merupakan kuartil 1. Nilai yang dinyatakan sebagai outlier nantinya akan diganti dengan nilai </span><span class="font2" style="font-style:italic;">mean</span><span class="font2"> dari kelompok datanya.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font2">2.3 &nbsp;&nbsp;&nbsp;Modeling Data</span></p>
<ul style="list-style:none;">
<li>
<p><span class="font2">2.3.1 &nbsp;&nbsp;&nbsp;X and y definision</span></p></li></ul></li></ul>
<p><span class="font2">Pada tahap ini data dibagi ke dalam 2 variabel yaitu x dan y dimana x sebagai fitur atau variabel yang mempengaruhi dan y sebagai label atau variabel yang dipengaruhi.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font2">2.3.2 &nbsp;&nbsp;&nbsp;Feature Scalling</span></p></li></ul>
<p><span class="font2">Scalling Features merupakan suatu cara untuk membuat data numerik pada dataset supaya memiliki jangkauan nilai (scale) yang sama [5]. Terdapat 3 scaler pada library scikit-learn yang sering digunakan untuk feature scalling dataset yaitu SrandardScaler, MinMaxScaler, dan RobustScaler namun pada penelitian ini digunakan StandardScaler. StandardScaler merupakan suatu metode dimana metode tersebut akan melakukan standarisasi fitur dengan menghapus rata-</span></p>
<p><span class="font2">rata dan menskalakan unit varian [6]. Rumus dari Standard Scaler ditunjukkan pada persamaan di bawah, dimana </span><span class="font8" style="font-style:italic;">X</span><span class="font2"> adalah rata-rata nilai sampel dan </span><span class="font8">σ </span><span class="font2">adalah standar deviasi.</span></p>
<p><span class="font7" style="font-style:italic;">I</span><span class="font9" style="font-style:italic;">Z =</span></p>
<p><span class="font9" style="font-style:italic;">σ</span></p>
<ul style="list-style:none;"><li>
<p><span class="font2">2.3.3 &nbsp;&nbsp;&nbsp;Split Data</span></p></li></ul>
<p><span class="font2">Pada tahap ini dengan menggunakan library python yaitu sklearn, data akan dibagi menjadi 2 yaitu data training dan data testing dengan perbandingan 80% untuk data training dan 20% untuk data testing.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font2">2.4 &nbsp;&nbsp;&nbsp;Decision Tree Classification</span></p></li></ul>
<p><span class="font2">Proses klasifikasi akan menggunakan algoritma Decision Tree. Algoritma Decision Tree merupakan model prediksi terhadap suatu keputusan menggunakan struktur hirarki atau pohon [7]. Setiap pohon memiliki cabang dimana cabang tersebut mewakili sebuah atribut yang harus dipenuhi agar dapat menuju ke cabang selanjutnya, hal tersebut berulang hingga tidak ada cabang lagi. Konsep data dalam decision tree adalah data dinyatakan dalam bentuk tabel yang terdiri dari atribut dan record dimana atribut digunakan sebagai parameter yang dibuat sebagai kriteria dalam pembuatan pohon [7].</span></p><img src="https://jurnal.harianregional.com/media/92723-2.png" alt="" style="width:324pt;height:145pt;">
<p><span class="font2" style="font-weight:bold;">Gambar 2</span><span class="font2">. Konsep Decision Tree</span></p>
<p><span class="font2">Tahapan algoritma decision tree dalam membentuk pohon keputusan yaitu [8] :</span></p>
<ul style="list-style:none;"><li>
<p><span class="font2">• &nbsp;&nbsp;&nbsp;Menentukan akar/root</span></p></li>
<li>
<p><span class="font2">• &nbsp;&nbsp;&nbsp;Menghitung Gain Information yang memiliki nilai terbesar sebagai splitting atribut yang nantinya dipilih sebagai cabang</span></p></li>
<li>
<p><span class="font2">• &nbsp;&nbsp;&nbsp;Ulangi langkah 2 dan 3 hingga terdapat leaf node.</span></p></li></ul>
<p><span class="font2">Gain information mengukur nilai impuritty dari suatu partisi, dengan perhitungan :</span></p>
<p><span class="font2">Gini (D) = 1 - </span><span class="font8" style="font-style:italic;">∑</span><span class="font6" style="font-style:italic;">^=<sub>1</sub></span><span class="font8" style="font-style:italic;">Pi</span><span class="font1" style="font-style:italic;"><sup>2</sup></span><span class="font2"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1)</span></p>
<p><span class="font2">Keterangan :</span></p>
<p><span class="font2">Gini(D) = nilai impurity dari partisi D</span></p>
<p><span class="font2">M = jumlah indeks</span></p>
<p><span class="font2">P</span><span class="font4">i </span><span class="font2">= peluang sebuah </span><span class="font2" style="font-style:italic;">tuple</span><span class="font2"> D pada indeks ke i</span></p>
<p><span class="font2">Nilai </span><span class="font2" style="font-style:italic;">Avarage Gini Impurity</span><span class="font2"> dapat dihitung dengan :</span></p>
<p><span class="font2">Gini</span><span class="font4">A</span><span class="font2">(D) </span><span class="font8">= &nbsp;&nbsp;&nbsp;&nbsp;</span><span class="font8" style="font-style:italic;">Gini(Di)</span><span class="font8"> + &nbsp;&nbsp;&nbsp;&nbsp;</span><span class="font8" style="font-style:italic;">Gini(D2)</span><span class="font2"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(2)</span></p>
<p><span class="font2">Keterangan :</span></p>
<p><span class="font2">D = </span><span class="font2" style="font-style:italic;">tuple</span><span class="font2"> D</span></p>
<p><span class="font2">D1 = partisi pertama </span><span class="font2" style="font-style:italic;">tuple</span><span class="font2"> D</span></p>
<p><span class="font2">D2 = partisi kedua </span><span class="font2" style="font-style:italic;">tuple</span><span class="font2"> D</span></p>
<p><span class="font2" style="font-variant:small-caps;">G</span><span class="font2">ini</span><span class="font2" style="font-variant:small-caps;">a(D)</span><span class="font2"> = impurity dari partisi D pada atribut A</span></p>
<p><span class="font2">Gini(D1) = impurity dari partisi pertama </span><span class="font2" style="font-style:italic;">tuple</span><span class="font2"> D</span></p>
<p><span class="font2">Gini(D2) = impurity dari partisi kedua </span><span class="font2" style="font-style:italic;">tuple</span><span class="font2"> D</span></p>
<p><span class="font2">Kemudian penurunan tingkat impurity, bisa dihitung dengan :</span></p>
<p><span class="font8" style="font-style:italic;">∆Gini(A)</span><span class="font8"> = </span><span class="font8" style="font-style:italic;">Gini(D') - GiniA(D)</span></p>
<div>
<p><span class="font2">(3)</span></p>
</div><br clear="all">
<p><span class="font2">Dimana :</span></p>
<p><span class="font8" style="font-style:italic;">∆Gini(A)</span><span class="font2"> = tingkat impurity</span></p>
<ul style="list-style:none;"><li>
<p><span class="font2">2.5 &nbsp;&nbsp;&nbsp;Model Evaluation</span></p></li></ul>
<p><span class="font2">Pada tahap ini akan dilakukan evaluasi terhadap performa dari model yang telah dijalankan menggunakan confusion matrix. Confusion matrix adalah alat ukur berbentuk matrix yang digunakan untuk mendapatkan jumlah ketepatan klasifikasi terhadap kelas dengan algoritma yang dipakai [9].Hasil evaluasi yang akan ditampilkan mencakup accuracy, precision, recall, dan f1-score pada basis per kelasnya.</span></p>
<div><img src="https://jurnal.harianregional.com/media/92723-3.jpg" alt="" style="width:214pt;height:150pt;">
</div><br clear="all">
<p><span class="font2" style="font-weight:bold;">Gambar 3</span><span class="font2">. Confusion Matrix</span></p>
<p><span class="font2">Confusion Matrix memiliki 4 istilah diantaranya :</span></p>
<ul style="list-style:none;"><li>
<p><span class="font2">1. &nbsp;&nbsp;&nbsp;True Negative (TN) : Ketika data berada di kelas negatif dan model memprediksi data ada di kelas negative</span></p></li>
<li>
<p><span class="font2">2. &nbsp;&nbsp;&nbsp;True Positive (TP) : Ketika data berada di kelas positif dan model memprediksi data ada di kelas positif</span></p></li>
<li>
<p><span class="font2">3. &nbsp;&nbsp;&nbsp;False Negative (FN) : Ketika data berada di kelas positif namun model memprediksi data ada di kelas negatif</span></p></li>
<li>
<p><span class="font2">4. &nbsp;&nbsp;&nbsp;False Positive (FP) : Ketika data berada di kelas negatif namun model memprediksi data ada di kelas negatif</span></p></li></ul>
<p><span class="font2">Precision merupakan ketepatan informasi yang diminta oleh user dengan jawaban yang diberikan oleh sistem. Nilai precision didapatkan dari hasil perbandingan antara True Positive (TP) dengan banyaknya data yang diprediksi positif.</span></p>
<p><span class="font2">Precision = ——— &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1)</span></p>
<p><span class="font6" style="font-style:italic;">(TP+FP)</span></p>
<p><span class="font2">Recall merupakan kemampuan classifier dalam menemukan kembali informasi. Nilai recall didapatkan dari hasil perbandingan antara setiap kelas yang didefinisikan sebagai rasio True Positive (TP) dengan jumlah True positive (TP) dan False Negative (FN).</span></p>
<p><span class="font2">Recall = -^- &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(2)</span></p>
<p><span class="font6" style="font-style:italic;">(TP+PN)</span></p>
<p><span class="font2">F1-Score merupakan rata-rata harmonik dari precision dan recall. Nilai terbaik dari F1-Score yaitu 1.0 dan nilai terburuknya adalah 0.</span></p>
<div>
<p><span class="font6">1</span></p>
<p><span class="font6">F1</span></p>
</div><br clear="all">
<div>
<p><span class="font8">= 1(-∑- +</span></p>
<p><span class="font6">2 </span><span class="font6" style="font-style:italic;">''precision</span></p>
</div><br clear="all">
<div>
<p><span class="font6">1 </span><span class="font6" style="font-style:italic;">recall</span></p>
</div><br clear="all">
<div>
<p><span class="font8">■)</span></p>
</div><br clear="all">
<div>
<p><span class="font2">(3)</span></p>
</div><br clear="all">
<ul style="list-style:none;"><li>
<h2><a name="bookmark6"></a><span class="font2" style="font-weight:bold;"><a name="bookmark7"></a>3. &nbsp;&nbsp;&nbsp;Hasil dan Pembahasan</span></h2></li></ul>
<p><span class="font2">Tahapan awal dalam penelitian ini dimulai dengan import dataset. Setelah melakukan import dataset selanjutnya penulis perlu mengetahui data-data serta nilai apa saja yang terkandung di dalam dataset. Pada Gambar 4 merupakan dataset yang digunakan dalam penelitian ini.</span></p>
<table border="1">
<tr><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">(8068,</span></p></td><td colspan="7" style="vertical-align:middle;">
<p><span class="font0">11)</span></p></td><td colspan="4" style="vertical-align:bottom;">
<p><span class="font0">1 to 10 Of 10 entries Filter O</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2" style="font-weight:bold;">©</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0">index</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">ID</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">Gender</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">Ever Married</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">Age</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">Graduated</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">Profession</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">Work Experience</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">Spending Score</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">Famιly<sub>-</sub>Sιze</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">Var_f</span></p></td><td colspan="2" style="vertical-align:bottom;">
<p><span class="font0">Segmentation</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font0">0</span></p></td><td style="vertical-align:top;">
<p><span class="font0">462809</span></p></td><td style="vertical-align:top;">
<p><span class="font0">Male</span></p></td><td style="vertical-align:top;">
<p><span class="font0">No</span></p></td><td style="vertical-align:top;">
<p><span class="font0">22</span></p></td><td style="vertical-align:top;">
<p><span class="font0">No</span></p></td><td style="vertical-align:top;">
<p><span class="font0">Healthcare</span></p></td><td style="vertical-align:top;">
<p><span class="font0">1.0</span></p></td><td style="vertical-align:top;">
<p><span class="font0">Low</span></p></td><td style="vertical-align:top;">
<p><span class="font0">4.0</span></p></td><td style="vertical-align:top;">
<p><span class="font0">Cat_4</span></p></td><td style="vertical-align:top;">
<p><span class="font0">D</span></p></td><td style="vertical-align:top;"></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font0">1</span></p></td><td style="vertical-align:top;">
<p><span class="font0">462643</span></p></td><td style="vertical-align:top;">
<p><span class="font0">Female</span></p></td><td style="vertical-align:top;">
<p><span class="font0">Yes</span></p></td><td style="vertical-align:top;">
<p><span class="font0">38</span></p></td><td style="vertical-align:top;">
<p><span class="font0">Yes</span></p></td><td style="vertical-align:top;">
<p><span class="font0">Engineer</span></p></td><td style="vertical-align:top;">
<p><span class="font0">NaN</span></p></td><td style="vertical-align:top;">
<p><span class="font0">Average</span></p></td><td style="vertical-align:top;">
<p><span class="font0">3.0</span></p></td><td style="vertical-align:top;">
<p><span class="font0">Cat_4</span></p></td><td style="vertical-align:top;">
<p><span class="font0">A</span></p></td><td style="vertical-align:top;"></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font0">2</span></p></td><td style="vertical-align:top;">
<p><span class="font0">466315</span></p></td><td style="vertical-align:top;">
<p><span class="font0">Female</span></p></td><td style="vertical-align:top;">
<p><span class="font0">Yes</span></p></td><td style="vertical-align:top;">
<p><span class="font0">67</span></p></td><td style="vertical-align:top;">
<p><span class="font0">Yes</span></p></td><td style="vertical-align:top;">
<p><span class="font0">Engineer</span></p></td><td style="vertical-align:top;">
<p><span class="font0">1.0</span></p></td><td style="vertical-align:top;">
<p><span class="font0">Low</span></p></td><td style="vertical-align:top;">
<p><span class="font0">1.0</span></p></td><td style="vertical-align:top;">
<p><span class="font0">Cal_6</span></p></td><td style="vertical-align:top;">
<p><span class="font0">B</span></p></td><td style="vertical-align:top;"></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font0">3</span></p></td><td style="vertical-align:top;">
<p><span class="font0">461735</span></p></td><td style="vertical-align:top;">
<p><span class="font0">Male</span></p></td><td style="vertical-align:top;">
<p><span class="font0">Yes</span></p></td><td style="vertical-align:top;">
<p><span class="font0">67</span></p></td><td style="vertical-align:top;">
<p><span class="font0">Yes</span></p></td><td style="vertical-align:top;">
<p><span class="font0">Lawyer</span></p></td><td style="vertical-align:top;">
<p><span class="font0">0.0</span></p></td><td style="vertical-align:top;">
<p><span class="font0">High</span></p></td><td style="vertical-align:top;">
<p><span class="font0">2.0</span></p></td><td style="vertical-align:top;">
<p><span class="font0">Cat_6</span></p></td><td style="vertical-align:top;">
<p><span class="font0">B</span></p></td><td style="vertical-align:top;"></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font0">4</span></p></td><td style="vertical-align:top;">
<p><span class="font0">462669</span></p></td><td style="vertical-align:top;">
<p><span class="font0">Female</span></p></td><td style="vertical-align:top;">
<p><span class="font0">Yes</span></p></td><td style="vertical-align:top;">
<p><span class="font0">40</span></p></td><td style="vertical-align:top;">
<p><span class="font0">Yes</span></p></td><td style="vertical-align:top;">
<p><span class="font0">Entertainment</span></p></td><td style="vertical-align:top;">
<p><span class="font0">NaN</span></p></td><td style="vertical-align:top;">
<p><span class="font0">High</span></p></td><td style="vertical-align:top;">
<p><span class="font0">6.0</span></p></td><td style="vertical-align:top;">
<p><span class="font0">Cat_6</span></p></td><td style="vertical-align:top;">
<p><span class="font0">A</span></p></td><td style="vertical-align:top;"></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font0">5</span></p></td><td style="vertical-align:top;">
<p><span class="font0">461319</span></p></td><td style="vertical-align:top;">
<p><span class="font0">Male</span></p></td><td style="vertical-align:top;">
<p><span class="font0">Yes</span></p></td><td style="vertical-align:top;">
<p><span class="font0">56</span></p></td><td style="vertical-align:top;">
<p><span class="font0">No</span></p></td><td style="vertical-align:top;">
<p><span class="font0">Artisl</span></p></td><td style="vertical-align:top;">
<p><span class="font0">0.0</span></p></td><td style="vertical-align:top;">
<p><span class="font0">Average</span></p></td><td style="vertical-align:top;">
<p><span class="font0">2.0</span></p></td><td style="vertical-align:top;">
<p><span class="font0">Cat 6</span></p></td><td style="vertical-align:top;">
<p><span class="font0">C</span></p></td><td style="vertical-align:top;"></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font0">6</span></p></td><td style="vertical-align:top;">
<p><span class="font0">460156</span></p></td><td style="vertical-align:top;">
<p><span class="font0">Male</span></p></td><td style="vertical-align:top;">
<p><span class="font0">No</span></p></td><td style="vertical-align:top;">
<p><span class="font0">32</span></p></td><td style="vertical-align:top;">
<p><span class="font0">Yes</span></p></td><td style="vertical-align:top;">
<p><span class="font0">Healthcare</span></p></td><td style="vertical-align:top;">
<p><span class="font0">1.0</span></p></td><td style="vertical-align:top;">
<p><span class="font0">Low</span></p></td><td style="vertical-align:top;">
<p><span class="font0">3.0</span></p></td><td style="vertical-align:top;">
<p><span class="font0">Cat_6</span></p></td><td style="vertical-align:top;">
<p><span class="font0">C</span></p></td><td style="vertical-align:top;"></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font0">7</span></p></td><td style="vertical-align:top;">
<p><span class="font0">464347</span></p></td><td style="vertical-align:top;">
<p><span class="font0">Female</span></p></td><td style="vertical-align:top;">
<p><span class="font0">No</span></p></td><td style="vertical-align:top;">
<p><span class="font0">33</span></p></td><td style="vertical-align:top;">
<p><span class="font0">Yes</span></p></td><td style="vertical-align:top;">
<p><span class="font0">Healthcare</span></p></td><td style="vertical-align:top;">
<p><span class="font0">1.0</span></p></td><td style="vertical-align:top;">
<p><span class="font0">Low</span></p></td><td style="vertical-align:top;">
<p><span class="font0">3.0</span></p></td><td style="vertical-align:top;">
<p><span class="font0">Cat_6</span></p></td><td style="vertical-align:top;">
<p><span class="font0">D</span></p></td><td style="vertical-align:top;"></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font0">8</span></p></td><td style="vertical-align:top;">
<p><span class="font0">465015</span></p></td><td style="vertical-align:top;">
<p><span class="font0">Female</span></p></td><td style="vertical-align:top;">
<p><span class="font0">Yes</span></p></td><td style="vertical-align:top;">
<p><span class="font0">61</span></p></td><td style="vertical-align:top;">
<p><span class="font0">Yes</span></p></td><td style="vertical-align:top;">
<p><span class="font0">Engineer</span></p></td><td style="vertical-align:top;">
<p><span class="font0">0.0</span></p></td><td style="vertical-align:top;">
<p><span class="font0">Low</span></p></td><td style="vertical-align:top;">
<p><span class="font0">3.0</span></p></td><td style="vertical-align:top;">
<p><span class="font0">Cat_7</span></p></td><td style="vertical-align:top;">
<p><span class="font0">D</span></p></td><td style="vertical-align:top;"></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font0">9</span></p></td><td style="vertical-align:top;">
<p><span class="font0">465176</span></p></td><td style="vertical-align:top;">
<p><span class="font0">Female</span></p></td><td style="vertical-align:top;">
<p><span class="font0">Yes</span></p></td><td style="vertical-align:top;">
<p><span class="font0">55</span></p></td><td style="vertical-align:top;">
<p><span class="font0">Yes</span></p></td><td style="vertical-align:top;">
<p><span class="font0">Artisl</span></p></td><td style="vertical-align:top;">
<p><span class="font0">1.0</span></p></td><td style="vertical-align:top;">
<p><span class="font0">Average</span></p></td><td style="vertical-align:top;">
<p><span class="font0">4.0</span></p></td><td style="vertical-align:top;">
<p><span class="font0">Cat_6</span></p></td><td style="vertical-align:top;">
<p><span class="font0">C</span></p></td><td style="vertical-align:top;"></td></tr>
</table>
<p><span class="font0">Show 25 * per page</span></p>
<p><span class="font2" style="font-weight:bold;">Gambar 4</span><span class="font2">. Dataset Awal</span></p>
<p><span class="font2">Dataset ini memiliki 11 atribut dengan jumlah data sebanyak 8068 baris. Tipe data yang digunakan dalam dataset ini terdiri dari tipe data int64, object, dan float64 seperti yang ditunjukkan pada gambar 5. Jenis data dalam dataset ini terbagi ke dalam dua jenis yaitu data kategorikal dan data numerikal. Tipe data yang termasuk ke dalam data kategorikal yaitu tipe data object sedangkan tipe data yang termasuk ke dalam data numerikal diantaranya tipe data int64 dan float64.</span></p>
<p><span class="font4">β⅜ &lt;class <sup>,</sup>pandas . core.frame.DataFrame'&gt; Rangeindex: 8068 entries, 0 to 8067</span></p>
<table border="1">
<tr><td rowspan="2" style="vertical-align:top;">
<p><span class="font4">Data #</span></p></td><td rowspan="2" style="vertical-align:top;">
<p><span class="font4">columns (total</span></p>
<p><span class="font4">Column</span></p></td><td colspan="2" style="vertical-align:bottom;">
<p><span class="font4">11 columns):</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font4">Non-Null Count</span></p></td><td style="vertical-align:top;">
<p><span class="font4">Dtype</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font4">0</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">ID</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">8068 non-null</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">int64</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font4">1</span></p></td><td style="vertical-align:top;">
<p><span class="font4">Gender</span></p></td><td style="vertical-align:top;">
<p><span class="font4">8068 non-null</span></p></td><td style="vertical-align:top;">
<p><span class="font4">object</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font4">2</span></p></td><td style="vertical-align:top;">
<p><span class="font4">Ever<sub>-</sub>Married</span></p></td><td style="vertical-align:top;">
<p><span class="font4">7928 non-null</span></p></td><td style="vertical-align:top;">
<p><span class="font4">object</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font4">3</span></p></td><td style="vertical-align:top;">
<p><span class="font4">Age</span></p></td><td style="vertical-align:top;">
<p><span class="font4">8068 non-null</span></p></td><td style="vertical-align:top;">
<p><span class="font4">int64</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font4">4</span></p></td><td style="vertical-align:top;">
<p><span class="font4">Graduated</span></p></td><td style="vertical-align:top;">
<p><span class="font4">7990 non-null</span></p></td><td style="vertical-align:top;">
<p><span class="font4">object</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font4">5</span></p></td><td style="vertical-align:top;">
<p><span class="font4">Profession</span></p></td><td style="vertical-align:top;">
<p><span class="font4">7944 non-null</span></p></td><td style="vertical-align:top;">
<p><span class="font4">object</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font4">6</span></p></td><td style="vertical-align:top;">
<p><span class="font4">Work-Experience</span></p></td><td style="vertical-align:top;">
<p><span class="font4">7239 non-null</span></p></td><td style="vertical-align:top;">
<p><span class="font4">float64</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font4">7</span></p></td><td style="vertical-align:top;">
<p><span class="font4">Spending Score</span></p></td><td style="vertical-align:top;">
<p><span class="font4">8068 non-null</span></p></td><td style="vertical-align:top;">
<p><span class="font4">object</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font4">8</span></p></td><td style="vertical-align:top;">
<p><span class="font4">Family Size</span></p></td><td style="vertical-align:top;">
<p><span class="font4">7733 non-null</span></p></td><td style="vertical-align:top;">
<p><span class="font4">float64</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font4">9</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">Var_l</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">7992 non-null</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">object</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font4">10</span></p></td><td style="vertical-align:top;">
<p><span class="font4">Segmentation</span></p></td><td style="vertical-align:top;">
<p><span class="font4">8068 non-null</span></p></td><td style="vertical-align:top;">
<p><span class="font4">object</span></p></td></tr>
</table>
<p><span class="font4">dtypes: float64(2), int64(2), object(7)</span></p>
<p><span class="font4">memory usage: 693.5+ KB</span></p>
<p><span class="font2" style="font-weight:bold;">Gambar 5</span><span class="font2">. Tipe Data Atribut</span></p>
<p><span class="font2">Tahap selanjutnya yaitu tahap preprocessing, seperti yang ditunjukkan pada gambar 6 terdapat missing value di beberapa atribut diantaranya pada atribut Ever_Married terdapat 140 missing value, atribut Graduated memiliki 78 missing value, atribut Profession memiliki 124 missing value, atribut Work_Experience memiliki 829 missing value, atribut Family_Size memiliki 335 missing value, dan atribut Var_1 memiliki 76 missing value. Untuk menghindari error ketika proses klasifikasi maka data yang mengandung missing value dihapus. Selain mengandung missing value, dataset yang digunakan juga mengandung data outliers. Data outliers ditemukan di beberapa column diantaranya column age, work experience, dan family size.</span></p>
<div>
<p><span class="font5">β⅛ Mising Value pada setiap atribut</span></p>
<table border="1">
<tr><td style="vertical-align:top;">
<p><span class="font5">ID</span></p></td><td style="vertical-align:top;">
<p><span class="font5">0</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font5">Gender</span></p></td><td style="vertical-align:top;">
<p><span class="font5">0</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font5">Ever_Married</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">140</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font5">Age</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">0</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font5">Graduated</span></p></td><td style="vertical-align:top;">
<p><span class="font5">78</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font5">Profession</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">124</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font5">Work_Experience</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">829</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font5">Spending_Score</span></p></td><td style="vertical-align:top;">
<p><span class="font5">0</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font5">Family_Size</span></p></td><td style="vertical-align:top;">
<p><span class="font5">335</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font5">Var_l</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">76</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font5">Segmentation</span></p></td><td style="vertical-align:top;">
<p><span class="font5">0</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font5">dtype: int64</span></p></td><td style="vertical-align:top;"></td></tr>
</table>
</div><br clear="all">
<div>
<p><span class="font4">Q&gt; &lt;matplotlib.axes.<sub>-</sub>subplots.AxesSubplot at 0x7fd679947e5E</span></p><img src="https://jurnal.harianregional.com/media/92723-4.jpg" alt="" style="width:166pt;height:110pt;">
<p><span class="font0">GendeEver Married Aje Gra□u⅞%Λ Exp⅛pe∏Efing Sfareily Size</span></p>
</div><br clear="all">
<p><span class="font2" style="font-weight:bold;">Gambar 6</span><span class="font2">. Missing Value Setiap Atribut</span></p>
<div>
<p><span class="font2" style="font-weight:bold;">Gambar 7</span><span class="font2">. Outliers Setiap Atribut</span></p>
</div><br clear="all">
<p><span class="font2">Hasil dari tahap preprocessing dapat dilihat pada Gambar 8. Jumlah baris pada dataset berkurang dari data awal 8068 baris menjadi 6665 baris karena hasil dari proses cleaning data, nilai pada dataset yang awalnya bertipe kategorikal seperti kolom Gender, Ever_Married, Graduated, dan lainnya diganti menjadi data numerikal dengan rentang nilai 0 – n, serta jumlah kolom pada dataset bertambah yang awalnya 11 menjadi 24 kolom karena hasil preprocessing data kategori.</span></p>
<table border="1">
<tr><td style="vertical-align:top;"></td><td style="vertical-align:top;">
<p><span class="font0" style="font-weight:bold;">Gender Ever-Merried</span></p></td><td style="vertical-align:top;">
<p><span class="font0" style="font-weight:bold;">Age</span></p></td><td style="vertical-align:top;">
<p><span class="font0" style="font-weight:bold;">Graduated</span></p></td><td style="vertical-align:top;">
<p><span class="font0" style="font-weight:bold;">WorkExperience</span></p></td><td style="vertical-align:top;">
<p><span class="font0" style="font-weight:bold;">Spending-Score</span></p></td><td style="vertical-align:top;">
<p><span class="font0" style="font-weight:bold;">Family_Size</span></p></td><td style="vertical-align:top;">
<p><span class="font0" style="font-weight:bold;">Segmentation</span></p></td><td style="vertical-align:top;">
<p><span class="font0" style="font-weight:bold;">Profession-Artist</span></p></td><td style="vertical-align:top;">
<p><span class="font0" style="font-weight:bold;">P rofes s ion_Doc tor</span></p></td><td style="vertical-align:top;">
<p><span class="font0" style="font-weight:bold;">.,. Profe</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font0">O</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">1 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">22</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">0</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">1.0</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">2</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">4,0</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">3</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">0</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">0</span></p></td><td style="vertical-align:top;"></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font0">2</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">0 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">67</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">1</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">1.0</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">2</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">1.0</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">1</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">0</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">0</span></p></td><td style="vertical-align:top;"></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font0">3</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">1 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">67</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">1</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">0.0</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">1</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">2.0</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">1</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">0</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">0</span></p></td><td style="vertical-align:top;"></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font0">5</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">1 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">56</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">0</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">0.0</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">0</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">2.0</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">2</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">1</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">0</span></p></td><td style="vertical-align:top;"></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font0">6</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">1 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">32</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">1</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">1.0</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">2</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">3.0</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">2</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">0</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">0</span></p></td><td style="vertical-align:top;"></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font0">8062</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">1 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">41</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">1</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">0.0</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">1</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">50</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">1</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">1</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">0</span></p></td><td style="vertical-align:top;"></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font0">8064</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">1 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">35</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">0</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">3.0</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">2</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">4.0</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">3</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">0</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">0</span></p></td><td style="vertical-align:top;"></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font0">8065</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">0 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">33</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">1</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">1.0</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">2</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">1.0</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">3</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">0</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">0</span></p></td><td style="vertical-align:top;"></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font0">8066</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">0 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">27</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">1</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">1.0</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">2</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">4.0</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">1</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">0</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">0</span></p></td><td style="vertical-align:top;"></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font0">8067</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">1 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">37</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">1</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">0.0</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">0</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">3.0</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">1</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">0</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">0</span></p></td><td style="vertical-align:top;"></td></tr>
<tr><td colspan="2" style="vertical-align:bottom;">
<p><span class="font0">6665 rows &quot;&nbsp;24 columns</span></p></td><td style="vertical-align:top;"></td><td style="vertical-align:top;"></td><td style="vertical-align:top;"></td><td style="vertical-align:top;"></td><td style="vertical-align:top;"></td><td style="vertical-align:top;"></td><td style="vertical-align:top;"></td><td style="vertical-align:top;"></td><td style="vertical-align:top;"></td></tr>
</table>
<p><span class="font2" style="font-weight:bold;">Gambar 8</span><span class="font2">. Hasil Preprocessing Data</span></p>
<p><span class="font2">Setelah melewati tahap preprocessing hingga klasifikasi, dilakukan evaluasi terhadap performa dari model yang telah dikembangkan. Dalam penelitian ini, digunakan confussion matrix dalam melakukan evaluasi terhadap performa dari model. Hasil evaluasi yang akan ditampilkan mencakup accuracy, precision, recall, dan f1-score pada basis per kelasnya. Hasil evaluasi ditampilkan dalam bentuk classification report yang yang mencakup accuracy, precision, recall, dan f1-score pada basis per kelasnya.</span></p>
<table border="1">
<tr><td style="vertical-align:top;">
<p><span class="font8">D</span></p></td><td style="vertical-align:top;">
<p><span class="font4">precision</span></p></td><td style="vertical-align:top;">
<p><span class="font6">recall</span></p></td><td style="vertical-align:top;">
<p><span class="font4">fl-score</span></p></td><td style="vertical-align:top;">
<p><span class="font4">support</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font4">A</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">θ.38</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0.41</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0.39</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">32θ</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font6">B</span></p></td><td style="vertical-align:top;">
<p><span class="font4">0.3θ</span></p></td><td style="vertical-align:top;">
<p><span class="font4">0.32</span></p></td><td style="vertical-align:top;">
<p><span class="font4">0.31</span></p></td><td style="vertical-align:top;">
<p><span class="font4">302</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font4">C</span></p></td><td style="vertical-align:top;">
<p><span class="font4">Θ.46</span></p></td><td style="vertical-align:top;">
<p><span class="font4">0.42</span></p></td><td style="vertical-align:top;">
<p><span class="font4">0.44</span></p></td><td style="vertical-align:top;">
<p><span class="font4">369</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font4">D</span></p></td><td style="vertical-align:top;">
<p><span class="font4">θ.58</span></p></td><td style="vertical-align:top;">
<p><span class="font4">0.56</span></p></td><td style="vertical-align:top;">
<p><span class="font4">0.57</span></p></td><td style="vertical-align:top;">
<p><span class="font4">342</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font4">accuracy</span></p></td><td style="vertical-align:top;"></td><td style="vertical-align:top;"></td><td style="vertical-align:bottom;">
<p><span class="font4">0.43</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">1333</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font4">macro avg</span></p></td><td style="vertical-align:top;">
<p><span class="font4">0.43</span></p></td><td style="vertical-align:top;">
<p><span class="font4">0.43</span></p></td><td style="vertical-align:top;">
<p><span class="font4">0.43</span></p></td><td style="vertical-align:top;">
<p><span class="font4">1333</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font4">weighted avg</span></p></td><td style="vertical-align:top;">
<p><span class="font4">Θ.44</span></p></td><td style="vertical-align:top;">
<p><span class="font4">0.43</span></p></td><td style="vertical-align:top;">
<p><span class="font4">0.43</span></p></td><td style="vertical-align:top;">
<p><span class="font4">1333</span></p></td></tr>
</table>
<table border="1">
<tr><td style="vertical-align:top;">
<p><span class="font4">[ [130</span></p></td><td style="vertical-align:top;">
<p><span class="font4">78</span></p></td><td style="vertical-align:top;">
<p><span class="font4">43</span></p></td><td style="vertical-align:top;">
<p><span class="font4">69]</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font4">[ 75</span></p></td><td style="vertical-align:top;">
<p><span class="font4">98</span></p></td><td style="vertical-align:top;">
<p><span class="font4">97</span></p></td><td style="vertical-align:top;">
<p><span class="font4">32]</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font4">[ 70</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">105</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">155</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">39]</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font4">[ 65</span></p></td><td style="vertical-align:top;">
<p><span class="font4">44</span></p></td><td style="vertical-align:top;">
<p><span class="font4">42</span></p></td><td style="vertical-align:top;">
<p><span class="font4">191]]</span></p></td></tr>
</table>
<p><span class="font2" style="font-weight:bold;">Gambar 7</span><span class="font2">. Classification Report</span></p>
<p><span class="font2">Berdasarkan output dari classification report didapatkan bahwa classification model mendapat akurasi 41% saat memprediksi segmen A, 32% saat memprediksi segmen B, 42% saat memprediksi segmen</span></p>
<p><span class="font2">C, dan 56% saat memprediksi segmen D. Secara keseluruhan, tingkat akurasi dari classification model menggunakan algoritma Decision Tree ketika digunakan untuk melakukan segementasi customer ke dalam 4 segmen hanya 43%.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark8"></a><span class="font2" style="font-weight:bold;"><a name="bookmark9"></a>4. &nbsp;&nbsp;Kesimpulan</span></h2></li></ul>
<p><span class="font2">Pada penelitian ini dilakukan klasifikasi menggunakan Algoritma Decision Tree terhadap suatu dataset dimana dataset tersebut terdiri data training dan data testing dimana masing-masing set data memiliki 11 atribut. Keluaran yang diharapkan dengan melakukan penelitian ini yaitu untuk mengetahui tingkat akurasi algoritma Decision Tree dalam mengklasifikasikan customer menjadi beberapa segmen. Setelah melalui tahap klasifikasi didapatkan bahwa secara keseluruhan tingkat akurasi dari classification model saat digunakan untuk mengklasifikasikan dataset ini hanya 43% dengan rincian akurasi 41% untuk segmentasi A, 32% untuk segmentasi B, 42% untuk segmentasi C, dan 56% untuk segmentasi D.</span></p>
<h2><a name="bookmark10"></a><span class="font2" style="font-weight:bold;"><a name="bookmark11"></a>Daftar Pustaka</span></h2>
<ul style="list-style:none;"><li>
<p><span class="font2">[1] &nbsp;&nbsp;&nbsp;TIRIS SUDRARTONO, “Pengaruh Segmentasi Pasar Terhadap Tingkat Penjualan Produk</span></p></li></ul>
<p><span class="font2">Fashion Umk,” </span><span class="font2" style="font-style:italic;">Coopetition J. Ilm. Manaj.</span><span class="font2">, vol. 10, no. 1, pp. 53–64, &nbsp;2019, doi:</span></p>
<p><span class="font2">10.32670/coopetition.v10i1.40.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font2">[2] &nbsp;&nbsp;&nbsp;A. Madani, A. Rahmah, F. Nurunnisa, and A. Elia, “SENTIMAS: Seminar Nasional Penelitian</span></p></li></ul>
<p><span class="font2">dan Pengabdian Masyarakat Customer Segmentation at BC HNI 2 Pekanbaru by Applying the K-Medoids Algorithm and Recency, Frequency, Monetary (RFM) Model Segmentasi Pelanggan pada BC HNI 2 Pekanbaru dengan Menerapkan Alg,” pp. 179–186, 2022, [Online]. Available: </span><a href="https://journal.irpi.or.id/index.php/sentimas"><span class="font2">https://journal.irpi.or.id/index.php/sentimas</span></a><span class="font2">.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font2">[3] &nbsp;&nbsp;&nbsp;I. Pratama, A. Y. Chandra, and P. T. Presetyaningrum, “Seleksi Fitur dan Penanganan</span></p></li></ul>
<p><span class="font2">Imbalanced Data menggunakan RFECV dan ADASYN,” </span><span class="font2" style="font-style:italic;">J. Eksplora Inform.</span><span class="font2">, vol. 11, no. 1, pp. 38–49, 2022, doi: 10.30864/eksplora.v11i1.578.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font2">[4] &nbsp;&nbsp;&nbsp;Generosa Lukhayu Pritalia, “Analisis Komparatif Algoritme Machine Learning dan Penanganan</span></p></li></ul>
<p><span class="font2">Imbalanced Data pada Klasifikasi Kualitas Air Layak Minum,” </span><span class="font2" style="font-style:italic;">KONSTELASI Konvergensi Teknol. dan Sist. Inf.</span><span class="font2">, vol. 2, no. 1, pp. 43–55, 2022, doi: 10.24002/konstelasi.v2i1.5630.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font2">[5] &nbsp;&nbsp;&nbsp;A. Rahmawati, I. Yulianti, Y. Yuliani, N. Nurhadianto, and H. B. Novitasari, “Analisis Algoritma</span></p></li></ul>
<p><span class="font2">KNN Berbasis Feature Selection untuk Memprediksi Nasabah Pengguna Deposito Melalui Pemasaran Langsung,” &nbsp;&nbsp;</span><span class="font2" style="font-style:italic;">Swabumi</span><span class="font2">, &nbsp;&nbsp;vol. 8, no. 1, pp. 29–36, &nbsp;&nbsp;2020, doi:</span></p>
<p><span class="font2">10.31294/swabumi.v8i1.7581.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font2">[6] &nbsp;&nbsp;&nbsp;&nbsp;R. Vincentius, M. Mirella, A. Anasthasya, S. Lauren, and Budiarjo, “Prediksi Rating Film Pada</span></p></li></ul>
<p><span class="font2">Website ImdbMenggunakan Metode Neural NetworkFilm Rating Prediction on Imdb Website Using Neural Network,” vol. 7, no. 1, 2022.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font2">[7] &nbsp;&nbsp;&nbsp;D. Sartika and D. I. Sensuse, “Perbandingan Algoritma Klasifikasi Naive Bayes, Nearest</span></p></li></ul>
<p><span class="font2">Neighbour, dan Decision Tree pada Studi Kasus Pengambilan Keputusan Pemilihan Pola Pakaian,” </span><span class="font2" style="font-style:italic;">J. Tek. Inform. Dan Sist. Inf.</span><span class="font2">, vol. 1, no. 2, pp. 151–161, 2017, [Online]. Available: </span><a href="https://doi.org/10.35957/jatisi.v3i2.78"><span class="font2">https://doi.org/10.35957/jatisi.v3i2.78</span></a><span class="font2">.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font2">[8] &nbsp;&nbsp;&nbsp;M. A. Hasanah, S. Soim, and A. S. Handayani, “Implementasi CRISP-DM Model Menggunakan</span></p></li></ul>
<p><span class="font2">Metode Decision Tree dengan Algoritma CART untuk Prediksi Curah Hujan Berpotensi Banjir,” </span><span class="font2" style="font-style:italic;">J. Appl. Informatics Comput.</span><span class="font2">, vol. 5, no. 2, pp. 103–108, 2021, doi: 10.30871/jaic.v5i2.3200.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font2">[9] &nbsp;&nbsp;&nbsp;Laila Qadrini, Andi Seppewali, and Asra Aina, “Decision Treedan Adaboost Pada Klasifikasi</span></p></li></ul>
<p><span class="font2">Penerima Program Bantuan Sosial,” </span><span class="font2" style="font-style:italic;">J. Inov. Penelit.</span><span class="font2">, vol. 2, no. 7, pp. 1959–1965, 2021.</span></p>
<p><span class="font2">322</span></p>