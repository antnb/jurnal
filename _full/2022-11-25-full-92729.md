---
layout: full_article
title: "Penerapan Long Short Term Memory dalam Mengklasifikasi Jenis Ujaran Kebencian pada Tweet Bahasa Indonesia"
author: "Ni Putu Sintia Wati, Cokorda Rai Adi Pramartha"
categories: jnatia
canonical_url: https://jurnal.harianregional.com/jnatia/full-92729 
citation_abstract_html_url: "https://jurnal.harianregional.com/jnatia/id-92729"
citation_pdf_url: "https://jurnal.harianregional.com/jnatia/full-92729"  
comments: true
---

<p><span class="font4">JNATIA Volume 1, Nomor 1, November 2022</span></p>
<p><span class="font4">Jurnal Nasional Teknologi Informasi dan Aplikasinya</span></p><a name="caption1"></a>
<h1><a name="bookmark0"></a><span class="font5" style="font-weight:bold;"><a name="bookmark1"></a>Penerapan </span><span class="font5" style="font-weight:bold;font-style:italic;">Long Short Term Memory</span><span class="font5" style="font-weight:bold;"> dalam Mengklasifikasi Jenis Ujaran Kebencian pada </span><span class="font5" style="font-weight:bold;font-style:italic;">Tweet </span><span class="font5" style="font-weight:bold;">Bahasa Indonesia</span></h1>
<p><span class="font4">Ni Putu Sintia Wati<sup>a1</sup></span><span class="font4" style="font-weight:bold;">, </span><span class="font4">Cokorda Pramartha<sup>b2</sup></span></p>
<p><span class="font4"><sup>a</sup>Program Studi Informatika, Fakultas Matematika dan Ilmu Pengetahuan Alam, Universitas Udayana</span></p>
<p><span class="font4"><sup>b</sup>Net-Centric Computing Laboratory, Universitas Udayana</span></p>
<p><span class="font4">Badung, Bali, Indonesia </span><a href="mailto:1putu.sintia.wati@student.unud.ac.id"><span class="font4"><sup>1</sup>putu.sintia.wati@student.unud.ac.id</span></a><span class="font4"> </span><a href="mailto:2cokorda@unud.ac.id"><span class="font4"><sup>2</sup>cokorda@unud.ac.id</span></a></p>
<p><span class="font4" style="font-weight:bold;font-style:italic;">Abstract</span></p>
<p><span class="font4" style="font-style:italic;">Tweets are messages posted to Twitter and contain photos, videos, links, and text. Twitter is a social media service that allows everyone to communicate and stay connected through the rapid and frequent exchange of messages. However, as many communities have sprung up, user is getting less control while communicating on Twitter. One of them, more and more hate speech is being hurled either through retweets, or replies to each other in one of the threads belonging to a particular community. To minimize this impact, a classification is needed to find out whether the tweet contains hate speech or not before being uploaded to Twitter. Due to the rapid increase in the current data usage, it is necessary to review it with other methods to classify the data more deeply. Based on these problems, the method that can be used is Long Short Term Memory (LSTM). This study succeeded in providing predictions with different hyperparameter accuracy values for the LSTM application reaching 74%.</span></p>
<p><span class="font4" style="font-weight:bold;font-style:italic;">Keywords: </span><span class="font4" style="font-style:italic;">classification, LSTM, Tweet, hate speech</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark2"></a><span class="font4" style="font-weight:bold;"><a name="bookmark3"></a>1. &nbsp;&nbsp;&nbsp;Pendahuluan</span></h2></li></ul>
<p><span class="font4" style="font-style:italic;">Tweet</span><span class="font4"> atau cuitan merupakan pesan yang diposting ke Twitter dan berisi foto, video, tautan, serta teks. Sedangkan twitter merupakan layanan media sosial yang memungkinkan setiap orang untuk berkomunikasi dan tetap terhubung melalui pertukaran pesan yang cepat dan sering. Pengguna dapat memposting pesan ke profil mereka serta dapat dicari pada kolom pencarian. Dilansir oleh Varitey, selama tiga bulan terakhir tahun 2021, rata-rata pengguna aktif harian (</span><span class="font4" style="font-style:italic;">mean Daily Active User</span><span class="font4">) di seluruh dunia mencapai 217 juta atau naik 6 juta secara berurutan dari tahun ke tahun[1].</span></p>
<p><span class="font4">Namun, seiring banyaknya komunitas yang bermunculan membuat pengguna semakin tidak terkendali selama berkomunikasi di twitter. Salah satu diantaranya, semakin banyak ujaran kebencian yang dilontarkan baik itu melalui retweet, atau saling balas (</span><span class="font4" style="font-style:italic;">reply</span><span class="font4">) di salah satu utas milik komunitas tertentu. Ujaran Kebencian adalah tindakan komunikasi yang dilakukan oleh suatu individu atau kelompok dalam bentuk provokasi, hasutan, ataupun hinaan terhadap individu atau kelompok lain dalam hal berbagai aspek seperti ras, warna kulit, gender, cacat, orientasi seksual, kewarganegaraan, agama dan lain-lain[2]. Dalam penyampaiannya, ujaran kebencian juga sering disertai dengan menggunakan bahasa kasar.</span></p>
<p><span class="font4">Untuk meminimalisir dampak tersebut, diperlukan klasifikasi untuk mengetahui apakah tweet tersebut mengandung ujaran kebencian atau tidak, sebelum diunggah dalam twitter. Dikarenakan pesatnya peningkatan data saat ini, maka perlu ditinjau kembali dengan metode lain agar dapat mengklasifikasi data lebih dalam. Berdasarkan masalah tersebut, metode yang dapat digunakan</span></p>
<p><span class="font4">Jurnal Nasional Teknologi Informasi dan Aplikasinya</span></p>
<p><span class="font4">yaitu Long Short Term Memory (LSTM). LSTM adalah salah satu jenis </span><span class="font4" style="font-style:italic;">Recurrent Neural Network </span><span class="font4">(RNN) yang merupakan modifikasi dari RNN, dengan menambahkan </span><span class="font4" style="font-style:italic;">memory cell</span><span class="font4"> agar dapat menyimpan informasi dalam jangka waktu yang lama. LSTM dapat meminimalisir terjadinya </span><span class="font4" style="font-style:italic;">vanishing gradient,</span><span class="font4"> dimana kondisi nilai gradien pada input layer lebih kecil dari output layer.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark4"></a><span class="font4" style="font-weight:bold;"><a name="bookmark5"></a>2. &nbsp;&nbsp;&nbsp;Metode Penelitian</span><br><br><span class="font4" style="font-weight:bold;"><a name="bookmark6"></a>1. &nbsp;2.1. Pengumpulan Data</span></h2></li></ul>
<p><span class="font4">Data yang digunakan dalam penelitian ini adalah data sekunder. Data sekunder merupakan data yang telah tersedia sebelum peneliti melakukan penelitian. Data yang akan digunakan bersumber dari Github yaitu multi-label hate speech and abusive language detection [3]. Data ini memiliki 13169 baris dengan 13 atribut dengan nilai 0 untuk nilai ‘tidak’ dan 1 untuk nilai ‘ya’. Selain itu, terdapat data yang memuat kata-kata penulisannya kurang tepat. Dokumen ini memiliki 15167 baris kata yang akan dinormalisasi serta data yang memuat kata-kata yang memuat </span><span class="font4" style="font-style:italic;">stopwords </span><span class="font4">dalam bahasa indonesia.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font4" style="font-weight:bold;font-style:italic;">2.</span><span class="font4" style="font-weight:bold;"> &nbsp;2.2. </span><span class="font4" style="font-weight:bold;font-style:italic;">Preprocessing</span></p></li></ul>
<p><span class="font4">Setelah melakukan pengumpulan data, tahap selanjutnya yaitu preprocessing data. Tahapan ini dilakukan untuk mempersiapkan data teks agar dapat diproses di tahap selanjutnya. Preprocessing data meliputi beberapa tahapan berikut :</span></p>
<ul style="list-style:none;"><li>
<p><span class="font4" style="font-style:italic;">a. &nbsp;&nbsp;&nbsp;Remove Null Value</span></p></li></ul>
<p><span class="font4">Memeriksa dan menghapus nilai null dengan dengan tujuan untuk meminimalisir error pada saat pelatihan dan pengujian model.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font4" style="font-style:italic;">b. &nbsp;&nbsp;&nbsp;Remove Characters</span></p></li></ul>
<p><span class="font4">Menghapus karakter khusus seperti karakter emoji serta kata kunci yang tidak digunakan seperti ‘RT’ untuk Retweet, ‘’USER” untuk username, “URL” untuk link.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font4" style="font-style:italic;">c. &nbsp;&nbsp;&nbsp;Case Folding</span></p></li></ul>
<p><span class="font4">Mengubah seluruh huruf-huruf pada satu data menjadi huruf kecil (lowercase) </span><span class="font4" style="font-style:italic;">d. Remove Punctuation</span></p>
<p><span class="font4">Menghapus simbol-simbol yang tidak dipergunakan pada data teks.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font4" style="font-style:italic;">e. &nbsp;&nbsp;&nbsp;Text Normalization</span></p></li></ul>
<p><span class="font4">Mengubah beberapa kosa kata gaul atau kata-kata yang penulisannya kurang tepat ke dalam kata baku.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font4" style="font-style:italic;">f. &nbsp;Stopword removal</span></p></li></ul>
<p><span class="font4">Menghapus kata-kata yang tidak dipergunakan.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font4" style="font-style:italic;">g. &nbsp;Tokenization</span></p></li></ul>
<p><span class="font4">Memecah kata-kata menjadi bagian-bagian yang lebih kecil</span></p>
<ul style="list-style:none;"><li>
<p><span class="font4" style="font-weight:bold;font-style:italic;">3.</span><span class="font4" style="font-weight:bold;"> 2.3. </span><span class="font4" style="font-weight:bold;font-style:italic;">Word Embedding</span></p></li></ul>
<p><span class="font4">Word Embedding merupakan proses konversi kata yang telah di </span><span class="font4" style="font-style:italic;">preprocessing </span><span class="font4">sebelumnya ke dalam bentuk vektor. Setiap kata pada vektor yang merepresentasikan sebuah titik pada ruang dengan dimensi tertentu. Pada pustaka Keras terdapat lapisan </span><span class="font4" style="font-style:italic;">Embedding</span><span class="font4"> yang digunakan dalam </span><span class="font4" style="font-style:italic;">Neural Network</span><span class="font4"> pada data teks. lapisan </span><span class="font4" style="font-style:italic;">Embedding</span><span class="font4"> didefinisikan sebagai layer yang tersembunyi dari jaringan. Terdapat 3 argumen yang digunakan, diantaranya : a. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;input_dim : ukuran kata pada dokumen teks,</span></p>
<ul style="list-style:none;"><li>
<p><span class="font4">b. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;output_dim : ukuran vektor dimana kata-kata tersebut disimpan, dan</span></p></li>
<li>
<p><span class="font4">c. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;input_length : panjang ukuran input.</span></p></li></ul>
<ul style="list-style:none;"><li>
<h2><a name="bookmark7"></a><span class="font4" style="font-weight:bold;"><a name="bookmark8"></a>4. 2.4. Long Short-Term Memory (LSTM)</span></h2></li></ul>
<p><span class="font4" style="font-style:italic;">Long Short Term Memory</span><span class="font4"> merupakan pengembangan dari metode RNN melalui penambahan sel (cell) LSTM di dalam arsitektur RNN. LSTM telah berhasil menyelesaikan berbagai permasalahan, seperti </span><span class="font4" style="font-style:italic;">handwriting recognition, speech recognition, handwriting generation,</span><span class="font4"> dan </span><span class="font4" style="font-style:italic;">image captioning[4].</span><span class="font4"> LSTM memungkinkan arsitektur machine learning menyimpan bobot (</span><span class="font4" style="font-style:italic;">weight</span><span class="font4">) dari suatu perhitungan lebih lama dari RNN. Hal ini disebabkan karena LSTM memiliki</span></p>
<p><span class="font4">Jurnal Nasional Teknologi Informasi dan Aplikasinya</span></p>
<p><span class="font4">sebuah node yang </span><span class="font4" style="font-style:italic;">self-recurrent</span><span class="font4">. LSTM dapat bekerja lebih baik daripada RNN pada data dengan sekuens yang lebih panjang.</span></p>
<p><span class="font4">Pada bagian bawah arsitektur LSTM, terdapat </span><span class="font4" style="font-style:italic;">cell gates</span><span class="font4"> yang berfungsi untuk meregulasi informasi yang akan dikeluarkan ke </span><span class="font4" style="font-style:italic;">cell state</span><span class="font4">. </span><span class="font4" style="font-style:italic;">Cell state</span><span class="font4"> adalah jalur pada bagian atas untuk mengirimkan informasi ke unit selanjutnya[4].</span></p>
<p><span class="font4">Pada </span><span class="font4" style="font-style:italic;">forget gate</span><span class="font4">, informasi yang tidak dibutuhkan akan diolah dan dihilangkan menggunakan fungsi sigmoid. Persamaan pada forget gate adalah sebagai berikut [4].</span></p>
<p><span class="font10" style="font-style:italic;">ft = σ(Wf[h<sub>t</sub></span><span class="font9" style="font-style:italic;">-ι</span><span class="font10" style="font-style:italic;">.x<sub>t</sub>]</span><span class="font10"> + </span><span class="font10" style="font-style:italic;">b<sub>f</sub>)</span><span class="font4"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1)</span></p>
<p><span class="font4">Pada input gate, informasi akan dipilah dan ditentukan sebelum dibawa ke bagian cell state dengan mengunakan fungsi aktivasi sigmoid. Proses ini dapat dihitung dengan persamaan 2. Selain itu, akan ditentukan kandidat vektor baru menggunakan fungsi aktivasi tanh yang akan dibawa ke bagian cell state dengan menggunakan persamaan 3 [4].</span></p>
<p><a href="#bookmark9"><span class="font10" style="font-style:italic;">i</span><span class="font9" style="font-style:italic;">t </span><span class="font10" style="font-style:italic;">= σ(W<sub>f</sub> [h<sub>t</sub></span><span class="font9" style="font-style:italic;">-ι</span><span class="font10" style="font-style:italic;">,x<sub>t</sub>]</span><span class="font10"> + </span><span class="font10" style="font-style:italic;">b<sub>i</sub>)</span><span class="font14">(2)</span></a></p>
<p><a href="#bookmark10"><span class="font10" style="font-style:italic;">~c<sub>t</sub> =tanh tanh </span><span class="font10" style="font-style:italic;font-variant:small-caps;">(W<sub>c</sub></span><span class="font10" style="font-style:italic;"> [h<sub>t-1</sub></span><span class="font3">.</span><span class="font10">X</span><span class="font3">t</span><span class="font10">] + </span><span class="font10" style="font-style:italic;">b<sub>c</sub> )</span><span class="font14">(3)</span></a></p>
<p><span class="font4">Nilai pada </span><span class="font4" style="font-style:italic;">cell state</span><span class="font4"> lama </span><span class="font4" style="font-style:italic;">□</span><span class="font2" style="font-style:italic;">□</span><span class="font11" style="font-weight:bold;"> <sub>-</sub></span><span class="font4" style="font-style:italic;"><sub>1</sub></span><span class="font4"> akan diperbarui ke nilai </span><span class="font4" style="font-style:italic;">cell state</span><span class="font4"> baru </span><span class="font4" style="font-style:italic;">□</span><span class="font2" style="font-style:italic;">□</span><span class="font4"> melalui persamaan 4 [4].</span></p>
<p><a href="#bookmark11"><span class="font10" style="font-style:italic;">c<sub>t</sub>= f</span><span class="font9" style="font-style:italic;">t</span><span class="font10" style="font-style:italic;">* c<sub>t</sub></span><span class="font9" style="font-style:italic;">-ι</span><span class="font10" style="font-style:italic;">+ i<sub>t</sub>*-c<sub>t</sub></span><span class="font14">(4)</span></a></p>
<p><span class="font4">Pada proses ini, fungsi sigmoid dijalankan untuk menghasilkan nilai output pada </span><span class="font4" style="font-style:italic;">hidden state</span><span class="font4"> dan menempatkan </span><span class="font4" style="font-style:italic;">cell state</span><span class="font4"> pada tanh. Selanjutnya, nilai </span><span class="font4" style="font-style:italic;">output sigmoi</span><span class="font4">d dan nilai </span><span class="font4" style="font-style:italic;">output tanh </span><span class="font4">dilakukan perkalian sebelum diproses menuju tahap selanjutnya. Perhitugan </span><span class="font4" style="font-style:italic;">output</span><span class="font4"> dilakukan pada persamaan 5 dan 6 [4].</span></p>
<p><span class="font6" style="font-style:italic;">O</span><span class="font8" style="font-style:italic;">t </span><span class="font6" style="font-style:italic;">= σ(W<sub>0</sub> * <sup>[</sup></span><span class="font10" style="font-style:italic;">h</span><span class="font9" style="font-style:italic;">t—i</span><span class="font10" style="font-style:italic;">,X</span><span class="font9" style="font-style:italic;">t</span><span class="font6" style="font-style:italic;"><sup>]</sup> + b<sub>o</sub>)</span><span class="font14"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(5)</span></p>
<p><span class="font6" style="font-style:italic;">h<sub>t</sub> = </span><span class="font10" style="font-style:italic;font-variant:small-caps;">o</span><span class="font7" style="font-style:italic;font-variant:small-caps;"><sub>c</sub></span><span class="font6" style="font-style:italic;"> * tαnh(c<sub>t</sub>)</span><span class="font14"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(6)</span></p>
<p><span class="font4">Pada arsitektur LSTM terdapat fungsi aktivasi, yaitu </span><span class="font4" style="font-style:italic;">Sigmoid</span><span class="font4"> dan </span><span class="font4" style="font-style:italic;">Tanh</span><span class="font4">. Fungsi </span><span class="font4" style="font-style:italic;">sigmoid </span><span class="font4">digunakan untuk mentransformasikan nilai antara -1 dan 1 menjadi 0 dan 1. Sedangkan fungsi </span><span class="font4" style="font-style:italic;">tanh</span><span class="font4"> digunakan untuk mengatur nilai yang melalui jaringan selalu berada dekat antara -1 dan 1 [4].</span></p>
<p><span class="font4">Seperti pada Gambar 1, pembuatan model LSTM pada penelitian ini mengimplementasikan sequence model yang terdiri dari tujuh layer yang diantaranya menerapkan </span><span class="font4" style="font-style:italic;">Embedding layer, LSTM layer, Dropout layer,</span><span class="font4"> serta </span><span class="font4" style="font-style:italic;">Dense layer.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font4" style="font-weight:bold;">Gambar 1. </span><span class="font4">Diagram Alir Proses Pelatihan dengan Model LSTM</span></p></li></ul>
<p><span class="font4">Jurnal Nasional Teknologi Informasi dan Aplikasinya</span></p><img src="https://jurnal.harianregional.com/media/92729-1.jpg" alt="" style="width:300pt;height:143pt;">
<p><span class="font4">Lapisan Embedding merupakan tahapan mengubah kata ke dalam bentuk vektor. Pendekatan yang digunakan untuk merepresentasikan vektor kata dan array pada bilangan rill. Hasil pada proses word embedding ini akan disimpan pada ruang embedding yang mana kata-kata yang terdapat pada satu ruang tersebut memiliki kesamaan semantik. Peneliti menggunakan library keras untuk proses ini. Cara kerja proses ini adalah sebagai berikut.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font4">a. &nbsp;&nbsp;&nbsp;Dokumen teks yang telah dilakukan preprocessing akan diberikan indeks pada masing-masing data.</span></p></li>
<li>
<p><span class="font4">b. &nbsp;&nbsp;&nbsp;Parameter input_length digunakan untuk mengatur panjang ukuran vektor.</span></p></li></ul>
<p><span class="font4">Pada LSTM layer terdapat parameter memory unit, input shape yang didapat dari hasil word embedding, dan dropout. Nilai dari memory unti dan dropout ditentukan secara eksplisit dengan rentang angka yang sesuai dengan data yang digunakan. Sedangkan parameter dropout digunakan untuk mencegah terjadinya overfitting/underfitting. Nilai yang digunakan berkisar diantara 0 hingga 1. Dense layer digunakan untuk menambahkan layer </span><span class="font4" style="font-style:italic;">fully-connected </span><span class="font4">berdasarkan jumlah class yang ditentukan.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark12"></a><span class="font4" style="font-weight:bold;"><a name="bookmark13"></a>3. Hasil dan Pembahasan</span><br><br><span class="font4" style="font-weight:bold;"><a name="bookmark14"></a>5. &nbsp;&nbsp;&nbsp;&nbsp;3.1. Data Understanding</span></h2></li></ul>
<p><span class="font4">Data yang digunakan dalam penelitian diperoleh melalui github, yaitu </span><span class="font4" style="font-style:italic;">multi-label hate speech and abusive language detection</span><span class="font4"> [3] dan kaggle yaitu </span><span class="font4" style="font-style:italic;">Indonesian Stoplist</span><span class="font4">. Dataset tersebut memiliki 13169 data dengan 13 label. Hasil pada tahap pengumpulan data ditampilkan pada Gambar 2.</span></p>
<p><span class="font4" style="font-weight:bold;">Gambar 2. </span><span class="font4">Hasil Pengumpulan Data</span></p><img src="https://jurnal.harianregional.com/media/92729-2.jpg" alt="" style="width:423pt;height:145pt;">
<p><span class="font1" style="font-weight:bold;">RT JSEfr Mffi Mape png Idai</span></p>
<p><span class="font11" style="font-weight:bold;">IWM</span></p>
<p><span class="font0" style="font-weight:bold;">USER USER AJtU (TU AKUVtVMU TAUtMTAMU SRTT</span></p>
<p><span class="font4">Jurnal Nasional Teknologi Informasi dan Aplikasinya</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark15"></a><span class="font4" style="font-weight:bold;"><a name="bookmark16"></a>6. &nbsp;&nbsp;&nbsp;&nbsp;3.2. Data Preprocessing and Preparation</span></h2></li></ul>
<p><span class="font4">Data diatas selanjutnya akan dilakukan preprocessing data untuk meminimalisir terjadinya bias pada proses selanjutnya. rincian pembagian data ditunjukkan pada Tabel 1:</span></p>
<p><span class="font4" style="font-weight:bold;">Table 1. </span><span class="font4">Hasil Preprocessing</span></p>
<table border="1">
<tr><td style="vertical-align:top;">
<p><span class="font4" style="font-weight:bold;">Process No.</span></p></td><td style="vertical-align:top;">
<p><span class="font4" style="font-weight:bold;">Process Title</span></p></td><td style="vertical-align:top;">
<p><span class="font4" style="font-weight:bold;">Result</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font4" style="font-weight:bold;">1</span></p></td><td style="vertical-align:top;">
<p><span class="font4" style="font-weight:bold;">Data Awal</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">USER USER USER USER BANCI KALENG MALU GA BISA JAWAB PERTANYAAN KAMI DARI 2 HARI LALU.... NYUNGSEP KOE USER URL</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font4" style="font-weight:bold;">2</span></p></td><td style="vertical-align:top;">
<p><span class="font4" style="font-weight:bold;font-style:italic;">remove character</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">BANCI KALENG MALU GA BISA JAWAB</span></p>
<p><span class="font4">PERTANYAAN KAMI DARI 2 HARI LALU.... NYUNGSEP KOE</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font4" style="font-weight:bold;">3</span></p></td><td style="vertical-align:top;">
<p><span class="font4" style="font-weight:bold;font-style:italic;">Case Folding</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">banci kaleng malu ga bisa jawab pertanyaan kami dari dua hari lalu…. nyungsep koe</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font4" style="font-weight:bold;">4</span></p></td><td style="vertical-align:middle;">
<p><span class="font4" style="font-weight:bold;font-style:italic;">remove punctuation</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">banci kaleng malu ga bisa jawab pertanyaan kami dari dua hari lalu nyungsep koe</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font4" style="font-weight:bold;">5</span></p></td><td style="vertical-align:middle;">
<p><span class="font4" style="font-weight:bold;font-style:italic;">text normalization</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">banci kaleng malu tidak bisa jawab pertanyaan kami dari dua hari lalu nyungsep kau</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font4" style="font-weight:bold;">6</span></p></td><td style="vertical-align:top;">
<p><span class="font4" style="font-weight:bold;font-style:italic;">Tokenization</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">['banci', 'kaleng', 'malu', 'tidak', 'bisa', 'pertanyaan', 'kami', 'dari', 'dua', ‘hari’, ‘lalu’,’nyungsep’,’kau’]</span></p></td></tr>
</table>
<p><span class="font4">Pada Tahapan tokenizer, kamus data atau num_word ditentukan sebanyak 1000. Tahap Selanjutnya yaitu membagi data menjadi 80% data latih dan 20% data uji. Rincian pembagian data dapat dilihat pada tabel 2</span></p>
<p><span class="font4" style="font-weight:bold;">Kelompok Data</span></p>
<div>
<p><span class="font4" style="font-weight:bold;">Jumlah</span></p>
</div><br clear="all">
<div>
<p><span class="font4" style="font-weight:bold;">1</span></p>
</div><br clear="all">
<div>
<p><span class="font4" style="font-weight:bold;">Data Latih</span></p>
</div><br clear="all">
<div>
<p><span class="font4">10.535</span></p>
</div><br clear="all">
<p><span class="font4">Jurnal Nasional Teknologi Informasi dan Aplikasinya</span></p>
<p><span class="font4" style="font-weight:bold;">2 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Data Uji</span></p>
<div>
<p><span class="font4">2.634</span></p>
</div><br clear="all">
<div>
<p><span class="font4" style="font-weight:bold;">jumlah</span></p>
</div><br clear="all">
<p><span class="font4">13169</span></p>
<p><span class="font4">Karena penulis akan melakukan klasifikasi berdasarkan jenis hate speech, maka fitur yang digunakan yaitu </span><span class="font4" style="font-style:italic;">tweet</span><span class="font4">, </span><span class="font4" style="font-style:italic;">hs_religion, hs_race, hs_physical, hs_gender, hs_other</span><span class="font4">. Selain dari fitur ini dapat dihapus.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark17"></a><span class="font4" style="font-weight:bold;"><a name="bookmark18"></a>3.3 &nbsp;&nbsp;&nbsp;Pemodelan menggunakan LSTM</span></h2></li></ul>
<p><span class="font4">Pemodelan diawali dengan menambahkan lapisan Embedding untuk mengubah kata dalam bentuk vektor dengan input_length sama dengan jumlah num_word. Setelah melalui tahapan embedding, kemudian dilanjutkan ke tahapan pemodelan dengan menerapkan parameterparameter berikut pada masing-masing lapisan.</span></p>
<table border="1">
<tr><td style="vertical-align:top;">
<p><span class="font4" style="font-weight:bold;">Layer</span></p></td><td style="vertical-align:top;">
<p><span class="font4" style="font-weight:bold;">jumlah neuron</span></p></td><td style="vertical-align:top;">
<p><span class="font4" style="font-weight:bold;">addition</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font4" style="font-weight:bold;">embedding</span></p></td><td style="vertical-align:top;"></td><td style="vertical-align:middle;">
<p><span class="font4">input_dim=1000, output_dim=32</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font4" style="font-weight:bold;">LSTM</span></p></td><td style="vertical-align:middle;">
<p><span class="font4" style="font-weight:bold;">64</span></p></td><td style="vertical-align:top;"></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font4" style="font-weight:bold;">LSTM</span></p></td><td style="vertical-align:middle;">
<p><span class="font4" style="font-weight:bold;font-style:italic;">64</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">return_sequences=True</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font4" style="font-weight:bold;">Dense</span></p></td><td style="vertical-align:middle;">
<p><span class="font4" style="font-weight:bold;font-style:italic;">16</span></p></td><td style="vertical-align:top;"></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font4" style="font-weight:bold;">Dropout</span></p></td><td style="vertical-align:middle;">
<p><span class="font4" style="font-weight:bold;font-style:italic;">0.2</span></p></td><td style="vertical-align:top;"></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font4" style="font-weight:bold;">Dense</span></p></td><td style="vertical-align:middle;">
<p><span class="font4" style="font-weight:bold;font-style:italic;">6</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">activation=softmax</span></p></td></tr>
</table>
<ul style="list-style:none;"><li>
<h2><a name="bookmark19"></a><span class="font4" style="font-weight:bold;"><a name="bookmark20"></a>3.4 &nbsp;&nbsp;&nbsp;Evaluasi Model</span></h2></li></ul>
<p><span class="font4">Berikut hasil evaluasi pengujian model pada evaluasi LSTM dengan menggunakan adam optimizer (Gambar 3).</span></p>
<ul style="list-style:none;"><li>
<p><span class="font4" style="font-weight:bold;">Gambar 3. </span><span class="font4">Hasil Evaluasi</span></p></li></ul>
<p><span class="font4">Jurnal Nasional Teknologi Informasi dan Aplikasinya</span></p>
<table border="1">
<tr><td style="vertical-align:top;"></td><td style="vertical-align:top;">
<p><span class="font3">precision</span></p></td><td style="vertical-align:top;">
<p><span class="font3">recall</span></p></td><td style="vertical-align:top;">
<p><span class="font3">fl-score</span></p></td><td style="vertical-align:top;">
<p><span class="font3">support</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font3">0</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3">9.6θ</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3">0.54</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3">0.57</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3">167</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font12" style="font-weight:bold;">1</span></p></td><td style="vertical-align:bottom;">
<p><span class="font12" style="font-weight:bold;">0.67</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3">0.60</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3">0.64</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3">91</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font3">2</span></p></td><td style="vertical-align:top;">
<p><span class="font12" style="font-weight:bold;">0.00</span></p></td><td style="vertical-align:top;">
<p><span class="font3">0.00</span></p></td><td style="vertical-align:top;">
<p><span class="font3">0.00</span></p></td><td style="vertical-align:top;">
<p><span class="font3">60</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font3">3</span></p></td><td style="vertical-align:bottom;">
<p><span class="font12" style="font-weight:bold;">0.60</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3">0.06</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3">0.11</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3">50</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font12" style="font-weight:bold;">4</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3">0.73</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3">0.68</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3">0.70</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3">727</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font3">5</span></p></td><td style="vertical-align:top;">
<p><span class="font3">0.8θ</span></p></td><td style="vertical-align:top;">
<p><span class="font3">0.89</span></p></td><td style="vertical-align:top;">
<p><span class="font3">0.84</span></p></td><td style="vertical-align:top;">
<p><span class="font3">1539</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font3">accuracy</span></p></td><td style="vertical-align:top;"></td><td style="vertical-align:top;"></td><td style="vertical-align:bottom;">
<p><span class="font3">0.77</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3">2634</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font3">macro avg</span></p></td><td style="vertical-align:top;">
<p><span class="font3">0.57</span></p></td><td style="vertical-align:top;">
<p><span class="font3">0.46</span></p></td><td style="vertical-align:top;">
<p><span class="font3">0.48</span></p></td><td style="vertical-align:top;">
<p><span class="font3">2634</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font3">weighted avg</span></p></td><td style="vertical-align:top;">
<p><span class="font3">0.74</span></p></td><td style="vertical-align:top;">
<p><span class="font3">0.77</span></p></td><td style="vertical-align:top;">
<p><span class="font3">0.75</span></p></td><td style="vertical-align:top;">
<p><span class="font3">2634</span></p></td></tr>
</table>
<h2><a name="bookmark21"></a><span class="font4" style="font-weight:bold;"><a name="bookmark22"></a>7.</span><br><br><span class="font4" style="font-weight:bold;"><a name="bookmark23"></a>4. &nbsp;&nbsp;&nbsp;Kesimpulan</span></h2>
<p><span class="font4">Berdasarkan hasil penelitian, nilai presisi yang didapat sebesar 74%, recall 77% dan f1-score sebesar 75%. Nilai tersebut dapat berubah jika dilakukan hyperparameter tuning untuk meningkatkan hasil akurasi.</span></p>
<h2><a name="bookmark24"></a><span class="font4" style="font-weight:bold;"><a name="bookmark25"></a>References</span></h2>
<ul style="list-style:none;"><li>
<p><span class="font4">[1] &nbsp;&nbsp;&nbsp;T. Spangler, &quot;Variety,&quot; 2 February 2022. [Online]. Available:</span></p></li></ul>
<p><a href="https://variety.com/2022/digital/news/twitter-q4-2021-earnings-users-growth-1235176882/"><span class="font4">https://variety.com/2022/digital/news/twitter-q4-2021-earnings-users-growth-1235176882/</span></a><span class="font4">.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font4">[2] &nbsp;&nbsp;&nbsp;D. K. Teologi, “Studia Sosial Religia,” vol. 3, no. 1, pp. 70–82, 2020, [Online]. Available: </span><a href="http://jurnal.uinsu.ac.id/index.php/ssr"><span class="font4">http://jurnal.uinsu.ac.id/index.php/ssr</span></a></p></li>
<li>
<p><span class="font4">[3] &nbsp;&nbsp;&nbsp;M. O. Ibrohim and I. Budi, “Multi-label Hate Speech and Abusive Language Detection in Indonesian Twitter,” pp. 46–57, 2019, doi: 10.18653/v1/w19-3506.</span></p></li>
<li>
<p><span class="font4">[4] &nbsp;&nbsp;&nbsp;J. Brownlee, “How to Prepare Text Data for Machine Learning with Scikit-Learn,” 2019. [Online]. Available: </span><a href="https://machinelearningmastery.com/prepare-text-data-machine-learning-scikit-learn/"><span class="font4">https://machinelearningmastery.com/prepare-text-data-machine-learning-scikit-learn/</span></a><span class="font4">.</span></p>
<div>
<p><span class="font4">Jurnal Nasional Teknologi Informasi dan Aplikasinya</span></p>
</div><br clear="all">
<div>
<p><span class="font4">Halaman ini sengaja dibiarkan kosong</span></p>
</div><br clear="all"></li></ul>
<p><span class="font13">762</span></p>