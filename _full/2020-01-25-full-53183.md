---
layout: full_article
title: "Sentiment Analysis of Snack Review Using the Naïve Bayes Method"
author: "I Gede Cahya Purnama Yasa, Ngurah Agus Sanjaya ER, Luh Arida Ayu Rahning Putri"
categories: jik
canonical_url: https://jurnal.harianregional.com/jik/full-53183 
citation_abstract_html_url: "https://jurnal.harianregional.com/jik/id-53183"
citation_pdf_url: "https://jurnal.harianregional.com/jik/full-53183"  
comments: true
---

<p><span class="font0">p-ISSN: 2301-5373</span></p>
<p><span class="font0">e-ISSN: 2654-5101</span></p>
<p><span class="font0">Jurnal Elektronik Ilmu Komputer Udayana</span></p>
<p><span class="font0">Volume 8, No 3. February 2020</span></p><a name="caption1"></a>
<h1><a name="bookmark0"></a><span class="font1" style="font-weight:bold;"><a name="bookmark1"></a>Sentiment Analysis of Snack Review Using the Naïve Bayes Method</span></h1>
<p><span class="font0">I Gede Cahya Purnama Yasa<sup>a1</sup> Ngurah Agus Sanjaya ER<sup>a2</sup></span><span class="font0" style="font-weight:bold;">, </span><span class="font0">Luh Arida Ayu Rahning Putri<sup>a3</sup></span></p>
<p><span class="font0"><sup>a</sup>Informatics Department, Udayana University Bali, Indonesia </span><a href="mailto:1cahya.purnama456@gmail.com"><span class="font0"><sup>1</sup>cahya.purnama456@gmail.com</span></a><span class="font0"> </span><a href="mailto:2agus_sanjaya@unud.ac.id"><span class="font0"><sup>2</sup>agus_sanjaya@unud.ac.id</span></a><span class="font0"> </span><a href="mailto:3luh.arida@cs.unud.ac.id"><span class="font0"><sup>3</sup>luh.arida@cs.unud.ac.id</span></a></p>
<p><span class="font0" style="font-weight:bold;font-style:italic;">Abstract</span></p>
<p><span class="font0" style="font-style:italic;">Fast food is a product that we often encounter in stores such as convenience stores. Ready-to-eat products can now be easily found by consumers. One of the reasons is due to the expansion of minimarkets in areas that are easily reached, such as housing complexes, school areas, and offices. Sentiment analysis is used to determine whether an opinion or comment on a product has a positive or negative interest and can be used as a reference in improving service, or improving product quality. In this research, we study the sentiments of consumers towards snack food products as a reference to improve the level of service and quality of these products. We classify the sentiment of a review on snack food products as positive and negative. To classify the sentiments we apply the Naïve Bayes and Multinomial Naïve Bayes methods. We compare the two methods to study the most effective and efficient method for classifying sentiments on reviews of snack food products.</span></p>
<p><span class="font0" style="font-weight:bold;font-style:italic;">Keywords: </span><span class="font0" style="font-style:italic;">Sentiment Analysis, TF-IDF, Naïve Bayes,Multinomial, Review, Snack, Preprocessing</span></p>
<ul style="list-style:none;"><li>
<h3><a name="bookmark2"></a><span class="font0" style="font-weight:bold;"><a name="bookmark3"></a>1. &nbsp;&nbsp;&nbsp;Introduction</span></h3></li></ul>
<p><span class="font0">There are various types of food and drinks on the Indonesian market, food and beverages are often found in minimarkets, for example, which provides various types of food and beverages in the form of fast food products. Through the Worldpanel Indonesia 2017 Study in urban communities shows that ready-to-eat products are three times more salable outside the home than consumed at home. Ready-to-eat products are becoming increasingly easy to find by consumers, one of them thanks to the expansion of minimarkets in easily accessible areas such as housing complexes, school areas, and offices [1]. Snack is one of the foods that are favorite and most in demand. Because the majority of snacks are dry and have a small size so it is very easy to take and put into the mouth. In addition, a quick snack makes people thirsty. After drinking, the person will consume again [2].</span></p>
<p><span class="font0">Not all fast food has good taste and is satisfying for consumers. Nowadays, internet users often use forums as a consideration to buy an item or food and drink. Generally, to provide a product review, users are asked to fill in a review sentence and rating results that are usually in the form of stars. Users are asked to write down their experiences using the product and assess whether the experience deserves a rating. However, users also often give results of reviews and ratings which are actually inversely proportional. For example, often the user writes down how satisfied he is with the product but instead gives a low rating, which means the review is negative.</span></p>
<p><span class="font0">Sentiment analysis studies one's perspective, behavior and feelings or emotions towards an individual, problem, activity, subject [3]. Sentiment analysis is done to determine whether an opinion or comment on a problem, has a positive or negative tendency and can be used as a reference in improving a service, or improving product quality</span></p>
<p><span class="font0">In previous studies relating to Sentiment Analysis conducted by [4] on opinions written in Roman-Urdu and English extracted from the blog. In this study a classification method or model which includes the Naïve Bayes method, decision tree, and K-Nearest Neighbor (KNN) is used.</span></p>
<p><span class="font0">The dataset used for the training process consisted of 150 positives and 150 negatives. Based on test results using precision, recall, and f-measure, the Naïve Bayes classification method produces better performance than the decision tree and KNN.</span></p>
<p><span class="font0">For the classification method itself many researchers use Naive Bayes where a text will be classified in machine learning based on probability [5]. Naïve Bayes classifiers are very simple and efficient [6]. In addition to its simplicity, the Naïve Bayes classifier is a popular machine learning technique for text classification, and has good performance in many domains [7].</span></p>
<p><span class="font0">Sentiment analysis helps a seller to evaluate the opinions and behavior of clients towards their products, so that the seller gets a review of their goods directly from the client. Therefore, sentiment analysis is needed to analyze a person's view of a product so that it can increase the usability and sale of the product by knowing the weaknesses of goods from the user's point of view. In this study, the authors conducted a study of snack or snack reviews to find out whether the sentiments were positive or negative. The final result that will be produced is the level of accuracy achieved in conducting sentiment analysis using the Naïve Bayes method.</span></p>
<ul style="list-style:none;"><li>
<h3><a name="bookmark4"></a><span class="font0" style="font-weight:bold;"><a name="bookmark5"></a>2. &nbsp;&nbsp;&nbsp;Reseach Methods</span></h3>
<div>
<p><span class="font0" style="font-style:italic;">i</span></p>
</div><br clear="all">
<div><img src="https://jurnal.harianregional.com/media/53183-1.jpg" alt="" style="width:53pt;height:22pt;">
</div><br clear="all">
<div>
<p><span class="font2">TF-IDF</span></p>
</div><br clear="all">
<div>
<p><span class="font2">Selesai</span></p>
</div><br clear="all">
<div><img src="https://jurnal.harianregional.com/media/53183-2.jpg" alt="" style="width:88pt;height:11pt;">
<p><span class="font2">Data Review</span></p>
</div><br clear="all">
<div>
<p><span class="font2">Preprocessing</span></p>
</div><br clear="all">
<div>
<p><span class="font2">Pengujian</span></p><img src="https://jurnal.harianregional.com/media/53183-3.jpg" alt="" style="width:96pt;height:21pt;">
</div><br clear="all">
<div>
<p><span class="font8">T</span></p>
</div><br clear="all"></li></ul>
<p><span class="font0" style="font-weight:bold;">Figure 1. </span><span class="font0">General System Flow</span></p>
<p><span class="font0">In the research method that the author uses regarding the stages that must be passed as shown in figure 1. The earliest stage that is passed is reading documents reviewing documents as a data system, after which a preprocessing process will be carried out, such as handling punctuation, deletion stopwords, stemming, tokenization and handling negative words. Then a feature that uses word weighting will use a Term Frequency - Inverse Document Frequency (TF-IDF) that will produce vector features. After completing the preprocessing and weighting stages, there will be a training and testing phase of the system.</span></p>
<ul style="list-style:none;"><li>
<h3><a name="bookmark6"></a><span class="font0" style="font-weight:bold;"><a name="bookmark7"></a>2.1. &nbsp;&nbsp;&nbsp;Dataset</span></h3></li></ul>
<p><span class="font0">In this study the authors used snack food product review data obtained from </span><a href="https://www.hometesterclub.com"><span class="font0">https://www.hometesterclub.com</span></a><span class="font0"> which consisted of 50 positive reviews and 50 negative reviews.</span></p>
<ul style="list-style:none;"><li>
<h3><a name="bookmark8"></a><span class="font0" style="font-weight:bold;"><a name="bookmark9"></a>2.2. &nbsp;&nbsp;&nbsp;Preprocessing</span></h3></li></ul>
<p><span class="font0">Preprocessing stage that the author uses for the dataset that is owned are:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font0">a. &nbsp;&nbsp;&nbsp;Tokenization</span></p></li></ul>
<p><span class="font0">From each review sentence contained in the dataset will go through the tokenization process. In the process of tokenisation each sentence is broken down into words.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font0">b. &nbsp;&nbsp;&nbsp;Stopwords Removal</span></p></li></ul>
<p><span class="font0">Namely the elimination of words that are not relevant, like this, is, that, only and so on.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font0">c. &nbsp;&nbsp;&nbsp;Punctuation Management</span></p></li></ul>
<p><span class="font0">In this method, the punctuation review will be removed.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font0">d. &nbsp;&nbsp;&nbsp;Stemming</span></p></li></ul>
<p><span class="font0">Stemming is a method used to convert words into root words by eliminating affixes and suffixes on words, such as using, using, and using where the basic words of all are use words.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font0">e. &nbsp;&nbsp;&nbsp;Handling Negative Words</span></p></li></ul>
<p><span class="font0">Changing the words in front of it there are negative words like, ‘no’, ‘ga’, ‘not’, and others will be given treatment, i.e. the addition of ‘no_’ before the word. For example, the word ‘does not match’ then the words become ‘not not suitable’. This treatment serves to distinguish the meaning of the word 'match' if it is preceded by a negative word and which is not preceded by a negative word.</span></p>
<p><span class="font0" style="font-weight:bold;">Table 1. </span><span class="font0">Preprocessing Results</span></p>
<table border="1">
<tr><td style="vertical-align:top;">
<p><span class="font0">Data</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">Rasanya hampir tidak ada lebih ke rasa kentang pada umumnya!</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font0">Tokenization</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">‘rasanya’,’hampir’,’</span></p>
<p><span class="font0">tidak’,’ada’,’lebih’,’ke’,’rasa’,’kentang’,’pada’,’umumnya!’</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0">Stopwords Removal</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">‘rasanya’,’ tidak’,’rasa’,’kentang’,’umumnya!’</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0">Penanganan Puctiation</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">‘rasanya’,’tidak’,’rasa’,’kentang’,’umumnya’</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0">Stemming</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">‘rasa’, ‘tidak’,’rasa’,’kentang’,’umum’</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font0">Penanganan Negative Words</span></p></td><td style="vertical-align:top;">
<p><span class="font0">‘rasa’, ‘tidak’,’tidak_rasa’,’kentang’,’umum’</span></p></td></tr>
</table>
<ul style="list-style:none;"><li>
<h3><a name="bookmark10"></a><span class="font0" style="font-weight:bold;"><a name="bookmark11"></a>2.3. &nbsp;&nbsp;&nbsp;Word Weighting</span></h3></li></ul>
<p><span class="font0">Word weighting (term) aims to give weight to each word (term) contained in the text document to be processed. The stages in word weighting are as follows:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font0">a. &nbsp;&nbsp;&nbsp;Term Frequency (TF)</span></p></li></ul>
<p><span class="font0">Term Frequency is the frequency of occurrence of words in a text document. Term Frequency (tft, d) is defined by the number of occurrences of the term t in the document d.</span></p>
<p><span class="font6" style="font-style:italic;">tf ( t<sub>l</sub>d} = <sup>f</sup>-^p-</span><span class="font0"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1)</span></p>
<ul style="list-style:none;"><li>
<p><span class="font0">b. &nbsp;&nbsp;&nbsp;Invers Document Frequency (IDF)</span></p></li></ul>
<p><span class="font0">Inverse Document Frequency is the frequency with which the term appears in all text documents. Term that rarely appears in the whole text document has a value of Inverse Document Frequency greater than the term that often appears.</span></p>
<p><a href="#bookmark12"><span class="font6" style="font-style:italic;">idf</span><span class="font6"> (t- = </span><span class="font6" style="font-style:italic;">log—-—</span></a></p>
<ul style="list-style:none;"><li>
<p><a href="#bookmark13"><span class="font0"><sup>j j &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;a</sup> 1+</span><span class="font0" style="font-style:italic;">df(t-' '</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><span class="font0">c. &nbsp;&nbsp;&nbsp;Term Frequency- Inverse Document Frequency</span></p></li></ul>
<p><span class="font0">The tf-idf value of a word is a combination of the tf value and idf value in the weight calculation.</span></p>
<p><a href="#bookmark14"><span class="font6" style="font-style:italic;">tf - Idftt, d') = tftt, d)</span><span class="font6"> × </span><span class="font6" style="font-style:italic;">Idftt)</span><span class="font0">(3)</span></a></p>
<ul style="list-style:none;"><li>
<h3><a name="bookmark15"></a><span class="font0" style="font-weight:bold;"><a name="bookmark16"></a>2.4. &nbsp;&nbsp;&nbsp;Naïve Bayes</span></h3></li></ul>
<p><span class="font0">Naïve Bayes is one of the probability statistical methods based on the application of the Bayes theorem with strong (naive) independent assumptions, to predict the class of a document based on its probabilities [8]. Naïve Bayes classifier assumes that the presence of certain features of a class is not related to the presence of other features (independent). Naïve Bayes is a very simple approach to classification text.</span></p>
<p><span class="font0">In the Bayes theorem, P (c | d) is determined where c is the class and d is the object (document) to be classified. P (c) is the prior probability of class c, P (d | c) is the probability of document (d) in a class (c). Bayes' theorem has the following formula</span></p>
<p><span class="font6">P(c</span><span class="font5">∣</span><span class="font6">d) </span><span class="font6" style="font-style:italic;">= </span><span class="font7" style="text-decoration:line-through;"><sup>P </sup></span><span class="font7" style="font-style:italic;text-decoration:line-through;"><sup>t</sup>↑<sup>c</sup>^<sup>tc-</sup></span><span class="font0"> (4)</span></p>
<ul style="list-style:none;"><li>
<p><span class="font0">a. &nbsp;&nbsp;&nbsp;Multinomial Naïve Bayes</span></p></li></ul>
<p><span class="font0">Multinomial Naïve Bayes is one of the specific methods of the Naïve Bayes method that uses conditional probability. Conditional probability can be done by using the frequency of occurrence of a word in a class (raw term frequency) [8]. Multinomial Naïve Bayes calculates the frequency of each word that appears in the document. For example there are documents d and class c. To calculate the class of document d, it can be calculated using the formula:</span></p>
<p><a href="#bookmark17"><span class="font6" style="font-style:italic;">P</span><span class="font6">(</span><span class="font6" style="font-style:italic;">c</span><span class="font6">| </span><span class="font6" style="font-style:italic;">term dokumen d</span><span class="font6">)= </span><span class="font6" style="font-style:italic;">P</span><span class="font6">(</span><span class="font6" style="font-style:italic;">c</span><span class="font6">)</span><span class="font6" style="font-style:italic;">x P</span><span class="font6">(</span><span class="font6" style="font-style:italic;">t</span><span class="font6">1|</span><span class="font6" style="font-style:italic;">C</span><span class="font6">)</span><span class="font6" style="font-style:italic;">x P</span><span class="font6">(</span><span class="font6" style="font-style:italic;">t</span><span class="font6">2|</span><span class="font6" style="font-style:italic;">C</span><span class="font6">)</span><span class="font6" style="font-style:italic;">x P</span><span class="font6">(</span><span class="font6" style="font-style:italic;">t</span><span class="font6">3|</span><span class="font6" style="font-style:italic;">C</span><span class="font6">)</span><span class="font6" style="font-style:italic;">X</span><span class="font6">...</span><span class="font6" style="font-style:italic;">x P</span><span class="font6">( </span><span class="font6" style="font-style:italic;">tn</span><span class="font6"> |</span><span class="font6" style="font-style:italic;">c</span><span class="font6">)</span></a></p>
<p><span class="font0">The probability of prior class c is determined by the formula: </span><span class="font0" style="font-style:italic;">N c</span></p>
<p><a href="#bookmark18"><span class="font6">P(c) = N</span></a></p>
<p><span class="font0">Multinomial Naïve Bayes for the value of input x are shown in the following equation:</span></p>
<p><a href="#bookmark19"><span class="font6" style="font-style:italic;">P</span><span class="font6">( </span><span class="font6" style="font-style:italic;">tn</span><span class="font6"> |</span><span class="font6" style="font-style:italic;">c</span><span class="font6">)= &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="font6" style="font-style:italic;">w</span><span class="font6"><sup>( c</sup>- <sup>,</sup> </span><span class="font6" style="font-style:italic;">tn</span><span class="font6"> <sup>)</sup>+ </span><span class="font0">1(7)</span></a></p>
<p><span class="font0">(∑W/€VW/ (c,tn) +B` )</span></p>
<p><span class="font0">Where :</span></p>
<p><span class="font6" style="font-style:italic;">W</span><span class="font6">(</span><span class="font6" style="font-style:italic;">c</span><span class="font6">, </span><span class="font6" style="font-style:italic;">tn</span><span class="font6">) </span><span class="font0">: Nilai pembobotan tfidf atau W dari term t di kategori c</span></p>
<ul style="list-style:none;"><li>
<p><span class="font6">∑</span><span class="font6" style="font-style:italic;">W</span><span class="font6">′€ </span><span class="font6" style="font-style:italic;">VW</span><span class="font6">′</span><span class="font6" style="font-style:italic;">ct</span><span class="font0"> : Jumlah total W dari keseluruhan term yang berada di kategori c.</span></p></li></ul>
<p><span class="font6" style="font-style:italic;">B</span><span class="font6">ʼ </span><span class="font0">: Jumlah W kata unik (nilai idf tidak dikali dengan tf) pada seluruh dokumen</span></p>
<ul style="list-style:none;"><li>
<p><span class="font0">b. &nbsp;&nbsp;&nbsp;Experiment Scenarios</span></p></li></ul>
<p><span class="font0">Calculation of the accuracy of the system to measure how well the system performance that we made is measured using the formula:</span></p>
<p><span class="font6" style="font-style:italic;">Akurasi</span><span class="font6"> <sub>=</sub> &nbsp;&nbsp;&nbsp;</span><span class="font6" style="font-style:italic;">100%</span></p>
<div>
<p><span class="font0">(8)</span></p>
</div><br clear="all">
<p><span class="font0">From that formula we obtained from the percentage of the results of a properly classified review divided by the total of all review tested.</span></p>
<ul style="list-style:none;"><li>
<h3><a name="bookmark20"></a><span class="font0" style="font-weight:bold;"><a name="bookmark21"></a>3. &nbsp;&nbsp;&nbsp;Result and Discussion</span></h3></li></ul>
<p><span class="font0">The proposed method uses 100 review data where 50 are positive reviews and 50 are negative reviews. For each dataset 20% is used as test data and the rest is used as training data.</span></p>
<p><span class="font0">Previously the data had to go through preprocessing as follows: (1) First, we separated each sentence into words, (2) Then eliminated irrelevant words, (3) After that it eliminated punctuation, (4) basics, and (5) lastly set the word negation. After going through the preprocessing stage, the results will be weighted using the tf-tdf formula as in equation (3). After the weights are obtained, the classification is done using the Naive Bayes and Multinomial Naive Bayes methods.</span></p>
<p><span class="font0">The results of the system evaluation collected with the calculations obtained are the amount of data classified correctly divided by all test data.</span></p>
<h2><a name="bookmark22"></a><span class="font4"><a name="bookmark23"></a>Chart Title</span></h2>
<p><span class="font3">100</span></p>
<p><span class="font3">80</span></p>
<p><span class="font3">60</span></p>
<p><span class="font3">40</span></p>
<p><span class="font3">20</span></p>
<p><span class="font3">0</span></p>
<p><span class="font3">1 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;4 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;5 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;6 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;7 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;8 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;9 &nbsp;&nbsp;&nbsp;&nbsp;10</span></p>
<p><span class="font3">^^^»NB ^^^^^»MNB</span></p>
<ul style="list-style:none;"><li>
<p><span class="font0" style="font-weight:bold;">Figure 2. </span><span class="font0">Accuracy</span></p></li></ul>
<p><span class="font0">From Figure 2 we conducted a number of experiments that obtained varying accuracy, this is because the distribution of training data and testing data was randomized by a percentage as stated. From these results it was found that the highest accuracy obtained when using the Naïve Bayes method was 84% and when using the Multinomial Naive Bayes method was 87% with an average accuracy obtained from 10 trials was 80,5% using the Naïve Bayes method and 81,3% using the Multinomial Naïve Bayes method.</span></p>
<ul style="list-style:none;"><li>
<h3><a name="bookmark24"></a><span class="font0" style="font-weight:bold;"><a name="bookmark25"></a>4. &nbsp;&nbsp;&nbsp;Conclusion</span></h3></li></ul>
<p><span class="font0">Naïve Bayes and Multinomial Naïve Bayes are some methods that used for classification. Where in this system the Naïve Bayes and Multinomial Naïve Bayes method is used to classify sentiments from the review of snacks, whether the review is included in positive sentiments or included in negative sentiments. Where the feature extraction method used is the weighting of words using the tf-idf method that provides statistics on the appearance of words and the level of importance of documents that support it.</span></p>
<p><span class="font0">The use of both methods to classify the system can already be implemented by applying feature extraction with TF-IDF, this is proven and also with the test results produced by the system which shows quite good results. This can be seen from the highest results obtained with Naïve Bayes is 84% and Multinomial Naïve Bayes is 87%, with an average accuracy 80,5% and 81,3%.</span></p>
<p><span class="font0">From the research conducted, both methods can classified review into a positive or negative sentiment quite well but it still cannot be grouped directly based on the product to determine the overall assessment of a product. In the future it might be possible to make improvements by directly evaluating based on the product.</span></p>
<h3><a name="bookmark26"></a><span class="font0" style="font-weight:bold;"><a name="bookmark27"></a>References</span></h3>
<ul style="list-style:none;"><li>
<p><span class="font0">[1] &nbsp;&nbsp;&nbsp;N. A. SAM, &quot;Kompas,&quot; Ekonomi Kompas, 28 &nbsp;12 &nbsp;2017. [Online]. Available:</span></p></li></ul>
<p><a href="https://ekonomi.kompas.com/read/2017/12/28/135401226/studi-kantar-makanan-dan-minuman-kemasan-lebih-laku-di-perkotaan"><span class="font0">https://ekonomi.kompas.com/read/2017/12/28/135401226/studi-kantar-makanan-dan-minuman-kemasan-lebih-laku-di-perkotaan</span></a><span class="font0">. [Accessed 24 05 2019].</span></p>
<ul style="list-style:none;"><li>
<p><span class="font0">[2] &nbsp;&nbsp;&nbsp;T. Sipahutar, &quot;Kompas,&quot; Lifestyle Kompas, 26 &nbsp;05 &nbsp;2011. [Online]. Available:</span></p></li></ul>
<p><a href="https://lifestyle.kompas.com/read/2011/05/26/08592040/kerupuk.atau.keripik.favorit.orang"><span class="font0">https://lifestyle.kompas.com/read/2011/05/26/08592040/kerupuk.atau.keripik.favorit.orang</span></a><span class="font0"> .indonesia. [Accessed 24 05 2019].</span></p>
<ul style="list-style:none;"><li>
<p><span class="font0">[3] &nbsp;&nbsp;&nbsp;A. Basari, B. Hussin, . I. Ananta and J. Zeniarja, &quot;Opinion Mining of Movie Review using Hybrid Method of Support Vector Machine and Particle Swarm Optimization,&quot; </span><span class="font0" style="font-style:italic;">Procedia Engineering,</span><span class="font0"> vol. 53, p. 453 – 462, 2013.</span></p></li>
<li>
<p><span class="font0">[4] &nbsp;&nbsp;&nbsp;M. Bilal, . H. Israr, . M. Shahid and A. Khan, &quot;Sentiment classification of Roman-Urdu opinions Using Naı¨ve Bayesian, Decision Tree and KNN classification techniques.,&quot; </span><span class="font0" style="font-style:italic;">ing Saud University.,</span><span class="font0"> 2015.</span></p></li>
<li>
<p><span class="font0">[5] &nbsp;&nbsp;W. Zhang and F. Gao, &quot;An Improvement to Naive Bayes for Text Classification,&quot;</span></p></li></ul>
<p><span class="font0" style="font-style:italic;">Advanced in Control Engineering and Information Science,</span><span class="font0"> vol. 15, p. 2160–2164, 2011.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font0">[6] &nbsp;&nbsp;&nbsp;J. Chen, H. Huang, . S. Tian and . Y. Qu, &quot;Feature selection for text classification with</span></p></li></ul>
<p><span class="font0">Naïve Bayes.,&quot; </span><span class="font0" style="font-style:italic;">Expert Systems with Applications,</span><span class="font0"> vol. 36(3), p. 5432–5435, 2009.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font0">[7] &nbsp;&nbsp;&nbsp;Q. Ye, . Z. Zhang and R. Law, &quot;xpert Systems with Applications Sentiment classification of online reviews to travel destinations by supervised machine learning approaches.,&quot; </span><span class="font0" style="font-style:italic;">Expert Systems With Applications,</span><span class="font0"> vol. 36(3), p. 6527–6535, 2009.</span></p></li>
<li>
<p><span class="font0">[8] &nbsp;&nbsp;&nbsp;A. Go, R. Bhayani and L. Huang, &quot;Twitter sentiment classification using distant supervision,&quot; </span><span class="font0" style="font-style:italic;">CS224N Project Report, Stanford,</span><span class="font0"> vol. 12, p. 1, 2009.</span></p></li>
<li>
<p><span class="font0">[9] &nbsp;&nbsp;&nbsp;S. Raschka, &quot;Naive Bayes and Text Classification I - Introduction and Theory,&quot; </span><span class="font0" style="font-style:italic;">CoRR,</span><span class="font0"> vol. 14105329, pp. 1-20, 2014.</span></p></li></ul>
<p><span class="font0">338</span></p>