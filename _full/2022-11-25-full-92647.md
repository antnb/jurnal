---
layout: full_article
title: "Hyperparameter Tuning Algoritma KNN Untuk Klasifikasi Kanker Payudara Dengan Grid Search CV"
author: "Nyoman Hendradinata Dharma, I Gede Santi Astawa"
categories: jnatia
canonical_url: https://jurnal.harianregional.com/jnatia/full-92647 
citation_abstract_html_url: "https://jurnal.harianregional.com/jnatia/id-92647"
citation_pdf_url: "https://jurnal.harianregional.com/jnatia/full-92647"  
comments: true
---

<p><span class="font3">JNATIA Volume 1, Nomor 1, November 2022</span></p>
<p><span class="font3">Jurnal Nasional Teknologi Informasi dan Aplikasinya</span></p><a name="caption1"></a>
<h1><a name="bookmark0"></a><span class="font4" style="font-weight:bold;font-style:italic;"><a name="bookmark1"></a>Hyperparameter Tuning Algoritma KNN Untuk Klasifikasi Kanker Payudara Dengan Grid Search CV</span></h1>
<p><span class="font3">Nyoman Hendradinata Dharma<sup>a1</sup> dan I Gede Santi Astawa<sup>a2</sup></span><span class="font3" style="font-weight:bold;">.</span></p>
<p><span class="font3"><sup>a</sup>Program Studi Informatika,</span></p>
<p><span class="font3">Fakultas Matematika dan Ilmu Pengetahuan Alam, Universitas Udayana</span></p>
<p><span class="font3">Bali, Indonesia</span></p>
<p><span class="font3"><sup>1</sup>nyomanhendradinata20@</span><a href="mailto:gmail.com@email.com"><span class="font3">gmail.com@email.com</span></a></p>
<p><a href="mailto:2santi.astawa@unud.ac.id"><span class="font3"><sup>2</sup>santi.astawa@unud.ac.id</span></a></p>
<p><span class="font3" style="font-weight:bold;font-style:italic;">Abstract</span></p>
<p><span class="font3" style="font-style:italic;">One of the deadliest diseases in the world is Breast cancer. Breast cancer is a disease caused by abnormal cells that grow and develop rapidly and malignantly in the human breast and spread quickly to the tissues or organs around the breast. Data from Riskesdas in 2019 stated that in Indonesia, the prevalence of breast cancer was 41.2 per 100,000 Indonesians with an average death rate of 17 per 100,000 Indonesians. Technology nowadays is increasingly advanced and developed which can help people to find out the disease they are suffering from early before carrying out further examinations with the doctor. Breast cancer can be detected early by classifying it with machine learning algorithm. In this research, Breast cancer will be classified using K-Nearest Neighbor algorithm with Grid Search to classify whether a person has breast cancer or not. K-Nearest Neighbor (KNN) is one of the classification algorithms, where classification is carried out on data objects based on learning data whose neighbors are closest to the data object. The performance results of the classification model using K-Nearest Neighbor are 83% accuracy, 73% precision, and 89% recall.</span></p>
<p><span class="font3" style="font-weight:bold;font-style:italic;">Keywords: </span><span class="font3" style="font-style:italic;">KNN, Kanker Payudara, Klasifikasi, Grid Search, Hyperparameter Tuning</span></p>
<ul style="list-style:none;"><li>
<h4><a name="bookmark2"></a><span class="font3" style="font-weight:bold;"><a name="bookmark3"></a>1. &nbsp;&nbsp;&nbsp;Introduction</span></h4></li></ul>
<p><span class="font3">Salah satu penyakit yang mematikan di dunia adalah Kanker Payudara. Kanker Payudara merupakan penyakit yang disebabkan oleh sel-sel abnormal yang tumbuh dan berkembang secara cepat dan ganas di payudara manusia dan cepat menyebar ke bagian jaringan atau organ sekitar payudara. Berdasarkan data dari Riskesdas pada tahun 2019 disebutkan di Indonesia, prevalensi kejadian untuk Kanker Payudara sebanyak 41,2 per 100.000 masyarakat Idonesia dengan rata-rata kematian 17 per 100.000 masyarakat Indonesia [1].</span></p>
<p><span class="font3">Teknologi dewasa ini sudah semakin maju dan berkembang dapat membantu masyarakat untuk mengetahui penyakit yang dideritanya lebih awal sebelum melakukan pemeriksaan lebih lanjut ke dokter. Kanker Payudara dapat diketahui lebih awal dengan melakukan klasifikasi menggunakan algoritma </span><span class="font3" style="font-style:italic;">machine learning</span><span class="font3">. Terdapat berbagai macam algoritma </span><span class="font3" style="font-style:italic;">machine learning</span><span class="font3"> yang dapat digunakan untuk melakukan klasifikasi, salah satunya adalah KNN atau K-Nearest Neighbor. KNN merupakan algoritma </span><span class="font3" style="font-style:italic;">supervised</span><span class="font3"> yang melakukan proses klasifikasi objek dari data pembelajaran yang memiliki ketetanggaan objek data paling dekat.</span></p>
<p><span class="font3">Penelitian sebelumnya dengan judul Hyperparameter Tuning pada Algoritma Klasifikasi dengan Grid Search oleh Wahyu Nugraha dan Agung Sasongko [5]. Pada penelitian tersebut dilakukan optimasi hyperparameter yaitu Grid Search terhadap 7 algoritma klasifikasi </span><span class="font3" style="font-style:italic;">machine learning </span><span class="font3">yaitu </span><span class="font3" style="font-style:italic;">XGBoost, Support Vector Machine (SVM), Random Forest, Logistic Regression, Gaussian Naive Bayes,</span><span class="font3"> K-</span><span class="font3" style="font-style:italic;">Nearest Neighbors (k-NN), Decision Tree.</span><span class="font3"> Pada penelitian tersebut menunjukan hasil eksperimen model </span><span class="font3" style="font-style:italic;">XGBoost</span><span class="font3"> memperoleh nilai terbaik yaitu sebesar 0,772 sedangkan untuk </span><span class="font3" style="font-style:italic;">Decision tree</span><span class="font3"> memiliki nilai terendah yaitu 0,701.</span></p>
<p><span class="font3">berdasarkan pemaparan diatas, penulis akan mengimplementasikan </span><span class="font3" style="font-style:italic;">hyperparameter tuning </span><span class="font3">algoritma KNN untuk klasifikasi kanker payudara dengan </span><span class="font3" style="font-style:italic;">Grid Search</span><span class="font3"> untuk melakukan klasifikasi apakah seseorang terkena kanker payudara atau tidak.</span></p>
<ul style="list-style:none;"><li>
<h4><a name="bookmark4"></a><span class="font3" style="font-weight:bold;"><a name="bookmark5"></a>2. &nbsp;&nbsp;&nbsp;Reseach Methods</span></h4></li></ul>
<p><span class="font3">Pada penelitian ini menggunakan </span><span class="font3" style="font-style:italic;">Breast Cancer Coimbra Dataset</span><span class="font3"> yang merupakan data sekunder yang diperoleh dari</span><a href="https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Coimbra"><span class="font3"> </span><span class="font3" style="text-decoration:underline;">https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Coimbra</span><span class="font3">.</span></a><span class="font3"> Pada dataset ini memiliki 9 atribut dan 1 label dengan jumlah data sebanyak 166 baris data. Klasifikasi Kanker Payudara memiliki alur penelitian yang dimulai dengan (1) Menginputkan dataset dari </span><span class="font3" style="font-style:italic;">Breast Cancer Coimbra Dataset,</span><span class="font3"> (2) Normalisasi Data, (3) Membagi data menjadi data training dan data testing, (4) </span><span class="font3" style="font-style:italic;">Hyperparameter Tuning</span><span class="font3"> dengan </span><span class="font3" style="font-style:italic;">Grid Search Cross Validation</span><span class="font3">, (5) Klasifikasi KKN menggunakan parameter K optimal, (6) Mendapatkan hasil </span><span class="font3" style="font-style:italic;">accuracy, precision, dan recall</span><span class="font3">.</span></p><img src="https://jurnal.harianregional.com/media/92647-1.jpg" alt="" style="width:341pt;height:218pt;">
<p><span class="font3" style="font-weight:bold;">Figure 1. </span><span class="font3">Alur Penelitian</span></p>
<ul style="list-style:none;"><li>
<h4><a name="bookmark6"></a><span class="font3" style="font-weight:bold;"><a name="bookmark7"></a>2.1. &nbsp;&nbsp;&nbsp;Kanker Payudara</span></h4></li></ul>
<p><span class="font3">Payudara merupakan salah satu organ penting yang berfungsi untuk memproduksi ASI (Air Susu Ibu) dan Menyusui Bayi. Payudara terdiri dari jaringan, saraf, pembuluh darah, dan saraf yang berkumpul menjadi satu kesatuan. Kanker merupakan pertumbuhan sel-sel abnormal yang berkembang dengan cepat dan tidak dapat dikendalikan. Kanker Payudara merupakan penyakit tumor ganas yang berasal dari sel-sel abnormal yang tanpa kendali memperbanyak diri sehingga menyebar dan berpindah ke jaringan maupun organ di sekitar payudara [4]. Kanker Payudara tidak hanya menyerang perempuan namun laki-laki juga dapat terkena penyakit Kanker Payudara. Gejala-gejala dari seseorang yang mengidap Kanker Payudara adalah benjolan pada daerah payudara yang tidak sembuh-sembuh, keluar cairan kuning pada puting, warna kulit di area payudara berubah, dan puting menjadi masuk ke dalam.</span></p>
<ul style="list-style:none;"><li>
<h4><a name="bookmark8"></a><span class="font3" style="font-weight:bold;"><a name="bookmark9"></a>2.2. &nbsp;&nbsp;&nbsp;K-Nearest Neighbor</span></h4></li></ul>
<p><span class="font3">K-Nearest Neighbor (KNN) merupakan salah satu algoritma klasifikasi, dimana klasifikasi dilakukan terhadap objek data berdasarkan data pembelajaran yang jarak ketetanggaannya paling dekat dengan objek data tersebut. K-Nearest Neighbor atau KNN merupakan salah satu algoritma </span><span class="font3" style="font-style:italic;">supervised learning,</span><span class="font3"> algoritma </span><span class="font3" style="font-style:italic;">supervised learning</span><span class="font3"> merupakan algoritma yang dilatih dengan diberikan data yang sudah diberikan label sehingga didapatkan suatu hasil tertentu. Dalam menghitung jarak ketetanggan paling dekat dapat digunakan dua cara yaitu </span><span class="font3" style="font-style:italic;">Euclidean</span></p>
<p><span class="font3" style="font-style:italic;">distance</span><span class="font3"> dan </span><span class="font3" style="font-style:italic;">Manhattan distance,</span><span class="font3"> namun </span><span class="font3" style="font-style:italic;">Euclidean distance</span><span class="font3"> secara umum lebih sering digunakan dalam menghitung jarak ketetanggan. Rumus dari </span><span class="font3" style="font-style:italic;">Euclidean distance</span><span class="font3"> dapat ditunjukkan dari persamaan dibawah</span></p>
<h2><a name="bookmark10"></a><span class="font10" style="font-style:italic;"><a name="bookmark11"></a>euc dist =</span><span class="font10"> √Σ</span><span class="font3">^<sub>1</sub> </span><span class="font10" style="font-style:italic;">(ai — bι)<sup>2</sup></span><span class="font3"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1)</span></h2>
<p><span class="font3">Keterangan:</span></p>
<p><span class="font3" style="font-style:italic;">euc dist</span><span class="font3"> = jarak ketetanggan</span></p>
<p><span class="font3">ai &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;= data training</span></p>
<p><span class="font3">bi &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;= data testing</span></p>
<p><span class="font3">i &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;= variabel atau record data</span></p>
<p><span class="font3">n &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;= dimensi data</span></p>
<ul style="list-style:none;"><li>
<h4><a name="bookmark12"></a><span class="font3" style="font-weight:bold;"><a name="bookmark13"></a>2.3. &nbsp;&nbsp;&nbsp;Normalisasi Data</span></h4></li></ul>
<p><span class="font3">Normalisasi merupakan proses yang digunakan untuk menskalakan nilai atribut data pada rentang tertentu sehingga nilai atribut tidak memiliki selisih yang cukup jauh. Dengan adanya</span></p>
<p><span class="font3">normalisasi data dapat membantu model klasifikasi untuk mempelajari data lebih mudah. Salah satu cara untuk menormalisasi data adalah </span><span class="font3" style="font-style:italic;">Z-score normalization,</span><span class="font3"> pada </span><span class="font3" style="font-style:italic;">Z-score normalization </span><span class="font3">data akan dinormalisasi berdasarkan dari nilai rata-rata atau </span><span class="font3" style="font-style:italic;">mean</span><span class="font3"> dan </span><span class="font3" style="font-style:italic;">standar deviation</span><span class="font3"> [2].</span></p>
<p><span class="font3">Persamaan dari </span><span class="font3" style="font-style:italic;">Z-score normalization</span><span class="font3"> adalah </span><span class="font3" style="font-style:italic;">sebagai berikut.</span></p>
<p><span class="font7" style="font-style:italic;">X- U</span></p>
<div>
<p><span class="font3">(2)</span></p>
</div><br clear="all">
<h3><a name="bookmark14"></a><span class="font10" style="font-style:italic;"><a name="bookmark15"></a>Z</span><span class="font10"> = -- σ</span></h3>
<p><span class="font3">Keterangan:</span></p>
<p><span class="font3" style="font-style:italic;">z</span><span class="font3"> &nbsp;&nbsp;&nbsp;&nbsp;= nilai baru</span></p>
<p><span class="font3">x &nbsp;&nbsp;&nbsp;&nbsp;= nilai lama</span></p>
<p><span class="font10" style="font-style:italic;">μ</span><span class="font3"> &nbsp;&nbsp;= mean</span></p>
<p><span class="font10" style="font-style:italic;">σ</span><span class="font3"> &nbsp;&nbsp;&nbsp;= standar deviasi</span></p>
<ul style="list-style:none;"><li>
<h4><a name="bookmark16"></a><span class="font3" style="font-weight:bold;"><a name="bookmark17"></a>2.4. &nbsp;&nbsp;&nbsp;Grid Search Cross Validation</span></h4></li></ul>
<p><span class="font3">Grid Search Cross Validation merupakan salah satu metode yang digunakan untuk mencari suatu parameter yang optimal dalam suatu model. </span><span class="font3" style="font-style:italic;">Grid Search</span><span class="font3"> adalah algoritma yang bekerja dengan cara menjadikan titik-titik </span><span class="font3" style="font-style:italic;">grid</span><span class="font3"> memiliki jarak yang mirip, lalu mengkalkulasikan kesalahan-kesalahan untuk setiap titik-titik parameter tersebut, dimana dalam hal ini titik yang mempunyai nilai kesalahan terendah merupakan parameter yang paling optimal [3]. </span><span class="font3" style="font-style:italic;">Grid Search Cross Validation</span><span class="font3"> akan melakukan pencocokan atau validasi dari semua model yang dikombinasikan dan hyperparameter secara otomatis [5].</span></p>
<ul style="list-style:none;"><li>
<p><span class="font3" style="font-weight:bold;">2.5.</span><span class="font3" style="font-weight:bold;font-style:italic;"> &nbsp;&nbsp;&nbsp;Accuracy, Precision, dan Recall</span></p></li></ul>
<p><span class="font3" style="font-style:italic;">Accuracy, Precision,</span><span class="font3"> dan </span><span class="font3" style="font-style:italic;">Recall</span><span class="font3"> merupakan salah satu cara untuk memperhitungkan tingkat kebenaran dari pengklasifikasian suatu data. </span><span class="font3" style="font-style:italic;">Accuracy</span><span class="font3"> digunakan untuk mengukur tingkat kemiripan nilai antara nilai prediksi dengan nilai sebenarnya, </span><span class="font3" style="font-style:italic;">precision</span><span class="font3"> digunakan untuk mengukur tingkat kecocokan antara informasi yang diperlukan dengan bagian data yang diambil, </span><span class="font3" style="font-style:italic;">recall</span><span class="font3"> digunakan untuk mengukur suatu tingkat keberhasilan sistem untuk menemukan suatu informasi kembali.</span></p>
<div>
<p><span class="font9" style="font-style:italic;">Accuracy </span><span class="font10" style="font-style:italic;">=</span></p>
</div><br clear="all">
<div>
<p><span class="font9" style="font-style:italic;">Precision.</span></p>
</div><br clear="all">
<div>
<p><span class="font9" style="font-style:italic;">Recall</span></p>
</div><br clear="all">
<div>
<p><span class="font7" style="font-style:italic;">TP+FN</span></p>
<p><span class="font7" style="font-style:italic;">TP+ FN+FP+ FN TP</span></p>
<p><span class="font7" style="font-style:italic;">TP+FP TP</span></p>
<p><span class="font7" style="font-style:italic;">TP+FN</span></p>
</div><br clear="all">
<div>
<p><span class="font3">(3)</span></p>
</div><br clear="all">
<div>
<p><span class="font3">(4)</span></p>
<p><span class="font3">(5)</span></p>
</div><br clear="all">
<div>
<p><span class="font3">Keterangan:</span></p>
<p><span class="font8">TP = Jumlah data yang memiliki nilai sebenarnya positif dan nilai prediksi positif FP = Jumlah data yang memiliki nilai sebenarnya negatif dan nilai prediksi positif FN = Jumlah data yang memiliki nilai sebenarnya positif dan nilai prediksi negatif TN = Jumlah data yang memiliki nilai sebenarnya negatif dan nilai prediksi negatif</span></p>
</div><br clear="all">
<ul style="list-style:none;"><li>
<h4><a name="bookmark18"></a><span class="font3" style="font-weight:bold;"><a name="bookmark19"></a>3. &nbsp;&nbsp;&nbsp;Result and Discussion</span></h4></li></ul>
<p><span class="font3">Pada penelitian ini dataset yang digunakan adalah </span><span class="font3" style="font-style:italic;">Breast Cancer Coimbra Dataset.</span><span class="font3"> Pada dataset tersebut berisi 166 baris dengan 9 atribut dan 1 label, dimana dalam label tersebut terdapat dua nilai yaitu 1 untuk </span><span class="font3" style="font-style:italic;">Healthy controls</span><span class="font3"> dan nilai 2 untuk </span><span class="font3" style="font-style:italic;">Patients.</span></p>
<p><span class="font8">c</span></p>
<table border="1">
<tr><td style="vertical-align:top;"></td><td style="vertical-align:top;">
<p><span class="font1">Age</span></p></td><td style="vertical-align:top;">
<p><span class="font1">BMI</span></p></td><td style="vertical-align:top;">
<p><span class="font1">Glucose</span></p></td><td style="vertical-align:top;">
<p><span class="font1">Insulin</span></p></td><td style="vertical-align:top;">
<p><span class="font1">HOMA</span></p></td><td style="vertical-align:top;">
<p><span class="font1">Leptin</span></p></td><td style="vertical-align:top;">
<p><span class="font1">Adiponectin</span></p></td><td style="vertical-align:top;">
<p><span class="font1">Resistin</span></p></td><td style="vertical-align:top;">
<p><span class="font1">MCP. 1</span></p></td><td style="vertical-align:top;">
<p><span class="font1">Classification</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font2">O</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">48</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">23.500000</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">70</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">2.707</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0.467409</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">8.8071</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">9.702400</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">7.99585</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">417 114</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">1</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font2">1</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">83</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">20.690495</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">92</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">3.115</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0.706897</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">8.8438</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">5.429285</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">4.06405</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">468.786</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">1</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font2">2</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">82</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">23.124670</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">91</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">4.498</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">1.009651</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">17.9393</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">22.432040</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">9 27715</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">554 697</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">1</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font2">3</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">68</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">21.367521</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">77</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">3.226</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0.612725</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">9.8827</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">7.169560</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">12.76600</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">928 220</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">1</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font2">4</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">86</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">21.111111</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">92</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">3.549</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0.805386</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">6.6994</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">4.8192.40</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">10.57635</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">773.920</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">1</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font2">5</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">49</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">22.854458</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">92</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">3.226</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0.732087</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">6.8317</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">13.679750</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">10 31760</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">530 410</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">1</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font2">6</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">89</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">22.700000</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">77</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">4.690</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0.890787</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">6.9640</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">5.589865</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">12.93610</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">1256 083</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">1</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font2">7</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">76</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">23.800000</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">118</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">6.470</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">1.883201</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">4.3110</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">13.251320</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">5.10420</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">280 694</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">1</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font2">8</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">73</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">22.000000</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">97</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">3.350</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0.801543</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">4.4700</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">10.358725</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">6.28445</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">136.855</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">1</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2">9</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">75</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">23.000000</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">83</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">4.952</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">1.013839</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">17.1270</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">11.578990</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">7 09130</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">318 302</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">1</span></p></td></tr>
</table>
<p><span class="font3" style="font-weight:bold;">Figure 2. </span><span class="font3" style="font-style:italic;">Breast Cancer Coimbra Dataset</span></p>
<p><span class="font3">Selanjutnya dilakukan korelasi atribut untuk mencari keberpengaruhan atribut-atribut yang ada dalam </span><span class="font3" style="font-style:italic;">Breast Cancer Coimbra Dataset</span><span class="font3"> dengan label kalsifikasi.</span></p>
<div>
<p><span class="font0">Adiponectin</span></p>
<p><span class="font0">Resistin</span></p>
<p><span class="font0">Qassrfication</span></p><img src="https://jurnal.harianregional.com/media/92647-2.jpg" alt="" style="width:371pt;height:202pt;">
<p><span class="font3" style="font-weight:bold;">Figure 3. </span><span class="font3">Korelasi Atribut</span></p>
<p><span class="font1">Insulin</span></p>
<p><span class="font0">HOMA</span></p>
<p><span class="font0">Leptin</span></p>
<p><span class="font0">MCPl</span></p>
</div><br clear="all">
<div>
<p><span class="font0">Glucose</span></p>
<table border="1">
<tr><td style="vertical-align:top;"></td><td style="vertical-align:middle;">
<p><span class="font0">00085</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">0.23</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">0032</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">0.13</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">Ol</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font0">- 0 0085</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">1</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">014</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">015</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">0.11</span></p></td><td style="vertical-align:top;"></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font0">- 023</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">014</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">1</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">OS</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">07</span></p></td><td style="vertical-align:top;"></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font0">- 0.032</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">015</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">05</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">1</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">0.93 </span><span class="font5">∖</span></p></td><td style="vertical-align:top;"></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font0">- 013</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">Oil</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">07</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">093</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">1</span></p></td><td style="vertical-align:top;"></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0">- &nbsp;&nbsp;0.1</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">057</span></p></td><td style="vertical-align:top;"></td><td style="vertical-align:top;"></td><td style="vertical-align:top;"></td><td style="vertical-align:bottom;">
<p><span class="font0">1</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font0">- 0 22</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">-0.3</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">O 12</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">-0.031</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">O 056</span></p></td><td style="vertical-align:top;">
<p><span class="font0">-0095 I</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font0">- 00027</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">02</span></p></td><td style="vertical-align:top;"></td><td style="vertical-align:middle;">
<p><span class="font0">015</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">023</span></p></td><td style="vertical-align:top;"></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font0">- 0013</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">022</span></p></td><td style="vertical-align:top;"></td><td style="vertical-align:middle;">
<p><span class="font0">0.17</span></p></td><td style="vertical-align:top;"></td><td style="vertical-align:middle;">
<p><span class="font0">0014</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font0">- 0 044</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">■0.13</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">0 38</span></p></td><td style="vertical-align:top;"></td><td style="vertical-align:top;"></td><td style="vertical-align:middle;">
<p><span class="font0">■0.0011</span></p></td></tr>
<tr><td style="vertical-align:top;"></td><td style="vertical-align:top;"></td><td style="vertical-align:bottom;">
<p><span class="font0">⅛°</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">J^</span></p></td><td style="vertical-align:top;"></td><td style="vertical-align:top;"></td></tr>
</table>
</div><br clear="all">
<ul style="list-style:none;"><li>
<h4><a name="bookmark20"></a><span class="font3" style="font-weight:bold;"><a name="bookmark21"></a>3.1. &nbsp;&nbsp;&nbsp;Normalisasi Data</span></h4></li></ul>
<p><span class="font3">Selanjutnya akan dilakukan normalisasi pada dataset. Hal ini dilakukan agar rentang nilai data dari 9 atribut yang ada tidak terlalu jauh. Dengan rentang nilai data yang berdekatan akan memudahkan model untuk melakukan klasifikasi.</span></p>
<p><span class="font6">array([[-0.57979363, -0.81667527, -1.23922225, -0.72873938, -0.61428241, -0.93233407, -0.07022151, -0.54551749, -0.34125061],</span></p>
<p><span class="font6">[ 1.60182096, -1.37875056, -0.25829943, -0.68803819, -0.54824045, -0.93041264, -0.69734988, -0.86421418, -0.1912238 ],</span></p>
<p><span class="font6">[ 1.53948912, -0.89176446, -0.30288683, -0.55007314, -0.46475236, -0.45421914, &nbsp;1.79799836, -0.4416602 , &nbsp;0.05821407],</span></p>
<p><span class="font6">[ 0.66684328, -1.24330321, -0.92711044, -0.67696507, -0.57420965, -0.87602119, -0.44194467, -0.15886735, 1.14271758],</span></p>
<p><span class="font6">[ 1.7888165 , -1.29460116, -0.25829943, -0.6447433 , -0.52108087, -1.04268238, -0.78688094, -0.33635201, 0.69471601]])</span></p>
<ul style="list-style:none;"><li>
<p><span class="font3" style="font-weight:bold;">Figure 4. </span><span class="font3">Hasil Korelasi Atribut 5 Data Teratas</span></p></li></ul>
<ul style="list-style:none;"><li>
<h4><a name="bookmark22"></a><span class="font3" style="font-weight:bold;"><a name="bookmark23"></a>3.2. &nbsp;&nbsp;&nbsp;Membagi Data menjadi </span><span class="font3" style="font-weight:bold;font-style:italic;">Data Training</span><span class="font3" style="font-weight:bold;"> Dan </span><span class="font3" style="font-weight:bold;font-style:italic;">Data Testing</span></h4></li></ul>
<p><span class="font3">Setelah dataset di normalisasi, akan dilakukan pemisahan dataset menjadi dua bagian yaitu menjadi data training dan data testing. Masing-masing pembagian dari dataset tersebut adalah 92 data atau 80% untuk data training dan 24 data atau 20% data testing.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font3" style="font-weight:bold;">3.3.</span><span class="font3" style="font-weight:bold;font-style:italic;"> &nbsp;&nbsp;&nbsp;Hyperparameter Tuning</span><span class="font3" style="font-weight:bold;"> dengan </span><span class="font3" style="font-weight:bold;font-style:italic;">Grid Search Cross Validation</span></p></li></ul>
<p><span class="font3">Selanjutnya dilakukan hyperparameter tuning, dimana dalam hal ini akan dicari </span><span class="font3" style="font-style:italic;">hyperparameter k</span><span class="font3"> (jumlah tetangga terdekat) terbaik dalam pengklasifikasian menggunakan </span><span class="font3" style="font-style:italic;">Grid Search Cross Validation</span><span class="font3">. Dimana digunakan 10 </span><span class="font3" style="font-style:italic;">Cross Validation</span><span class="font3"> dan range dari parameter k adalah 1-10. Setelah dilakukan </span><span class="font3" style="font-style:italic;">hyperparameter tuning dengan</span><span class="font3"> data training didapatkan jumlah k yang paling baik atau optimal adalah k=7.</span></p>
<p><span class="font2">print(grid_search.bestparams)</span></p>
<p><span class="font2">{'n_neighbors': 7}</span></p>
<ul style="list-style:none;"><li>
<p><span class="font3" style="font-weight:bold;">Figure 5. </span><span class="font3">Hasil Hyperparameter Tuning</span></p></li></ul>
<ul style="list-style:none;"><li>
<p><span class="font3" style="font-weight:bold;">3.4.</span><span class="font3" style="font-weight:bold;font-style:italic;"> &nbsp;&nbsp;&nbsp;Klasifikasi KNN Dengan Parameter k Optimal</span></p></li></ul>
<p><span class="font3">Selanjutnya dibangun model klasifikasi K-Nearest Neighbor (KNN) pada </span><span class="font3" style="font-style:italic;">Breast Cancer Coimbra Dataset</span><span class="font3"> dengan parameter k (jumlah tetangga terdekat) terbaik yang sudah didapatkan di </span><span class="font3" style="font-style:italic;">Grid Search Cross Validation</span><span class="font3"> yaitu k=7</span><span class="font3" style="font-style:italic;">.</span><span class="font3"> Dimana hasil yang didapatkan dari model klasifikasi menggunakan data testing adalah tingkat dari akurasi 83%, tingkat presisi 73%, dan recall 89%.:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font3" style="font-weight:bold;">Table 1. </span><span class="font3">Perbandingan Hasil Performa KNN</span></p></li></ul>
<p><span class="font3">Precision &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Recall &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Accuracy</span></p>
<p><span class="font3">KNN dengan</span></p>
<p><span class="font3">Grid Search &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.73% &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.89% &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.83%</span></p>
<p><span class="font3">CV, k=7</span></p>
<ul style="list-style:none;"><li>
<h4><a name="bookmark24"></a><span class="font3" style="font-weight:bold;"><a name="bookmark25"></a>4. &nbsp;&nbsp;&nbsp;Conclusion</span></h4></li></ul>
<p><span class="font3">Pada penelitian ini, klasifikasi kanker payudara dibantu dengan algoritma K-Nearest Neighbor (KNN) dengan parameter </span><span class="font3" style="font-style:italic;">k</span><span class="font3"> (jumlah tetangga terdekat) yaitu 7. Untuk meningkatkan performa algoritma KNN dilakukan </span><span class="font3" style="font-style:italic;">Hyperparameter Tuning</span><span class="font3"> dengan </span><span class="font3" style="font-style:italic;">Grid Search Cross Validation.</span><span class="font3"> Dimana performa yang dimaksud disini adalah </span><span class="font3" style="font-style:italic;">Accuracy, Precision,</span><span class="font3"> dan </span><span class="font3" style="font-style:italic;">Recall.</span><span class="font3"> Hasil performa dari model klasifikasi menggunakan K-Nearest Neighbor adalah tingkat dari akurasi 83%, tingkat presisi 73%, dan recall 89%.</span></p>
<p><span class="font3">Saran yang diharapkan untuk penelitian selanjutnya adalah dapat membandingkan algoritma-algoritma lain untuk dilakukan </span><span class="font3" style="font-style:italic;">Hyperparameter Tuning</span><span class="font3"> dengan </span><span class="font3" style="font-style:italic;">Grid Search Cross Validation</span></p>
<p><span class="font3">dalam mendeteksi penyakit kanker payudara, agar didapatkan algoritma mana yang memiliki performa lebih akurat dan efisien. Sehingga dapat ditemukan algoritma yang lebih baik dalam pengklasifikasian penyakit kanker payudara.</span></p>
<h4><a name="bookmark26"></a><span class="font3" style="font-weight:bold;"><a name="bookmark27"></a>References</span></h4>
<ul style="list-style:none;"><li>
<p><span class="font3">[1] &nbsp;&nbsp;&nbsp;Ariq. Naupal. Azmi, Bambang. Kurniawan, Andi. Lukman and Ade. Utia. Detty, &quot;Hubungan Faktor Keturunan Dengan Kanker Payudara DI RSUD Abdoel Moeloek&quot;, </span><span class="font3" style="font-style:italic;">Jurnal Ilmiah Kesehatan Sandi Husada,</span><span class="font3"> vol. 9, no. 2, pp.702-707, 2020.</span></p></li>
<li>
<p><span class="font3">[2] &nbsp;&nbsp;&nbsp;Darnisa. Azzahra. Nasution, Hidayah. Husnul. Khotimah, and Nurul. Chamidah, &quot;PERBANDINGAN NORMALISASI DATA UNTUK KLASIFIKASI WINE MENGGUNAKAN ALGORITMA K-NN&quot;, </span><span class="font3" style="font-style:italic;">CESS (Journal of Computer Engineering System and Science),</span><span class="font3"> vol. 4, no. 1, pp.78-82, 2021.</span></p></li>
<li>
<p><span class="font3">[3] &nbsp;&nbsp;&nbsp;Dewi. Satriani, Latifah. Uswatun. Khasanah and Nanda. Arista. Rizki, &quot;PENERAPAN METODE GRID-SEARCH DALAM MENENTUKAN PARAMETER MODEL PERTUMBUHAN PENDUDUK DI KOTA SAMARINDA&quot;, </span><span class="font3" style="font-style:italic;">Prosiding Seminar Nasional Matematika, Statistika, dan Aplikasinya,</span><span class="font3"> vol. 1, no. 5, pp.65-74, 2019.</span></p></li>
<li>
<p><span class="font3">[4] &nbsp;&nbsp;&nbsp;Laili. Rahayuwati, Iqbal. Abdul. Rizal, Tuti. Pahria, Makmat. Lukman and Neti.Juniarti, &quot;Pendidikan Kesehatan tentang Pencegahan Penyakit Kanker dan Menjaga Kualitas Kesehatan&quot;, </span><span class="font3" style="font-style:italic;">Media Karya Kesehatan,</span><span class="font3"> vol. 3, no. 1, pp.59-69, 2020.</span></p></li>
<li>
<p><span class="font3">[5] &nbsp;&nbsp;&nbsp;Wahyu. Nugraha and Agung. Sasongko, &quot;Hyperparameter Tuning pada Algoritma Klasifikasi dengan Grid Search&quot;, </span><span class="font3" style="font-style:italic;">SISTEMASI: Jurnal Sistem Informasi,</span><span class="font3"> vol. 11, no.21, pp.391-401, 2020.</span></p></li></ul>
<p><span class="font8">402</span></p>