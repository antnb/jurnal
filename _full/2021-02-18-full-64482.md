---
layout: full_article
title: "Mangrove ecosystem Segmentation from Drone Images using Otsu Method"
author: "Ni Made Dinda Pratiwi, I Made Widiartha"
categories: jik
canonical_url: https://jurnal.harianregional.com/jik/full-64482 
citation_abstract_html_url: "https://jurnal.harianregional.com/jik/id-64482"
citation_pdf_url: "https://jurnal.harianregional.com/jik/full-64482"  
comments: true
---

<p><span class="font1">p-ISSN: 2301-5373</span></p>
<p><span class="font1">e-ISSN: 2654-5101</span></p>
<p><span class="font1">Jurnal Elektronik Ilmu Komputer Udayana</span></p>
<p><span class="font1">Volume 9 No. 3, February 2021</span></p><a name="caption1"></a>
<h1><a name="bookmark0"></a><span class="font2" style="font-weight:bold;"><a name="bookmark1"></a>Mangrove Ecosystem Segmentation from Drone Images using Otsu Method</span></h1>
<p><span class="font1">Ni Made Dinda Pratiwi<sup>a1</sup></span><span class="font1" style="font-weight:bold;">, </span><span class="font1">I Made Widiartha<sup>a2</sup></span></p>
<p><span class="font1"><sup>a</sup>Informatics Department, Udayana University Bali, Indonesia</span></p>
<p><a href="mailto:1dinda0605@gmail.com"><span class="font1"><sup>1</sup>dinda0605@gmail.com</span></a></p>
<p><a href="mailto:2madewidiartha@unud.ac.id"><span class="font1"><sup>2</sup>madewidiartha@unud.ac.id</span></a></p>
<p><span class="font1" style="font-weight:bold;font-style:italic;">Abstract</span></p>
<p><span class="font1" style="font-style:italic;">Mangrove ecosystems are found mainly in tropical and subtropical coastal areas. they are playing a very important ecological role in land-ocean interfaces. These ecosystems are protecting the environment and providing a habitat that supports many living organisms. Identification of area images in mangrove ecosystems is very helpful in monitoring and conservation of this ecosystem. In this study, we will present the segmentation of drone image taken from TAHURA Ngurah Rai mangrove area using otsu method. The otsu method giving well accuracy to segmented image to divide mangrove area and non mangrove area. Because Otsu method operates on a grayscale image so that it cannot distinguish the dark green of the tree canopies from the dark shadows of the trees, then the segmentation accuracy will decrease.</span></p>
<p><span class="font1" style="font-weight:bold;font-style:italic;">Keywords: </span><span class="font1" style="font-style:italic;">Image Segmentation, Otsu Method, Thresholding, Mangrove, Drones</span></p>
<ul style="list-style:none;"><li>
<h3><a name="bookmark2"></a><span class="font1" style="font-weight:bold;"><a name="bookmark3"></a>1. &nbsp;&nbsp;&nbsp;Introduction</span></h3></li></ul>
<p><span class="font1">Unmanned aerial vehicles (UAV) has been heightened interest in the use for acquiring images for mapping and monitoring vegetation, over this past decade. UAVs commonly known as drones refer to small aircraft without a pilot on board with its associated elements such as ground station and communications link. The use of UAVs is very useful in helping for monitoring environmental management, road traffic analysis, mapping, and many other applications [1].</span></p>
<p><span class="font1">Mangrove ecosystems are found mainly in tropical and subtropical coastal areas. they are playing a very important ecological role in land-ocean interfaces. Mangrove ecosystem is a place for reciprocal relationships between abiotic components such as organic and inorganic compounds, protection from storms and erosion, aid in the breaking of waves, controlling seawater intrusion. In addition, the mangrove ecosystem has biological/ecological (sources of germplasm, and fish spawning sites), and economics. (NTFP, recreation, and infrastructure). It is extremely important to protect and preserve the mangrove ecosystem, by monitoring the condition of the mangrove ecosystem, and later it is used as material for mangrove management planning.</span></p>
<p><span class="font1">The mangrove ecosystem is difficult to penetrate because it has tall roots blocking the road, plus a muddy substrate that traps the feet. This becomes an obstacle when conducting direct monitoring of the mangrove ecosystem. Aerial photograph using drones could be a promising way in mangrove monitoring. The drones can be use to get images for mapping hard-to-reach areas, easy to launch on demand and to repeat surveys when required, can be programmed to fly at very low altitudes so they are not affected by the cloud cover conditions, taking imagery of higher resolution than satellite images.</span></p>
<p><span class="font1">Segmenting airborne drone images of mangrove ecosystems is an important part of classifying the image. Segmentation is the process of partitioning an image into multiple segments. In the process of image segmentation, several studies with varied approaches have been carried out.</span></p>
<p><span class="font1">Otsu method is global thresholding selection method, which it depends only gray value of the image. Otsu method is widely used because it is simple and effective [2]. There are several studies that have been made previously related to segmentation using otsu method. To segment</span></p>
<p><span class="font1">the roads and residential areas from the vegetation areas in remote sensing images. The Otsu method improves the image segmentation effectively. Because it directly operates on the gray level histogram, so it gets better accuracy and the precision than other thresholding methods [3].</span></p>
<p><span class="font1">In this study, the author will use otsu method to segment mangrove areas from the areas in drone image. segmentation will focus on determining image which parts are mangroves and not mangroves.</span></p>
<ul style="list-style:none;"><li>
<h3><a name="bookmark4"></a><span class="font1" style="font-weight:bold;"><a name="bookmark5"></a>2. &nbsp;&nbsp;Reseach Methods</span></h3></li></ul>
<p><span class="font1">In these research methods, the steps in the research will be explained. Subchapters of discussion that will be explained include :</span></p>
<ul style="list-style:none;"><li>
<h3><a name="bookmark6"></a><span class="font1" style="font-weight:bold;"><a name="bookmark7"></a>2.1 &nbsp;&nbsp;&nbsp;Datasets</span></h3></li></ul>
<p><span class="font1">The airborne imagery used in this study was acquired using drones flying over TAHURA Ngurah Rai Bali mangrove area. All the images are of size 4864x3648 , 72 dpi and have bit depth of 24. All the images are RGB images with color information ranging [0–255]. The amount of image data used is 5 drone images.</span></p>
<ul style="list-style:none;"><li>
<h3><a name="bookmark8"></a><span class="font1" style="font-weight:bold;"><a name="bookmark9"></a>2.2 &nbsp;&nbsp;&nbsp;Grayscaling</span></h3></li></ul>
<p><span class="font1">Grayscaling preprocessing is to convert the input image RGB to a grayscale image. This process is an image processing process to convert color images that have a matrix value of red, green, and blue respectively into grayscale images.</span></p>
<p><span class="font9" style="font-style:italic;">( R e d+G r e en+Blu</span><span class="font9"> e)</span></p>
<div>
<p><span class="font1">(1)</span></p>
</div><br clear="all">
<p><span class="font10" style="font-style:italic;">gray = -----------</span></p>
<div><img src="https://jurnal.harianregional.com/media/64482-1.jpg" alt="" style="width:172pt;height:128pt;">
<p><span class="font1" style="font-weight:bold;">Figure 1. </span><span class="font1">Grayscale Image</span></p>
</div><br clear="all">
<ul style="list-style:none;"><li>
<h3><a name="bookmark10"></a><span class="font1" style="font-weight:bold;"><a name="bookmark11"></a>2.3 &nbsp;&nbsp;&nbsp;Binary Image</span></h3></li></ul>
<p><span class="font1">Changing the grayscale image to binary image. Binary images are digital images that have only two possible pixel values, namely black and white. Globally, every pixel in the image is mapped into two values, namely 1 and 0, with the development function as in equation (2):</span></p>
<div>
<p><span class="font10" style="font-style:italic;">F<sub>t</sub>[i,j]</span><span class="font10"> = {</span></p>
</div><br clear="all">
<p><span class="font10" style="font-style:italic;">1 if F[i,j]≤T </span><span class="font10">0 </span><span class="font10" style="font-style:italic;">otherwise</span></p>
<div>
<p><span class="font1">(2)</span></p>
</div><br clear="all">
<div><img src="https://jurnal.harianregional.com/media/64482-2.png" alt="" style="width:182pt;height:128pt;">
<p><span class="font1" style="font-weight:bold;">Figure 2. </span><span class="font1">Binary Image</span></p>
</div><br clear="all">
<ul style="list-style:none;"><li>
<h3><a name="bookmark12"></a><span class="font1" style="font-weight:bold;"><a name="bookmark13"></a>2.4 &nbsp;&nbsp;&nbsp;Image Segmentation</span></h3></li></ul>
<p><span class="font1">The image will be segmented using otsu thresholding, to separate between the foreground and background on an image based on differences in brightness or lightness.</span></p>
<p><span class="font1">The otsu method aims to divide the gray image histogram into two different areas automatically without any help from the user to enter a threshold value [4]. The algorithm assumes that the image contains two classes of pixels, foreground pixels and background pixels, then calculates the optimum threshold separating the two classes so that their combined spread (intra-class variance) is minimal, or equivalently (because the sum of pairwise squared distances is constant), so that their inter-class variance is maximal [5].</span></p>
<p><span class="font1">Otsu's method, exhaustively search for the threshold that minimizes the intra-class variance (the variance within the class), defined as a weighted sum of variances of the two classes:</span></p>
<p><span class="font1">The weighted within–class variance is:</span></p>
<p><a href="#bookmark14"><span class="font9"><sub>σ</sub>^</span><span class="font10"><sub>c</sub>(t) = fc<sub>1</sub>(t)σ<sub>1</sub><sup>2</sup>(t)+ </span><span class="font10" style="font-style:italic;">k<sub>2</sub>(t)σ⅝)</span><span class="font1">(3)</span></a></p>
<p><span class="font1">Weights k1 and k2 are the probabilities of the two classes separated by a threshold t,σ1and σ2 are the variances of these two classes.</span></p>
<p><span class="font1">The class probabilities </span><span class="font10" style="font-style:italic;">k<sub>1</sub>(t)</span><span class="font1"> and </span><span class="font10" style="font-style:italic;">k<sub>2</sub>(t)</span><span class="font1"> are computed from the L bins of histogram:</span></p>
<p><a href="#bookmark15"><span class="font10" style="font-style:italic;">k</span><span class="font9" style="font-style:italic;">ι</span><span class="font10" style="font-style:italic;">(t) = ∑<sup>t</sup></span><span class="font9" style="font-style:italic;">~</span><span class="font10" style="font-style:italic;"><sup>1</sup></span><span class="font9" style="font-style:italic;">1 </span><span class="font10" style="font-style:italic;">p(i)</span><span class="font1">(4)</span></a></p>
<p><a href="#bookmark16"><span class="font10" style="font-style:italic;">k</span><span class="font9" style="font-style:italic;">ι</span><span class="font10" style="font-style:italic;">(t) = ∑<sup>t</sup></span><span class="font9" style="font-style:italic;">-1</span><span class="font10" style="font-style:italic;">v(i)</span><span class="font1">(5)</span></a></p>
<p><span class="font1">Otsu shows that minimizing the intra-class variance is the same as maximizing inter-class variance:</span></p>
<p><a href="#bookmark17"><span class="font10" style="font-style:italic;">σ</span><span class="font9" style="font-style:italic;">^2c</span><span class="font10" style="font-style:italic;">(t) = σ<sup>2</sup> - σ<sup>2</sup> </span><span class="font9" style="font-style:italic;">c</span><span class="font10" style="font-style:italic;">(t)</span><span class="font1">(6)</span></a></p>
<p><span class="font1">The total variance can be express as :</span></p>
<p><a href="#bookmark18"><span class="font10">σ<sup>2</sup> (t) = </span><span class="font10" style="font-style:italic;">σ<sup>2</sup></span><span class="font9" style="font-style:italic;">c</span><span class="font10" style="font-style:italic;">(t)</span><span class="font10"> + </span><span class="font10" style="font-style:italic;">k</span><span class="font9" style="font-style:italic;">ι</span><span class="font10" style="font-style:italic;">(t)[1</span><span class="font10"> - </span><span class="font10" style="font-style:italic;">k</span><span class="font9" style="font-style:italic;">ι</span><span class="font10" style="font-style:italic;">(t)][μ</span><span class="font9" style="font-style:italic;">ι</span><span class="font10" style="font-style:italic;">(t)</span><span class="font10"> - Mt)] <sup>2</sup></span></a></p>
<ul style="list-style:none;"><li>
<h3><a name="bookmark19"></a><span class="font1" style="font-weight:bold;"><a name="bookmark20"></a>2.5 &nbsp;&nbsp;&nbsp;Evaluation</span></h3></li></ul>
<p><span class="font1">Evaluation is done on a binary image based on the foreground and background. The evaluation or testing process uses confusion matrix by calculating quantitative values of accuracy to its groundtruth image.</span></p>
<p><span class="font1">The confusion matrix is a table of visualizing the algorithm process. Each row in the matrix represents an example of each actual class while each column represents an example of the predicted class. Confusion matrix for background (N) and foreground (P) classes.</span></p><img src="https://jurnal.harianregional.com/media/64482-3.jpg" alt="" style="width:222pt;height:150pt;">
<p><span class="font1" style="font-weight:bold;">Figure 3. </span><span class="font1">Confusion Matrix</span></p>
<p><span class="font1">Accuracy is a value calculated from the number of properly detected background and foreground pixels with the total number of background and foreground pixels.</span></p>
<div>
<h2><a name="bookmark21"></a><span class="font11" style="font-style:italic;"><a name="bookmark22"></a>Accuracy</span><span class="font11"> =</span></h2>
</div><br clear="all">
<div>
<p><span class="font6" style="font-style:italic;">TP+TN</span></p>
<p><span class="font6" style="font-style:italic;">TP+FP+TN+FN</span></p>
</div><br clear="all">
<div>
<p><span class="font1">(8)</span></p>
</div><br clear="all">
<ul style="list-style:none;"><li>
<h3><a name="bookmark23"></a><span class="font1" style="font-weight:bold;"><a name="bookmark24"></a>3. &nbsp;&nbsp;&nbsp;Result and Discussion</span></h3></li></ul>
<p><span class="font1">This study, several test results were obtained, differentiating the mangrove area and non mangrove area :</span></p>
<p><span class="font1" style="font-weight:bold;">Table 1</span><span class="font1">. Segmentation Result</span></p>
<table border="1">
<tr><td style="vertical-align:middle;">
<p><span class="font1">No.</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">Input Image</span></p></td><td colspan="2" style="vertical-align:middle;">
<p><span class="font1">Otsu output image</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">Accuracy</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font1">1.</span></p></td><td style="vertical-align:top;">
<p><span class="font7">⅛&gt;!</span></p>
<p><span class="font7">'⅛wHKBMτ</span></p></td><td style="vertical-align:top;"></td><td style="vertical-align:middle;">
<p><span class="font0">.■.'.'''■.■&lt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;' -■</span></p></td><td style="vertical-align:top;">
<p><span class="font1">0.94720019395</span></p>
<p><span class="font1">99204</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font1">2.</span></p></td><td style="vertical-align:top;">
<p><span class="font7"><sup>i</sup> '¾⅛<sup>,</sup>⅛</span></p></td><td style="vertical-align:top;"></td><td style="vertical-align:top;">
<p><span class="font3" style="font-weight:bold;">■■■m</span></p></td><td style="vertical-align:top;">
<p><span class="font1">0.90598016036</span></p>
<p><span class="font1">18421</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font1">3.</span></p></td><td style="vertical-align:top;">
<p><span class="font5" style="font-variant:small-caps;">≡^im</span></p>
<p><span class="font7">- <sup>;</sup>’ ⅛^⅛</span></p></td><td style="vertical-align:top;"></td><td style="vertical-align:top;">
<p><span class="font3" style="font-weight:bold;">^O^^RΠH</span></p>
<p><span class="font3" style="font-weight:bold;">wW⅛⅛B</span></p></td><td style="vertical-align:top;">
<p><span class="font1">0.61429489572</span></p>
<p><span class="font1">5127</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font1">4.</span></p></td><td style="vertical-align:top;">
<p><span class="font4">L <sup>;</sup> MM</span></p>
<p><span class="font7">■ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- &nbsp;&nbsp;&nbsp;'■ ∖y&lt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<sup>u</sup></span></p>
<p><span class="font7">lBIfe⅛<sup>5</sup>⅛&lt;; ■ ⅛⅛⅛</span></p>
<p><span class="font7">⅛SII⅛⅛⅛siffls^</span></p></td><td style="vertical-align:top;"></td><td style="vertical-align:middle;">
<p><span class="font3" style="font-weight:bold;">, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;i’---</span></p>
<p><span class="font4">HMHi</span></p></td><td style="vertical-align:top;">
<p><span class="font1">0.93041524420</span></p>
<p><span class="font1">37453</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font1">5.</span></p></td><td style="vertical-align:middle;">
<p><span class="font7">⅛S&gt; ¼&lt;U∕' I</span></p>
<p><span class="font7"><sup>7</sup>''&lt;</span></p></td><td style="vertical-align:top;">
<p><span class="font2" style="font-weight:bold;">'⅛ ^3H ¾o</span><span class="font2" style="font-weight:bold;text-decoration:underline;">⅞θ</span><span class="font2" style="font-weight:bold;">iw</span><span class="font8" style="font-weight:bold;">∣</span><span class="font2" style="font-weight:bold;">ιι</span><span class="font2" style="font-weight:bold;text-decoration:underline;">^</span></p></td><td style="vertical-align:top;">
<p><span class="font3" style="font-weight:bold;text-decoration:underline;">K</span><span class="font3" style="font-weight:bold;">⅛⅜⅜</span></p></td><td style="vertical-align:top;">
<p><span class="font1">0.74911152424</span></p>
<p><span class="font1">90478</span></p></td></tr>
</table>
<p><span class="font1">From above results, we can see that the results of the accuracy value have the highest value 94,72% and the lowest value 61,42%.</span></p>
<p><span class="font1">The otsu method doesn’t giving best performance to the image that has a lot shadows. Because Otsu method operates on a grayscale image so that it cannot distinguish the dark green of the tree canopies from the dark shadows of the trees.</span></p>
<ul style="list-style:none;"><li>
<h3><a name="bookmark25"></a><span class="font1" style="font-weight:bold;"><a name="bookmark26"></a>4. &nbsp;&nbsp;&nbsp;Conclusion</span></h3></li></ul>
<p><span class="font1">This study discusses mangrove segmentation from drone image TAHURA Ngurah Rai Bali mangrove area. The method used is otsu threshold method. Previously the preprocessing process was done by grayscaling and binarization to produce a good system output in the segmentation process.</span></p>
<p><span class="font1">Segmentation using the otsu method gives quite good results. But gives fewer results if the image used has a lot of shadows. The Otsu method operates on a grayscale image so that it cannot distinguish the dark green of the tree canopies from the dark shadows of the trees.</span></p>
<h3><a name="bookmark27"></a><span class="font1" style="font-weight:bold;"><a name="bookmark28"></a>References</span></h3>
<ul style="list-style:none;"><li>
<p><span class="font1">[1] &nbsp;&nbsp;&nbsp;E. Zimudzi, I. Sanders, N. Rollings and C. Omlin, &quot;Segmenting mangrove ecosystems drone images using SLIC superpixels,&quot; </span><span class="font1" style="font-style:italic;">Geocarto International,</span><span class="font1"> 2018.</span></p></li>
<li>
<p><span class="font1">[2] &nbsp;&nbsp;&nbsp;Khushbu and I. Vats, &quot;Otsu Image Segmentation Algorithm: A Review,&quot; </span><span class="font1" style="font-style:italic;">International Journal of Innovative Research in Computer and Communication Engineering,</span><span class="font1"> vol. 5, no. 5, pp. 11945-11948, 2017.</span></p></li>
<li>
<p><span class="font1">[3] &nbsp;&nbsp;&nbsp;C. V. V. S. Srinivas, M. V. R. V. Prasad and M. Sirisha, &quot;Remote Sensing Image Segmentation using OTSU Algorithm,&quot; </span><span class="font1" style="font-style:italic;">International Journal of Computer Applications,</span><span class="font1"> vol. 178, p. 0975 – 8887, 2019.</span></p></li>
<li>
<p><span class="font1">[4] &nbsp;&nbsp;&nbsp;P. Harnis, Y. A. Sari and M. A. Rahman, &quot;Segmentasi Citra Kue Tradisional menggunakan Otsu Thresholding pada Ruang Warna CIE LAB,&quot; </span><span class="font1" style="font-style:italic;">Jurnal Pengembangan Teknologi Informasi dan Ilmu Komputer,</span><span class="font1"> vol. 3, pp. 6799-6808, 2019.</span></p></li>
<li>
<p><span class="font1">[5] &nbsp;&nbsp;&nbsp;S. I. Syafi’i, R. T. Wahyuningrum and A. Muntasa, &quot;Segmentasi Obyek Pada Citra Digital Menggunakan Metode Otsu Thresholding,&quot; </span><span class="font1" style="font-style:italic;">Jurnal Informatika,</span><span class="font1"> vol. 13, no. 1, pp. 1-8, 2015.</span></p></li>
<li>
<p><span class="font1">[6] &nbsp;&nbsp;&nbsp;P. P. Vijay and N. C. Patil, &quot;Gray Scale Image Segmentation using OTSU Thresholding Optimal Approach,&quot; </span><span class="font1" style="font-style:italic;">International Journal for Scientific Research and Development,</span><span class="font1"> vol. 2, no. 5, pp. 20-24, 2016.</span></p></li></ul>
<p><span class="font1">This page is intentionally left blank</span></p>
<p><span class="font1">396</span></p>