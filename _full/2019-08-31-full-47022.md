---
layout: full_article
title: "Detecting the Ripeness of Harvest-Ready Dragon Fruit using Smaller VGGNet-Like Network"
author: "I Made Wismadi, Duman Care Khrisne, I Made Arsa Suyadnya"
categories: jeei
canonical_url: https://jurnal.harianregional.com/jeei/full-47022 
citation_abstract_html_url: "https://jurnal.harianregional.com/jeei/id-47022"
citation_pdf_url: "https://jurnal.harianregional.com/jeei/full-47022"  
comments: true
---

<p><span class="font5">Journal of Electrical, Electronics and Informatics, Vol. 3 No. 2, August 2019</span></p>
<p><span class="font5">35</span></p><a name="caption1"></a>
<h1><a name="bookmark0"></a><span class="font7"><a name="bookmark1"></a>Detecting the Ripeness of Harvest-Ready Dragon Fruit using Smaller </span><span class="font7" style="font-style:italic;">VGGNet-Like Network</span></h1>
<h3><a name="bookmark2"></a><span class="font6"><a name="bookmark3"></a>I Made Wismadi<sup>1</sup>, Duman Care Khrisne<sup>*2</sup>, I Made Arsa Suyadnya<sup>3</sup></span></h3>
<ul style="list-style:none;"><li>
<p><span class="font5"><sup>1,2,3</sup>Department of Electrical Engineering, Faculty of Engineering,</span></p></li></ul>
<p><span class="font5">Udayana University, Badung, Indonesia</span></p>
<p><span class="font5">Email: </span><a href="mailto:duman@unud.ac.id"><span class="font5">duman@unud.ac.id</span></a></p>
<p><span class="font4" style="font-weight:bold;font-style:italic;">Abstract</span><span class="font4" style="font-weight:bold;">—This study has a purpose to develop an application to detect the ripeness of the dragon fruit with the deep learning approach using the Smaller VGGNet-like Network method. In this study, the dragon fruit are classified into two classes: ripe or ready for harvest and still raw, by using the Convolutional Neural Network (CNN). The training process utilize the hard packages in python with the backend tensorflow. The model in this research is tested using the confusion matrix and ROC method with the condition that 100 new data are tested. Based on the test conducted, the level of accuracy in classifying the ripeness of the dragon fruit is 91%, and the test using 20 epoch, 50 epoch, 100 epoch, and 500 epoch produced an AUROC value of 0,95.</span></p>
<p><span class="font4" style="font-weight:bold;font-style:italic;">Keywords</span><span class="font4">—</span><span class="font4" style="font-weight:bold;font-style:italic;">Dragon Fruit, Deep Learning, Smaller VGGNet-like Network</span><span class="font4" style="font-weight:bold;">.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font5">I. &nbsp;&nbsp;&nbsp;INTRODUCTION</span></p></li></ul>
<p><span class="font5">In Indonesia, the dragon fruit has become popular since the year of 2000. Several regions that produce dragon fruit in Indonesia are Jember, Malang, Pasuruan, and also Bali. The ripeness of the dragon fruit is among the most important factors which must be given attention. The dragon fruit is a non-climacteric fruit (the type of fruit which will not become ripe if it is harvested in an unripe condition). Additionally, dragon fruit do not require substances such as carbide, ethylene gas, or CO</span><span class="font2">2 </span><span class="font5">to hasten the ripening process. Consequently, the dragon fruit must be harvested when they are fully ripe so that the quality of the fruit can be maintained after it is harvested and even when it is stored [1]. Today, the dragon fruit farmers still use the manual method to determine whether the fruit is ready to harvest. The dragon fruit farmers must count the time from when the flowers first bloom until it bears fruit, to determine the right time to harvest it.</span></p>
<p><span class="font5">This study tried to overcome the problem of detecting the ripeness of harvest-ready dragon fruit by building an application using deep learning approach and smaller VGGNet-Like Network method. The deep learning approach classifies data in accordance with the label given in a training session after studying the extracted feature from each data repeatedly in order to differentiate one label from other labels. In the data testing session, the data tested can be analyzed in accordance with the specific characteristics of each label from the training session results.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font5">II. &nbsp;&nbsp;&nbsp;RELATED WORK</span></p></li></ul>
<p><span class="font5">To better understand about the ripeness of dragon fruit, research conducted by [2] regarding the influence of time of harvest and storage temperature on the quality and the storability of the super-red dragon fruit (</span><span class="font5" style="font-style:italic;">Hylocereus Costaricensis</span><span class="font5">) revealed that there is a very significant interaction between the harvest time, the storage room</span></p>
<p><span class="font5">temperature, and the cumulative yield loss, freshness, and hardness. Another research was conducted by [3] in which a dragon fruit ripeness quality assessment tool was designed using the image processing technique with the HSV image segmentation method. The test result of the dragon fruit assessment process using the HSV image segmentation method, after conducting 100 trials showed a success percentage of 86% and the time needed to assess one dragon fruit is between 15 to 22 seconds. Research [3] uses a machine learning approach in an attempt to determine the ripeness of dragon fruit, but the use of color features (HSV) triggers a weakness, dragon fruit cannot be checked in its natural state.</span></p>
<p><span class="font5">Several studies [4], [5] state that the use of deep learning is very good for overcoming these machine learning problems. Based on these issues and previous studies, an application to determine the ripeness of the dragon fruit is developed in this study by utilizing the deep learning classification approach with the VGGNet-like Network method. For this, the deep learning approach is needed to analyze the picture of the dragon fruit’s surface and classify the dragon fruit into the category of ripe or not ripe with an optimal accuracy. The deep learning approach with the convolutional neural network architecture and the Smaller VGGNet-like Network method are used in this research to develop the application to detect the ripeness level of the dragon fruit.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font5">III. &nbsp;&nbsp;&nbsp;PROPOSED APPROACH</span></p></li></ul>
<p><span class="font5">This study proposed the use of CNN model to classify the harvest-ready of dragon fruit and use a smaller VGGNet-Like Network to create the model. We use deep learning approach which is a field in machine learning that utilize the artificial neural network to solve an issue using a large dataset. A deep (many layers) artificial neural network application can be implemented on an existing machine learning algorithm so that computers now can learn at a great speed, accuracy and scale. Feature engineering is one of the main features in deep learning to extract useful</span></p>
<p><span class="font5">patterns from the data which will assist the model in differentiating classes.</span></p>
<div><img src="https://jurnal.harianregional.com/media/47022-1.jpg" alt="" style="width:223pt;height:168pt;">
<p><span class="font3">Fig. 1. Ripe and Ready for Harvest Classification Results</span></p>
</div><br clear="all">
<p><span class="font5">In this study, two processes are performed on the system, namely the training process and the test process. In the training process, there will be pictures which are used to develop the model. The training pictures have their own labels because at the start of the process, the data (pictures) are manually categorized into ready for harvest and not ready for harvest with the help of experts (cultivators). The training pictures are then directed to the VGGNet-like features extraction. After this step, the system will be trained through several epochs to produce a model called the VGGNet-like Model. If the training process has been done, the next step is the labelling process. It starts with the picture which will be extracted into the VGGNet-like features extraction, and afterwards directed to the VGGNet-like Model which was previously produced through the training process. This model contains the VGGNet which has the task to predict whether the picture of the dragon fruit is categorized as ready for harvest or not. Lastly, is the process of producing pictures with tables.</span></p>
<div><img src="https://jurnal.harianregional.com/media/47022-2.jpg" alt="" style="width:199pt;height:150pt;">
<p><span class="font3">Fig. 2. Training Loss and Accuracy for 20 Epochs</span></p>
</div><br clear="all">
<p><span class="font5">To determine the performance of the application model produced, the labeling accuracy of the validation picture is tested. The labeled test pictures are directed to the VGGNet-like Model which were produced in the training process. The system will predict whether the fruit in the test pictures are ready to harvest or not, producing labeled pictures. Afterwards, the labeled pictures will be compared with the test pictures, if the labels are the same, then the performance of the model can be said to be accurate. However, if the label results are different, it can be said that it is inaccurate. The number of pictures used in the test process are 20% from the total amount of pictures provided.</span></p>
<div><img src="https://jurnal.harianregional.com/media/47022-3.jpg" alt="" style="width:202pt;height:151pt;">
<p><span class="font3">Fig. 3. Training Loss and Accuracy for 50 Epochs</span></p>
</div><br clear="all">
<ul style="list-style:none;"><li>
<p><span class="font5">IV. &nbsp;&nbsp;&nbsp;RESULTS</span></p></li></ul>
<p><span class="font5">The main process in creating this model is started with the data training process. This process has a purpose to form the model which will be used for data testing. The parameter used to measure the model’s level of success is the accuracy value. The accuracy value of the model can be determined by conducting the data testing. The training process used the hard packages in python with the backend tensorflow.</span></p>
<p><span class="font5">Fig. 1 Below are the result examples of the unripe category which were attained after the classification process conducted on the available test data. From Fig. 1, it can be seen that the program output, through the classification process, shows that the dragon fruit is classified as ripe. If the dragon fruit pictures of this class are classified as ripe, the results are correct, but if it is classified as unripe, the results are incorrect. The truth percentage of each picture’s classification results are also displayed.</span></p>
<div><img src="https://jurnal.harianregional.com/media/47022-4.jpg" alt="" style="width:202pt;height:151pt;">
<p><span class="font3">Fig. 4. Training Loss and Accuracy for 100 Epochs</span></p>
</div><br clear="all">
<p><span class="font5">After conducting several processes in the Convolutional Neural Network (CNN) algorithm, the training and validation results are attained. This process utilize iterations with a total of 20 epochs, 50 epochs, 100 epochs, and 500 epochs and a learning rate value of 0.001. Displayed below is the comparison of all the epochs used in the training process.</span></p>
<p><span class="font3">TABLE I. &nbsp;&nbsp;ACCURACY BASED ON EPOCH</span></p>
<table border="1">
<tr><td style="vertical-align:top;">
<p><span class="font5">Epoch</span></p></td><td style="vertical-align:middle;">
<p><span class="font5">Accuracy</span></p>
<p><span class="font5">Validation</span></p></td><td style="vertical-align:middle;">
<p><span class="font5">Loss</span></p>
<p><span class="font5">Validation</span></p></td><td style="vertical-align:middle;">
<p><span class="font5">Time (Seconds)</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font5">20</span></p></td><td style="vertical-align:middle;">
<p><span class="font5">0,8889</span></p></td><td style="vertical-align:middle;">
<p><span class="font5">0,4989</span></p></td><td style="vertical-align:middle;">
<p><span class="font5">1400</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font5">50</span></p></td><td style="vertical-align:middle;">
<p><span class="font5">0,9667</span></p></td><td style="vertical-align:middle;">
<p><span class="font5">0,1441</span></p></td><td style="vertical-align:middle;">
<p><span class="font5">4000</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font5">100</span></p></td><td style="vertical-align:middle;">
<p><span class="font5">0,6556</span></p></td><td style="vertical-align:middle;">
<p><span class="font5">2,0282</span></p></td><td style="vertical-align:middle;">
<p><span class="font5">7200</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font5">500</span></p></td><td style="vertical-align:middle;">
<p><span class="font5">0,9111</span></p></td><td style="vertical-align:middle;">
<p><span class="font5">0,4997</span></p></td><td style="vertical-align:middle;">
<p><span class="font5">36000</span></p></td></tr>
</table>
<div><img src="https://jurnal.harianregional.com/media/47022-5.jpg" alt="" style="width:211pt;height:158pt;">
<p><span class="font3">Fig. 5. Training Loss and Accuracy for 100 Epochs</span></p>
</div><br clear="all">
<p><span class="font5">Based on Table I and by using a learning rate value of 0,001, decently high accuracies were attained, reaching up to 0,9667. From assessing the table, it can be concluded that the closer the value used is to 50 epoch, the higher the accuracy of the testing results.. However, when the epoch is increased to a value above 50, the accuracy experiences a fall. This may be due to the number of epochs that are too high which may also influence the number of dataset.</span></p>
<p><span class="font5">From the confusion matrix test results for 20 epoch, 50 epoch, 100 epoch, and 500 epoch, the FPR value and TPR value are attained and displayed in Table II. Afterwards, using the FPR and TPR values, the receiver operating characteristic curve is formed and shown in Fig.5.</span></p>
<p><span class="font3">TABLE II. FPR AND RECALL (TPR) OF EACH EPOCH</span></p>
<table border="1">
<tr><td style="vertical-align:middle;">
<p><span class="font5">Epoch</span></p></td><td style="vertical-align:middle;">
<p><span class="font5">20</span></p></td><td style="vertical-align:middle;">
<p><span class="font5">50</span></p></td><td style="vertical-align:middle;">
<p><span class="font5">100</span></p></td><td style="vertical-align:middle;">
<p><span class="font5">500</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font5">FPR</span></p></td><td style="vertical-align:middle;">
<p><span class="font5">0,04</span></p></td><td style="vertical-align:middle;">
<p><span class="font5">0,16</span></p></td><td style="vertical-align:middle;">
<p><span class="font5">0,74</span></p></td><td style="vertical-align:middle;">
<p><span class="font5">0</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font5">TPR</span></p></td><td style="vertical-align:middle;">
<p><span class="font5">0,88</span></p></td><td style="vertical-align:middle;">
<p><span class="font5">0,98</span></p></td><td style="vertical-align:middle;">
<p><span class="font5">0,98</span></p></td><td style="vertical-align:middle;">
<p><span class="font5">0,84</span></p></td></tr>
</table><img src="https://jurnal.harianregional.com/media/47022-6.jpg" alt="" style="width:223pt;height:101pt;">
<p><span class="font0" style="font-weight:bold;">Fake Positive Rate</span></p>
<p><span class="font3">Fig. 5. ROC Curve</span></p>
<p><span class="font5">To attain the AUROC, the area is calculated using the trapezoid method which is shown in the equation below.</span></p>
<div>
<p><span class="font1" style="font-style:italic;">Σ</span><span class="font2" style="font-style:italic;">n<sup>-</sup>1</span><span class="font5"> 1</span></p>
<p><span class="font5">∙-<sub>1</sub> 2 (<sup>yli</sup>+<sup>y2i</sup>)</span></p>
</div><br clear="all">
<div>
<p><span class="font5">× </span><span class="font5" style="font-style:italic;">ωi</span></p>
</div><br clear="all">
<h2><a name="bookmark4"></a><span class="font5"><a name="bookmark5"></a>AUROC = (</span><span class="font2">1 </span><span class="font5">(0,84 + 0,88) × 0,04) + (</span><span class="font2">1 </span><span class="font5">(0,88 + 0,98) × 0,12) + (0,98 × 0,58) + (<sup>1</sup> (0,98 + 1) × 0,26)</span></h2>
<p><span class="font5">= 0,03 + 0,11 + 0,56 + 0,25</span></p>
<p><span class="font5">= 0,95</span></p>
<p><span class="font5">Referring to [6], the AUROC level of truth, measured for the performance of the dragon fruit ripeness detection application, ranges between 0,9 – 1,0 (very good).</span></p>
<ul style="list-style:none;"><li>
<p><span class="font5">V. &nbsp;&nbsp;&nbsp;CONCLUSION</span></p></li></ul>
<p><span class="font5">Based on the results and analysis conducted, several conclusions were attained:</span></p>
<p><span class="font5">The dragon fruit ripeness detection application is developed by firstly training the prepared dataset (training process), which produced labels and models that are used by the system to examine the test data (testing process) and label the output pictures.</span></p>
<p><span class="font5">From the model training conducted with 20 epoch, 50 epoch, 100 epoch, and 500 epoch and a learning rate value of 0.001, a model with a maximum validation accuracy of 0.9667 is attained, which is the training model with 50 epoch. This study utilize new testing data, with a total of 100 pictures which were tested using the model formed. The test results of the 50 epoch model shows 91% accuracy level in classifying the ripeness of the dragon fruit.</span></p>
<p><span class="font5">The test on the model in this study utilize the confusion matrix method, with a test condition in which the 100 test data must be new. To determine the false positive rate and true positive rate value of the epochs tested, the AUROC value attained from using the trapezoid method is 0,95 which is categorized as very good.</span></p>
<p><span class="font5">REFERENCES</span></p>
<ul style="list-style:none;"><li>
<p><span class="font5">[1] &nbsp;&nbsp;&nbsp;&nbsp;F. L. Bellec, F. Vaillant, and E. Imbert, “Pitahaya</span></p></li></ul>
<p><span class="font5">(Hylocereus spp): a new fruit crop, a market with a future,” </span><span class="font5" style="font-style:italic;">Fruit</span><span class="font5">, vol. 61, no. 4, pp. 237–250, 2006.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font5">[2] &nbsp;&nbsp;&nbsp;T. Istianingsih and D. Efendi, “Pengaruh Umur</span></p></li></ul>
<p><span class="font5">Panen dan Suhu Simpan terhadap Umur Simpan Buah Naga Super Red (Hylocereus Costaricensis),” </span><span class="font5" style="font-style:italic;">J. Hort. Indones.</span><span class="font5">, vol. 4, no. 1, pp. 54–61, 2013.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font5">[3] &nbsp;&nbsp;&nbsp;Sustiono and W. S. Pambudi, “Rancang Bangun</span></p></li></ul>
<p><span class="font5">Pemilahan Kualitas Buah Naga Menggunakan Teknik Image Processing dengan Metode Image Segmentation HSV,” </span><span class="font5" style="font-style:italic;">J. Sains dan Inform.</span><span class="font5">, vol. 1, no. 2, pp. 28–37, 2015.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font5">[4] &nbsp;&nbsp;&nbsp;D. C. Khrisne and I. M. A. Suyadnya, “Indonesian</span></p></li></ul>
<p><span class="font5">Herbs and Spices Recognition using Smaller VGGNet-like Network,” in </span><span class="font5" style="font-style:italic;">2018 International Conference on Smart Green Technology in Electrical and Information Systems (ICSGTEIS)</span><span class="font5">, 2018, October, pp. 221–224.</span></p>
<table border="1">
<tr><td style="vertical-align:top;">
<p><span class="font5">[5]</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">K. Simonyan and A. Zisserman, “Very deep &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Receiver Operating Characteristic (ROC) Curve,”</span></p>
<p><span class="font5">convolutional networks for large-scale image &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2016. [Online]. Available:</span></p>
<p><span class="font5">recognition,” in </span><span class="font5" style="font-style:italic;">arXiv preprint arXiv:1409.1556</span><span class="font5">, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><a href="http://www.statisticshowto.com/receiver-operating-"><span class="font5">http://www.statisticshowto.com/receiver-operating-</span></a></p>
<p><span class="font5">2014. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;characteristic-roc-curve/, . [Accessed: 09-Sep-</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font5">[6]</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">Stephanie, “Receiver Operating Characteristic &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2018].</span></p>
<p><span class="font5">(ROC) Curve: Definition, Example. Retrieved from</span></p></td></tr>
</table>