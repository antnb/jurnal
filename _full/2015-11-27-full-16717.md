---
layout: full_article
title: "DATA MINING USING FUZZY METHOD FOR CUSTOMER RELATIONSHIP MANAGEMENT IN RETAIL INDUSTRY"
author: "Yohana Nugraheni"
categories: lontar
canonical_url: https://jurnal.harianregional.com/lontar/full-16717 
citation_abstract_html_url: "https://jurnal.harianregional.com/lontar/id-16717"
citation_pdf_url: "https://jurnal.harianregional.com/lontar/full-16717"  
comments: true
---

<p><span class="font2">LONTAR KOMPUTERVOL. 4, NO. 1, APRIL 2013</span></p>
<p><span class="font2">ISSN: 2088-1541</span></p><a name="caption1"></a>
<h1><a name="bookmark0"></a><span class="font3" style="font-weight:bold;"><a name="bookmark1"></a>DATA MINING USING FUZZY METHOD FOR CUSTOMER RELATIONSHIP MANAGEMENT IN RETAIL INDUSTRY</span></h1>
<h3><a name="bookmark2"></a><span class="font2" style="font-weight:bold;"><a name="bookmark3"></a>Yohana Nugraheni</span></h3>
<p><span class="font2">STIKOM, Bali, Indonesia e-mail: </span><a href="mailto:yohana_biz@yahoo.com"><span class="font2">yohana_biz@yahoo.com</span></a></p>
<p><span class="font2" style="font-weight:bold;font-style:italic;">Abstrak</span></p>
<p><span class="font2" style="font-style:italic;">Masalah yang umum muncul dalam industri retail adalah bagaimana mengidentifikasi pelanggan potensial. Sebuah industri retail dapat mengidentifikasi pelanggan terbaiknya melalui segmentasi pelanggan dengan menerapakan teknologi data mining dan konsep customer relationship management (CRM). Paper ini memperlihatkan proses data mining dari data pelanggan dalam perusahaan retail dengan mengkombinasikan algoritma fuzzy RFM dengan fuzzy c-means (FCM) dan algoritma fuzzy subtractive. Data yang digunakan dalam riset terdiri dari 3.000.000 baris data transaksi dari tahun 2006 sampai 2010. Data ini ditransfer ke 499 RFM data untuk masing-masing periode waktu.Penelitian ini menguji dua sampai enam cluster dengan mengubah nilai nomer cluster (FCM) dan radii (fuzzy subtractive). Hasil clustering kemudian akan dikelompokkan untuk menentukan segmentasi pelanggan menggunakan model fuzzy RFM. Modified partition coefficient dan partition entropy index digunakan untuk mengevaluasi unjuk kerja kedua algoritma diatas.Hasil yang didapat dari penelitian ini ternyata FCM mempunyai tingkat validitas yang lebih baik daripada fuzzy subtractive. Hasil segmentasi Fuzzy RFM memperlihatkan bahwa fuzzy subtractive tidak dapat membentuk sebuah cluster yang dikelompokkan sebagai pelanggan potensial, oleh karena itu FCM lebih sesuai digunakan untuk segmentasi pelanggan di industri retail.</span></p>
<p><span class="font2" style="font-weight:bold;font-style:italic;">Kata kunci: </span><span class="font2" style="font-style:italic;">fuzzy RFM model,fuzzy c-means, fuzzy subtractive, modified partition coefficient, partition entropy</span></p>
<p><span class="font2" style="font-weight:bold;font-style:italic;">Abstract</span></p>
<p><span class="font2" style="font-style:italic;">A problem that appears in a retail industry with a great quantity of customers is how to identify potential customers. A retail industry could identify their best customer through customer segmentation by applying data miningand customer relationship managementconcept. This paper presents data mining process from customer's data in retail company by combining fuzzy RFM model with fuzzy c-meansand fuzzy subtractive algorithm. The dataconsisted of 3.000.000 rows of transaction data from 2006 to 2010. The data transferred to 499 RFM data for each time period selected. Experiments tried two to six clusters by changing the value of cluster number (FCM) and radii(fuzzy subtractive). The clustering result will then be classified to determine customer segmentation using fuzzy RFM models. The modified partition coefficient and partition entropy indexes used to evaluate the performance of both clustering algorithm.The results indicate that FCM has a higher validity rate than fuzzy subtractive. Fuzzy RFM segmentationindicates that fuzzy subtractive can not form a cluster that are categorized as potential customers, therefore FCM is more appropriate for customer segmentation in retail industry.</span></p>
<p><span class="font2" style="font-weight:bold;font-style:italic;">Keywords: </span><span class="font2" style="font-style:italic;">fuzzy RFM model,fuzzy c-means, fuzzy subtractive, modified partition coefficient, partition entropy</span></p>
<ul style="list-style:none;"><li>
<h3><a name="bookmark4"></a><span class="font2" style="font-weight:bold;"><a name="bookmark5"></a>1. &nbsp;&nbsp;&nbsp;Introduction</span></h3></li></ul>
<p><span class="font2">In the midst of a tight business competition nowadays, retail companies have shifted their attention from simply developing products and superior service to the creation of personal</span></p>
<p><span class="font2">experiences of customer. This is done with a full awareness that the relationship between companies and customer is essential to support the development and sustainability of the company [1]. According to the Pareto law (the law 80:20), only 20% of all customers represent 80% of corporate revenue. In this case, different customers represent different values.The management of retail companies should be able to recognize the best customer and increasing the company’s understanding of customers’ needs as individual to maintain customer value, satisfaction and loyalty.</span></p>
<p><span class="font2">Customer relationship management (CRM) has grown in recent decades to reflect the primary role of the consumer for setting corporate strategy. CRM is the strategy for building, managing, and strengthening loyal and long-lasting customer relationships. CRM should be a customercentric approach based on customer insight. Its scope should be the ‘‘personalized’’ handling of customers as distinct entities through the identification and understanding of their differentiated needs, preferences, and behaviors [1]. To succeed with CRM and address theafore mentioned objectives, organizations need to gain insight into customers, their needs, and wants through data analysis. This is where analytical CRM comes in. Analytical CRM is concerned with capturing, storing, extracting, integrating, processing, interpreting, distributing, using and reporting customer-related data to enhance both customer and company value [3]. Analytical CRM builds on the foundation of customer-related information. Customer-related data may be found in enterprise-wide repositories: sales data (purchase history), financial data (payment history, credit score), marketing data (campaign response, loyalty scheme data) and service data. With the application of data mining technology, a company can then interrogate these data for customer identification by segmenting customer [2]. Data mining aims to extract knowledge and insight through the analysis of large amounts of data using sophisticated modeling techniques. It converts data into knowledge and actionable information. The purpose of customer segmentation process is to provide an assessment of the customers (customer scoring) and determines profile of the customer [2], so a company can determine customer behavior and implement appropriate marketing strategies to maximize profit for the company.</span></p>
<p><span class="font2">Analysis of data mining in relation to explore the customer segmentation process has been done in many researches. Various algorithms and methods i.e k-means, k-medoids, fuzzy c-means, Gustafson Kessel dan Gath Geva Clustering algorithm [4],self organizingmap (SOM), decision tree, and Markov Chain Model [5]. Many research related to the RFM model also has been done a lot e.g. by combining RFM theory with k-means and rough set theory to segment customers in an electronics company [6], and also combining the use of RFM and bandwidth usage with k-means to determine the customer segmentation in a telecommunication company [7]. There is no data mining tools for CRM that works perfectly, therefore this paper is worth to explore combination of fuzzy RFM model with FCM and Fuzzy subtractive algorithm.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font2" style="font-weight:bold;">2. &nbsp;&nbsp;&nbsp;Methodology</span></p></li></ul><img src="https://jurnal.harianregional.com/media/16717-1.jpg" alt="" style="width:225pt;height:172pt;">
<p><span class="font2" style="font-weight:bold;">Figure 1. Research overview diagram</span></p>
<p><span class="font2">The overview diagram of this research is shown in Fig 1. In the figure there are five main steps: data processing, fuzzy RFM modeling, FCM and fuzzy subtractive clustering, cluster evaluation using MPC and PE index, and cluster analysis.</span></p>
<ul style="list-style:none;"><li>
<h3><a name="bookmark6"></a><span class="font2" style="font-weight:bold;"><a name="bookmark7"></a>2.1 &nbsp;&nbsp;&nbsp;Data Preprocessing</span></h3></li></ul>
<p><span class="font2">The data used in this paper is the transaction data from 2006 to 2010 with 3 million records data. This study performed an analysis of the clustering and segmentation process result of the transaction data in a period of one year, ie 2008, which consist of 17.999 rows of transaction data and was modeled into 499 rows of RFM data. Oneyear period was chosen on the data mining process in the consideration that it is the most appropriate period to describe the consumer behavior.</span></p>
<p><span class="font2">The aim of data preprocessing is to select and ensure the quality of data. At this stage the problem encountered are noisy data and missing values. At this stage the structure of the database will be prepared to facilitate the mining process. Table 1 shows the pieces of data used before transformed into RFM data. The pieces of data used in Table 1 will be modeled into RFM model (see Table 2). Value of recency is taken by searching the time interval between the last transaction dates until the end of period is set. Frequency is taken by summing the number of times the transaction is done by a customer until the end of period is set and Monetary is taken by summing the customers’ transaction amount until the end of period is set.</span></p>
<table border="1">
<tr><td colspan="3" style="vertical-align:bottom;">
<p><span class="font2" style="font-weight:bold;">Table1. The pieces of data used before transformed into RFM data</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font2">Customer Id</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Transaction Date</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Transaction Amount</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2">C0219</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">2008-11-17</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">155500000</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2">C0308</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">2008-02-28</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">150570000</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2">C0359</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">2008-01-30</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">123175000</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2">CO311</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">2008-02-25</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">100980000</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2">C0203</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">2008-02-29</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">86650000</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2">C0203</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">2008-01-30</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">86650000</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2">C0109</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">2006-04-29</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">2752250</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2">C0246</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">2006-05-06</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">2869000</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2">C0117</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">2006-05-06</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">16486240</span></p></td></tr>
</table>
<p><span class="font2" style="font-weight:bold;">Table 2. The pieces of RFM data used</span></p>
<table border="1">
<tr><td style="vertical-align:bottom;">
<p><span class="font2">Customer Id</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">Recency</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">Frequency</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">Monetary</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">Year</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2">C0234</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">364</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">118</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">240179800</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">2008</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2">C0337</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">13</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">2</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">8357500</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">2008</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2">C0752</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">347</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">120</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">2886000</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">2008</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2">C0221</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">347</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">153</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">6136500</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">2008</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2">C0026</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">365</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">175</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">256950800</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">2008</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2">C0081</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">353</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">111</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">4134900</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">2008</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font2">C0050</span></p></td><td style="vertical-align:top;">
<p><span class="font2">365</span></p></td><td style="vertical-align:top;">
<p><span class="font2">236</span></p></td><td style="vertical-align:top;">
<p><span class="font2">176860250</span></p></td><td style="vertical-align:top;">
<p><span class="font2">2008</span></p></td></tr>
</table>
<ul style="list-style:none;"><li>
<h3><a name="bookmark8"></a><span class="font2" style="font-weight:bold;"><a name="bookmark9"></a>2.2 &nbsp;&nbsp;&nbsp;Clustering Process</span><br><br><span class="font2" style="font-weight:bold;"><a name="bookmark10"></a>a. &nbsp;&nbsp;&nbsp;Fuzzy C-Means Algorithm</span></h3></li></ul>
<p><span class="font2">The traditional fuzzy c-means algorithm is one of the most widely used fuzzy clustering algorithms. This technique was originally introduced by Jim Bezdek in 1981. The fuzzy c-means algorithm attempts to partition a finite collection of elements </span><span class="font2" style="font-style:italic;">X={ x<sub>1</sub>,x<sub>2</sub>,...,x<sub>n</sub>}</span><span class="font2"> into a collection of c fuzzy clusters with respect to some given criterions. Fuzzy sets allow for</span></p>
<p><span class="font2">degrees of membership. A single point can have partial membership in more than one class. There can be no empty classes and no class that contains no data points. The output of such algorithms is a clustering, but not a partition some times. Fuzzy clustering is a widely applied method for obtaining fuzzy models from data. It is based on minimization of the criterion function as defined follows:</span></p>
<h2><a name="bookmark11"></a><span class="font10" style="font-style:italic;"><a name="bookmark12"></a>J<sub>m</sub> = ΣfL<sub>1</sub>Σj=<sub>1</sub>u^</span><span class="font5"> h-ς∙</span><span class="font6">∣∣</span><span class="font5"><sup>2</sup>,l≤ </span><span class="font10" style="font-style:italic;">m&lt;∞</span></h2>
<div>
<p><span class="font2">(1)</span></p>
</div><br clear="all">
<p><span class="font2">where </span><span class="font2" style="font-style:italic;">m</span><span class="font2"> is any real number greater than 1, </span><span class="font2" style="font-style:italic;">u</span><span class="font1" style="font-style:italic;">ij</span><span class="font2"> is the degree of membership of </span><span class="font2" style="font-style:italic;">x</span><span class="font1" style="font-style:italic;">i</span><span class="font2"> in the cluster </span><span class="font2" style="font-style:italic;">j</span><span class="font2">, </span><span class="font2" style="font-style:italic;">x</span><span class="font1" style="font-style:italic;">i</span><span class="font2"> is the </span><span class="font2" style="font-style:italic;">i</span><span class="font2">th of </span><span class="font2" style="font-style:italic;">d</span><span class="font2">-dimensional measured data, </span><span class="font2" style="font-style:italic;">c</span><span class="font1" style="font-style:italic;">j</span><span class="font2"> is the </span><span class="font2" style="font-style:italic;">d</span><span class="font2">-dimension center of the cluster, and ||*|| is any norm expressing the similarity between any measured data and the center. Fuzzy partitioning is carried out through an iterative optimization of the objective function shown above, with the update of membership </span><span class="font2" style="font-style:italic;">u</span><span class="font1" style="font-style:italic;">ij</span><span class="font2"> and the cluster centers </span><span class="font2" style="font-style:italic;">cj</span><span class="font2"> by:</span></p>
<div>
<p><span class="font1" style="font-style:italic;"><sup>u</sup>ij</span></p>
</div><br clear="all">
<div>
<p><span class="font1" style="font-style:italic;">C</span></p>
<p><span class="font1" style="font-style:italic;">k=ι</span></p>
</div><br clear="all">
<div>
<p><span class="font5">IWI h-⅛ll</span></p>
</div><br clear="all">
<div>
<p><span class="font0">2/(m-l)</span></p>
</div><br clear="all">
<div>
<p><span class="font2">(2)</span></p>
</div><br clear="all">
<div>
<p><span class="font1" style="font-style:italic;">C ij=</span></p>
</div><br clear="all">
<p><span class="font8" style="text-decoration:underline;">¼=1 </span><span class="font1" style="font-style:italic;text-decoration:underline;"><sup>u</sup>l]<sup>λ </sup></span><span class="font8"><sup>:</sup> yW </span><span class="font1" style="font-style:italic;">m </span><span class="font8">¼=ι </span><span class="font1" style="font-style:italic;"><sup>u</sup>ιj</span></p>
<div>
<p><span class="font2">(3)</span></p>
</div><br clear="all">
<p><span class="font2">This iteration will stop when </span><span class="font2" style="font-style:italic;">u</span><span class="font2">∏<sup>+1</sup>) <sup>-</sup>w</span><span class="font7">∣</span><span class="font2">j<sup>t</sup>)l</span><span class="font7">∣</span><span class="font2"> &lt;<sup>ω</sup>, where is a termination criterion </span><span class="font4" style="font-style:italic;">∖</span><span class="font2" style="font-style:italic;">J LJ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;IJ</span></p>
<p><span class="font2">between 0 and 1, whereas </span><span class="font2" style="font-style:italic;">k</span><span class="font2"> are the iteration steps. This procedure converges to a local minimum or an encumber point of </span><span class="font2" style="font-style:italic;">Jm</span><span class="font2">. The algorithm is composed of the following steps:</span></p>
<p><span class="font2">Step 1 &nbsp;&nbsp;&nbsp;&nbsp;: &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Initialize </span><span class="font2" style="font-style:italic;">U</span><span class="font9"> = </span><span class="font2" style="font-style:italic;">[u</span><span class="font2"><sub>i</sub>J, matrix U(0)</span></p>
<p><span class="font2">Step 2 &nbsp;&nbsp;&nbsp;&nbsp;: &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;In </span><span class="font2" style="font-style:italic;">k</span><span class="font2">step: Calculate the centers of vector </span><span class="font2" style="font-style:italic;">C[k} =</span><span class="font2"> [c</span><span class="font7">∣</span><span class="font2">] using Eq. 3</span></p>
<p><span class="font2">Step 3 &nbsp;&nbsp;&nbsp;: &nbsp;&nbsp;&nbsp;&nbsp;Compute </span><span class="font2" style="font-style:italic;">U(k), U(k+1)</span><span class="font2"> using Eq.2</span></p>
<p><span class="font2">Step 4 &nbsp;&nbsp;&nbsp;&nbsp;: &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;If {</span><span class="font7">∣</span><span class="font2">Uy<sup>+1)</sup> - Uy)</span><span class="font7">∣</span><span class="font2">} &lt;&nbsp;ω, then stop, else go to step 2</span></p>
<p><span class="font2">This algorithm, data are leap to every cluster by membership procedure, which represents the fuzzy performance of algorithms. The algorithm constructs a suitable matrix named </span><span class="font2" style="font-style:italic;">U</span><span class="font2">, factors are numbers between 0 and 1 also represent the level of membership among data and centers of clusters.</span></p>
<ul style="list-style:none;"><li>
<h3><a name="bookmark13"></a><span class="font2" style="font-weight:bold;"><a name="bookmark14"></a>b. &nbsp;&nbsp;&nbsp;Fuzzy Subtractive Algorithm</span></h3></li></ul>
<p><span class="font2">Clustering algorithms typically require the user to pre-specify the number of cluster centers and their initial locations. The fuzzy c-means algorithm [8] is well-known examples of such clustering algorithms. The quality of the solution depends strongly on the choice of initial values (i.e., the number of cluster centres and their initial locations). Yager and Filev [9] proposed a simple and effective algorithm, called the mountain method, for estimating the number and initial location of cluster centers. Their method is based on gridding the data space and computing a potential value for each grid point based on its distances to the actual data points. A grid point with many data points nearby will have a high potential value. The grid point with the highest potential value is chosen as the first cluster center. The key idea in their method is that once the first cluster center is chosen, the potential of all grid points is reduced according to their distance from the cluster center. Grid points near the first cluster center will have greatly reduced potential. The next cluster center is then placed at the grid point with the highest remaining potential value. This procedure of acquiring new cluster center and reducing the potential of surrounding grid points repeats until the potential of all grid points falls below a threshold. Although this method is simple and effective, the computation grows</span></p>
<p><span class="font2">exponentially with the dimension of the problem because the mountain function has to be evaluated at each grid point.</span></p>
<p><span class="font2">Chiu [10] proposed an extension of Yager and Filev’s mountain method, called subtractive clustering.This method solves the computational problem associated with mountain method. It uses data points as the candidates for cluster centers, instead of grid points as in mountain clustering. The computation for this technique is now proportional to the problem size instead of the problem dimension. The problem with this method is that sometimes the actual cluster centres are not necessarily located at one of the data points. However, this method provides a good approximation, especially with the reduced computation that this method offers. It also eliminates the need to specify a grid resolution, in which tradeoffs between accuracy and computational complexity must be considered. The subtractive clustering method also extends the mountain method’s criterion for accepting and rejecting cluster centres.</span></p>
<p><span class="font2">The parameters of the subtractive clustering are </span><span class="font2" style="font-style:italic;">x</span><span class="font1" style="font-style:italic;">i</span><span class="font2"> is the normalized data vector of both input and output dimensions defined as:</span></p>
<p><span class="font1" style="font-style:italic;">i _</span><span class="font8"> xj-min </span><span class="font1" style="font-style:italic;">{x<sup>l</sup>}</span></p>
<div>
<p><span class="font2">(4)</span></p>
</div><br clear="all">
<p><span class="font1" style="font-style:italic;">X— </span><span class="font8">r 'i &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;”</span></p>
<p><span class="font8">max[x<sup>l</sup>)-min {x<sup>l</sup>}</span></p>
<p><span class="font2" style="font-style:italic;">n</span><span class="font2"> is total number of data vectors, </span><span class="font2" style="font-style:italic;">r</span><span class="font1" style="font-style:italic;">a</span><span class="font2"> is hyper sphere cluster radius in data space, </span><span class="font2" style="font-style:italic;">r</span><span class="font1" style="font-style:italic;">b</span><span class="font2"> is the hyper sphere penalty radius in data space, </span><span class="font2" style="font-style:italic;">P</span><span class="font1" style="font-style:italic;">i</span><span class="font2"> is the potential value of data vector </span><span class="font2" style="font-style:italic;">i</span><span class="font2">, is the squash factor — —.</span></p>
<p><span class="font1" style="font-style:italic;"><sup>r</sup>b</span></p>
<p><span class="font2">The subtractive clustering method works as follows. Consider a collection of n data points {</span><span class="font2" style="font-style:italic;">x</span><span class="font1" style="font-style:italic;">1</span><span class="font2" style="font-style:italic;">, x</span><span class="font1" style="font-style:italic;">2</span><span class="font2" style="font-style:italic;">, x</span><span class="font1" style="font-style:italic;">3</span><span class="font2" style="font-style:italic;">,..., x</span><span class="font1" style="font-style:italic;">n</span><span class="font2">} in an M dimensional space. Without loss of generality, the data points are assumed to have been normalized in each dimension so that they are bounded by a unit hypercube. Each data point is considered as a potential cluster center. The potential of data point </span><span class="font2" style="font-style:italic;">x</span><span class="font1" style="font-style:italic;">i</span><span class="font2">is defined as:</span></p>
<p><span class="font2">L⅛rt</span><span class="font7">∣∣</span><span class="font2">!^</span></p>
<p><span class="font8">P—</span><span class="font1" style="font-style:italic;">J</span><span class="font2"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(5)</span></p>
<p><span class="font2">where</span><span class="font2" style="font-style:italic;">r</span><span class="font1" style="font-style:italic;">b</span><span class="font2"> is a positive constant. Thus, we subtract an amount of potential from each data point as a function of its distance from the first cluster center. The data points near the first cluster center will have greatly reduced potential, and therefore will unlikely be selected as the next cluster center. The constant </span><span class="font2" style="font-style:italic;">r</span><span class="font1" style="font-style:italic;">b</span><span class="font2"> is effectively the radius defining the neighborhood which will have measurable reductions in potential. When the potential of all data points has been revised, we select the data point with the highest remaining potential as the second cluster center. This process continues until a sufficient number of clusters are obtained. In addition to these criterions for ending the clustering process are criteria for accepting and rejecting cluster centers that help avoid marginal cluster centers.</span></p>
<ul style="list-style:none;"><li>
<h3><a name="bookmark15"></a><span class="font2" style="font-weight:bold;"><a name="bookmark16"></a>2.3 &nbsp;&nbsp;&nbsp;Segmentation Process : Fuzzy RFM Model</span></h3></li></ul>
<p><span class="font2">Fuzzy RFM model integrated RFM model with fuzzy logic theory. RFM model is a common approach for understanding customer purchase behavior [1]. It is quite popular, especially in the retail industry. As its name implies, it involves the calculation and the examination of three variables – recency, frequency, and monetary – that summarize the corresponding dimensions of the customer relationship with the organization.The complete description is described below [1]:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font2">1. &nbsp;&nbsp;&nbsp;Recency – Recency refers to the time interval between the last transactions was conducted by customer until the present time or within a certain period. The closer interval time between last times purchasing with the present produce the higher value of recency (R).</span></p></li>
<li>
<p><span class="font2">2. &nbsp;&nbsp;&nbsp;Frequency – Frequency refers to total number of transaction within a certain period. The larger number of transaction (frequently transaction) makes the higher value of frequency (F)</span></p></li>
<li>
<p><span class="font2">3. &nbsp;&nbsp;&nbsp;Monetary – Monetary refers to the amount of money was spent on a transaction within a specific time period. The larger amount of money was spent makes the higher value of monetary (M)</span></p></li></ul>
<p><span class="font2">Each variables R, F, and M in fuzzy RFM model divided into three fuzzy set. Linguistic variable and domain value for each fuzzy set are shown in Table 3. Figs.2,3 and 4 show trapezoidal curve for fuzzy set of each variable R, F, and M.</span></p>
<p><span class="font2" style="font-weight:bold;">Table 3.Linguistic variable and domain values for each of fuzzy set</span></p>
<table border="1">
<tr><td style="vertical-align:top;">
<p><span class="font2">Variable</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Linguistic Variable</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Domain Value</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font2">Recency</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">Recently</span></p>
<p><span class="font2">Rather long-time Long-time</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">0 ≤ r &lt;&nbsp;21 days</span></p>
<p><span class="font2">7 &lt;&nbsp;r &lt;&nbsp;44 days</span></p>
<p><span class="font2">30 days &lt;&nbsp;r</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font2">Frequency</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Seldom</span></p>
<p><span class="font2">Quite Often Often</span></p></td><td style="vertical-align:top;">
<p><span class="font2">0 ≤ f &lt;&nbsp;100 transactions</span></p>
<p><span class="font2">40 &lt;&nbsp;f &lt;&nbsp;200 transactions</span></p>
<p><span class="font2">140 transactions &lt;&nbsp;f</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font2">Monetary</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">Low Medium High</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">0 ≤ m &lt;&nbsp;500 mil Rupiahs</span></p>
<p><span class="font2">100 juta &lt;&nbsp;m &lt;&nbsp;1 mil Rupiahs</span></p>
<p><span class="font2">600 mil Rupiahs &lt;&nbsp;m</span></p></td></tr>
</table><img src="https://jurnal.harianregional.com/media/16717-2.png" alt="" style="width:205pt;height:66pt;">
<p><span class="font2" style="font-weight:bold;">Figure 2.Trapezoidal Curve for Recency</span></p><img src="https://jurnal.harianregional.com/media/16717-3.png" alt="" style="width:218pt;height:83pt;">
<p><span class="font2" style="font-weight:bold;">Figure 3.Trapezoidal Curve for Frequency</span></p><img src="https://jurnal.harianregional.com/media/16717-4.png" alt="" style="width:216pt;height:84pt;">
<p><span class="font2" style="font-weight:bold;">Figure 4.Trapezoidal Curve for Monetary</span></p>
<p><span class="font2">Class definition with the definition of linguistic variables and consumer label which is given in fuzzy RFM models are shown in Table 4. Consumer segmentation process will be done by calculating the degree of membership of the cluster center of each cluster ( ) to all customer classes (A) of fuzzy RFM model using Eq. 2:</span></p>
<p><span class="font0">μAW=(∏mιμiW)(1<sup>-v</sup>)(l-∏mι(l^^ &nbsp;&nbsp;,0≤γ≤1</span></p>
<div>
<p><span class="font2">(6)</span></p>
</div><br clear="all">
<p><span class="font2">Where is a membership function of each linguistic variable (</span><span class="font2" style="font-style:italic;">i</span><span class="font2">) of R, F, and M in each customer classes (A), whereas </span><span class="font2" style="font-style:italic;">x</span><span class="font2"> is a cluster centre. From the membership degree for each classes of which has been obtained, can be determined the class of cluster, ie the class which has the highest membership degree.</span></p>
<table border="1">
<tr><td colspan="4" style="vertical-align:bottom;">
<p><span class="font2" style="font-weight:bold;">Table 4. Description of customer classes</span></p></td></tr>
<tr><td colspan="3" style="vertical-align:top;">
<p><span class="font2">Description of Linguistic Variables</span></p></td><td rowspan="2" style="vertical-align:middle;">
<p><span class="font2">Class</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2">Recency</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">Frequency</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">Monetary</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2">Recently</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">Seldom</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">Low</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">Dormant D</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font2">Recently</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Seldom</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Medium</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Dormant A</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font2">Recently</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Seldom</span></p></td><td style="vertical-align:top;">
<p><span class="font2">High</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Occasional A</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font2">Recently</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Quite Often</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Low</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Everyday D</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font2">Recently</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Quite Often</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Medium</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Golden D</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2">Recently</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">Quite Often</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">High</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">Superstar D</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font2">Recently</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Often</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Low</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Everyday A</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font2">Recently</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Often</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Medium</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Golden A</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font2">Recently</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Often</span></p></td><td style="vertical-align:top;">
<p><span class="font2">High</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Superstar A</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font2">Rather Long-Time</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Seldom</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Low</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Dormant E</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2">Rather Long-Time</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">Seldom</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">Medium</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">Dormant B</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2">Rather Long-Time</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">Seldom</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">High</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">Occasional B</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2">Rather Long-Time</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">Quite Often</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">Low</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">Everyday E</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font2">Rather Long-Time</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Quite Often</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Medium</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Golden E</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2">Rather Long-Time</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">Quite Often</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">High</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">Superstar E</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font2">Rather Long-Time</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Often</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Low</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Everyday B</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font2">Rather Long-Time</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Often</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Medium</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Golden B</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2">Rather Long-Time</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">Often</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">High</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">Superstar B</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font2">Long-Time</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Seldom</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Low</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Dormant F</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2">Long-Time</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">Seldom</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">Medium</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">Dormant C</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2">Long-Time</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">Seldom</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">High</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">Occasional C</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font2">Long-Time</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Quite Often</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Low</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Everyday F</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font2">Long-Time</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Quite Often</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Medium</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Golden F</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2">Long-Time</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">Quite Often</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">High</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">Superstar F</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font2">Long-Time</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Often</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Low</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Everyday C</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font2">Long-Time</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Often</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Medium</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Golden C</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font2">Long-Time</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Often</span></p></td><td style="vertical-align:top;">
<p><span class="font2">High</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Superstar C</span></p></td></tr>
</table>
<p><span class="font2">Each class in fuzzy RFM model corresponds with a consumer label that states the characteristics of each consumer class. Generally there are five consumers label with the characteristic described as follows[1]:</span></p>
<ul style="list-style:none;"><li>
<h3><a name="bookmark17"></a><span class="font2" style="font-weight:bold;"><a name="bookmark18"></a>1.Superstar Customers</span></h3></li></ul>
<p><span class="font2">Customers in this class are the most loyal customers with highest value, increased number of visit and high transaction spending.</span></p>
<ul style="list-style:none;"><li>
<h3><a name="bookmark19"></a><span class="font2" style="font-weight:bold;"><a name="bookmark20"></a>2 .Golden Customers</span></h3></li></ul>
<p><span class="font2">Golden customers are the second highest value customers with increased number of visits and average transaction spending.</span></p>
<ul style="list-style:none;"><li>
<h3><a name="bookmark21"></a><span class="font2" style="font-weight:bold;"><a name="bookmark22"></a>3 .Occasions Customers</span></h3></li></ul>
<p><span class="font2">Occasions customers are customers who have low frequency, large basket and have a long time transaction after their last visit.</span></p>
<ul style="list-style:none;"><li>
<h3><a name="bookmark23"></a><span class="font2" style="font-weight:bold;"><a name="bookmark24"></a>4 .Everyday Customers</span></h3></li></ul>
<p><span class="font2">Everyday customers are customers with increasing number of visits but low in transaction value.</span></p>
<ul style="list-style:none;"><li>
<h3><a name="bookmark25"></a><span class="font2" style="font-weight:bold;"><a name="bookmark26"></a>5 .Dormant Customers</span></h3></li></ul>
<p><span class="font2">Dormant customers are the lowest class, customers in this class that have the lowest values, transaction amount andfrequency,did transaction long time after the last visit.</span></p>
<ul style="list-style:none;"><li>
<h3><a name="bookmark27"></a><span class="font2" style="font-weight:bold;"><a name="bookmark28"></a>2 .4 ClusterAnalysis</span></h3></li></ul>
<p><span class="font2">In fact, if cluster analysis is to make a significant contribution to engineering applications, much more attention must be paid to cluster validity issues that are concerned with determining the optimal number of clusters and checking the quality of clustering results. Cluster validation refers to procedures thatevaluate the clustering results in a quantitative and objective function. Some kinds of validity indices are usually adopted to measure the adequacy of a structure recovered through cluster analysis.Modified partition coefficient (MPC) and partition entropy (PE) indexeswill be used to verify the validity of the cluster and the comparison between fuzzy c-means and fuzzy subtractive.</span></p>
<ul style="list-style:none;"><li>
<h3><a name="bookmark29"></a><span class="font2" style="font-weight:bold;"><a name="bookmark30"></a>a. &nbsp;&nbsp;&nbsp;Modified Partition Coefficient</span></h3></li></ul>
<p><span class="font2">Modified partition coefficient (MPC) index is a refinement from partition coefficient (PC) index. Bezdek designed the PC index to measure the amount of “overlap” between clusters. PC possess monotonic evolution tendency with cluster number and was defined by [11]:</span></p>
<p><span class="font2" style="font-style:italic;">PC</span><span class="font2"> W =⅛<sub>1</sub>∑‰(∕√) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(7)</span></p>
<p><span class="font2">where is the membership of data point </span><span class="font2" style="font-style:italic;">j</span><span class="font2"> in cluster </span><span class="font2" style="font-style:italic;">i</span><span class="font2">.Modification of the PC index proposed by Dave (1996) can reduce the monotonic tendency and was defined by [11] :</span></p>
<p><span class="font2" style="font-style:italic;">MPC</span><span class="font2">(c) = 1 - ⅛(1- </span><span class="font2" style="font-style:italic;">PC(c))</span><span class="font2"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(8)</span></p>
<p><span class="font2">where 0 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;umber </span><span class="font2" style="font-style:italic;">c</span><span class="font2">isfound by solving</span></p>
<p><span class="font2" style="font-style:italic;">(max<sub>2</sub>&lt;<sub>c</sub>&lt;<sub>n</sub>~<sub>1</sub>PC</span><span class="font2"> (c)) to produce a best clustering performance for the data set.</span></p>
<ul style="list-style:none;"><li>
<h3><a name="bookmark31"></a><span class="font2" style="font-weight:bold;"><a name="bookmark32"></a>b. &nbsp;&nbsp;&nbsp;Partition Entropy</span></h3></li></ul>
<p><span class="font2">Basically, partition entropy is a measure for the fuzziness of the cluster partition and defined by :</span></p>
<p><span class="font2" style="font-style:italic;">PE(c) = -⅛<sub>1</sub>∑⅛<sub>7</sub>∙ log (μ<sub>ij</sub>)</span><span class="font2"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(9)</span></p>
<p><span class="font2">where 0 ≤ PE(c) ≤ log<sub>2</sub>c </span><span class="font2" style="font-style:italic;">.</span><span class="font2">In general, an optimal c by solving(min<sub>2</sub>≤<sub>c</sub>≤<sub>n</sub>-<sub>1</sub>PE(c)).</span></p>
<ul style="list-style:none;"><li>
<h3><a name="bookmark33"></a><span class="font2" style="font-weight:bold;"><a name="bookmark34"></a>3. &nbsp;&nbsp;&nbsp;Experiments and Results</span></h3></li></ul>
<p><span class="font2">Clustering process were tested with various value of cluster number (</span><span class="font2" style="font-style:italic;">c</span><span class="font2">) for FCM and radii (</span><span class="font2" style="font-style:italic;">r</span><span class="font2">) parameter (Fuzzy Subtractive) to form 2 until 6 cluster. Segmentation process using Fuzzy RFM model was performed on the result of each clustering algorithm. Below are some of the experiment results.</span></p>
<div><img src="https://jurnal.harianregional.com/media/16717-5.jpg" alt="" style="width:169pt;height:142pt;">
<p><span class="font2" style="font-weight:bold;">Figure 5.FCM clustering result (c=2)</span></p>
</div><br clear="all">
<p><span class="font2">Fig.5 shows clustering result using FCM with parameter value c=2. While the segmentation results using fuzzy RFM are shown in Table 5. The 2 clusters formed 2 consumer class, that is Dormant F and Superstar D.</span></p>
<h3><a name="bookmark35"></a><span class="font2" style="font-weight:bold;"><a name="bookmark36"></a>Table 5.Fuzzy RFM segmentation result (FCM clustering result)</span></h3>
<div>
<p><span class="font2">Fig.6 shows clustering result using fuzzy subtractive with parameter value </span><span class="font2" style="font-style:italic;">r</span><span class="font2">=0.5 which form 2 cluster. The segmentation results using fuzzy RFM are shown in Table 6. The 2 clusters formed 2 consumer class, that is Dormant E and Dormant F.</span></p><img src="https://jurnal.harianregional.com/media/16717-6.jpg" alt="" style="width:167pt;height:139pt;">
</div><br clear="all">
<table border="1">
<tr><td style="vertical-align:top;">
<p><span class="font2">Cluster no</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">Cluster member (%)</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Cluster centre coordinate and linguistic variable of R, F, M</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Consumer Class</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font2">1</span></p></td><td style="vertical-align:top;">
<p><span class="font2">94.39 %</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">R &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;62.2811</span></p>
<p><span class="font2">Long-time (µ</span><span class="font0">R</span><span class="font2">=1)</span></p>
<p><span class="font2">F &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;27.2048</span></p>
<p><span class="font2">Seldom (µ</span><span class="font0">F</span><span class="font2">=1)</span></p>
<p><span class="font2">M &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;64,887,916.46</span></p>
<p><span class="font2">Low (µ</span><span class="font0">M</span><span class="font2">=1)</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Dormant F (µ</span><span class="font0">A</span><span class="font2">=1)</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font2">2</span></p></td><td style="vertical-align:top;">
<p><span class="font2">5.61 %</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">R &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;4.2888</span></p>
<p><span class="font2">Recently (µ</span><span class="font0">R</span><span class="font2">=1)</span></p>
<p><span class="font2">F &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;161.3914</span></p>
<p><span class="font2">Quite Often (µ</span><span class="font0">F</span><span class="font2">=0.6435)</span></p>
<p><span class="font2">M &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1,269,542,546.57</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Superstar D (µ</span><span class="font0">A</span><span class="font2">=0.8022)</span></p></td></tr>
</table>
<p><span class="font2">High (µ</span><span class="font0">M</span><span class="font2">=1)</span></p>
<p><span class="font2" style="font-weight:bold;">Figure 6.Fuzzy subtractive clustering result (</span><span class="font2" style="font-weight:bold;font-style:italic;">r</span><span class="font2" style="font-weight:bold;">=0.5)</span></p>
<p><span class="font2" style="font-weight:bold;">Table 6.Clustering (fuzzy subtractive) and segmentation result</span></p>
<table border="1">
<tr><td style="vertical-align:top;">
<p><span class="font2">Cluster no</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Cluster member (%)</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Cluster centre coordinate and linguistic variable of R, F, M</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Consumer Class</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font2">1</span></p></td><td style="vertical-align:top;">
<p><span class="font2">81.96 % R</span></p>
<p><span class="font2">F</span></p>
<p><span class="font2">M</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">21</span></p>
<p><span class="font2">Rather Long-time (µ</span><span class="font0">R</span><span class="font2">=1)</span></p>
<p><span class="font2">24</span></p>
<p><span class="font2">Seldom (µ</span><span class="font0">F</span><span class="font2">=1) 71,253,800.00</span></p>
<p><span class="font2">Low (µ</span><span class="font0">M</span><span class="font2">=1)</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Dormant E (µ</span><span class="font0">A</span><span class="font2">=1)</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font2">2</span></p></td><td style="vertical-align:top;">
<p><span class="font2">18.04 % R</span></p>
<p><span class="font2">F</span></p>
<p><span class="font2">M</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">231 Long-Time(µ</span><span class="font0">R</span><span class="font2">=1) 1 Seldom (µ</span><span class="font0">F</span><span class="font2">=1) 5,100,000.00 Low (µ</span><span class="font0">M</span><span class="font2">=1)</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Dormant F (µ</span><span class="font0">A</span><span class="font2">=1)</span></p></td></tr>
</table>
<p><span class="font2">Fig.7 shows clustering result using FCM with parameter value c=4. Segmentation results using fuzzy RFM are shown in Table 7. The 4 clusters formed 4 consumer class, that is everyday D, Superstar D, Superstar A, and Dormant F.</span></p><img src="https://jurnal.harianregional.com/media/16717-7.jpg" alt="" style="width:158pt;height:142pt;">
<p><span class="font2" style="font-weight:bold;">Figure 7.FCM clustering result (c=4)</span></p>
<p><span class="font2" style="font-weight:bold;text-decoration:underline;">Table 7.Fuzzy RFM segmentation result (FCM clustering result)</span></p>
<table border="1">
<tr><td style="vertical-align:top;">
<p><span class="font2">Cluster no</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Cluster member (%)</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Cluster centre coordinate and linguistic variable of R, F, M</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Consumer Class</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font2">1</span></p></td><td style="vertical-align:top;">
<p><span class="font2">15.23 %</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">R 6.3198</span></p>
<p><span class="font2">Recently (µ</span><span class="font0">R</span><span class="font2">=1)</span></p>
<p><span class="font2">F 74.8598</span></p>
<p><span class="font2">Quite Often (µ</span><span class="font0">F</span><span class="font2">=0.5810)</span></p>
<p><span class="font2">M 262,175,001.37</span></p>
<p><span class="font2">Low (µ</span><span class="font0">M</span><span class="font2">=0.5946)</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Everyday D (µ</span><span class="font0">A</span><span class="font2">=0.5877)</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font2">2</span></p></td><td style="vertical-align:top;">
<p><span class="font2">3.81 %</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">R 2.4884</span></p>
<p><span class="font2">Recently (µ</span><span class="font0">R</span><span class="font2">=1)</span></p>
<p><span class="font2">F 149.2276</span></p>
<p><span class="font2">Quite Often (µ</span><span class="font0">F</span><span class="font2">=0,8462)</span></p>
<p><span class="font2">M 935,793,370.97</span></p>
<p><span class="font2">High (µ</span><span class="font0">M</span><span class="font2">=0,8395)</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Superstar D (µ</span><span class="font0">A</span><span class="font2">=0.8428)</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font2">3</span></p></td><td style="vertical-align:top;">
<p><span class="font2">2.00 %</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">R 4.8983</span></p>
<p><span class="font2">Recently (µ</span><span class="font0">R</span><span class="font2">=1)</span></p>
<p><span class="font2">F 212.1149</span></p>
<p><span class="font2">Often (µ</span><span class="font0">F</span><span class="font2">=1)</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Superstar A (µ</span><span class="font0">A</span><span class="font2">=1)</span></p></td></tr>
</table>
<table border="1">
<tr><td style="vertical-align:top;"></td><td style="vertical-align:top;">
<p><span class="font2">M</span></p></td><td colspan="2" style="vertical-align:bottom;">
<p><span class="font2">1,761,409,932.74</span></p>
<p><span class="font2">High (µ</span><span class="font0">M</span><span class="font2">=1)</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font2">4</span></p></td><td style="vertical-align:top;">
<p><span class="font2">78.96 % R</span></p>
<p><span class="font2">F</span></p>
<p><span class="font2">M</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">74.6464 Long-Time(µ</span><span class="font0">R</span><span class="font2">=1) 16.6602</span></p>
<p><span class="font2">Seldom (µ</span><span class="font0">F</span><span class="font2">=1) 25,895,238.98 Low (µ</span><span class="font0">M</span><span class="font2">=1)</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Dormant F (µ</span><span class="font0">A</span><span class="font2">=1)</span></p></td></tr>
</table>
<p><span class="font2">Fig.8 shows clustering result using fuzzy subtractive with parameter value </span><span class="font2" style="font-style:italic;">r</span><span class="font2">=0.15 which form 4 cluster. Segmentation results using fuzzy RFM are shown in Table 8. The 4 clusters formed 3 consumer class, theyare Dormant D, Dormant F, and Everyday D.</span></p><img src="https://jurnal.harianregional.com/media/16717-8.jpg" alt="" style="width:155pt;height:142pt;">
<p><span class="font2" style="font-weight:bold;">Figure 8.Fuzzy Subtractive clustering result (</span><span class="font2" style="font-weight:bold;font-style:italic;">r</span><span class="font2" style="font-weight:bold;">=0.15)</span></p>
<p><span class="font2" style="font-weight:bold;">Table 8.Clustering (fuzzy subtractive) and segmentation result</span></p>
<table border="1">
<tr><td style="vertical-align:top;">
<p><span class="font2">Cluster no</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">Cluster member (%)</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Cluster centre coordinate and linguistic variable of R, F, M</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Consumer Class</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font2">1</span></p></td><td style="vertical-align:top;">
<p><span class="font2">41.08 %</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">R 13</span></p>
<p><span class="font2">Recently(µ</span><span class="font0">R</span><span class="font2">=0.5714)</span></p>
<p><span class="font2">F 16</span></p>
<p><span class="font2">Seldom (µ</span><span class="font0">F</span><span class="font2">=1)</span></p>
<p><span class="font2">M 59,218,000.00</span></p>
<p><span class="font2">Low (µ</span><span class="font0">M</span><span class="font2">=1)</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Dormant D (µ</span><span class="font0">A</span><span class="font2">=0.7559)</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font2">2</span></p></td><td style="vertical-align:top;">
<p><span class="font2">12.22 %</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">R 61</span></p>
<p><span class="font2">Long-Time (µ</span><span class="font0">R</span><span class="font2">=1)</span></p>
<p><span class="font2">F 3</span></p>
<p><span class="font2">Seldom (µ</span><span class="font0">F</span><span class="font2">=1)</span></p>
<p><span class="font2">M 16,125,350.00</span></p>
<p><span class="font2">Low (µ</span><span class="font0">M</span><span class="font2">=1)</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Dormant F (µ</span><span class="font0">A</span><span class="font2">=1)</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font2">3</span></p></td><td style="vertical-align:top;">
<p><span class="font2">24.65 %</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">R 0</span></p>
<p><span class="font2">Recently (µ</span><span class="font0">R</span><span class="font2">=1)</span></p>
<p><span class="font2">F 73</span></p>
<p><span class="font2">Quite Often (µ</span><span class="font0">F</span><span class="font2">=0.5500)</span></p>
<p><span class="font2">M 156,106,750.00</span></p>
<p><span class="font2">Low (µ</span><span class="font0">M</span><span class="font2">=0.8597)</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Everyday D (µ</span><span class="font0">A</span><span class="font2">=0.6876)</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font2">4</span></p></td><td style="vertical-align:top;">
<p><span class="font2">22.04 %</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">R 128</span></p>
<p><span class="font2">Long-Time (µ</span><span class="font0">R</span><span class="font2">=1)</span></p>
<p><span class="font2">F 6</span></p>
<p><span class="font2">Seldom (µ</span><span class="font0">F</span><span class="font2">=1)</span></p>
<p><span class="font2">M 9.088.100,00</span></p>
<p><span class="font2">Low (µ</span><span class="font0">M</span><span class="font2">=1)</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Dormant F (µ</span><span class="font0">A</span><span class="font2">=1)</span></p></td></tr>
</table>
<p><span class="font2">From the results of experiments performed using the transaction data in 2008, there are some things that can be analyzed. Table 9 shows the MPC and the CE index for each number of clusters tested using both clustering algorithm.Figs.9 and 10 showthe MPC and the CE index values that are displayed graphically for FCM and FS algorithm.</span></p>
<p><span class="font2" style="font-weight:bold;">Table 9.MPC and CE index for FCM and Fuzzy Subtractive (FS) clustering result</span></p>
<table border="1">
<tr><td colspan="2" style="vertical-align:top;">
<p><span class="font2">Number of Cluster</span></p></td><td style="vertical-align:top;">
<p><span class="font2">2</span></p></td><td style="vertical-align:top;">
<p><span class="font2">3</span></p></td><td style="vertical-align:top;">
<p><span class="font2">4</span></p></td><td style="vertical-align:top;">
<p><span class="font2">5</span></p></td><td style="vertical-align:top;">
<p><span class="font2">6</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2">MPC</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">FCM</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">0,9353</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">0,8981</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">0,8644</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">0,8640</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">0,8309</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font2">Index</span></p></td><td style="vertical-align:top;">
<p><span class="font2">FS</span></p></td><td style="vertical-align:top;">
<p><span class="font2">0,3194</span></p></td><td style="vertical-align:top;">
<p><span class="font2">0,1662</span></p></td><td style="vertical-align:top;">
<p><span class="font2">0,2017</span></p></td><td style="vertical-align:top;">
<p><span class="font2">0,1829</span></p></td><td style="vertical-align:top;">
<p><span class="font2">0,1541</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2">CE</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">FCM</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">0,0597</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">0,1280</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">0,1901</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">0,2119</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">0,2777</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2">Index</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">FS</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">0,1817</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">0,2115</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">0,3432</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">0,3142</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">0,2832</span></p></td></tr>
</table><img src="https://jurnal.harianregional.com/media/16717-9.jpg" alt="" style="width:227pt;height:169pt;">
<p><span class="font2" style="font-weight:bold;">Figure 9. MPC and CE index graphs for FCM</span></p><img src="https://jurnal.harianregional.com/media/16717-10.jpg" alt="" style="width:233pt;height:174pt;">
<p><span class="font2" style="font-weight:bold;">Figure 10. MPC and CE index graphs for FS</span></p>
<p><span class="font2">FCM’s MPC index value for each number of clusters is greater than fuzzy subtractive’s. While the FCM’s CE index value for each number of clusters is smaller than fuzzy subtractive’s. From the results of this comparisonfuzzy c-means algorithm has better performance than fuzzy subtractive algorithm.</span></p>
<ul style="list-style:none;"><li>
<h3><a name="bookmark37"></a><span class="font2" style="font-weight:bold;"><a name="bookmark38"></a>4. &nbsp;&nbsp;&nbsp;Conclusion and Future Work</span></h3></li></ul>
<p><span class="font2">This paper demonstrated data mining process from customer's data in retail company by combining fuzzy RFM model with FCM and fuzzy subtractive algorithm. From the MPC and CE index obtained from clustering process to form 2 until 6 cluster, FCM has better performance than fuzzy subtractive algorithm for data mining process in retail company. Reffering the segmentation result using fuzzy RFM models, fuzzy subtractive algorithm failed to form a cluster that included in potential consumer i.e Superstar and Golden customer.For future development, data mining process can be improved with other method and use more than one cluster validation index algorithm to obtain better optimum cluster.The application of data mining tools for customer segmentation can with fuzzy method is expected also be done on a various kind of data.</span></p>
<h3><a name="bookmark39"></a><span class="font2" style="font-weight:bold;"><a name="bookmark40"></a>Acknowledgments</span></h3>
<p><span class="font2">Our thank goes to Department of Information Technology Udayana University, Bali, Indonesia who has helped organize this research.</span></p>
<h3><a name="bookmark41"></a><span class="font2" style="font-weight:bold;"><a name="bookmark42"></a>References</span></h3>
<ul style="list-style:none;"><li>
<p><span class="font2">[1] &nbsp;&nbsp;&nbsp;Tsiptsis, Kontantinos. Chorianopoulos, Antonios, “Data Mining Techniques in CRM: Inside Customer Segmentation”, United Kingdom, John Wiley &amp;&nbsp;Sons.Ltd, 2009.</span></p></li>
<li>
<p><span class="font2">[2] &nbsp;&nbsp;&nbsp;Zumstein, D.,“Customer Performance Measurement: Analysis of the Benefit of a Fuzzy Classification Approach in Customer Relationship Management (Thesis)”, Switzerland, University of Fribourg, 2007.</span></p></li>
<li>
<p><span class="font2">[3] &nbsp;&nbsp;&nbsp;Buttle, F., “Customer Relationship Management: Concept and Technologies”, Butterworth-Heinemann, 2008.</span></p></li>
<li>
<p><span class="font2">[4] &nbsp;&nbsp;&nbsp;Jansen, S.M.H.,“Customer Segmentation and Customer Profiling for a Mobile Telecommunications Company Based on Usage Behavior: A Vodafone Case Study (Thesis)”,Maastricht ,University of Maastricht, 2007.</span></p></li>
<li>
<p><span class="font2">[5] &nbsp;&nbsp;&nbsp;Ha, S.H., Bae, S.M., &amp;&nbsp;Park, S.C., “Customer's Time-Variant Purchase Behavior and Corresponding Marketing Strategies: An Online Retailer's Case”,Computers and Industrial Engineering, Volume 43, Number 4, pp.801-820(20), 2002.</span></p></li>
<li>
<p><span class="font2">[6] &nbsp;&nbsp;&nbsp;Cheng, C.H, Chen, Y.S., “ClassifyingTheSegmentation of CustomerValueVia RFM model and RS Theory”, Expert Systems with Applications, 36,pp.4176–4184, 2009.</span></p></li>
<li>
<p><span class="font2">[7] &nbsp;&nbsp;&nbsp;Gemala, Y., “Segmentasi Pelanggan dengan Algoritma K-Means dan Analisa RFM Untuk Mendukung Strategi Pengelolaan Pelanggan di PT. Indosat Mega Media”, Skripsi, Institut Teknologi Sepuluh November,2011.</span></p></li>
<li>
<p><span class="font2">[8] &nbsp;&nbsp;&nbsp;Bezdek, J. C., “Pattern Recognition with Fuzzy Objective Function”, Plenum Press, NewYork, 1981.</span></p></li>
<li>
<p><span class="font2">[9] &nbsp;&nbsp;&nbsp;Yager, R., Filev, D., “Generation of Fuzzy Rules by Mountain Clustering”, Journal of Intelligent &amp;&nbsp;Fuzzy Systems, Vol. 2(3), pp.209-219,1994.</span></p></li>
<li>
<p><span class="font2">[10] &nbsp;&nbsp;&nbsp;Chiu, S.L., “Fuzzy model identification based on cluster estimation”, Fuzzy Systems, Vol. 2, pp.267-278, 1994.</span></p></li>
<li>
<p><span class="font2">[11] &nbsp;&nbsp;&nbsp;Wu, K., Yang, M.,“A Cluster Validity Index for Fuzzy Clustering”, Pattern Recognition Letters 26, pp.1275-1291, 2005.</span></p></li></ul>
<p><span class="font5">200</span></p>