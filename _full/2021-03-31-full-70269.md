---
layout: full_article
title: "Electrooculogram (EOG) based Mouse Cursor Controller Using the Continuous Wavelet Transform and Statistic Features"
author: "Triadi Triadi, Inung Wijayanto, Sugondo Hadiyoso"
categories: lontar
canonical_url: https://jurnal.harianregional.com/lontar/full-70269 
citation_abstract_html_url: "https://jurnal.harianregional.com/lontar/id-70269"
citation_pdf_url: "https://jurnal.harianregional.com/lontar/full-70269"  
comments: true
---

<p><span class="font1" style="font-weight:bold;">LONTAR KOMPUTER VOL. 12, NO. 1 APRIL 2021</span></p>
<p><span class="font1" style="font-weight:bold;">DOI : 10.24843/LKJITI.2021.v12.i01.p06</span></p>
<p><span class="font1" style="font-weight:bold;">Accredited Sinta 2 by RISTEKDIKTI Decree No. 30/E/KPT/2018</span></p>
<p><span class="font1" style="font-weight:bold;">p-ISSN 2088-1541</span></p>
<p><span class="font1" style="font-weight:bold;">e-ISSN 2541-5832</span></p><a name="caption1"></a>
<h1><a name="bookmark0"></a><span class="font4" style="font-weight:bold;"><a name="bookmark1"></a>Electrooculogram (EOG) based Mouse Cursor Controller Using the Continuous Wavelet Transform and Statistic Features</span></h1>
<p><span class="font1">Triadi<sup>a1</sup></span><span class="font1" style="font-weight:bold;">, </span><span class="font1">Inung Wijayanto<sup>a2</sup></span><span class="font1" style="font-weight:bold;">, </span><span class="font1">Sugondo Hadiyoso<sup>b3</sup></span></p>
<p><span class="font1"><sup>a</sup>School of Electrical Engineering, Telkom University Bandung, Indonesia</span></p>
<p><a href="mailto:1nasher.triadi@gmail.com"><span class="font1"><sup>1</sup>nasher.triadi@gmail.com</span></a></p>
<p><a href="mailto:2iwijayanto@telkomuniversity.ac.id"><span class="font1"><sup>2</sup>iwijayanto@telkomuniversity.ac.id</span></a></p>
<p><span class="font1"><sup>b</sup> School of Applied Science, Telkom University Bandung, Indonesia</span></p>
<p><a href="mailto:3sugondo@telkomuniversity.ac.id"><span class="font1"><sup>3</sup>sugondo@telkomuniversity.ac.id</span></a><span class="font1"> </span><span class="font0" style="font-variant:small-caps;">(c</span><span class="font0">orresponding author)</span></p>
<p><span class="font1" style="font-weight:bold;font-style:italic;">Abstract</span></p>
<p><span class="font1" style="font-style:italic;">This study design a system prototype to control a mouse cursor's movement on a computer using an electrooculogram (EOG) signal. The EOG signal generated from eye movement was processed utilizing a microcontroller with an analog to the digital conversion process, which communicates with the computer through a USB port. The signal was decomposed using continuous wavelet transform (CWT), followed by feature extraction processes using statistic calculation, and then classified using K-Nearest Neighbors (k-NN) to decide the movement and direction of the mouse cursor. The test was carried out with 110 EOG signals then separated, 0.5 as training data and 0.5 as test data with eight categories of directional movement patterns, including up, bottom, right, left, top right, top left, bottom right bottom left. The highest accuracy that can be achieved using CWT-bump and kurtosis is 100%, while the time needed to translate the eye movement to the cursor movement is 1.9792 seconds. It is hoped that the proposed system can help assistive devices, particularly for Amyotrophic Lateral Sclerosis (ALS) sufferers.</span></p>
<p><span class="font1" style="font-weight:bold;font-style:italic;">Keywords: </span><span class="font1" style="font-style:italic;">cursor movement, CWT, EOG, statistic, k-NN.</span></p>
<ul style="list-style:none;"><li>
<h3><a name="bookmark2"></a><span class="font1" style="font-weight:bold;"><a name="bookmark3"></a>1. &nbsp;&nbsp;&nbsp;Introduction</span></h3></li></ul>
<p><span class="font1">Modern technology in the health sector in monitoring and as a tool for bodily functions makes it very easy for its users. Eye-tracking technology has enabled the movement of the human eye to be used as a Human-Computer Interface (HCI) [1], [2]. The application of the HCI system based on eye movements as a human-computer interaction communication was applied to patients with Amyotrophic Lateral Sclerosis (ALS) or other diseases that experience paralysis of the hands [3]– [6]. ALS was a neurodegenerative disease of motor nerve cells that develops rapidly and is caused by damage to nerve cells in the brain [7], [8]. Patients with ALS experience paralysis of the muscles in their limbs and speaking difficulty; thus, it was difficult for ALS people to use their hands or voice to communicate with other people [7].</span></p>
<p><span class="font1">Apart from being used in the HCI field, human eye movement was also useful in various fields, such as healthcare, security systems, and interface design [9]–[11]. In intelligent transportation, eye movements were also useful for detecting the driver's attention level, which indicates the level of driver's drowsiness [12], [13].</span></p>
<p><span class="font1">On eye movement, the cornea and retina's potential produces a source of the Electrooculogram (EOG) signal. The application of EOG based control system has been commonly proposed, for example, in the control of mobile robots [14] and wheelchairs [15]–[17]. Meanwhile, computer interaction development has recently become an important issue to implement, for example, cursor control. Horizontal and vertical eye movement and flashing signals controlling the mouse cursor system by moving the direction from the EOG-based cursor [18]. Therefore, this study proposes a mouse cursor control system using EOG signals. The proposed system consists of</span></p>
<p><span class="font1">an EOG signal recorder, USB interface, and feature extraction and decision-making applications. The raw EOG signal was decomposed using a wavelet transform and then calculating the statistical features into a feature vector that becomes the classification algorithm's input. This system was designed to move the mouse cursor, including up, bottom, right, left, top right, top left, bottom right, and bottom left.</span></p>
<p><span class="font1">This paper is structured as follows, section 2 describes the design and implementation of the proposed system, including hardware design, software design, feature extraction, and classification process. Section 3 contains an explanation of implementation results followed by a discussion. The final section briefly describes the conclusions and implications of this study.</span></p>
<ul style="list-style:none;"><li>
<h3><a name="bookmark4"></a><span class="font1" style="font-weight:bold;"><a name="bookmark5"></a>2. &nbsp;&nbsp;&nbsp;System Design and Implementation</span></h3></li></ul>
<p><span class="font1">The design and implementation of the system in this study were to adopt the human-computer interface (HCI) mechanism. The output of this system was a mouse cursor movement control with an EOG signal.</span></p>
<ul style="list-style:none;"><li>
<h3><a name="bookmark6"></a><span class="font1" style="font-weight:bold;"><a name="bookmark7"></a>2.1. &nbsp;&nbsp;&nbsp;Hardware Design</span></h3></li></ul>
<p><span class="font1">Figure 1 shows the two components of the EOG consisting of horizontal and vertical obtained from five electrodes placed around the eye. These were attached on the edges of both eyes and also over and under the eye. The middle electrode serves as a reference. The EOGv1 and EOGv2 electrodes obtain relative corneal-retinal vertical motion of the eye, while EOGh1 and EOGh2 get a signal from the potential relative to the horizontal movement of the eye.</span></p><img src="https://jurnal.harianregional.com/media/70269-1.jpg" alt="" style="width:418pt;height:210pt;">
<p><span class="font1" style="font-weight:bold;">Figure 1. </span><span class="font1">Mouse cursor controller system overview</span></p>
<p><span class="font1">The component for horizontal EOG signal acquisition is obtained by subtracting the left-eye electrode signal from the right eye electrode signal (EOGh = EOGh2 - EOGh1). The vertical EOG component was obtained by subtracting the signal at the eye's bottom edge from the signal at the top edge of the eye EOGv = EOGv2-EOGv1. EOGh and EOGv were notations that denote the horizontal and vertical elements of EOG.</span></p>
<p><span class="font1">This system consists of hardware for EOG signal acquisition and software for signal processing and decision-making, as shown in Figure 2. EOG hardware contains components for signal acquisition, consisting of an instrumentation amplifier, low pass filter (LPF), high pass filter (HPF), and level shifter. The instrumentation amplifiers amplify the electrode signal leads. The instrumentation amplifier component used in this study was INA118P with an amplification of 1000 times.</span></p>
<div><img src="https://jurnal.harianregional.com/media/70269-2.jpg" alt="" style="width:342pt;height:211pt;">
<p><span class="font1" style="font-weight:bold;">Figure 2. </span><span class="font1">The components of the mouse cursor controller system</span></p>
</div><br clear="all">
<div><img src="https://jurnal.harianregional.com/media/70269-3.jpg" alt="" style="width:334pt;height:270pt;">
<p><span class="font1" style="font-weight:bold;">Figure 3. </span><span class="font1">The schematic design of the amplifier (2-Channel EOG)</span></p>
</div><br clear="all">
<p><span class="font1">Figure 3 shows the schematic design of the 2-channel EOG amplifier used in this study. The HPF implemented in this study has a cut-off frequency of 0.05 Hz to eliminate low-frequency noise due to body movement. The value of R was obtained by applying Equation (1).</span></p>
<p><span class="font10" style="font-style:italic;">F</span><span class="font11"> =</span><span class="font10" style="font-style:italic;"><sup>1</sup></span><span class="font11" style="font-style:italic;">π</span><span class="font10" style="font-style:italic;">RC </span><span class="font6" style="font-style:italic;">c</span><span class="font8"><sub>2</sub></span></p>
<div>
<p><span class="font1">(1)</span></p>
</div><br clear="all">
<p><span class="font1">Here the value of </span><span class="font10" style="font-style:italic;">C</span><span class="font11"> = </span><span class="font10" style="font-style:italic;">2.2</span><span class="font11" style="font-style:italic;">μ</span><span class="font10" style="font-style:italic;">F</span><span class="font1"> then the R-value was obtained </span><span class="font9" style="font-style:italic;">R</span><span class="font1"> = </span><span class="font9">1.4</span><span class="font9" style="font-style:italic;">M</span><span class="font1">Ω .</span></p>
<p><span class="font1">Meanwhile, the LPF was designed to have a cut-off frequency of 40 Hz to reject a large amount of high-frequency noise such as muscle noise. The low pass filter was designed using the Butterworth 4th order filter method and the Sallen-key circuit type, as shown in figure 4.</span></p><img src="https://jurnal.harianregional.com/media/70269-4.jpg" alt="" style="width:351pt;height:150pt;">
<p><span class="font1" style="font-weight:bold;">Figure 4. </span><span class="font1">Schematic design of low pass filter 40 Hz</span></p>
<p><span class="font1">To match the reading range of the ADC component, the signal was amplified by the final amplifier. Before amplification, the EOG signal has a relatively small amplitude of about 3.5 mV, so that at the end of the amplifier, 120 times gain was required. The final amplifier was designed using OP07. Then, so that the ADC can ultimately convert all EOG signals, a level shifter was designed to make all EOG signal components positive. The schematic of the amplifier and the level shifter is shown in Figure 5.</span></p><img src="https://jurnal.harianregional.com/media/70269-5.jpg" alt="" style="width:243pt;height:240pt;">
<p><span class="font1" style="font-weight:bold;">Figure 5. </span><span class="font1">Schematic design of the amplifier and level shifter</span></p>
<ul style="list-style:none;"><li>
<h3><a name="bookmark8"></a><span class="font1" style="font-weight:bold;"><a name="bookmark9"></a>2.2. &nbsp;&nbsp;&nbsp;Software Design</span></h3></li></ul>
<p><span class="font1">The design software developed was used to display the EOG signal's output, feature extraction, classification, and simulation of the mouse cursor. The software design with ADC reading uses the Arduino IDE. It performs serial calibration with python to perform mouse cursor direction movements with the py.mouse library data obtained from python with *.csv format.</span></p>
<p><span class="font1">At the classification stage, there were training data and test data. The training data was used as</span></p>
<p><span class="font1">the calibration data when sampling the mouse cursor motion data, while the test data with test data that has been adjusted with the calibration data was processed to determine the accuracy with the method used in this study. The classification process was shown in Figure 6.</span></p>
<div><img src="https://jurnal.harianregional.com/media/70269-6.png" alt="" style="width:423pt;height:33pt;">
<p><span class="font1" style="font-weight:bold;">Figure 6. </span><span class="font1">Classification process</span></p>
</div><br clear="all">
<p><span class="font1">The systematic workflow was started by signal acquisition using the EOG hardware, followed by the signals' amplitude normalization. The signal was decomposed by the wavelet transform then characterized using statistical analysis including entropy, mean, kurtosis, and skewness. This feature vector was then stored as training data for each eye movement. The new input feature vector was then classified based on the vector closest to the training vector. The classification process was carried out using k-Nearest Neighbor (k-NN) with k = 3. The k-NN was chosen because it has low computational cost and effectiveness in hardware implementation.</span></p>
<ul style="list-style:none;"><li>
<h3><a name="bookmark10"></a><span class="font1" style="font-weight:bold;"><a name="bookmark11"></a>2.3. &nbsp;&nbsp;&nbsp;Feature Extraction and Classification</span></h3></li></ul>
<p><span class="font1">Feature extraction in this study is used to calculate the features contained in the signal as the first step in signal classification. Feature extraction is calculated on the wavelet decomposition signal. In this study, statistical calculations were used for feature extraction. The calculated statistical parameters include:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1">1. &nbsp;&nbsp;&nbsp;Mean</span></p></li></ul>
<p><span class="font1">For a </span><span class="font9" style="font-style:italic;">N</span><span class="font1"> number data of a set </span><span class="font10" style="font-style:italic;">X</span><span class="font6" style="font-style:italic;">,</span><span class="font1"> the mean </span><span class="font10" style="font-style:italic;">(</span><span class="font11" style="font-style:italic;">μ</span><span class="font10" style="font-style:italic;">)</span><span class="font1"> can be calculated using (2)</span></p>
<p><span class="font6" style="font-style:italic;">N</span></p>
<p><span class="font10" style="font-style:italic;">μ</span><span class="font9"> =—∑</span><span class="font9" style="font-style:italic;">X N </span><span class="font12" style="font-style:italic;">∑</span></p>
<div>
<p><span class="font1">(2)</span></p>
</div><br clear="all">
<ul style="list-style:none;"><li>
<p><span class="font1">2. &nbsp;&nbsp;&nbsp;Entropy</span></p></li></ul>
<p><span class="font1">Entropy is used to measure the irregularity of signal distribution </span><span class="font10">(</span><span class="font10" style="font-style:italic;">p</span><span class="font10">)</span><span class="font1">. The entropy calculation is shown in (3).</span></p>
<p><span class="font6" style="font-style:italic;">N</span><span class="font7">-</span><span class="font6">1</span></p>
<p><span class="font9" style="font-style:italic;">entropy</span><span class="font1"> = -</span><span class="font4">∑ </span><span class="font9" style="font-style:italic;">p</span><span class="font9"> (</span><span class="font9" style="font-style:italic;">i</span><span class="font9">) log</span><span class="font6">2 </span><span class="font9">(</span><span class="font9" style="font-style:italic;">p</span><span class="font9">) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="font1">(3)</span></p>
<p><span class="font6" style="font-style:italic;">i</span><span class="font7">=</span><span class="font6">0</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1">3. &nbsp;&nbsp;&nbsp;Skewness</span></p></li></ul>
<p><span class="font1">Skewness is the symmetry value of a set </span><span class="font10" style="font-style:italic;">X</span><span class="font1"> , and it is calculated using (4).</span></p>
<div>
<p><span class="font10" style="font-style:italic;">skewness</span><span class="font11"> =</span></p>
</div><br clear="all">
<div>
<p><span class="font10" style="font-style:italic;">ZNjX<sub>1</sub>-XiZN-</span></p>
</div><br clear="all">
<div>
<p><span class="font2" style="font-style:italic;">σ</span></p>
</div><br clear="all">
<div>
<p><span class="font6">3</span></p>
</div><br clear="all">
<div>
<p><span class="font1">(4)</span></p>
</div><br clear="all">
<p><span class="font1">Here, the mean, the </span><span class="font3" style="font-style:italic;">σ</span><span class="font1"> and </span><span class="font9" style="font-style:italic;">N</span><span class="font1"> is the standard deviation, and the number of data, respectively.</span></p>
<div>
<p><span class="font1">4.</span></p>
</div><br clear="all">
<div>
<p><span class="font1">Kurtosis</span></p>
<p><span class="font1">Kurtosis calculates the relative sharpness of a signal's distribution curve, which calculates using (5).</span></p>
</div><br clear="all">
<div>
<p><span class="font10" style="font-style:italic;">kurtosis</span><span class="font11"> =</span></p>
</div><br clear="all">
<div>
<h2><a name="bookmark12"></a><span class="font13"><a name="bookmark13"></a>∑ </span><span class="font6" style="font-style:italic;">Z,</span><span class="font5"> (</span><span class="font10" style="font-style:italic;">X</span><span class="font6" style="font-style:italic;">i</span><span class="font11"> - </span><span class="font10" style="font-style:italic;">X</span><span class="font5"> )</span><span class="font11">4,</span><span class="font14" style="font-style:italic;font-variant:small-caps;">Z<sup>n</sup></span></h2>
</div><br clear="all">
<div>
<p><span class="font10" style="font-style:italic;">σ<sup>4</sup></span></p>
</div><br clear="all">
<div>
<p><span class="font1">(5)</span></p>
</div><br clear="all">
<p><span class="font1">These parameters then become the feature vector as input fork-NN to be classified. In this study, the method of measuring the distance in k-NN is the Euclidean method.</span></p>
<ul style="list-style:none;"><li>
<h3><a name="bookmark14"></a><span class="font1" style="font-weight:bold;"><a name="bookmark15"></a>3. &nbsp;&nbsp;&nbsp;Result and Discussion</span></h3></li></ul>
<p><span class="font1">This section discusses the results of testing and analysis of the system that has been implemented. This test aims to determine system performance. Testing was done during eye movement to control mouse movement. The test was carried out on seven individuals with normal vision by moving the sun horizontally (left and right movement) and vertically (up and down movement). Figure 7 shows an example of an EOG signal when the eyeball is left and right, respectively. This signal is then decomposed with a wavelet, and its statistical characteristics are calculated.</span></p>
<p><span class="font1">The test scenario consists of four procedures. The first procedure was equipment preparation, which checks and verifies the connection of the equipment used. This procedure was done to ensure all electrodes' positions are confirmed and ready to be used. The second procedure was user preparation, which focused on the electrodes' placement in the participant's face. Before the electrodes were placed, the face surface must be cleaned using a gel cleanser. The vertical electrodes were placed above the right eyebrow, and the lower lid, with distance, is set for about 1 cm and 1.5 cm, respectively. The horizontal electrodes were placed in the outer canthi for about 1.5 cm on each side. The reference electrode was placed on the forehead.</span></p><img src="https://jurnal.harianregional.com/media/70269-7.jpg" alt="" style="width:321pt;height:204pt;">
<p><span class="font1" style="font-weight:bold;">Figure 7. </span><span class="font1">Example of an EOG signal (left and right eyeball)</span></p>
<p><span class="font1">The third procedure was system calibration. It was started by the calculation of eye blinks and movement. Thus it can be used as the system's threshold. The threshold for each participant was calculated by calculating the amplitude of their various eye movements. The eye movement was measured by giving the participants visual stimulation using a video showing a moving square object. The square moved to five different locations and stayed for five seconds on each location. The last procedure was exiting the calibration process. The calibration process was ended when the participants make a spontaneous blink using the right eye.</span></p>
<p><span class="font1">In EOG signal processing, there were three types of CWT wavelets used in this study: morse, amor, and bump. The feature extraction method was done using the statistical features of mean, entropy, skewness, and kurtosis. Before the testing phase, a system training stage using Euclidean distance with a value of k = 3 was performed using the training data. After that, the testing data was fed to the system to be classified.</span></p><img src="https://jurnal.harianregional.com/media/70269-8.jpg" alt="" style="width:314pt;height:182pt;">
<p><span class="font1" style="font-weight:bold;">Figure 8. </span><span class="font1">Effect of mother wavelet and statistical features on system accuracy</span></p>
<p><span class="font1">Figure 8 shows that the effect of wavelet types and statistical features on the accuracy of the generation. The result shows that there is no significant difference between the use of statistical measurement and entropy. However, the signal sharpness analysis using kurtosis in the bump CWT can provide the best performance, which was 100%. Since the EOG signal was not symmetrical, signal analysis using skewness could not give a good result. Therefore, the use of skewness achieves the lowest accuracy of 69%.</span></p>
<p><span class="font1">Furthermore, the computation time for each test scenario was shown in Figure 9. The kurtosis feature takes longer than other features (1.9792 seconds) but provides the highest accuracy. The difference in processing time was not significant, so that if this system is applied, the characteristic of kurtosis was most suitable to be used by considering the accuracy.</span></p><img src="https://jurnal.harianregional.com/media/70269-9.jpg" alt="" style="width:321pt;height:170pt;">
<p><span class="font1" style="font-weight:bold;">Figure 9. </span><span class="font1">The computation time of each scenario</span></p>
<p><span class="font1">The mouse control system proposed in this study is expected to help people with disabilities when they want to operate a computer with simple commands. A control system using EOG signals may be the last alternative if the hands and feet are also disabled. This proposed study can complement the previous study by Rusydi et al. [19], where muscle signals and EOG can be utilized for the control system.</span></p>
<ul style="list-style:none;"><li>
<h3><a name="bookmark16"></a><span class="font1" style="font-weight:bold;"><a name="bookmark17"></a>4. &nbsp;&nbsp;&nbsp;Conclusion</span></h3></li></ul>
<p><span class="font1">In this study, a mouse control system using EOG signals has been successfully implemented. The EOG signal was decomposed using a wavelet transform, and then the statistical features</span></p>
<p><span class="font1">were calculated, including entropy, mean, kurtosis, and skewness. K-Nearest Neighbor was used to classifying the mouse's moving, including up, top right, top left bottom, bottom right, bottom left, right, and left. From the proposed system's test results, the highest accuracy was 100%, obtained using the statistical features of kurtosis and wavelet bump with a computation time of 1.9792 seconds. The proposed system is expected to be used by people with disabilities to operate computers with simple commands. In future studies, a user interface similar to a keyboard compatible with the operating system will be developed to write text. Another important issue is that this system requires a faster processing time to run in real-time.</span></p>
<h3><a name="bookmark18"></a><span class="font1" style="font-weight:bold;"><a name="bookmark19"></a>References</span></h3>
<ul style="list-style:none;"><li>
<p><span class="font1">[1] &nbsp;&nbsp;&nbsp;S. Chandra, G. Sharma, S. Malhotra, D. Jha, and A. P. Mittal, &quot;Eye tracking based human computer interaction: Applications and their uses,&quot; in </span><span class="font1" style="font-style:italic;">Proceedings - 2015 International Conference on Man and Machine Interfacing, MAMI 2015</span><span class="font1">, 2016, no. December, pp. 1–5, doi: 10.1109/MAMI.2015.7456615.</span></p></li>
<li>
<p><span class="font1">[2] &nbsp;&nbsp;&nbsp;X. Zhang, X. Liu, S. M. Yuan, and S. F. Lin, &quot;Eye Tracking Based Control System for Natural Human-Computer Interaction,&quot; </span><span class="font1" style="font-style:italic;">Computational Intelligence and Neuroscience</span><span class="font1">, vol. 2017, pp. 1–9, 2017, doi: 10.1155/2017/5739301.</span></p></li>
<li>
<p><span class="font1">[3] &nbsp;&nbsp;&nbsp;D. Y. Kim, C. H. Han, and C. H. Im, &quot;Development of an electrooculogram-based humancomputer interface using involuntary eye movement by spatially rotating sound for communication of locked-in patients,&quot; </span><span class="font1" style="font-style:italic;">Scientific Reports</span><span class="font1">, vol. 8, no. 1, pp. 1–10, 2018, doi: 10.1038/s41598-018-27865-5.</span></p></li>
<li>
<p><span class="font1">[4] &nbsp;&nbsp;&nbsp;C.-Y. Su and J.-J. Wong, &quot;Connecting with Dysphonia: Human-Computer Interface for Amyotrophic Lateral Sclerosis Patients,&quot; 2011, pp. 453–457.</span></p></li>
<li>
<p><span class="font1">[5] &nbsp;&nbsp;&nbsp;H. Ka Hou and S. K.G., &quot;Low-Cost Wireless Electrooculography Speller,&quot; in </span><span class="font1" style="font-style:italic;">2018 IEEE International Conference on Systems, Man, and Cybernetics (SMC)</span><span class="font1">, Oct. 2018, pp. 123– 128, doi: 10.1109/SMC.2018.00032.</span></p></li>
<li>
<p><span class="font1">[6] &nbsp;&nbsp;&nbsp;G. Teng, Y. He, H. Zhao, D. Liu, J. Xiao, and S. Ramkumar, &quot;Design And Development Of Human Computer Interface Using Electrooculogram With Deep Learning,&quot; </span><span class="font1" style="font-style:italic;">Artificial Intelligence in Medicine</span><span class="font1">, vol. 102, p. 101765, Jan. 2020, doi: 10.1016/j.artmed.2019.101765.</span></p></li>
<li>
<p><span class="font1">[7] &nbsp;&nbsp;&nbsp;O. Hardiman </span><span class="font1" style="font-style:italic;">et al.</span><span class="font1">, &quot;Amyotrophic lateral sclerosis,&quot; </span><span class="font1" style="font-style:italic;">Nature Reviews Disease Primers</span><span class="font1">, vol. 3, no. 1, p. 17071, Dec. 2017, doi: 10.1038/nrdp.2017.71.</span></p></li>
<li>
<p><span class="font1">[8] &nbsp;&nbsp;&nbsp;E. Zucchi </span><span class="font1" style="font-style:italic;">et al.</span><span class="font1">, &quot;Neurofilaments in motor neuron disorders: towards promising diagnostic and prognostic biomarkers,&quot; </span><span class="font1" style="font-style:italic;">Molecular Neurodegeneration</span><span class="font1">, vol. 15, no. 1, p. 58, Dec. 2020, doi: 10.1186/s13024-020-00406-3.</span></p></li>
<li>
<p><span class="font1">[9] &nbsp;&nbsp;&nbsp;D. Yuan </span><span class="font1" style="font-style:italic;">et al.</span><span class="font1">, &quot;A closed-loop electrical stimulation system triggered by EOG for acupuncture therapy,&quot; </span><span class="font1" style="font-style:italic;">Systems Science &amp;&nbsp;Control Engineering</span><span class="font1">, vol. 8, no. 1, pp. 128–140, 2020, doi: 10.1080/21642583.2020.1733130.</span></p></li>
<li>
<p><span class="font1">[10] &nbsp;&nbsp;&nbsp;A. Bissoli, D. Lavino-Junior, M. Sime, L. Encarnação, and T. Bastos-Filho, &quot;A human– machine interface based on eye tracking for controlling and monitoring a smart home using the internet of things,&quot; </span><span class="font1" style="font-style:italic;">Sensors (Switzerland)</span><span class="font1">, vol. 19, no. 4, pp. 1–26, 2019, doi:</span></p></li></ul>
<p><span class="font1">10.3390/s19040859.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1">[11] &nbsp;&nbsp;&nbsp;C.-I. Wu, &quot;HCI and Eye Tracking Technology for Learning Effect,&quot; </span><span class="font1" style="font-style:italic;">Procedia - Social and Behavioral Sciences</span><span class="font1">, vol. 64, pp. 626–632, Nov. 2012, doi: 10.1016/j.sbspro.2012.11.073.</span></p></li>
<li>
<p><span class="font1">[12] &nbsp;&nbsp;&nbsp;A. Sahayadhas, K. Sundaraj, and M. Murugappan, &quot;Detecting Driver Drowsiness Based on Sensors: A Review,&quot; </span><span class="font1" style="font-style:italic;">Sensors</span><span class="font1">, vol. 12, no. 12, pp. 16937–16953, Dec. 2012, doi: 10.3390/s121216937.</span></p></li>
<li>
<p><span class="font1">[13] &nbsp;&nbsp;&nbsp;J. Xu, J. Min, and J. Hu, &quot;Real-time eye tracking for the assessment of driver fatigue,&quot; </span><span class="font1" style="font-style:italic;">Healthcare Technology Letters</span><span class="font1">, vol. 5, no. 2, pp. 54–58, 2018, doi: 10.1049/htl.2017.0020.</span></p></li>
<li>
<p><span class="font1">[14] &nbsp;&nbsp;&nbsp;W. S. Sanjaya, D. Anggraeni, R. Multajam, M. N. Subkhi, and I. Muttaqien, &quot;Design and Experiment of Electrooculogram (EOG) System and Its Application to Control Mobile Robot,&quot; </span><span class="font1" style="font-style:italic;">Journal of Physics: Conference Series</span><span class="font1">, vol. 180, pp. 1–8, 2017, doi: 10.1088/1742</span></p></li></ul>
<p><span class="font1">6596/755/1/011001.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1">[15] &nbsp;&nbsp;&nbsp;R. B. Navarro, L. B. Vázquez, and E. L. Guillén, </span><span class="font1" style="font-style:italic;">EOG-based wheelchair control</span><span class="font1">, Second Edition Elsevier B.V., 2018.</span></p></li>
<li>
<p><span class="font1">[16] &nbsp;&nbsp;&nbsp;N. Borkar, T. Dongare, P. Chahande, J. Bonsod, and A. B. Jirapure, &quot;Microcontroller Based EOG and Accelerometer Guide Wheelchair,&quot; </span><span class="font1" style="font-style:italic;">International Research Journal of Engineering and Technology (IRJET)</span><span class="font1">, vol. 5, no. 3, pp. 3803–3807, 2018.</span></p></li>
<li>
<p><span class="font1">[17] &nbsp;&nbsp;&nbsp;W. Xu, N. Chen, X. Han, and J. Sun, &quot;Research on wheelchair robot control system based on EOG,&quot; </span><span class="font1" style="font-style:italic;">AIP Conference Proceedings</span><span class="font1">, vol. 1955, no. April, pp. 1–5, 2018, doi:</span></p></li></ul>
<p><span class="font1">10.1063/1.5033815.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1">[18] &nbsp;&nbsp;&nbsp;A. U. Kabir, F. Bin Shahin, and M. Kafiul Islam, &quot;Design and Implementation of an EOGbased Mouse Cursor Control for Application in Human-Computer Interaction,&quot; </span><span class="font1" style="font-style:italic;">Journal of Physics Conference Series</span><span class="font1">, vol. &nbsp;1487, no. 1, pp. &nbsp;1–6, 2020, doi: 10.1088/1742</span></p></li></ul>
<p><span class="font1">6596/1487/1/012043.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1">[19] &nbsp;&nbsp;&nbsp;M. I. Rusydi, I. Aryeni, Joefrinaldo, Z. Romadhon, and A. Rusydi, &quot;Robot mobile control based on three EMG signals using an artificial neural network,&quot; IOP Conference Series: Materials Science and Engineering, vol. 602, no. 1, pp. 1–11, 2019, doi: 10.1088/1757-899X/602/1/012028.</span></p></li></ul>
<p><span class="font1">61</span></p>