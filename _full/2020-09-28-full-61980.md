---
layout: full_article
title: "Metode ROBPCA (Robust Principal Component Analysis) dan Clara (Clustering Large Area) pada Data dengan Outlier"
author: "Bekti Endar Susilowati, Pardomuan Robinson Sihombing"
categories: jik
canonical_url: https://jurnal.harianregional.com/jik/full-61980 
citation_abstract_html_url: "https://jurnal.harianregional.com/jik/id-61980"
citation_pdf_url: "https://jurnal.harianregional.com/jik/full-61980"  
comments: true
---

<p><span class="font3">Jurnal Ilmu Komputer VOL. XIII, No 2</span></p>
<p><span class="font3">p-ISSN: 1979-5661</span></p>
<p><span class="font3">e-ISSN: 2622-321X</span></p><a name="caption1"></a>
<h1><a name="bookmark0"></a><span class="font7" style="font-weight:bold;"><a name="bookmark1"></a>Metode ROBPCA (Robust Principal Component Analysis) dan Clara (Clustering Large Area) pada Data dengan Outlier</span></h1>
<h3><a name="bookmark2"></a><span class="font4"><a name="bookmark3"></a>(</span><span class="font5" style="font-weight:bold;">Studi Kasus Data Laporan Indeks Kebahagiaan Dunia Tahun 2018</span><span class="font4">)</span></h3>
<h4><a name="bookmark4"></a><span class="font3" style="font-weight:bold;"><a name="bookmark5"></a>Bekti Endar Susilowati </span><span class="font0"><sup>1)</sup></span><span class="font3" style="font-weight:bold;">, Pardomuan Robinson Sihombing </span><span class="font0"><sup>2)</sup></span></h4>
<p><span class="font3" style="font-style:italic;"><sup>1</sup>Badan Pusat Statistik Kabupaten Sleman, Jalan Purbaya, Mlati, Kabupaten Sleman, Yogyakarta <sup>1</sup></span><a href="mailto:bekti@bps.go.id"><span class="font3" style="font-style:italic;text-decoration:underline;">bekti@bps.go.id</span></a></p>
<p><span class="font3"><sup>2</sup></span><span class="font3" style="font-style:italic;">Badan Pusat Statistik, Jalan Dr. Sutomo No 6-8, Jakarta Pusat </span><a href="mailto:2robinson@bps.go.id"><span class="font3"><sup>2</sup>robinson@bps.go.id</span></a></p>
<h4><a name="bookmark6"></a><span class="font3" style="font-weight:bold;"><a name="bookmark7"></a>Abstract</span></h4>
<p><span class="font3" style="font-style:italic;">PCA is one of multivariate analysis used for deputizing variables using less number of Principal Components without losing much information. In other words, it is used for explaining the underlying variance-covariance structure of the large data set of variables through a few linear combinations of these variables. PCA is significantly influenced by the outliers, since the covariant matrix are sensitive to outliers. Thus, the analysis for this study was conducted by using a PCA that is robust to outliers, namely ROBPCA or Hubert PCA. Then, the principal components formed were used as inputs in cluster analysis using the Clara method. Clara is one of the k-medoids methods that is robust to outliers and is appropriate for large data analysis. In the case study of the compiling variables of happiness index based on The World Happiness Report (WHR)2018 using the Clara method with Manhattan distance, the best average value of Overall Average Silhouette Width in the 5 clusters were obtained</span><span class="font3">.</span></p>
<p><span class="font3">Keywords: robust, outlier, ROBPCA, Clara</span></p>
<h4><a name="bookmark8"></a><span class="font3" style="font-weight:bold;"><a name="bookmark9"></a>Abstrak</span></h4>
<p><span class="font3" style="font-style:italic;">PCA</span><span class="font3"> merupakan salah satu analisis multivariat yang digunakan untuk mengganti variable dengan </span><span class="font3" style="font-style:italic;">Principal Component</span><span class="font3"> yang sedikit jumlahnya namun tidak terlalu banyak informasi yang hilang. Atau dengan kata lain, </span><span class="font3" style="font-style:italic;">it used to explain the underlying variancecovariance structure of the large data set of variables through a few linear combination of these variables.</span><span class="font3"> PCA sangat dipengaruhi oleh kehadiran </span><span class="font3" style="font-style:italic;">outlier</span><span class="font3"> karena didasarkan pada matriks kovarian yang sensitive terhadap </span><span class="font3" style="font-style:italic;">outlier</span><span class="font3">. Oleh karena itu, pada analisis ini akan digunakan PCA yang robust terhadap outlier yaitu ROBPCA atau PCA Hubert. Selanjutnya, dari </span><span class="font3" style="font-style:italic;">Principal Component</span><span class="font3"> yang terbentuk digunakan sebagai input (masukan) untuk </span><span class="font3" style="font-style:italic;">cluster analysis</span><span class="font3"> dengan metode Clara. </span><span class="font3" style="font-style:italic;">Clara</span><span class="font3"> merupakan salah satu metode k-medoids yang robust terhadap </span><span class="font3" style="font-style:italic;">outlier </span><span class="font3">dan baik digunakan pada data dalam jumlah besar. Dalam studi kasus terhadap variabel penyusun indeks kebahagiaan berdasarkan </span><span class="font3" style="font-style:italic;">The World Happiness Report</span><span class="font3"> 2018 dengan metode Clara yang menggunakan jarak manhattan didapatkan nilai rata-rata </span><span class="font3" style="font-style:italic;">Overall Average Silhouette Width</span><span class="font3"> yang terbaik pada 5 cluster.</span></p>
<p><span class="font3">Kata kunci: robust, outlier, ROBPCA, Clara</span></p>
<p><span class="font3">Data yang dikaji dalam menyusun WHR antara lain </span><span class="font3" style="font-style:italic;">kekuatan ekonomi (GDP per capita), social support, Healthy life expectancy at birth, Freedom to make life choices, Generosity, Perceptions of corruption, Positive Affect, Negative Affect, Confidence in National Government, GINI index (World Bank estimate) average 2000-15, and gini of household income reported in Gallup, by wp5-year. </span><span class="font3">Berdasarkan hasil penelitian sebelumnya (Sobiroh, 2015), ROBPCA yang menggabungkan konsep </span><span class="font3" style="font-style:italic;">Projection Pursuit (PP)</span><span class="font3"> dan </span><span class="font3" style="font-style:italic;">Minimum Covariance Determinant (FAST-</span><span class="font3">MCD dengan teorema C-step) memberikan kesimpulan lebih baik daripada </span><span class="font3" style="font-style:italic;">Classic Principal Component Analysis (CPCA)</span><span class="font3"> karena mampu menghasilkan jumlah komponen utama lebih sedikit namun telah mampu mejelaskan sebesar 84,79% dari total variasi sampel.</span></p>
<p><span class="font3">Pada penelitian kali ini akan dilakukan analisis komponen utama (</span><span class="font3" style="font-style:italic;">PCA)</span><span class="font3"> dari variabel-variabel tersebut kemudian dilanjutkan dengan analisis cluster terhadap negara-negara anggota. Untuk melakukan analisis dari kedua meotode tersebut, dipilih metode yang </span><span class="font3" style="font-style:italic;">robust</span><span class="font3"> terhadap </span><span class="font3" style="font-style:italic;">outlier</span><span class="font3"> sehingga diharapkan didapatkan hasil analisis yang lebih akurat. Pada metode PCA dipilih salah satu metode yang robust terhadap outlier yaitu ROBPCA(Robust PCA) sedangkan untuk analysis Cluster dipilih metode Clara yang dalam penelitian sebelumnya disebutkan bahwa metode tersebut </span><span class="font3" style="font-style:italic;">robust</span><span class="font3"> terhadap </span><span class="font3" style="font-style:italic;">outlier</span><span class="font3"> dan efektif digunakan dalam data yang cukup besar.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font3" style="font-weight:bold;">2. &nbsp;&nbsp;&nbsp;METODE PENELITIAN</span></p></li></ul>
<h4><a name="bookmark10"></a><span class="font3" style="font-weight:bold;"><a name="bookmark11"></a>Sumber Data dan Variabel Penelitian</span></h4>
<p><span class="font3">Data diperoleh dari </span><span class="font3" style="font-style:italic;">The World Happiness Report 2018.</span><span class="font3"> Data yang akan digunakan sebanyak 141 negara dengan 11 variabel. (Statistical Appendix 1 for Chapter 2 of World Happiness Report 2018). Adapun variabel yang digunakan dalam penelitian ini adalah:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font3" style="font-style:italic;">a. &nbsp;&nbsp;&nbsp;GDP per capita</span><span class="font3"> atau pendapatan per kapita adalah besarnya pendapatan rata-rata penduduk di suatu negara. Pendapatan per kapita didapatkan dari hasil pembagian pendapatan nasional suatu negara dengan jumlah penduduk negara tersebut.</span></p></li>
<li>
<p><span class="font3" style="font-style:italic;">b. &nbsp;&nbsp;&nbsp;Social support</span><span class="font3"> (dukungan sosial) merupakan rata-rata nasional dari respon dalam bentuk biner (0 atau 1).</span></p></li>
<li>
<p><span class="font3" style="font-style:italic;">c. &nbsp;&nbsp;&nbsp;Healthy life expectancy at birth;</span><span class="font3"> Variabel </span><span class="font3" style="font-style:italic;">Healthy life expectancy at birth (</span><span class="font3">harapan hidup sehat) dihitung berdasarkan data dari World Health Organization (WHO), the World Development Indicators (WDI), and jurnal-jurnal statistik.</span></p></li>
<li>
<p><span class="font3" style="font-style:italic;">d. &nbsp;&nbsp;&nbsp;Freedom to make life choice;</span><span class="font3"> Freedom to make life choices (kebebasan untuk membuat pilihan hidup) rata-rata respons nasional terhadap pertanyaan &quot;Apakah Anda puas atau tidak puas dengan kebebasan Anda untuk memilih apa yang Anda lakukan dengan hidup Anda?&quot;</span></p></li>
<li>
<p><span class="font3" style="font-style:italic;">e. &nbsp;&nbsp;&nbsp;Generosity;</span><span class="font3"> Variabel Generosity (kemurahan hati) merupakan rata-rata nasional dari respon Sudahkah Anda menyumbangkan uang untuk kegiatan amal dalam sebulan terakhir?” pada PDB per kapita.</span></p></li>
<li>
<p><span class="font3" style="font-style:italic;">f. &nbsp;&nbsp;&nbsp;Perceptions of corruption; Perceptions of corruption (persepsi tentang korupsi)</span><span class="font3"> merupakan variabel yang mengukur rata-rata nasional dari respons survei terhadap dua pertanyaan: &quot;Apakah korupsi tersebar luas di seluruh pemerintah atau tidak&quot; dan &quot;Apakah korupsi tersebar luas di dalam bisnis atau tidak?&quot;.</span></p></li>
<li>
<p><span class="font3" style="font-style:italic;">g. &nbsp;&nbsp;&nbsp;Positive Affect; Positive Affect</span><span class="font3"> (pengaruh positif) merupakan variabel yang didefinisikan sebagai rata-rata dari tiga ukuran efek positif: kebahagiaan, tawa dan kesenangan.</span></p></li>
<li>
<p><span class="font3">h.</span><span class="font3" style="font-style:italic;"> &nbsp;&nbsp;&nbsp;Negative Affect</span><span class="font3">; </span><span class="font3" style="font-style:italic;">Negative Affect</span><span class="font3"> (pengaruh negatif) merupakan variabel yang didefinisikan sebagai rata-rata dari tiga ukuran efek negative yaitu kekhawatiran, kesedihan dan kemarahan.</span></p></li>
<li>
<p><span class="font3" style="font-style:italic;">i. &nbsp;&nbsp;&nbsp;Confidence in National Government</span><span class="font3"> merupakan variabel yang merngukur kepercayaan terhadap pemerintah.</span></p></li>
<li>
<p><span class="font3" style="font-style:italic;">j. &nbsp;&nbsp;&nbsp;GINI index (World Bank estimate) average 2000-15;</span><span class="font3"> Indeks Gini merupakan indikator yang menunjukkan tingkat ketimpangan pendapatan secara menyeluruh. Nilai Koefisien Gini berkisar antara 0 hingga 1. Koefisien Gini bernilai 0 menunjukkan adanya pemerataan pendapatan yang sempurna, atau setiap orang memiliki pendapatan yang sama.</span></p></li>
<li>
<p><span class="font3" style="font-style:italic;">k. &nbsp;&nbsp;&nbsp;Gini of household income reported in Gallup, by wp5-year;</span><span class="font3"> Variabel ini merupakan indeks Gini dari pendapatan rumah tangga. Variabel pendapatan dibuat dengan mengonversi mata uang lokal ke Dolar Internasional (ID) menggunakan rasio paritas daya beli.</span></p></li></ul>
<h4><a name="bookmark12"></a><span class="font3" style="font-weight:bold;"><a name="bookmark13"></a>ROBPCA (ROBust PCA)</span></h4>
<p><span class="font3">ROBPCA (ROBust PCA) atau disebut juga </span><span class="font3" style="font-style:italic;">Hubert PCA</span><span class="font3"> ditemukan oleh Hubert dkk (2005) sebagai perkembangan dari </span><span class="font3" style="font-style:italic;">robust PCA.</span><span class="font3"> Metode tersebut merupakan gabungan konsep </span><span class="font3" style="font-style:italic;">Projection </span><span class="font8">89</span></p>
<div>
<p><span class="font3" style="font-style:italic;">Pursuit(PP)</span><span class="font3"> dan estimator kovarian yang robust yaitu </span><span class="font3" style="font-style:italic;">Minimum Covariant Determinant</span><span class="font3"> (MCD) yang dimodifikasi bersama dengan Van Driessen menjadi </span><span class="font3" style="font-style:italic;">Fast Minimum Covariance Determinant</span><span class="font3"> (FAST-MCD) pada tahun 1999. Metode tersebut digunakan untuk mendapatkan komponen utama (</span><span class="font3" style="font-style:italic;">PCA) </span><span class="font3">yang tidak terpengaruh terlalu banyak dengan kehadiran data </span><span class="font3" style="font-style:italic;">outlier</span><span class="font3">.</span></p>
<p><span class="font3">Untuk analisis selanjutnya, robust principal komponen yang telah diperoleh dengan metode ROBPCA digunakan sebagai input (masukan) untuk cluster analysis. Berdasarkan penelitian sebelumnya (Muslim, 2018), </span><span class="font3" style="font-style:italic;">cluster analysis</span><span class="font3"> dengan Clara method menyimpulkan bahwa Clara</span></p>
</div><br clear="all">
<div>
<p><span class="font3">method dengan jarak manhattan lebih robust dibandingkan dengan K-means dengan jarak Manhattan dan Pam. Oleh karena itu pada penelitian kali akan mengaplikasikan Clara method dengan jarak</span></p>
</div><br clear="all">
<div>
<p><span class="font3">manhattan untuk studi kasus data dengan variabel-variabel</span></p>
</div><br clear="all">
<div>
<p><span class="font3" style="font-style:italic;">Happiness Report</span><span class="font3"> (WHR) 2018.</span></p>
</div><br clear="all">
<div>
<p><span class="font3">yang</span></p>
</div><br clear="all">
<div>
<p><span class="font3">bersumber dari </span><span class="font3" style="font-style:italic;">The World</span></p>
</div><br clear="all">
<div>
<p><span class="font3">Matriks kovariansi didefinisikan sebagai berikut:</span></p>
<p><span class="font3" style="font-style:italic;">^ = C0v(<sub>1</sub>X) =</span></p>
</div><br clear="all">
<div><img src="https://jurnal.harianregional.com/media/61980-1.jpg" alt="" style="width:16pt;height:18pt;">
</div><br clear="all">
<div><img src="https://jurnal.harianregional.com/media/61980-2.jpg" alt="" style="width:13pt;height:18pt;">
</div><br clear="all">
<div>
<p><span class="font11" style="font-weight:bold;">.ftι ft: •■■</span></p>
</div><br clear="all">
<div>
<p><span class="font11" style="font-weight:bold;">ftp ftp</span></p>
<p><span class="font11" style="font-weight:bold;">ftp</span></p>
</div><br clear="all">
<div>
<p><span class="font3">Matriks korelasi didefinisikan sebagai berikut:</span></p>
</div><br clear="all">
<div><img src="https://jurnal.harianregional.com/media/61980-3.jpg" alt="" style="width:34pt;height:16pt;">
<p><span class="font10" style="font-weight:bold;">' &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1</span></p>
</div><br clear="all">
<div><img src="https://jurnal.harianregional.com/media/61980-4.jpg" alt="" style="width:35pt;height:10pt;">
</div><br clear="all">
<div>
<p><span class="font10" style="font-weight:bold;">i**12</span></p>
<p><span class="font10" style="font-weight:bold;">'<sup>l</sup>≡i2''¾2</span></p>
<p><span class="font10" style="font-weight:bold;">√⅜p&gt;'¾2</span></p>
</div><br clear="all">
<div>
<p><span class="font10" style="font-weight:bold;">C<sup>r</sup>Ip '<sup>lff</sup>l 1 ⅛'<sup>σ</sup>lp</span></p>
</div><br clear="all">
<div>
<p><span class="font10" style="font-weight:bold;">'<sup>l</sup>¾!<sub>v</sub>'¾p</span></p>
</div><br clear="all">
<div><img src="https://jurnal.harianregional.com/media/61980-5.jpg" alt="" style="width:11pt;height:15pt;">
</div><br clear="all">
<div>
<p><span class="font11" style="font-weight:bold;">1 Pu - </span><span class="font12" style="font-variant:small-caps;">Pl<sub>p</sub></span></p>
<p><span class="font11" style="font-weight:bold;">PlZ 1 &nbsp;&nbsp;&nbsp;•■■ &nbsp;ftp</span></p>
<p><span class="font12" style="font-variant:small-caps;">Plp Pip</span><span class="font11" style="font-weight:bold;"> - &nbsp;&nbsp;1</span></p>
</div><br clear="all">
<div>
<p><span class="font3">(1)</span></p>
<p><span class="font3">(2)</span></p>
<p><span class="font3">(3)</span></p>
</div><br clear="all">
<h4><a name="bookmark14"></a><span class="font3" style="font-weight:bold;"><a name="bookmark15"></a>Mahalanobis Distance</span></h4>
<p><span class="font3">Jarak mahalanobis pada data multivariate digunakan untuk mendeteksi outlier, yang diperoleh dengan menghitung jarak tiap observasi terhadap pusat datanya.</span></p>
<p><span class="font3" style="font-style:italic;">^MD</span><span class="font3"> <sup>=</sup> (<sup>X</sup>i </span><span class="font3" style="font-style:italic;">~ ^y^</span><span class="font3"> <sup>1</sup>(*i “M) &gt;&nbsp;Zpi(I-C) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(4)</span></p>
<p><span class="font3">Deteksi outlier dengan jarak mahalanobis kurang maksimal ketika datanya mengandung lebih dari satu outlier, sehingga dikembangkan jarak mahalanobis robust (robust distance/RD) didasarkan pada</span></p>
<table border="1">
<tr><td style="vertical-align:top;">
<p><span class="font3">penaksir robust apabila jika:</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3">untuk vector rata-rata dan matriks kovariansi. Pengamatan <sup>x</sup>i dikatakan outlier</span></p>
<p><span class="font12" style="font-style:italic;font-variant:small-caps;"><sup>1</sup>'rD</span><span class="font3"> <sup>-</sup> (<sup>x</sup>i <sup>-</sup> </span><span class="font3" style="font-style:italic;">^MCDy^MCD^i ~ </span><span class="font12" style="font-style:italic;font-variant:small-caps;">PmCd)</span><span class="font3" style="font-style:italic;"> ^ ^pι(L-a)</span><span class="font3"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(5)</span></p></td></tr>
</table>
<p><span class="font3">Dengan </span><span class="font3" style="font-style:italic;">k<sup>l</sup>Mcn</span><span class="font3"> dan </span><span class="font11" style="font-variant:small-caps;">∑MlD</span><span class="font3"> merupakan vector rata-rata dan matriks kovariansi dari sebagiam data </span><span class="font3" style="font-weight:bold;">X </span><span class="font3">yang mempunyai determinan matriks kovariansi terkecil.</span></p>
<p><span class="font3">Terdapat tiga macam jenis outlier sebagai berikut (Sobiroh, 2015):</span></p>
<ul style="list-style:none;"><li>
<p><span class="font3">a. &nbsp;&nbsp;&nbsp;Good Leverage, merupakan pengamatan yang berada di ruang distribusi tetapi sudah tidak berada di daerah mayoritas data</span></p></li>
<li>
<p><span class="font3">b. &nbsp;&nbsp;&nbsp;Bad Leverage, merupakan pengamatan yang tidak berada baik dalam ruang distribusi maupun daerah mayoritas data</span></p></li>
<li>
<p><span class="font3">c. &nbsp;&nbsp;&nbsp;Orthogonal Leverage, merupakan pengamatan yang memiliki jarak pengamatan sangat besar dari daerah mayoritas data sehingga pengamatan tersebut sudah tidak dapat dilihat dalam ruang distribusinya.</span></p></li></ul>
<p><span class="font3" style="font-weight:bold;font-style:italic;">Minimum Covariance Determinant (MCD) dan Projection Pursuit</span></p>
<p><span class="font3">Misal </span><span class="font3" style="font-style:italic;">X</span><span class="font3"> = [x<sub>1</sub>,x<sub>2</sub>, ...,X<sub>tl</sub>] adalah himpunan data sejumlah n pengamatan yang terdiri dari p variabel dimana n ≥ p+1.</span></p>
<div><img src="https://jurnal.harianregional.com/media/61980-6.jpg" alt="" style="width:53pt;height:36pt;">
</div><br clear="all">
<p><span class="font3" style="font-style:italic;">C <sup>=</sup> </span><span class="font3">(<sup>x</sup>i ^^ ^l)(<sup>x</sup>i <sup>-</sup> ^l)</span></p>
<p><span class="font3">r = 1 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(7)</span></p>
<p><span class="font3" style="font-weight:bold;">t </span><span class="font3">dan </span><span class="font3" style="font-weight:bold;">C </span><span class="font3">merupakan matriks definit positif simetri berdimensi pxp dari suatu sub sampel berukuran h n+p+1</span></p>
<p><span class="font3">pengamatan dimana 2 &nbsp;&nbsp;≤ h ≤ n yang meminimumkan det (C). Metode MCD mencari himpunan</span></p>
<p><span class="font3">bagian dari </span><span class="font3" style="font-weight:bold;">X </span><span class="font3">sejumlah h elemen dimana h adalah integer terkecil dari (n+p+1)/2. Dimisalkan bahwa himpunan bagian itu adalah ^h<sup>1</sup> Untuk mendapatkan penaksir MCD perlu dicari Cft kombinasi. Jika n kecil maka penaksir MCD cukup mudah ditemukan. Akan tetapi masalh muncul ketika n cukup besar karena terdapat banyak kombinasi sub sampel yang harus ditemukan untuk memperoleh penaksir MCD. </span><span class="font3" style="font-style:italic;">Projection Pursuit (PP)</span><span class="font3"> bertujuan untuk mendapatkan struktur pada data peubah ganda dengan memproyeksikannya pada subruang berdimensi lebih rendah (Hubert, 1985). Seperti CPCA, metode tersebut mencari suatu arah dengan penyebaran maksimal data diproyeksikan di dalamnya.</span></p>
<p><span class="font3" style="font-style:italic;">PCA</span><span class="font3"> yang diperkenalkan pertama kali oleh Pearson pada tahun 1901, merupakan suatu analisis multivariate yang mentransformasi variabel-variabel asal yang saling berkorelasi menjadi variabel-variabel baru yang tidak saling berkorelasi dengan mereduksi sejumlah variabel tersebut. Hal ini bertujuan agar dihasilkan dimensi yang lebih kecil namun dapat menerangkan sebagian besar keragaman variabel aslinya. Dalam perkembangannya, dipengaruhi adanya kebutuhan suatu model PCA yang robust terhadap data </span><span class="font3" style="font-style:italic;">outlier.</span><span class="font3"> PCA yang juga dikenal dengan </span><span class="font3" style="font-style:italic;">Clasisical Principal Component Analysis</span><span class="font3"> (CPCA) sangat dipengaruhi oleh kehadiran </span><span class="font3" style="font-style:italic;">outlier</span><span class="font3"> karena didasarkan pada matriks kovarian yang peka terhadap </span><span class="font3" style="font-style:italic;">outlier.</span><span class="font3"> Untuk mengatasi hal tersebut beberapa ahli menggantikan matriks kovarian klasik dengan estimator kovarian robust.</span></p>
<p><span class="font3">Sebagai perkembangan dari </span><span class="font3" style="font-style:italic;">robust PCA,</span><span class="font3"> Hubert dkk (2005) menemukan ROBPCA atau disebut juga </span><span class="font3" style="font-style:italic;">Hubert PCA.</span><span class="font3"> Metode tersebut merupakan gabungan konsep </span><span class="font3" style="font-style:italic;">Projection Pursuit(PP)</span><span class="font3"> dan estimator kovarian yang robust yaitu </span><span class="font3" style="font-style:italic;">Minimum Covariant Determinant</span><span class="font3"> (MCD) yang dimodifikasi bersama dengan Van Driessen menjadi </span><span class="font3" style="font-style:italic;">Fast Minimum Covariance Determinant</span><span class="font3"> (FAST-MCD) pada tahun 1999. Metode tersebut digunakan untuk mendapatkan komponen utama (</span><span class="font3" style="font-style:italic;">PCA)</span><span class="font3"> yang tidak terpengaruh terlalu banyak dengan kehadiran data </span><span class="font3" style="font-style:italic;">outlier</span><span class="font3">.</span></p>
<p><span class="font3">Algoritma ROBPCA:</span></p>
<div>
<p><span class="font3">2.</span></p>
</div><br clear="all">
<div>
<p><span class="font3">Menghitung outlyingness setiap data <sup>x</sup>t dengan rumus Stanhel-Donoho</span></p>
</div><br clear="all">
<div>
<p><span class="font6">c(χ<sub>i</sub>)</span></p>
</div><br clear="all">
<div>
<p><span class="font13">mαx<sub>vefi</sub></span></p>
</div><br clear="all">
<div>
</div><br clear="all">
<div>
<h2><a name="bookmark16"></a><span class="font14" style="font-variant:small-caps;"><a name="bookmark17"></a>⅛ Cd(<sup>x</sup>^<sup>v</sup>)</span></h2>
</div><br clear="all">
<div>
<p><span class="font3">(9)</span></p>
</div><br clear="all">
<ul style="list-style:none;"><li>
<p><span class="font3">3. &nbsp;&nbsp;&nbsp;Matriks covarian ^o dikomposisi sehingga diperoleh komponen utamanya.</span></p></li>
<li>
<p><span class="font3">4. &nbsp;&nbsp;&nbsp;Pada n, k dari algoritma ke-3 dihitung kembali penduga nilai tengah (/'2) dan matriks kovarian MCD (■$i) menggunakan FAST-MCD yang diadaptasi. Komponen utama akhir adalah vector eigen dari matriks kovarian tersebut (^J</span></p></li></ul>
<p><span class="font3">Berdasarkan studi-studi sebelumnya, ROBPCA merupakan suatu pendekatan </span><span class="font3" style="font-style:italic;">PCA</span><span class="font3"> yang lebih efektif dalam untuk data yang mengandung </span><span class="font3" style="font-style:italic;">outlier.</span></p>
<h4><a name="bookmark18"></a><span class="font3" style="font-weight:bold;"><a name="bookmark19"></a>Jarak Euclidean dan Manhattan</span></h4>
<p><span class="font3">Jarak Euclidean merupakan jarak terpendek antar 2 titik, digunakan untuk menghitung jarak Euclidean antara suatu objek dengan pusat klaster.</span></p>
<div><img src="https://jurnal.harianregional.com/media/61980-7.jpg" alt="" style="width:172pt;height:50pt;">
</div><br clear="all">
<div>
<p><span class="font3">(10)</span></p>
</div><br clear="all">
<p><span class="font3">Jarak Manhattan (</span><span class="font3" style="font-style:italic;">city block distance)</span><span class="font3"> diibaratkan sebagai jarak blok antara 2 titik suatu kota.</span></p>
<p><span class="font3" style="font-style:italic;">^man (<sup>x</sup>tj'<sup>c</sup>κj) <sup>=</sup> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="font3" style="font-weight:bold;">l<sup>x</sup>y <sup>-</sup> ¾</span><span class="font9" style="font-weight:bold;">∣</span></p>
<p><span class="font3">∕=1 i= 1 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(11)</span></p>
<p><span class="font3" style="font-style:italic;">^euc (<sup>x</sup>ij&gt;<sup>c</sup>kj</span><span class="font3">) : jarak Euclidean antara pengamatan ke-i variabel ke-j ke pusat klaster ke-k pada variabel ke-j</span></p>
<p><span class="font3" style="font-style:italic;">^man(<sup>x</sup>ii&gt;<sup>c</sup>ki)</span><span class="font3">: jarak Manhattan antara pengamatan ke-i variabel ke-j ke pusat klaster ke-k pada variabel ke-j</span></p>
<ul style="list-style:none;"><li>
<p><span class="font3" style="font-style:italic;"><sup>x</sup>i i</span><span class="font3">: objek pada pengamatan ke-i variabel ke-j</span></p></li></ul>
<p><span class="font3" style="font-style:italic;"><sup>c</sup>ki</span><span class="font3">: pusat klaster ke-k pada variabel ke-j</span></p>
<p><span class="font3">p :banyak variabel</span></p>
<p><span class="font3">n : banyak pengamatan</span></p>
<h4><a name="bookmark20"></a><span class="font3" style="font-weight:bold;"><a name="bookmark21"></a>CLARA</span></h4>
<p><span class="font3" style="font-style:italic;">Clara</span><span class="font3"> (Kaufman dan Rousseew, 1990) merupakan salah satu macam pengelompokan data dengan medoid sebagai pusat klasternya. Medoid merupakan objek yang letaknya terpusat pada suatu klaster, atau dengan kata lain merupakan suatu objek yang merepresentasikan anggota pada suatu data dan memiliki rata-rata perbedaan (dissimailarity) yang paling kecil dengan anggota-anggota lain.</span></p>
<p><span class="font3">Berbeda dengan metode medoid lainnya, yaitu Pam, metode Clara memiliki sifat robust terhadap outlier dan dapat digunakan untuk data dalam jumlah besar. Metode ini lebih efisien dalam hal waktu komputasi dan dalam penyimpanan data set yang besar.</span></p>
<p><span class="font3">Clara menggunakan pendekatan sampling, kemudian menerapkan algoritma Pam untuk mendapatkan medoid yang optimal untuk sampel. Kualitas medoid yang dihasilkan diukur dengan rata-rata perbedaan jarak antara setiap objek di data set dan medoid pada sampel. Dengan mengambil sampel cesara acak, medoid dari sampel diharapkan akan mendekati nilai medoid dari data set.</span></p>
<p><span class="font3">Algoritma Clara (Muslim, 2018):</span></p>
<ul style="list-style:none;"><li>
<p><span class="font3">1. &nbsp;&nbsp;&nbsp;Menentukan banyaknya klaster (k),</span></p></li>
<li>
<p><span class="font3">2. &nbsp;&nbsp;&nbsp;Membagi data set secara acak dalam beberapa sub set dengan ukuran tetap, dimana ukuran sampel setiap sub set minimal 40+2*k,</span></p></li>
<li>
<p><span class="font3">3. &nbsp;&nbsp;&nbsp;Menentukan medoid awal ,</span></p></li>
<li>
<p><span class="font3">4. &nbsp;&nbsp;&nbsp;Menghitung jarak non-medoid dengan medoid setiap klaster,</span></p></li>
<li>
<p><span class="font3">5. &nbsp;&nbsp;&nbsp;Menempatkan objek berdasarkan jarak terdekat dengan medoid,</span></p></li>
<li>
<p><span class="font3">6. &nbsp;&nbsp;&nbsp;Menghitung total jarak yang diperoleh,</span></p></li>
<li>
<p><span class="font3">7. &nbsp;&nbsp;&nbsp;Memilih secara acak objek non-medoid pada masing-masing klaster sebagai kandidat medoid baru,</span></p></li>
<li>
<p><span class="font3">8. &nbsp;&nbsp;&nbsp;Menghitung jarak setiap objek non medoid dengan kandidat medoid baru dan menempatkan objek berdasarkan jarak terdekat dengan medoid baru tersebut.</span></p></li>
<li>
<p><span class="font3">9. &nbsp;&nbsp;&nbsp;Menghitung selisih total jarak kandidat medoid baru dengan total jarak pada medoid lama. Jika total jarak setiap objek dengan kandidat medoid baru kurang dari total jarak setiap objek dengan medoid lama, maka kandidat medoid baru menjadi medoid baru,</span></p></li>
<li>
<p><span class="font3">10 . Mengulangi kembali langkah 7-9,</span></p></li>
<li>
<p><span class="font3">11 . Menghitung jarak antara semua </span><span class="font3" style="font-style:italic;">non medoid</span><span class="font3"> dengan objek yang menjadi </span><span class="font3" style="font-style:italic;">medoid</span><span class="font3">, hingga diperoleh sub set dengan jumlah terkecil adalah yang dipilih.</span></p></li></ul>
<ul style="list-style:none;"><li>
<p><span class="font3" style="font-weight:bold;">3. &nbsp;&nbsp;&nbsp;HASIL DAN PEMBAHASAN</span></p></li></ul>
<h4><a name="bookmark22"></a><span class="font3" style="font-weight:bold;"><a name="bookmark23"></a>Analisis Deskriptif</span></h4>
<p><span class="font3">Dari </span><span class="font3" style="font-style:italic;">summary</span><span class="font3"> data pada Tabel 1, terlihat bahwa terdapat beberapa </span><span class="font3" style="font-style:italic;">missing values (NA)</span><span class="font3">. Untuk melanjutkan analisis berikutnya, perlu dilakukan penanganan terhadap </span><span class="font3" style="font-style:italic;">missing values</span><span class="font3">, yaitu dengan mengestimasi nilai-nilai tersebut dengan menggunakan EM-Algorithm. Metode EM-Alghorithm merupakan suatu metode dengan Expectation-Step dilanjutkan Maximation-Step dengan iteratif maximum likelihood. Metode ini mengasumsikan sebuah distribusi dari data hilang secara parsial dan berdasarkan fungsi </span><span class="font3" style="font-style:italic;">likelihood</span><span class="font3"> dari distribusi tersebut. Dari pengujian dapat disimpulkan bahwa mekanisme </span><span class="font3" style="font-style:italic;">missing values</span><span class="font3"> yaitu dengan MCAR dan data tersebut berdistribusi normal, sehingga</span></p>
<p><span class="font3">untuk menaksir </span><span class="font3" style="font-style:italic;">missing values</span><span class="font3"> dapat dilakukan dengan EM Alghoritma. Selanjutnya dilakukan uji normalitas multivariat, didapatkan asumsi normalitas multivariat terpenuhi.</span></p>
<p><span class="font3">Tabel 1. Analis Deskriptif</span></p>
<table border="1">
<tr><td style="vertical-align:bottom;">
<p><span class="font3" style="font-weight:bold;">Variable</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3" style="font-weight:bold;">x1</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3" style="font-weight:bold;">x2</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3" style="font-weight:bold;">x3</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3" style="font-weight:bold;">x4</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font3" style="font-weight:bold;">Median</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3">9.544</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3">0.829</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3">65.13</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3">0.812</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font3" style="font-weight:bold;">Max.</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3">11.465</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3">0.967</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3">76.54</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3">0.985</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font3" style="font-weight:bold;">NA's</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3">7</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3" style="text-decoration:underline;">1</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3">0</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3">1</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font3" style="font-weight:bold;">Variable</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3" style="font-weight:bold;">x5</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3" style="font-weight:bold;">x6</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3" style="font-weight:bold;">x7</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3" style="font-weight:bold;">x8</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font3">Median</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3">-0.035</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3">0.781</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3">0.712</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3">0.281</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font3">Mean</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3">-0.011</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3">0.735</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3">0.707</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3">0.292</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font3">NA's</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3">8</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3" style="text-decoration:underline;">12</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3">1</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3">1</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font3" style="font-weight:bold;">Variable</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3" style="font-weight:bold;">x9</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3" style="font-weight:bold;">x10</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3" style="font-weight:bold;">x11</span></p></td><td style="vertical-align:top;"></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font3">Median</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3">0.476</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3">0.368</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3">0.439</span></p></td><td style="vertical-align:top;"></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font3">Mean</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3">0.496</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3">0.384</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3">0.459</span></p></td><td style="vertical-align:top;"></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font3">NA's :</span></p></td><td style="vertical-align:middle;">
<p><span class="font3">13</span></p></td><td style="vertical-align:middle;">
<p><span class="font3">16</span></p></td><td style="vertical-align:middle;">
<p><span class="font3">0</span></p></td><td style="vertical-align:top;"></td></tr>
</table>
<h4><a name="bookmark24"></a><span class="font3" style="font-weight:bold;"><a name="bookmark25"></a>Deteksi Outlier</span></h4>
<p><span class="font3">Fungsi aq.plot pada R (packages mvoutlier) menggambarkan jarak Mahalanobis kuadrat robust dari pengamatan terhadap fungsi distribusi empiris dari jarak Mahalanobis. Perhitungan jarak didasarkan pada Estimator MCD. Dari plot terlihat cukup banyak observasi yang merupakan outlier</span><span class="font3" style="font-style:italic;">.</span></p><img src="https://jurnal.harianregional.com/media/61980-8.jpg" alt="" style="width:181pt;height:215pt;">
<p><span class="font3">Gambar 1 Plot Uji Outlier</span></p>
<p><span class="font3" style="font-weight:bold;">Hasil ROBPCA</span></p>
<p><span class="font3">Dari ROBPCA didapatkan Principal Component 1 (PC1) menjelaskan 51,01%, kemudian ditambahkan PC2 sudah mampu menjelaskan sebesar 77,20 % dan ditambahkan PC3 menjadi sebesar 92,6 %. Nilai eigen &gt;1 yang diperoleh yang diperoleh dari matriks korelasi dibandingkan dengan nilai 1 dengan alasan karena ketika komponen utama diperoleh dari matriks korelasi (standardized data) variansi dari masing-masing variabelnya sama dengan 1. Jika suatu komponen utama tidak dapat menerangkan variansi melebihi dirinya sendiri, maka komponen utama tersebut tidak signifikan atau dengan kata lain, komponen utama yang memiliki nilai eigen &lt;1 dapat diabaikan.</span></p>
<p><span class="font3">Tabel 2. Proporsi Kumulatif dan Nilai Eigen ROBPCA</span></p>
<table border="1">
<tr><td style="vertical-align:top;">
<p><span class="font3">ROBPCA</span></p></td><td style="vertical-align:top;">
<p><span class="font3">PC1</span></p></td><td style="vertical-align:top;">
<p><span class="font3">PC2</span></p></td><td style="vertical-align:top;">
<p><span class="font3">PC3</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font3">Cumulative Proportion</span></p></td><td style="vertical-align:top;">
<p><span class="font3">0.5101</span></p></td><td style="vertical-align:top;">
<p><span class="font3">0.7720</span></p></td><td style="vertical-align:top;">
<p><span class="font3">0.926</span></p></td></tr>
<tr><td style="vertical-align:top;"></td><td style="vertical-align:top;"></td><td style="vertical-align:top;"></td><td style="vertical-align:top;"></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font3">4.7325703</span></p></td><td style="vertical-align:top;">
<p><span class="font3">2.4298</span></p>
<p><span class="font3">481</span></p></td><td style="vertical-align:top;">
<p><span class="font3">1.4285</span></p>
<p><span class="font3">390</span></p></td><td style="vertical-align:top;">
<p><span class="font3">0.6862</span></p>
<p><span class="font3">558</span></p></td></tr>
</table>
<p><span class="font3">Dari output tersebut didapatkan ^ρΛ2; ^ 3 yang memiliki nilai eigen &gt;1 sehingga untuk selanjutnya didapatkan 3 principal komponen. Hasil dari ROBPCA lebih baik, jika dibandingkan dengan hasil yang didapatkan dari Classic Principal Component Analysis sebagai berikut:</span></p>
<p><span class="font3">Tabel 3. Proporsi Kumulatif PCA Classic</span></p>
<table border="1">
<tr><td style="vertical-align:top;">
<p><span class="font3">CPCA</span></p></td><td style="vertical-align:top;">
<p><span class="font3">PC1</span></p></td><td style="vertical-align:top;">
<p><span class="font3">PC2</span></p></td><td style="vertical-align:top;">
<p><span class="font3">PC3</span></p></td><td style="vertical-align:top;">
<p><span class="font3">PC4</span></p></td><td style="vertical-align:top;">
<p><span class="font3">PC5</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font3">Cumulative</span></p>
<p><span class="font3">Proportion</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3">0.393</span></p>
<p><span class="font3">5</span></p></td><td style="vertical-align:top;">
<p><span class="font3">0.6030</span></p></td><td style="vertical-align:top;">
<p><span class="font3">0.7309</span></p></td><td style="vertical-align:top;">
<p><span class="font3">0.7991</span></p></td><td style="vertical-align:top;">
<p><span class="font3">0.85879</span></p></td></tr>
</table>
<p><span class="font3">Dari PCA didapatkan Principal Component yang lebih banyak, Principal Componen ke 3 hanya dapat dapat menjelaskan sebesar 73% sedangkan 85,89% dijelaskan oleh Principal Componen ke 5.</span></p>
<p><span class="font1">Robust PCA</span></p><img src="https://jurnal.harianregional.com/media/61980-9.jpg" alt="" style="width:149pt;height:126pt;">
<p><span class="font0">0 &nbsp;&nbsp;12 &nbsp;&nbsp;3</span></p>
<p><span class="font0">Score distance</span></p>
<p><span class="font3">Gambar 2. Output RobPCA</span></p>
<p><span class="font3">Dari plot di atas terlihat bahwa nomor observasi 56, 57 dan 68 dan lain-lain merupakan observasi yang outlier orthogonal karena mempunyai OD (</span><span class="font3" style="font-style:italic;">Orthogonal Distance</span><span class="font3">) besar </span><span class="font3" style="font-style:italic;">(&gt;cut-off point</span><span class="font3">), dan SD (Score Distance) kecil (&lt; cut-off point). Nomor 22, 49, dan 96 merupakan bad leverage point karena OD bernilai kecil namun SD besar. Nilai Loading ROBPCA merupakan bentuk standardisasi, maka persamaan Principal Component sebagai berikut:</span></p>
<p><span class="font2">F<sub>i</sub> = </span><span class="font2" style="font-weight:bold;">β<sub>i</sub>Z = </span><span class="font2">-0.42752694Z<sub>1</sub>- 0.41890063 Z<sub>2</sub> - 0.41660572Z<sub>3</sub> - 0.278C2083Z<sub>4</sub> - 0.10265343Z<sub>5</sub></span></p>
<p><span class="font2">+ 0.21175268Z<sub>6</sub> - 0.25418623Z<sub>7</sub> + 0.38125181Z<sub>8</sub> + 0.C1212936Z<sub>9</sub> + 0.133810 94Z<sub>i0</sub></span></p>
<p><span class="font2">+ 0.30267638 Z<sub>11</sub></span></p>
<p><span class="font2">F<sub>2</sub> = </span><span class="font2" style="font-weight:bold;">β<sub>2</sub>Z = </span><span class="font2">0.13711767 Z<sub>1</sub> - 0.057 9 634SZ<sub>2</sub> + 0.18385556Z<sub>3</sub> - 0.46310641Z<sub>4</sub> - 0.3243S379Z<sub>s</sub></span></p>
<p><span class="font2">+ O 23825719Z<sub>6</sub> - 0.40141868 Z<sub>7</sub> - C.00568559Z<sub>8</sub> - 0.4 78 0 52C9Z<sub>9</sub>- 0∙27 843 6 09Z<sub>10</sub></span></p>
<p><span class="font2">- 0.31680164Z<sub>11</sub></span></p>
<p><span class="font2" style="font-weight:bold;">F<sub>3</sub> = e<sub>3</sub>Z = </span><span class="font2">0.12414565 Z<sub>1</sub> + 0.17582854Z<sub>2</sub> + 0.08799225Z<sub>3</sub> + 0.13112D34Z<sub>4</sub> - 0.42608314Z<sub>5</sub></span></p>
<p><span class="font2">+ O 27371537Z<sub>6</sub> + O 33210065Z<sub>7</sub> + 0.02486175Z<sub>s</sub> - 0.38743172Z<sub>9</sub> + 0.60 1 64699Z<sub>lo</sub></span></p>
<p><span class="font2">+ 0 22198799Z<sub>11</sub></span></p>
<p><span class="font3">Nilai j dapat diterangkan paling baik oleh variabel (</span><span class="font3" style="font-style:italic;">log GDP per capita</span><span class="font3">), <sup>,</sup> ^H(</span><span class="font3" style="font-style:italic;">social support</span><span class="font3">), Zg(</span><span class="font3" style="font-style:italic;">Healthy life expectancy at birth</span><span class="font3">) dengan korelasi antara Fl dengan ketiga variabel tersebut adalah negatif. Hal ini berarti apabila ketiga variabel tersebut besar maka </span><span class="font11" style="font-variant:small-caps;">Fl</span><span class="font3"> bernilai kecil. Demikian pula</span></p>
<p><span class="font3">dengan variabel-variabel lain, jika bertanda negatif berarti korelasi antara ^i dengan variabel tersebut negatif, yang berarti jika variabel tersebut bernilai besar maka maka Ki akan bernilai kecil meskipun dengan rentang yang tidak begitu besar.</span></p>
<p><span class="font3">Tabel 4. Korelasi antara variabel and principal component</span></p>
<table border="1">
<tr><td style="vertical-align:top;"></td><td style="vertical-align:top;"></td><td style="vertical-align:bottom;">
<p><span class="font2">Kn</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">K<sub>3</sub></span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font3">Z<sub>1</sub></span></p></td><td style="vertical-align:bottom;">
<p><span class="font3">-0.930</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3">0.214</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3">0.148</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2">z<sub>s</sub></span></p></td><td style="vertical-align:bottom;">
<p><span class="font3">-0.911</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3">0.090</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3">0.210</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font3">Z<sub>a</sub></span></p></td><td style="vertical-align:bottom;">
<p><span class="font3">-0.906</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3">0.287</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3">0.105</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2">Z.</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3">-0.605</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3">-0.722</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3">0.157</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font3">Z<sub>s</sub></span></p></td><td style="vertical-align:bottom;">
<p><span class="font3">-0.223</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3">-0.506</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3">-0.509</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font3">Z<sub>s</sub></span></p></td><td style="vertical-align:bottom;">
<p><span class="font3">0.461</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3">0.371</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3">0.327</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font3">Z,</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3">-0.553</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3">-0.626</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3">0.397</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2">Z<sub>a</sub></span></p></td><td style="vertical-align:bottom;">
<p><span class="font3">0.829</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3">-0.009</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3">0.030</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font3">Z<sub>a</sub></span></p></td><td style="vertical-align:bottom;">
<p><span class="font3">0.026</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3">-0.745</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3">-0.463</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font3">Z<sub>u</sub></span></p></td><td style="vertical-align:bottom;">
<p><span class="font3">0.400</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3">-0.434</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3">0.719</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font3">Z<sub>i</sub>.</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3">0.658</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3">-0.494</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3">0.265</span></p></td></tr>
</table>
<p><span class="font3">Nilai ⅞ dapat diterangkan paling baik oleh variabel Zj (</span><span class="font3" style="font-style:italic;">Freedom to make life choices</span><span class="font3">), Z?(</span><span class="font3" style="font-style:italic;">Positive affect</span><span class="font3">), <sup>l</sup>&quot; Γ(</span><span class="font3" style="font-style:italic;">Confidence in national government</span><span class="font3">), koefisien ketiganya bernilai negative yang berarti korelasi antara ^™dengan ketiga variabel tersebut adalah negative. Hal ini berarti apabila K's kecil maka ketiga variabel tersebut besar. Demikian pula dengan variabel-variabel lain, jika bertanda positif berarti korelasi antara ^Hdengan variabel tersebut positif, yang berarti jika K≡ besar berarti maka variabel tersebut bernilai besar meskipun dengan rentang yang tidak begitu besar.</span></p>
<p><span class="font3">Nilai ^s dapat diterangkan paling baik oleh variabel 2w (</span><span class="font3" style="font-style:italic;">gini of household income reported in Gallup</span><span class="font3">), yang bernilai positif yang berarti korelasi dengan Zg adalah positif, jika variabel gini of household income reported in Gallup besar maka 's juga besar. Variabel ¾(</span><span class="font3" style="font-style:italic;">Generosity</span><span class="font3">) dan ¾(</span><span class="font3" style="font-style:italic;">Confidence in national government</span><span class="font3">) memiliki koefisien bernilai negative yang berarti korelasi antara 'sdengan ketdua variabel tersebut adalah negative. Hal ini berarti apabila ⅛3 kecil maka kedua variabel tersebut besar. Demikian pula dengan variabel-variabel lain, jika bertanda positif berarti korelasi antara 5<sup>7</sup>3dengan variabel tersebut positif, yang berarti jika ^3 besar berarti maka variabel tersebut bernilai besar meskipun dengan rentang yang tidak begitu besar.</span></p>
<p><span class="font3">Skor komponen utama diperoleh dari mensubtitusikan setiap observasi yang telah distandardisasi ke il,i<sup>r</sup>2∕^3. Dari skor komponen utama tersebut, selanjutnya akan dilakukan </span><span class="font3" style="font-style:italic;">cluster analysis</span><span class="font3"> dengan Clara Method.</span></p>
<h4><a name="bookmark26"></a><span class="font3" style="font-weight:bold;"><a name="bookmark27"></a>CLARA</span></h4>
<p><span class="font3">Dari analisis cluster dengan Clara Method dengan k dari 1 sampai dengan 10 dengan jarak Manhattan diperoleh nilai rata-rata Overall Average Silhouette Width paling tinggi untuk cluster 5 yaitu sebesar 0,40082. Hal ini menunjukkan bahwa terdapat ikatan yang cukup baik antara objek dan klaster yang terbentuk.</span></p>
<p><span class="font3">Selanjutnya dilakukan profiliasasi pada hasil kuster. Profilisasi dilakukan pada metode Clara dengan jarak Manhattan dengan jumlah klaster sebanyak 5. Pada tahap profilisasi akan dilihat karakteristik dari tiap klaster yang terbentuk, sehingga dapat dilihat kecenderungan tiap klaster.</span></p>
<p><span class="font3">Pada metode Clara, karakteristik dari klaster yang terbentuk, direpresentasikan dengan medoid tiap klaster. Selanjutnya, untuk menentukan karakteristik tiap klaster dilakukan perbandingan medoid antar klaster dengan memberikan skor setiap klaster untuk masing-masing variabel.</span></p>
<p><span class="font3">Tabel 5. Output Metode Clara dengan Jarak Manhattan</span></p>
<table border="1">
<tr><td style="vertical-align:top;"></td><td style="vertical-align:middle;">
<p><span class="font3">Medoid 1</span></p></td><td style="vertical-align:middle;">
<p><span class="font3">Medoid 2</span></p></td><td style="vertical-align:middle;">
<p><span class="font3">Medoid3</span></p></td><td style="vertical-align:middle;">
<p><span class="font3">Medoid4</span></p></td><td style="vertical-align:middle;">
<p><span class="font3">Medoid5</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font3">PC1</span></p></td><td style="vertical-align:top;">
<p><span class="font3">0.6597170</span></p></td><td style="vertical-align:top;">
<p><span class="font3">-0.2559214</span></p></td><td style="vertical-align:top;">
<p><span class="font3">-3.4573324</span></p></td><td style="vertical-align:top;">
<p><span class="font3">-1.2281044</span></p></td><td style="vertical-align:top;">
<p><span class="font3">1.3392786</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font3">PC2</span></p></td><td style="vertical-align:top;">
<p><span class="font3">2.3116726</span></p></td><td style="vertical-align:top;">
<p><span class="font3">-0.3103989</span></p></td><td style="vertical-align:top;">
<p><span class="font3">-1.2828750</span></p></td><td style="vertical-align:top;">
<p><span class="font3">1.5429096</span></p></td><td style="vertical-align:top;">
<p><span class="font3">-1.1803006</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font3">PC3</span></p></td><td style="vertical-align:top;">
<p><span class="font3">-0.4269951</span></p></td><td style="vertical-align:top;">
<p><span class="font3">2.0638235</span></p></td><td style="vertical-align:top;">
<p><span class="font3">-1.0097316</span></p></td><td style="vertical-align:top;">
<p><span class="font3">0.3678118</span></p></td><td style="vertical-align:top;">
<p><span class="font3">-0.4829762</span></p></td></tr>
</table>
<p><span class="font3">Skor disesuaikan dengan korelasi (positif atau negatif) antara variabel asal dengan variabel </span><span class="font3" style="font-style:italic;">Principal Component</span><span class="font3"> dan berdasarkan literatur dari makna setiap variabel, didapatkan:</span></p>
<p><span class="font3">Tabel 6.Skor dari Medoid</span></p>
<table border="1">
<tr><td style="vertical-align:top;">
<p><span class="font3">Score</span></p></td><td style="vertical-align:top;">
<p><span class="font3">Medoid 1</span></p></td><td style="vertical-align:top;">
<p><span class="font3">Medoid 2</span></p></td><td style="vertical-align:top;">
<p><span class="font3">Medoid 3</span></p></td><td style="vertical-align:top;">
<p><span class="font3">Medoid 4</span></p></td><td style="vertical-align:top;">
<p><span class="font3">Medoid 5</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font3">PC1</span></p></td><td style="vertical-align:top;">
<p><span class="font3">2</span></p></td><td style="vertical-align:top;">
<p><span class="font3">3</span></p></td><td style="vertical-align:top;">
<p><span class="font3">5</span></p></td><td style="vertical-align:top;">
<p><span class="font3">4</span></p></td><td style="vertical-align:top;">
<p><span class="font3">1</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font3">PC2</span></p></td><td style="vertical-align:top;">
<p><span class="font3">1</span></p></td><td style="vertical-align:top;">
<p><span class="font3">3</span></p></td><td style="vertical-align:top;">
<p><span class="font3">5</span></p></td><td style="vertical-align:top;">
<p><span class="font3">2</span></p></td><td style="vertical-align:top;">
<p><span class="font3">4</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font3">PC3</span></p></td><td style="vertical-align:top;">
<p><span class="font3">3</span></p></td><td style="vertical-align:top;">
<p><span class="font3">1</span></p></td><td style="vertical-align:top;">
<p><span class="font3">5</span></p></td><td style="vertical-align:top;">
<p><span class="font3">2</span></p></td><td style="vertical-align:top;">
<p><span class="font3">4</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font3">Total</span></p></td><td style="vertical-align:top;">
<p><span class="font3">6</span></p></td><td style="vertical-align:top;">
<p><span class="font3">7</span></p></td><td style="vertical-align:top;">
<p><span class="font3">15</span></p></td><td style="vertical-align:top;">
<p><span class="font3">8</span></p></td><td style="vertical-align:top;">
<p><span class="font3">9</span></p></td></tr>
</table>
<h4><a name="bookmark28"></a><span class="font3" style="font-weight:bold;"><a name="bookmark29"></a>Intrepetasi Setiap Medoid</span><br><br><span class="font3" style="font-weight:bold;"><a name="bookmark30"></a>Medoid 1 merupakan cluster dengan skor 6</span></h4>
<p><span class="font3">Medoid 1 merupakan cluster dengan karakteristik yang tersusun sebagai berikut:</span></p>
<p><span class="font3" style="font-style:italic;">S</span><span class="font3"> PC1 diterangkan dengan korelasi yang tinggi untuk variabel ■ </span><span class="font9">∣</span><span class="font3">(</span><span class="font3" style="font-style:italic;">log GDP per capita</span><span class="font3">), C (</span><span class="font3" style="font-style:italic;">social support</span><span class="font3">), &nbsp;&nbsp;&nbsp;&nbsp;(</span><span class="font3" style="font-style:italic;">healthy life expectancy at birth)</span><span class="font3"> yang berarti variabel dalam medoid</span></p>
<p><span class="font3">tersebut memiliki nilai rendah dan </span><span class="font3" style="font-style:italic;">(negative affect)</span><span class="font3"> yang memiliki korelasi positif dengan nilai yang tinggi.</span></p>
<p><span class="font3" style="font-style:italic;">S</span><span class="font3"> PC2 diterangkan dengan korelasi negative yang tinggi oleh variabel ■'■ -, (</span><span class="font3" style="font-style:italic;">Freedom to make life choices</span><span class="font3">), &nbsp;&nbsp;&nbsp;(</span><span class="font3" style="font-style:italic;">Positive affect</span><span class="font3">), &nbsp;&nbsp;&nbsp;(</span><span class="font3" style="font-style:italic;">Confidence in national government</span><span class="font3">) yang berarti variabel</span></p>
<p><span class="font3">dalam medoid tersebut memiliki nilai kecil.</span></p>
<p><span class="font3" style="font-style:italic;">S</span><span class="font3"> PC3 diterangkan dengan korelasi positif yang tinggi oleh variabel ■'.: (</span><span class="font3" style="font-style:italic;">gini of household income reported in Gallup</span><span class="font3">) yang berarti dalam medoid tersebut memiliki nilai yang rendah. Koefisien gini yang rendah berarti ketimpangan kecil, dalam hal ini diberikan skor yang tinggi terkait kontribusinya terhadapat indeks kebahagiaan. Jumlah anggota pada cluster ini sebanyak 26 negara, yaitu Afghanistan, Albania, Algeria, Armenia, Belarus, Bosnia Herzegovina, Kroasia, Agypt, Gabon, Georgia, Greece, Iraq, Jordan, Lebanon, Macedonia, Mauritania, Moldova, Montenegro, Palestina, Terrotories, Serbia, Korea Selatan, Tunisia, Turki, Ukraina, Vietnam, Yaman</span></p>
<p><span class="font3" style="font-weight:bold;">Medoid 2 merupakan klaster dengan skor 7</span></p>
<p><span class="font3">Medoid 2 merupakan cluster dengan karakteristik yang tersusun sebagai berikut:</span></p>
<p><span class="font3" style="font-style:italic;">S</span><span class="font3"> PC1 diterangkan dengan korelasi yang tinggi untuk variabel ■ </span><span class="font9">∣</span><span class="font3">(</span><span class="font3" style="font-style:italic;">log GDP per capita</span><span class="font3">), C (</span><span class="font3" style="font-style:italic;">social support</span><span class="font3">), &nbsp;&nbsp;&nbsp;&nbsp;(</span><span class="font3" style="font-style:italic;">healthy life expectancy at birth)</span><span class="font3"> yang berarti variabel dalam medoid</span></p>
<p><span class="font3">tersebut memiliki nilai tinggi dan </span><span class="font3" style="font-style:italic;">(negative affect)</span><span class="font3"> yang memiliki korelasi positif dengan nilai yang tinggi.</span></p>
<p><span class="font3" style="font-style:italic;">S</span><span class="font3"> PC2 diterangkan dengan korelasi negatif yang tinggi oleh variabel ■'■-. (</span><span class="font3" style="font-style:italic;">Freedom to make life choices</span><span class="font3">), &nbsp;&nbsp;&nbsp;(</span><span class="font3" style="font-style:italic;">Positive affect</span><span class="font3">), &nbsp;&nbsp;&nbsp;(</span><span class="font3" style="font-style:italic;">Confidence in national government</span><span class="font3">) yang berarti variabel</span></p>
<p><span class="font3">dalam medoid tersebut memiliki nilai besar (skor tinggi).</span></p>
<p><span class="font3" style="font-style:italic;">S</span><span class="font3"> PC3 diterangkan dengan korelasi positif yang tinggi oleh variabel ■'■_: (</span><span class="font3" style="font-style:italic;">gini of household income reported in Gallup</span><span class="font3">) yang berarti dalam medoid tersebut memiliki nilai yang besar. Koefisien gini yang besar berarti ketimpangan tinggi, dalam hal ini diberikan skor yang rendah terkait kontribusinya terhadapat indeks kebahagiaan. Jumlah anggota pada cluster ini sebanyak 24 negara, yaitu Argentina, Bolivia, Brazil, Chile, Colombia, Costa Rica, Dominica,</span></p>
<p><span class="font3">Ekuador, El Savador, Guatemala, Honduras, Jamaica, Libya, Mexico, Namibia, Nicaragua, Panama, Peru, Sri Lanka, Trinidad dan Tobago, Afrika Selatan, Amerika Serikat, Uruguay.</span></p>
<p><span class="font3" style="font-weight:bold;">Medoid 3 merupakan klaster dengan skor 15</span></p>
<p><span class="font3">Medoid 3 merupakan cluster dengan karakteristik yang tersusun sebagai berikut:</span></p>
<p><span class="font3" style="font-style:italic;">S</span><span class="font3"> PC1 diterangkan dengan korelasi yang tinggi untuk variabel ■ </span><span class="font9">∣</span><span class="font3">(</span><span class="font3" style="font-style:italic;">log GDP per capita</span><span class="font3">), C (</span><span class="font3" style="font-style:italic;">social support</span><span class="font3">), &nbsp;&nbsp;&nbsp;&nbsp;(</span><span class="font3" style="font-style:italic;">healthy life expectancy at birth</span><span class="font3">) yang berarti variabel dalam medoid</span></p>
<p><span class="font3">tersebut memiliki nilai tinggi dan </span><span class="font3" style="font-style:italic;">(negative affect)</span><span class="font3"> yang memiliki korelasi positif dengan nilai yang rendah.</span></p>
<p><span class="font3" style="font-style:italic;">S</span><span class="font3"> PC2 diterangkan dengan korelasi negative yang tinggi oleh variabel ■'■ -, (</span><span class="font3" style="font-style:italic;">Freedom to make life choices</span><span class="font3">), &nbsp;&nbsp;&nbsp;(</span><span class="font3" style="font-style:italic;">Positive affect</span><span class="font3">), &nbsp;&nbsp;&nbsp;</span><span class="font3" style="font-style:italic;">(Confidence in national government</span><span class="font3">) yang berarti variabel</span></p>
<p><span class="font3">dalam medoid tersebut memiliki nilai besar.</span></p>
<p><span class="font3" style="font-style:italic;">S</span><span class="font3"> PC3 diterangkan dengan korelasi positif yang tinggi oleh variabel ■'■_: (</span><span class="font3" style="font-style:italic;">gini of household income reported in Gallup</span><span class="font3">) yang berarti dalam medoid tersebut memiliki nilai yang rendah. Koefisien gini yang rendah berarti ketimpangan kecil, dalam hal ini diberikan skor yang tinggi terkait kontribusinya terhadapat indeks kebahagiaan. Jumlah anggota pada cluster ini sebanyak 22 negara, yaitu Australia, Austria, Belgium, Denmark, Finlandia, Jerman, Hong Kong, Islandia, Irlandia, Kyrgystan, Luxemburg, Malta, Mauritius, Belanda, Selandia Baru, Norway, Singapura, Arab Saudi, Switzerland, Swedia, United Kingdom, dan Uzbekistan.</span></p>
<p><span class="font3" style="font-weight:bold;">Medoid 4 merupakan klaster dengan skor 8</span></p>
<p><span class="font3">Medoid 4 merupakan cluster dengan karakteristik yang tersusun sebagai berikut:</span></p>
<p><span class="font3" style="font-style:italic;">S</span><span class="font3"> PC1 diterangkan dengan korelasi yang tinggi untuk variabel ■'■-(</span><span class="font3" style="font-style:italic;">log GDP per capita</span><span class="font3">), ■'■; (</span><span class="font3" style="font-style:italic;">social support</span><span class="font3">), &nbsp;&nbsp;&nbsp;&nbsp;(</span><span class="font3" style="font-style:italic;">healthy life expectancy at birth)</span><span class="font3"> yang berarti variabel dalam medoid</span></p>
<p><span class="font3">tersebut memiliki nilai tinggi dan </span><span class="font3" style="font-style:italic;">(negative affect)</span><span class="font3"> yang memiliki korelasi positif dengan nilai yang tinggi.</span></p>
<p><span class="font3" style="font-style:italic;">S</span><span class="font3"> PC2 diterangkan dengan korelasi negatif yang tinggi oleh variabel ■'■-. (</span><span class="font3" style="font-style:italic;">Freedom to make life choices</span><span class="font3">), &nbsp;&nbsp;&nbsp;(</span><span class="font3" style="font-style:italic;">Positive affect</span><span class="font3">), &nbsp;&nbsp;&nbsp;(</span><span class="font3" style="font-style:italic;">Confidence in national government</span><span class="font3">) yang berarti variabel</span></p>
<p><span class="font3">dalam medoid tersebut memiliki nilai rendah.</span></p>
<p><span class="font3" style="font-style:italic;">S</span><span class="font3"> PC3 diterangkan dengan korelasi positif yang tinggi oleh variabel ■'■_: (</span><span class="font3" style="font-style:italic;">gini of household income reported in Gallup)</span><span class="font3"> yang berarti dalam medoid tersebut memiliki nilai yang tinggi. Koefisien gini yang tinggi berarti ketimpangan besar, dalam hal ini diberikan skor yang rendah terkait kontribusinya terhadapat indeks kebahagiaan. Anggota dari Klaster 4 antara lain, Azerbaijan, Bahrain, Bulgaria, Cyprus, Republik Ceko, Estonia, Perancis, Hongaria, Israel, Italia, Jepang, Kazakhstan, Kosovo, Kuwait, Latvia, Lituania, Mongolia, Polandia, Turkmenistan, Romania, Russia, Arab Saudi, Slovakia, Slovenia, Spanyol, Portugal, Thailand, Taiwan.</span></p>
<p><span class="font3" style="font-weight:bold;">Medoid 5 merupakan klaster dengan skor 9</span></p>
<p><span class="font3">Medoid 5 merupakan cluster dengan karakteristik yang tersusun sebagai berikut:</span></p>
<p><span class="font3" style="font-style:italic;">S</span><span class="font3"> PC1 diterangkan dengan korelasi yang tinggi untuk variabel ■'■-(</span><span class="font3" style="font-style:italic;">log GDP per capita</span><span class="font3">), ■'■; (</span><span class="font3" style="font-style:italic;">social support</span><span class="font3">), &nbsp;&nbsp;&nbsp;&nbsp;(</span><span class="font3" style="font-style:italic;">healthy life expectancy at birth</span><span class="font3">) yang berarti variabel dalam medoid</span></p>
<p><span class="font3">tersebut memiliki nilai rendah dan &nbsp;&nbsp;&nbsp;(</span><span class="font3" style="font-style:italic;">negative affect</span><span class="font3">) yang memiliki korelasi positif dengan</span></p>
<p><span class="font3">nilai yang besar.</span></p>
<p><span class="font3" style="font-style:italic;">S</span><span class="font3"> PC2 diterangkan dengan korelasi negative yang tinggi oleh variabel ■'■ - (</span><span class="font3" style="font-style:italic;">Freedom to make life choices</span><span class="font3">), &nbsp;&nbsp;&nbsp;(</span><span class="font3" style="font-style:italic;">Positive affect</span><span class="font3">), &nbsp;&nbsp;&nbsp;(</span><span class="font3" style="font-style:italic;">Confidence in national government</span><span class="font3">) yang berarti variabel</span></p>
<p><span class="font3">dalam medoid tersebut memiliki nilai tinggi.</span></p>
<p><span class="font3" style="font-style:italic;">S</span><span class="font3"> PC3 diterangkan dengan korelasi positif yang tinggi oleh variabel ■'■_. (</span><span class="font3" style="font-style:italic;">gini of household income reported in Gallup</span><span class="font3">) yang berarti dalam medoid tersebut memiliki nilai yang rendah. Koefisien gini yang rendah berarti ketimpangan rendah, dalam hal ini diberikan skor yang tinggi terkait kontribusinya terhadapat indeks kebahagiaan. Jumlah anggota pada cluster ini sebanyak 41 negara, yaitu Bangladesh, Benin, Botswana, Burkina Faso, Cambodia, Cameroon, Zimbabwe, Chad, Congo (Brazzaville), Congo (Kinshasa), Ethiopia, Ghana,</span></p>
<p><span class="font3">Guinea, Haiti, India, Indonesia, Iran, Pantai Gading, Kenya, Laos, Liberia, Madagaskar, Malawi, Mali, Morocco, Mozambik, Myanmar, Nepal, Niger, Nigeria, Pakistan, Filipina, Senegal, Sierra Leone, Sudan Selatan, Tajikistan, Tanzania, Togo, Uganda, Zambia, Republik Afrika Tengah.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font3" style="font-weight:bold;">4. &nbsp;&nbsp;&nbsp;KESIMPULAN DAN SARAN</span></p></li></ul>
<h4><a name="bookmark31"></a><span class="font3" style="font-weight:bold;"><a name="bookmark32"></a>Kesimpulan</span></h4>
<p><span class="font3">Metode ROBPCA merupakan suatu model PCA yang </span><span class="font3" style="font-style:italic;">robust</span><span class="font3"> terhadap outlier, dan lebih efisien (mampu menghasilkan lebih sedikit jumlah Principal Component) daripada Classic PCA. Dengan metode ROBPCA yang diterapkan untuk studi kasus variable-variabel penyusun indeks kebahagiaan dari data The World Happiness Report 2018, didapatkan 3 (tiga) Principal Component yang dapat menjelaskan sebesar 92,6 % dari total varians data. Hal ini terbukti ROBPCA lebih efisien daripada metode PCA dengan sebanyak 5 Principal Componen yang dapat menjelaskan sebesar 85,89% dari total varians. Metode Clara merupakan Analysis Cluster dengan pusat cluster medoid yang robust untuk mengelompokkan data dengan outlier dan data dalam jumlah besar. Analysis Cluster dengan Clara method dari Principal Component yang terbentuk menggunakan jarak manhattan didapatkan nilai rata-rata Overall Average Silhouette Width yang terbaik pada 5 cluster. Berdasarkan profiling cluster dengan score antar medoid, didapatkan score paling tinggi pada cluster 3. Berdasrkan literature dari setiap variabel berarti bahwa cluster 3 terdiri dari negara-negara dengan indeks kebahagiaan yang baik. Sedangkan score medoid terendah adalah cluster 1..</span></p>
<h4><a name="bookmark33"></a><span class="font3" style="font-weight:bold;"><a name="bookmark34"></a>Saran</span></h4>
<p><span class="font3">Penerapan metode ROBPCA dan Metode Clara (Clustering Large Area) pada studi kasus yang lain khususnya untuk high dimensional data.</span></p>
<h4><a name="bookmark35"></a><span class="font3" style="font-weight:bold;"><a name="bookmark36"></a>UCAPAN TERIMA KASIH</span></h4>
<p><span class="font3">Terima kasih kepada Bpk Dr. Irlandia Ginanjar,S.Si., M.Si atas masukan dan bimbingannya untuk penelitian ini.</span></p>
<h4><a name="bookmark37"></a><span class="font3" style="font-weight:bold;"><a name="bookmark38"></a>REFERENSI</span></h4>
<p><span class="font3">Hubert, M,,Rousseeuw, P,J,, and Branden, K,,V, 2005, </span><span class="font3" style="font-style:italic;">ROBPCA:</span><span class="font3"> a New Approach to Robust Principal Component Analysis, American Statistical and the American Society for Quality, </span><span class="font3" style="font-style:italic;">Technometric, Vol,47, No,1, Belgium.</span></p>
<p><span class="font3">Johnson, R.A. dan Winchern, D.W.2007, </span><span class="font3" style="font-style:italic;">Applied Multivariate Statistical Analysis</span><span class="font3">. 6<sup>th</sup> edition, Pearson Education,Inc., USA.</span></p>
<p><span class="font3">Kassambra, Alboukadel, 2017, Practical Guide to Cluster Analysis in R.STHDA.</span></p>
<p><span class="font3">Kaufman, L. dan Rousseeuw, P.J., 1990, FindingGroups in Data : </span><span class="font3" style="font-style:italic;">An Introduction to Cluster Analysis</span><span class="font3">, John Wiley and Sons, Inc, New Jersey.</span></p>
<p><span class="font3">Muslim,A,B, 2018, </span><span class="font3" style="font-style:italic;">Cluster Analysis using Clara Method for Data with Outlier,</span><span class="font3"> FMIPA UGM, Yogyakarta.</span></p>
<p><span class="font3">Rencher, A.C., 2002, </span><span class="font3" style="font-style:italic;">Methods of Multivariate Analysis</span><span class="font3">, Second Edition, John Wiley and Sons, Inc., New York.</span></p>
<p><span class="font3">Sobiroh,T,R, 2015, </span><span class="font3" style="font-style:italic;">Robust Principal Component Analysis (ROBPCA) for High Dimensional Data with Outlier</span><span class="font3">, FMIPA UGM, Yogyakarta.</span></p>
<p><span class="font3">Statistical Appendix 1 for Chapter 2 of World Happiness Report.2018.</span></p>
<p><span class="font8">98</span></p>