---
layout: full_article
title: "METODE WEIGHTED MAXIMUM CAPTURING UNTUK KLASTERISASI DOKUMEN BERBASIS FREQUENT ITEMSETS"
author: "Gede Aditra Pradnyana, Arif Djunaidy"
categories: jik
canonical_url: https://jurnal.harianregional.com/jik/full-8408 
citation_abstract_html_url: "https://jurnal.harianregional.com/jik/id-8408"
citation_pdf_url: "https://jurnal.harianregional.com/jik/full-8408"  
comments: true
---

<p><span class="font11" style="font-weight:bold;">Jurnal Ilmiah </span><span class="font0" style="font-weight:bold;font-variant:small-caps;">Ilmukomputer </span><span class="font11" style="font-weight:bold;">Universitas Udayana Vol. 6, No. 2, September 2013</span></p>
<div>
<p><span class="font11" style="font-weight:bold;">ISSN 1979-5661</span></p>
</div><br clear="all"><a name="caption1"></a>
<h1><a name="bookmark0"></a><span class="font15" style="font-weight:bold;"><a name="bookmark1"></a>METODE WEIGHTED MAXIMUM CAPTURING UNTUK</span><br><br><span class="font15" style="font-weight:bold;"><a name="bookmark2"></a>KLASTERISASI DOKUMEN BERBASIS FREQUENT ITEMSETS</span></h1>
<h3><a name="bookmark3"></a><span class="font14" style="font-weight:bold;"><a name="bookmark4"></a>Gede Aditra Pradnyana<sup>1</sup>, Arif Djunaidy<sup>2</sup></span></h3>
<ul style="list-style:none;"><li>
<p><span class="font12"><sup>1</sup> &nbsp;&nbsp;&nbsp;Jurusan Teknik Informatika, Fakultas Teknologi Informasi, Institut Teknologi Sepuluh Nopember Kampus ITS Keputih Sukolilo</span><span class="font12" style="font-style:italic;">,</span><span class="font12"> Surabaya, Jawa Timur</span></p></li>
<li>
<p><span class="font12"><sup>2</sup> &nbsp;&nbsp;&nbsp;Jurusan Sistem Informasi, Fakultas Teknologi Informasi, Institut Teknologi Sepuluh Nopember Kampus ITS Keputih Sukolilo</span><span class="font12" style="font-style:italic;">,</span><span class="font12"> Surabaya, Jawa Timur</span></p></li></ul>
<p><span class="font12">Email: </span><a href="mailto:gede.aditra@gmail.com"><span class="font12">gede.aditra@gmail.com</span></a></p>
<h3><a name="bookmark5"></a><span class="font14" style="font-weight:bold;"><a name="bookmark6"></a>ABSTRAK</span></h3>
<p><span class="font12" style="font-style:italic;">Klasterisasi dokumen berbasis frequent itemsets merupakan salah satu metode klasterisasi dokumen baru yang dapat digunakan untuk mengatasi masalah tingginya ruang dimensi dari dokumen yang akan diklasterisasi. Teknik maximum capturing merupakan salah satu algoritma klasterisasi dokumen berbasis frequent itemsets yang mampu menghasilkan kualitas klasterisasi yang lebih baik dibandingkan dengan yang dihasilkan oleh algoritma sejenis lainnya. Teknik maximum capturing ini masih memiliki kekurangan atau kelemahan, yaitu: tidak diperhitungkannya bobot suatu kata (item) dalam frequent itemsets saat perhitungan kemiripan dokumen dan dalam proses pembentukan klaster tidak memperhitungkan informasi global dari klaster yang telah terbentuk sebelumnya. Dalam penelitian ini dikembangkan suatu metode baru untuk klasterisasi dokumen dengan berbasis frequent itemsets yaitu metode weighted maximum capturing (WMC), untuk memperbaiki kekurangan teknik maximum capturing sehingga kualitas akurasi hasil klasterisasi dokumen dapat ditingkatkan. Pada metode weighted maximum capturing ini kemiripan dokumen dihitung dengan menggabungkan metode cosine similarity dan jaccard coefficient berdasarkan jumlah frequent itemsets yang sama yang dimiliki sehingga bobot dari item dalam itemsets dapat diperhitungkan, sedangkan pada proses pembentukan klaster diadaptasi algoritma single linkage agglomerative hierarchical clustering. Hasil uji coba dengan data uji Reuters 21578 menunjukkan nilai F-measure dan purity dari metode WMC lebih baik dibandingkan dengan metode awal, yaitu sebesar 0,723 untuk nilai F-measure dengan rasio perbaikan 2,8% dan 0,73 untuk nilai purity dengan rasio perbaikan 3,3%.</span></p>
<p><span class="font12" style="font-weight:bold;">Kata kunci: </span><span class="font12">Klasterisasi dokumen, </span><span class="font12" style="font-style:italic;">frequent itemsets</span><span class="font12">, </span><span class="font12" style="font-style:italic;">weighted maximum capturing</span><span class="font12">, </span><span class="font12" style="font-style:italic;">cosine similarity</span><span class="font12">, </span><span class="font12" style="font-style:italic;">jaccard coefficient</span></p>
<p><span class="font12" style="font-style:italic;">Document clustering based on frequent itemsets is one of the new document clustering method that can be used to overcome the problem of high-dimensional space of the document being clustered. Maximum capturing technique is one document clustering algorithm based frequent itemsets that can generate better clustering quality compared to those produced by other similar algorithms. The maximum capturing technique still has the lack or weakness, ie: not accounting for the weight of a word (item) in the calculation of frequent itemsets when the document similarity and the cluster formation process does not take into account the global information of the cluster previously formed. In this research developed a new method for clustering documents based frequent itemset namely weighted maximum capturing method (WMC), to correct deficiencies maksimum capturing accuracy so that the quality of document clustering results can be improved. In the weighted maximum capturing method, document similarity is computed by combining the cosine similarity method and Jaccard coefficient based on the same number of frequent itemsets owned so that the weight of items in itemsets can be taken into account, while in the process of constructing cluster adapted single linkage agglomerative hierarchical clustering algorithm. Experimental results show the value of F-measure and purity of WMC method is better than the earlier method, that is equal to 0.723 for the F-measure with improvement ratio of 2.8% and a purity value of 0.73 with improvement ratio 3.3%.</span></p>
<p><span class="font12" style="font-weight:bold;">Keywords: </span><span class="font12">document clustering, frequent itemsets, weighted maximum capturing, cosine similarity, jaccard coefficient</span></p>
<ul style="list-style:none;"><li>
<h3><a name="bookmark7"></a><span class="font14" style="font-weight:bold;"><a name="bookmark8"></a>1. &nbsp;&nbsp;&nbsp;PENDAHULUAN</span></h3></li></ul>
<p><span class="font12">Peningkatan jumlah dokumen dalam format teks yang cukup signifikan membuat proses</span></p>
<p><span class="font12">pengelompokkan atau klasterisasi dokumen (</span><span class="font12" style="font-style:italic;">document clustering</span><span class="font12">) menjadi penting. Zhao dan Karypis (2004) mendefinisikan klasterisasi sebagai proses yang membagi suatu set objek menjadi</span></p>
<p><span class="font12">beberapa jumlah kelompok (klaster) secara spesifik. Klasterisasi dokumen bertujuan membagi dokumen dalam beberapa kelompok sedemikian hingga dokumen-dokumen dalam klaster yang sama (</span><span class="font12" style="font-style:italic;">intra-</span><span class="font12">klaster) memiliki kesamaan yang tinggi, sementara dokumen-dokumen dalam klaster yang berbeda (</span><span class="font12" style="font-style:italic;">inter-</span><span class="font12">klaster) memiliki kesamaan yang rendah (Jain, dkk., 1999; Steinbach, dkk., 2000; Zhao dan Karypis, 2004).</span></p>
<p><span class="font12">Secara umum terdapat dua teknik utama dalam proses klasterisasi yaitu </span><span class="font12" style="font-style:italic;">hierarchical</span><span class="font12"> dan </span><span class="font12" style="font-style:italic;">partitional clustering</span><span class="font12"> (Jain, dkk., 1999). Algoritma-algoritma klasterisasi </span><span class="font12" style="font-style:italic;">hierarchical</span><span class="font12"> dan </span><span class="font12" style="font-style:italic;">partitional </span><span class="font12">sebenarnya belum sepenuhnya dapat mengatasi tantangan dalam kasus klasterisasi dokumen, misalnya seperti: algoritma tersebut masih mengklaster ruang vektor berdimensi tinggi (</span><span class="font12" style="font-style:italic;">high dimensional vector space</span><span class="font12">) sepenuhnya dan </span><span class="font12" style="font-style:italic;">centroid </span><span class="font12">ataupun rata-rata dari klaster yang terbentuk tidak menyediakan deskripsi yang dimengerti mengenai klaster tersebut. Dalam model ruang vektor (</span><span class="font12" style="font-style:italic;">vector space model</span><span class="font12">), penggunaan kata-kata yang berdiri sendiri (</span><span class="font12" style="font-style:italic;">individual words</span><span class="font12">) akan mengakibatkan tingginya dimensi vektor. Di lain sisi sebenarnya tidak semua dokumen dalam koleksi juga mengandung semua indeks kata yang digunakan dalam vektor. Permasalahan ini mendorong pengembangan metode baru dalam klasterisasi dokumen yang tidak didasari penggunaan model ruang vektor (Beil dkk., 2002).</span></p>
<p><span class="font12" style="font-style:italic;">Frequent itemsets</span><span class="font12"> muncul untuk mengatasi masalah ini. Beberapa peneliti (Beil, dkk., 2002; Fung, dkk., 2003; Li, dkk., 2008; Zhang, dkk., 2010) telah menerapkan konsep </span><span class="font12" style="font-style:italic;">frequent itemsets </span><span class="font12">dalam klasterisasi dokumen. Diawali oleh Beil, dkk (2002) yang menggunakan </span><span class="font12" style="font-style:italic;">frequent</span><span class="font12"> item untuk merepresentasikan kandidat dari suatu klaster. Fung, dkk (2003) kemudian mengenalkan penggunaan global </span><span class="font12" style="font-style:italic;">frequent itemsets</span><span class="font12"> dan klaster </span><span class="font12" style="font-style:italic;">frequent itemsets</span><span class="font12"> untuk kemudian digunakan dalam proses </span><span class="font12" style="font-style:italic;">clustering</span><span class="font12"> dokumen secara hirarki. Penelitian yang dilakukan oleh Li, dkk (2008) menambahkan aspek urutan (</span><span class="font12" style="font-style:italic;">sequence</span><span class="font12">) item dari suatu </span><span class="font12" style="font-style:italic;">frequent itemsets</span><span class="font12"> untuk digunakan dalam klasterisasi dokumen. Dari percobaan yang dilakukan pada penelitian-penelitian diatas, kualitas hasil klasterisasi dengan konsep </span><span class="font12" style="font-style:italic;">frequent itemsets </span><span class="font12">lebih baik dari algoritma-algoritma </span><span class="font12" style="font-style:italic;">clustering </span><span class="font12">konvensional seperti </span><span class="font12" style="font-style:italic;">K-means</span><span class="font12">, </span><span class="font12" style="font-style:italic;">bisecting K-means</span><span class="font12">, dan UPGMA. Hasil dari penelitian-penelitian diatas juga membuktikan bahwa konsep </span><span class="font12" style="font-style:italic;">frequent itemsets </span><span class="font12">yang digunakan dapat melakukan reduksi dimensi dengan baik yang berkibat meningkatnya efisiensi dan skalabilitas proses </span><span class="font12" style="font-style:italic;">clustering</span><span class="font12"> dokumen. Selanjutnya, Zhang, dkk (2010) mengajukan metode </span><span class="font12" style="font-style:italic;">text clustering</span><span class="font12"> dengan </span><span class="font12" style="font-style:italic;">frequent itemsets </span><span class="font12">yang terbukti lebih baik dari metode-metode berbasis </span><span class="font12" style="font-style:italic;">frequent itemsets</span><span class="font12"> sebelumnya dalam hal akurasi hasil klasterisasi. Metode yang diajukan menggunakan teknik </span><span class="font12" style="font-style:italic;">maximum capturing</span><span class="font12"> dalam</span></p>
<p><span class="font12">membentuk klaster dari </span><span class="font12" style="font-style:italic;">frequent itemsets</span><span class="font12"> yang ada. Dalam proses klasterisasi dokumen, metode yang diajukan oleh Zhang, dkk (2010) ini juga mengadaptasi algoritma </span><span class="font12" style="font-style:italic;">minimum spanning tree</span><span class="font12"> ke dalam metode klasterisasi </span><span class="font12" style="font-style:italic;">partitional</span><span class="font12">.</span></p>
<p><span class="font12">Metode klasterisasi dokumen berbasis </span><span class="font12" style="font-style:italic;">frequent itemsets</span><span class="font12"> dengan teknik </span><span class="font12" style="font-style:italic;">maximum capturing</span><span class="font12"> masih memiliki beberapa kekurangan. Pertama, metode </span><span class="font12" style="font-style:italic;">maximum capturing</span><span class="font12"> yang digunakan tidak memperhatikan bobot kata (item) pada </span><span class="font12" style="font-style:italic;">frequent itemset</span><span class="font12"> saat pengalian </span><span class="font12" style="font-style:italic;">frequent itemsets</span><span class="font12"> dan penggukuran kemirpan (</span><span class="font12" style="font-style:italic;">similarity</span><span class="font12">) antar dokumen dalam membentuk suatu klaster. Pada saat proses pembentukan klaster, kemiripan suatu dokumen dengan dokumen lain pada teknik </span><span class="font12" style="font-style:italic;">maximum capturing</span><span class="font12"> hanya diukur berdasarkan jumlah </span><span class="font12" style="font-style:italic;">frequent itemsets</span><span class="font12"> yang sama yang dimiliki dokumen tersebut. Semakin banyak jumlah </span><span class="font12" style="font-style:italic;">frequent itemsets</span><span class="font12"> yang sama dimiliki maka akan semakin mirip dokumen tersebut. Suatu </span><span class="font12" style="font-style:italic;">frequent itemsets</span><span class="font12"> dikatakan sama apabila memiliki item yang sama tanpa memperhitungkan bobot dari item-item tersebut, padahal bobot ini akan sangat berpengaruh terhadap kemiripan dokumen. Hal ini juga tentu saja akan mengurangi akurasi hasil klasterisasi karena suatu kata yang sering muncul di suatu dokumen seharusnya memiliki bobot yang lebih besar dari kata yang jarang muncul. Kedua, Adaptasi metode </span><span class="font12" style="font-style:italic;">minimum spanning tree</span><span class="font12"> ke dalam proses pembentukan klaster kurang tepat, karena tidak memperhatikan kemiripan global saat melakukan pemutakhiran kemiripan klaster yang baru terbentuk dengan klaster lain. Pada pembentukan suatu klaster dengan adaptasi </span><span class="font12" style="font-style:italic;">minimum spanning tree</span><span class="font12"> jika dokumen </span><span class="font12" style="font-style:italic;">A</span><span class="font12"> berada dalam klaster yang sama dengan dokumen </span><span class="font12" style="font-style:italic;">B</span><span class="font12"> dan </span><span class="font12" style="font-style:italic;">C</span><span class="font12">, kemudian </span><span class="font12" style="font-style:italic;">A</span><span class="font12"> memiliki kemiripan yang tinggi dengan dokumen </span><span class="font12" style="font-style:italic;">D</span><span class="font12">, maka dokumen </span><span class="font12" style="font-style:italic;">D</span><span class="font12"> tersebut akan dimasukkan ke dalam klaster yang sama yang juga berisikan dokumen </span><span class="font12" style="font-style:italic;">B</span><span class="font12"> dan </span><span class="font12" style="font-style:italic;">C</span><span class="font12"> tersebut. Hal ini akan mengurangi kualitas hasil klasterisasi jika ternyata dokumen </span><span class="font12" style="font-style:italic;">D</span><span class="font12"> ini memiliki kemiripan yang rendah dengan dokumen </span><span class="font12" style="font-style:italic;">B</span><span class="font12"> dan </span><span class="font12" style="font-style:italic;">C</span><span class="font12">. Pada penelitian ini diusulkan suatu metode untuk klasterisasi dokumen yang berbasis </span><span class="font12" style="font-style:italic;">frequent itemsets</span><span class="font12"> dengan metode </span><span class="font12" style="font-style:italic;">weighted maximum capturing</span><span class="font12">, untuk memperbaiki kelemahan dari metode </span><span class="font12" style="font-style:italic;">maximum capturing</span><span class="font12"> sehingga kualitas hasil klasterisasi menjadi lebih baik.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark9"></a><span class="font14" style="font-weight:bold;"><a name="bookmark10"></a>2. &nbsp;&nbsp;&nbsp;METODE </span><span class="font14" style="font-weight:bold;font-style:italic;">WEIGHTED MAXIMUM</span></h2></li></ul>
<h3><a name="bookmark11"></a><span class="font14" style="font-weight:bold;font-style:italic;"><a name="bookmark12"></a>CAPTURING</span><span class="font14" style="font-weight:bold;"> (WMC) UNTUK KLASTERISASI DOKUMEN BERBASIS </span><span class="font14" style="font-weight:bold;font-style:italic;">FREQUENT ITEMSETS</span></h3>
<p><span class="font12">Dalam penelitian ini dikembangkan suatu metode baru dalam klasterisasi dokumen berbasis </span><span class="font12" style="font-style:italic;">frequent itemsets</span><span class="font12"> dengan metode maximum capturing. Metode ini mengadaptasi algoritma</span></p>
<p><span class="font12">single lingkage aglomerative hierarchical clustering pada saat proses pembentuk klaster dokumen. Proses pembobotan dilakukan saat perhitungan kemiripan antar dokumen dengan menggabungkan metode </span><span class="font12" style="font-style:italic;">cosine similarity</span><span class="font12"> dan </span><span class="font12" style="font-style:italic;">jaccard coefficient </span><span class="font12">berdasarkan jumlah </span><span class="font12" style="font-style:italic;">frequent itemsets</span><span class="font12"> yang sama yang dimiliki antar dokumen. Secara umum metode yang diajukan terdiri dari dua proses utama, yaitu proses penggalian </span><span class="font12" style="font-style:italic;">frequent itemsets</span><span class="font12"> dan proses pembentukan klaster dokumen.</span></p>
<ul style="list-style:none;"><li>
<h4><a name="bookmark13"></a><span class="font12" style="font-weight:bold;"><a name="bookmark14"></a>2.1 &nbsp;&nbsp;&nbsp;Proses Penggalian </span><span class="font12" style="font-weight:bold;font-style:italic;">Frequent Itemsets</span><span class="font12" style="font-weight:bold;"> dari</span><br><br><span class="font12" style="font-weight:bold;"><a name="bookmark15"></a>Kumpulan Dokumen</span></h4></li></ul>
<p><span class="font12">Dalam penelitian ini algoritma </span><span class="font12" style="font-style:italic;">FP-growth </span><span class="font12">diaplikasikan dalam penggalian </span><span class="font12" style="font-style:italic;">frequent itemsets </span><span class="font12">dari sekumpulan dokumen tanpa penentuan </span><span class="font12" style="font-style:italic;">minsup</span><span class="font12">. Algoritma </span><span class="font12" style="font-style:italic;">FP-growth</span><span class="font12"> pada umumnya digunakan pada basis data transaksional. Oleh karena itu, dalam penelitian ini terdapat beberapa proses yang dilakukan pada algoritma </span><span class="font12" style="font-style:italic;">FP-growth</span><span class="font12"> tersebut agar dapat digunakan dalam proses klasterisasi dokumen dengan efektif. Secara keseluruhan alur dari proses penggalian </span><span class="font12" style="font-style:italic;">frequent itemsets</span><span class="font12"> dari sekumpulan dokumen dapat dilihat dalam Gambar 1.</span></p>
<p><span class="font12">Seperti pada Gambar 1, proses penggalian </span><span class="font12" style="font-style:italic;">frequent itemsets</span><span class="font12"> dari sekumpulan dokumen terdiri dari beberapa tahap. Adapun tahapan dalam menggali </span><span class="font12" style="font-style:italic;">frequent itemsets</span><span class="font12"> dari sekumpulan dokumen dapat diuraikan sebagai berikut:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font12">a. &nbsp;&nbsp;&nbsp;Pra-proses dokumen, yang terdiri dari beberapa tahap atau proses yaitu :</span></p></li></ul>
<ul style="list-style:none;"><li>
<p><span class="font12">- &nbsp;&nbsp;&nbsp;Tokenisasi dokumen : proses pemisahan setiap kata (</span><span class="font12" style="font-style:italic;">term</span><span class="font12">) yang terkandung dalam sebuah dokumen. Setelah proses ini selesai dilanjutkan dengan proses </span><span class="font12" style="font-style:italic;">case folding</span><span class="font12"> yaitu proses penyamaan bentuk (</span><span class="font12" style="font-style:italic;">case</span><span class="font12">) suatu kata. Tidak semua kata dalam dokumen konsisten dalam pengunaan huruf capital, oleh karena itu proses </span><span class="font12" style="font-style:italic;">case folding</span><span class="font12"> dibutuhkan untuk mengkonversi keseluruhan kata menjadi suatu bentuk standar yang umumnya berupa huruf kecil (</span><span class="font12" style="font-style:italic;">small case</span><span class="font12">).</span></p></li>
<li>
<p><span class="font12">-</span><span class="font12" style="font-style:italic;"> &nbsp;&nbsp;&nbsp;Stopwords removal</span><span class="font12"> : proses penghilangan kata-kata tidak penting (</span><span class="font12" style="font-style:italic;">stopwords</span><span class="font12">) dari suatu dokumen. Proses penghilangan dilakukan dengan pencocokan kata-kata yang ada dalam dokumen terhadap sebuah tabel yang berisikan daftar kata-kata tidak penting (</span><span class="font12" style="font-style:italic;">stoplist</span><span class="font12">).</span></p></li>
<li>
<p><span class="font12">-</span><span class="font12" style="font-style:italic;"> &nbsp;&nbsp;&nbsp;Stemming</span><span class="font12">: proses pengembalian suatu kata berimbuhan ke bentuk dasarnya (</span><span class="font12" style="font-style:italic;">root word</span><span class="font12">). Pada penelitian ini digunakan algoritma </span><span class="font12" style="font-style:italic;">Porter Stemmer</span><span class="font12"> untuk bahasa Inggris dalam mencari kata dasar (</span><span class="font12" style="font-style:italic;">root word</span><span class="font12">) dari suatu kata.</span></p></li></ul>
<ul style="list-style:none;"><li>
<p><span class="font12">b. &nbsp;&nbsp;&nbsp;Setelah tahap pra-proses dokumen selesai, selanjutnya akan dilakukan penggalian </span><span class="font12" style="font-style:italic;">frequent itemsets</span><span class="font12"> dengan nilai </span><span class="font12" style="font-style:italic;">minimum support</span><span class="font12"> (minsup) yang dimasukkan pengguna</span></p><img src="https://jurnal.harianregional.com/media/8408-1.png" alt="" style="width:186pt;height:338pt;"></li></ul>
<p><span class="font12">Gambar 1. Diagram Alir Proses Penggalian Frequent Itemsets</span></p>
<ul style="list-style:none;"><li>
<p><span class="font12">c. &nbsp;&nbsp;&nbsp;Proses penggalian </span><span class="font12" style="font-style:italic;">frequent itemsets</span><span class="font12"> pada metode yang dikembangkan menggunakan algoritma &nbsp;</span><span class="font12" style="font-style:italic;">FP-growth</span><span class="font12"> &nbsp;(Han, dkk.,2000).</span></p></li></ul>
<p><span class="font12">Struktur data yang digunakan untuk mencari </span><span class="font12" style="font-style:italic;">frequent itemset</span><span class="font12"> dengan algoritma </span><span class="font12" style="font-style:italic;">FP-growth </span><span class="font12">adalah perluasan dari penggunaan sebuah pohon </span><span class="font12" style="font-style:italic;">prefix</span><span class="font12">, yang biasa disebut </span><span class="font12" style="font-style:italic;">FP-tree</span><span class="font12">. Dengan menggunakan </span><span class="font12" style="font-style:italic;">FP-tree</span><span class="font12">, algoritma </span><span class="font12" style="font-style:italic;">FP-growth</span><span class="font12"> dapat langsung mengekstrak </span><span class="font12" style="font-style:italic;">frequent itemsets</span><span class="font12"> dari </span><span class="font12" style="font-style:italic;">FP-tree</span><span class="font12"> yang telah terbentuk dengan menggunakan konsep </span><span class="font12" style="font-style:italic;">divide</span><span class="font12"> and </span><span class="font12" style="font-style:italic;">conquer</span><span class="font12">. Proses implementasi algoritma </span><span class="font12" style="font-style:italic;">FP-growth</span><span class="font12"> pada penelitian ini sesuai dengan Borgelt dalam (Borgelt, 2005).</span></p>
<ul style="list-style:none;"><li>
<p><span class="font12">d. &nbsp;&nbsp;&nbsp;Proses selanjutnya adalah proses pembuatan tabel </span><span class="font12" style="font-style:italic;">Doc-List</span><span class="font12"> berdasarkan </span><span class="font12" style="font-style:italic;">frequent itemsets </span><span class="font12">yang berhasil digali. Tabel </span><span class="font12" style="font-style:italic;">Doc-List</span><span class="font12"> dibuat dengan cara mencocokan item-item yang terdapat pada setiap </span><span class="font12" style="font-style:italic;">frequent itemsets</span><span class="font12"> yang dihasilkan dari proses penggalian dengan item-item yang dimiliki oleh sebuah dokumen. Tabel </span><span class="font12" style="font-style:italic;">Doc-List</span><span class="font12"> yang dihasilkan selanjutnya akan digunakan dalam proses pembentukan klaster dokumen.</span></p></li></ul>
<ul style="list-style:none;"><li>
<h4><a name="bookmark16"></a><span class="font12" style="font-weight:bold;"><a name="bookmark17"></a>2.2 &nbsp;&nbsp;&nbsp;Proses Pembentukan Klaster Dokumen</span></h4></li></ul>
<p><span class="font12">Setelah </span><span class="font12" style="font-style:italic;">frequent itemsets</span><span class="font12"> dari masing-masing dokumen berhasil digali dan telah dihasilkan tabel </span><span class="font12" style="font-style:italic;">Doc-List</span><span class="font12">, &nbsp;&nbsp;&nbsp;&nbsp;selanjutnya &nbsp;&nbsp;&nbsp;dilakukan proses</span></p>
<p><span class="font12">pembentukan klaster dokumen berdasarkan tabel </span><span class="font12" style="font-style:italic;">Doc-List</span><span class="font12"> yang diperoleh. Pada proses pembentukan klaster dalam penelitian ini dilakukan perbaikan terhadap metode </span><span class="font12" style="font-style:italic;">maximum capturing</span><span class="font12"> yang mengadaptasi metode </span><span class="font12" style="font-style:italic;">minimum spanning tree</span><span class="font12"> agar akurasi hasil klasterisasi dapat ditingkatkan. Perbaikan dilakukan terhadap dua sub-proses utama dari proses pembentukan klaster, yaitu sub-proses perhitungan kemiripan (</span><span class="font12" style="font-style:italic;">similarity</span><span class="font12">) antar dokumen berdasarkan tabel </span><span class="font12" style="font-style:italic;">Doc-List</span><span class="font12"> yang terbentuk dan subproses rekonstruksi klaster yang akan dibentuk. Secara keseluruhan alur dari proses pembentukan klaster berdasarkan tabel </span><span class="font12" style="font-style:italic;">Doc-List</span><span class="font12"> dapat dilihat dalam Gambar 2.</span></p>
<p><span class="font12">Seperti yang terlihat pada Gambar 2, proses pembentukan klaster berbasis </span><span class="font12" style="font-style:italic;">frequent itemsets </span><span class="font12">dengan metode </span><span class="font12" style="font-style:italic;">weighted maximum capturing </span><span class="font12">terdiri dari beberapa tahap, yaitu:</span></p>
<p><span class="font12">a. Perhitungan kemiripan antar dokumen. Perhitungan kemiripan antar dokumen menggunakan metode yang merupakan penggabungan antara </span><span class="font12" style="font-style:italic;">jaccard coefficient </span><span class="font12">sebagai metode </span><span class="font12" style="font-style:italic;">asymetrical binary similarity </span><span class="font12">dengan metode </span><span class="font12" style="font-style:italic;">cosine similarity</span><span class="font12">. </span><span class="font12" style="font-style:italic;">Jaccard coefficient</span><span class="font12"> digunakan untuk melihat kemiripan jumlah </span><span class="font12" style="font-style:italic;">frequent itemsets</span><span class="font12"> yang dimiliki dari pasangan dokumen, sedangkan metode </span><span class="font12" style="font-style:italic;">cosine similarity</span><span class="font12"> digunakan untuk menghitung kemiripan antar </span><span class="font12" style="font-style:italic;">frequent itemsets</span><span class="font12"> tersebut berdasarkan bobot dari tiap item dalam </span><span class="font12" style="font-style:italic;">itemset </span><span class="font12">tersebut. Metode </span><span class="font12" style="font-style:italic;">cosine similarity</span><span class="font12"> merupakan metode yang digunakan untuk menghitung tingkat kemiripan antar dua buah objek. Secara umum penghitungan metode ini didasarkan pada </span><span class="font12" style="font-style:italic;">vector space similarity measure.</span><span class="font12"> Metode </span><span class="font12" style="font-style:italic;">cosine similarity</span><span class="font12"> ini menghitung kemiripan antara dua buah objek yang dinyatakan dalam dua buah vektor dengan menggunakan </span><span class="font12" style="font-style:italic;">keywords </span><span class="font12">(kata kunci) dari sebuah dokumen sebagai ukuran.</span></p>
<p><span class="font12">Jika </span><span class="font12" style="font-style:italic;">Q</span><span class="font12"> adalah vektor dokumen pertama dan </span><span class="font12" style="font-style:italic;">D </span><span class="font12">adalah vektor dokumen kedua, yang merupakan dua buah vektor dalam ruang berdimensi-</span><span class="font12" style="font-style:italic;">n</span><span class="font12">, dan </span><span class="font12" style="font-style:italic;">θ</span><span class="font12"> adalah sudut yang dibentuk oleh kedua vektor tersebut. Maka</span></p>
<p><a href="#bookmark18"><span class="font12" style="font-style:italic;">Q</span><span class="font3"> • </span><span class="font12" style="font-style:italic;">D</span><span class="font3"> = ∣</span><span class="font12" style="font-style:italic;">Q</span><span class="font6" style="font-style:italic;">∣∣</span><span class="font12" style="font-style:italic;">D</span><span class="font6">∣</span><span class="font12"> cosθ,(1)</span></a></p>
<p><span class="font12">dimana Q </span><span class="font2">• </span><span class="font12">D adalah hasil perkalian dalam (</span><span class="font12" style="font-style:italic;">inner product</span><span class="font12">) kedua vektor, sedangkan</span></p>
<p><a href="#bookmark19"><span class="font12">I^I = </span><span class="font12" style="font-style:italic;">√∑^</span><span class="font12">(2)</span></a></p>
<p><a href="#bookmark20"><span class="font12">IQI = </span><span class="font12" style="font-style:italic;">√∑-&lt;&gt;</span><span class="font12">(3)</span></a></p>
<div><img src="https://jurnal.harianregional.com/media/8408-2.jpg" alt="" style="width:194pt;height:355pt;">
</div><br clear="all">
<p><span class="font12">Gambar 2. Proses Pembentukan Klaster dengan Metode </span><span class="font12" style="font-style:italic;">Weighted Maximum Capturing</span></p>
<p><span class="font12">merupakan panjang vektor atau jarak </span><span class="font12" style="font-style:italic;">euclidean </span><span class="font12">suatu vektor dengan titik nol. Metode pengukuran kemiripan ini memiliki beberapa keuntungan, yaitu adanya normalisasi terhadap panjang dokumen. Hal ini memperkecil pengaruh panjang dokumen. Jarak </span><span class="font12" style="font-style:italic;">euclidean </span><span class="font12">(panjang) kedua vektor digunakan sebagai faktor normalisasi. Hal ini diperlukan karena dokumen yang panjang cenderung mendapatkan nilai yang besar dibandingkan dengan dokumen yang lebih pendek. Perhitungan </span><span class="font12" style="font-style:italic;">cosine similarity</span><span class="font12"> yang memperhitungkan perhitungan pembobotan kata pada suatu dokumen dapat dinyatakan dengan perumusan :</span></p>
<p><span class="font14" style="font-style:italic;">CosSim( d<sub>1</sub></span><span class="font14">., </span><span class="font14" style="font-style:italic;">q<sub>i</sub></span><span class="font14">) = </span><span class="font7" style="font-style:italic;"><sup>q</sup></span><span class="font8" style="font-style:italic;">∙d7</span></p>
<p><span class="font12" style="font-style:italic;"><sup>i &nbsp;&nbsp;&nbsp;i &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</sup></span><span class="font7" style="font-style:italic;"><sup>q</sup>i <sup>d</sup>i</span></p>
<p><span class="font7" style="font-style:italic;">t</span></p>
<p><span class="font12">∑ (</span><span class="font12" style="font-style:italic;">q</span><span class="font12">-. </span><span class="font7" style="font-style:italic;"><sup>d</sup></span><span class="font12">J</span></p>
<p><span class="font12"><sup>2:1</sup>-------------(4)</span></p>
<div><img src="https://jurnal.harianregional.com/media/8408-3.png" alt="" style="width:70pt;height:27pt;">
</div><br clear="all">
<p><span class="font12">Dimana </span><span class="font12" style="font-style:italic;">q</span><span class="font9" style="font-style:italic;">ij</span><span class="font12"> adalah bobot istilah </span><span class="font12" style="font-style:italic;">j</span><span class="font12"> pada dokumen </span><span class="font12" style="font-style:italic;">i</span><span class="font12"> = </span><span class="font12" style="font-style:italic;">tf</span><span class="font9" style="font-style:italic;">ij </span><span class="font12" style="font-style:italic;">* idf</span><span class="font9" style="font-style:italic;">j</span><span class="font12"> dan </span><span class="font12" style="font-style:italic;">d</span><span class="font9" style="font-style:italic;">ij</span><span class="font12"> adalah bobot istilah </span><span class="font12" style="font-style:italic;">j</span><span class="font12"> pada dokumen </span><span class="font12" style="font-style:italic;">i</span><span class="font12"> = </span><span class="font12" style="font-style:italic;">tf</span><span class="font9" style="font-style:italic;">ij </span><span class="font12" style="font-style:italic;">* idf</span><span class="font9" style="font-style:italic;">j.</span></p>
<p><span class="font12">Metode </span><span class="font12" style="font-style:italic;">jaccard coefficient</span><span class="font12"> adalah sebuah metode yang sering digunakan untuk membandingkan kemiripan, perbedaan, dan jarak suatu set data. </span><span class="font12" style="font-style:italic;">Jaccard coefficient</span><span class="font12"> atau yang terkadang disebut </span><span class="font12" style="font-style:italic;">tanimoto coefficient </span><span class="font12">membandingkan bobot dari jumlah istilah atau kata yang muncul bersama pada dokumen dengan bobot istilah atau kata yang tidak muncul pada kedua dokumen. Perhitungan kemiripan dua buah dokumen dengan </span><span class="font12" style="font-style:italic;">jaccard coefficien</span><span class="font12">t dapat dilihat pada persamaan berikut (Niwattanakul, dkk., 2013):</span></p>
<div>
<p><span class="font12">Sim(Dok<sub>1</sub>,Dok<sub>2</sub>) =</span></p>
</div><br clear="all">
<div>
<p><span class="font9">Dok</span><span class="font8">ι</span><span class="font9">∩Dok<sub>2</sub></span></p>
<p><span class="font9" style="font-style:italic;">Dok<sub>1</sub>VDok<sub>2</sub></span></p>
</div><br clear="all">
<div>
<p><span class="font12">(5)</span></p>
</div><br clear="all">
<p><span class="font12" style="font-style:italic;">Dokl</span><span class="font12"> ∩</span><span class="font12" style="font-style:italic;">Dok2</span><span class="font12"> berisikan jumlah atribut yang sama yang dimiliki oleh kedua dokumen (</span><span class="font12" style="font-style:italic;">intersection</span><span class="font12">), sedangkan </span><span class="font12" style="font-style:italic;">Dokl</span><span class="font12"> U</span><span class="font12" style="font-style:italic;">Dok2</span><span class="font12"> berisikan jumlah kata yang dimiliki oleh kedua dokumen ditambah dengan jumlah kata </span><span class="font12" style="font-style:italic;">Dok2</span><span class="font12"> yang tidak dimiliki oleh </span><span class="font12" style="font-style:italic;">Dok1</span><span class="font12"> ditambah jumlah kata </span><span class="font12" style="font-style:italic;">Dok1 </span><span class="font12">yang tidak dimiliki oleh </span><span class="font12" style="font-style:italic;">Dok2</span><span class="font12"> (</span><span class="font12" style="font-style:italic;">union</span><span class="font12">). </span><span class="font12" style="font-style:italic;">Jaccard coefficient</span><span class="font12"> merupakan metode pengukuran kemiripan dari suatu atribut biner yang tidak simetris. Melihat suatu objek dalam format biner akan memungkinkan pengguna untuk mengukur kemiripan menjadi lebih mudah dengan menentukan objek A dan B terdiri dari </span><span class="font12" style="font-style:italic;">n </span><span class="font12">fitur kemudian menggunakan ukuran dari jumlah properti yang sama yang dimiliki objek A dan B.</span></p>
<p><span class="font12">Tabel 1 memperlihatkan contoh tabel </span><span class="font12" style="font-style:italic;">Doc-List </span><span class="font12">dari sekumpulan dokumen hasil dari proses penggalian. Dalam Tabel 1 kolom </span><span class="font12" style="font-style:italic;">frequent itemsets</span><span class="font12"> berisikan informasi </span><span class="font12" style="font-style:italic;">frequent itemsets </span><span class="font12">dari setiap dokumen beserta frekuensi kemunculan item-item dari </span><span class="font12" style="font-style:italic;">frequent itemsets </span><span class="font12">tersebut pada dokumen yang sesuai.</span></p>
<p><span class="font12">Tabel 1 Contoh Tabel </span><span class="font12" style="font-style:italic;">Doc-List</span><span class="font12"> dari Kumpulan Dokumen</span></p>
<table border="1">
<tr><td colspan="2" style="vertical-align:bottom;">
<p><span class="font12">ID</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font12">Dokumen</span></p></td><td style="vertical-align:top;">
<p><span class="font12" style="font-style:italic;">Frequent Itemsets</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font12" style="font-style:italic;">Dok1</span></p></td><td style="vertical-align:bottom;">
<p><span class="font12" style="font-style:italic;">{I</span><span class="font9" style="font-style:italic;">1</span><span class="font12" style="font-style:italic;">: 5 , I</span><span class="font9" style="font-style:italic;">3</span><span class="font12" style="font-style:italic;">: 2, I</span><span class="font9" style="font-style:italic;">4</span><span class="font12" style="font-style:italic;">: 3}, { I</span><span class="font9" style="font-style:italic;">2</span><span class="font12" style="font-style:italic;">: 4, I</span><span class="font9" style="font-style:italic;">5</span><span class="font12" style="font-style:italic;">: 3}</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font12" style="font-style:italic;">Dok2</span></p></td><td style="vertical-align:bottom;">
<p><span class="font12" style="font-style:italic;">{I</span><span class="font9" style="font-style:italic;">1 </span><span class="font12" style="font-style:italic;">: 4, I</span><span class="font9" style="font-style:italic;">3</span><span class="font12" style="font-style:italic;">: 3, I</span><span class="font9" style="font-style:italic;">4</span><span class="font12" style="font-style:italic;">: 4}, { I</span><span class="font9" style="font-style:italic;">1</span><span class="font12" style="font-style:italic;">: 4, I</span><span class="font9" style="font-style:italic;">2</span><span class="font12" style="font-style:italic;">: 5}, { I</span><span class="font9" style="font-style:italic;">2</span><span class="font12" style="font-style:italic;">: 5, I</span><span class="font9" style="font-style:italic;">5</span><span class="font12" style="font-style:italic;">: 8}</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font12" style="font-style:italic;">Dok3</span></p></td><td style="vertical-align:top;">
<p><span class="font12" style="font-style:italic;">{I</span><span class="font9" style="font-style:italic;">2 </span><span class="font12" style="font-style:italic;">: 3, I</span><span class="font9" style="font-style:italic;">4</span><span class="font12" style="font-style:italic;">: 5, I</span><span class="font9" style="font-style:italic;">5</span><span class="font12" style="font-style:italic;">: 4}, { I</span><span class="font9" style="font-style:italic;">1</span><span class="font12" style="font-style:italic;">: 3, I</span><span class="font9" style="font-style:italic;">2</span><span class="font12" style="font-style:italic;">: 5,}</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font12" style="font-style:italic;">Dok4</span></p></td><td style="vertical-align:top;">
<p><span class="font12" style="font-style:italic;">{ I</span><span class="font9" style="font-style:italic;">2</span><span class="font12" style="font-style:italic;">: 4, I</span><span class="font9" style="font-style:italic;">5</span><span class="font12" style="font-style:italic;">: 6,} { I</span><span class="font9" style="font-style:italic;">1</span><span class="font12" style="font-style:italic;">:3, I</span><span class="font9" style="font-style:italic;">2</span><span class="font12" style="font-style:italic;">:4,}</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font12" style="font-style:italic;">Dok5</span></p></td><td style="vertical-align:top;">
<p><span class="font12" style="font-style:italic;">{I</span><span class="font9" style="font-style:italic;">1</span><span class="font12" style="font-style:italic;">: 2 , I</span><span class="font9" style="font-style:italic;">3</span><span class="font12" style="font-style:italic;">: 3, I</span><span class="font9" style="font-style:italic;">4</span><span class="font12" style="font-style:italic;">: 4}</span></p></td></tr>
</table>
<p><span class="font12">Berdasarkan contoh dalam Tabel 1, proses perhitungan kemiripan antara dokumen </span><span class="font12" style="font-style:italic;">Dok1 </span><span class="font12">dengan dokumen </span><span class="font12" style="font-style:italic;">Dok2</span><span class="font12"> dapat diuraikan sebagai berikut:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font12">a) &nbsp;&nbsp;&nbsp;Perhitungan bobot dari masing-masing item dalam </span><span class="font12" style="font-style:italic;">frequent itemset</span><span class="font12"> suatu dokumen sesuai dengan metode pembobotan TF-IDF seperti pada persamaan (6).</span></p>
<div>
<p><span class="font10" style="font-style:italic;">w<sub>y</sub> = tfy<sup>χlo</sup>g</span><span class="font8" style="font-style:italic;">2</span><span class="font10" style="font-style:italic;">(±<sup>1</sup>)</span></p>
</div><br clear="all">
<div>
<p><span class="font12">(6)</span></p>
</div><br clear="all"></li></ul>
<p><span class="font12">dimana </span><span class="font12" style="font-style:italic;">w</span><span class="font9" style="font-style:italic;">ij</span><span class="font12"> adalah bobot </span><span class="font12" style="font-style:italic;">term j</span><span class="font12"> pada dokumen </span><span class="font12" style="font-style:italic;">i, tf</span><span class="font9" style="font-style:italic;">ij</span><span class="font12"> adalah frekuensi </span><span class="font12" style="font-style:italic;">term</span><span class="font12"> j pada dokumen </span><span class="font12" style="font-style:italic;">i</span><span class="font12">, </span><span class="font12" style="font-style:italic;">N </span><span class="font12">adalah jumlah total dokumen yang diproses, dan </span><span class="font12" style="font-style:italic;">df</span><span class="font9" style="font-style:italic;">j</span><span class="font12"> adalah jumlah dokumen yang memiliki </span><span class="font12" style="font-style:italic;">term j</span><span class="font12"> didalamnya. Sebagai contoh, berikut ini adalah perhitungan bobot item </span><span class="font12" style="font-style:italic;">I</span><span class="font9" style="font-style:italic;">1</span><span class="font12"> yang dimiliki oleh </span><span class="font12" style="font-style:italic;">Dok1</span><span class="font12">:</span></p>
<p><span class="font10" style="font-style:italic;">W<sub>1</sub></span><span class="font8" style="font-style:italic;">J </span><span class="font10" style="font-style:italic;">= <sup>tf</sup>u x Iog<sub>2</sub></span><span class="font10"> <sup>(</sup>^f </span><span class="font10" style="font-style:italic;">+</span><span class="font10">1) = 5xlog<sub>2</sub>(</span><span class="font5">∣</span><span class="font10">+1) </span><span class="font10" style="font-style:italic;">=</span><span class="font10"> 1,51</span></p>
<p><span class="font12">(2.9)</span></p>
<p><span class="font12">Perhitungan serupa juga dilakukan pada seluruh item yang terdapat dalam </span><span class="font12" style="font-style:italic;">Dok2</span><span class="font12">. Hasil perhitungan bobot dari masing-masing item yang terdapat dalam </span><span class="font12" style="font-style:italic;">Dok1</span><span class="font12"> dan </span><span class="font12" style="font-style:italic;">Dok2</span><span class="font12"> terlihat dalam Tabel 2.</span></p>
<p><span class="font12">Tabel 2. Bobot Item pada </span><span class="font12" style="font-style:italic;">Dok1</span><span class="font12"> dan </span><span class="font12" style="font-style:italic;">Dok2</span></p>
<table border="1">
<tr><td style="vertical-align:bottom;">
<p><span class="font12">Item</span></p></td><td style="vertical-align:bottom;">
<p><span class="font12">Bobot pada </span><span class="font12" style="font-style:italic;">Dok1</span></p></td><td style="vertical-align:bottom;">
<p><span class="font12">Bobot pada </span><span class="font12" style="font-style:italic;">Dok2</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font12" style="font-style:italic;">I</span><span class="font9" style="font-style:italic;">1</span></p></td><td style="vertical-align:bottom;">
<p><span class="font12">1,51</span></p></td><td style="vertical-align:bottom;">
<p><span class="font12">1,20</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font12" style="font-style:italic;">I</span><span class="font9" style="font-style:italic;">2</span></p></td><td style="vertical-align:bottom;">
<p><span class="font12">1,40</span></p></td><td style="vertical-align:bottom;">
<p><span class="font12">1,76</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font12" style="font-style:italic;">I</span><span class="font9" style="font-style:italic;">3</span></p></td><td style="vertical-align:bottom;">
<p><span class="font12">0,85</span></p></td><td style="vertical-align:bottom;">
<p><span class="font12">1,28</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font12" style="font-style:italic;">I</span><span class="font9" style="font-style:italic;">4</span></p></td><td style="vertical-align:bottom;">
<p><span class="font12">1,06</span></p></td><td style="vertical-align:bottom;">
<p><span class="font12">1,40</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font12" style="font-style:italic;">I</span><span class="font9" style="font-style:italic;">5</span></p></td><td style="vertical-align:bottom;">
<p><span class="font12">1,06</span></p></td><td style="vertical-align:bottom;">
<p><span class="font12">2,82</span></p></td></tr>
</table>
<ul style="list-style:none;"><li>
<p><span class="font12">b) &nbsp;&nbsp;&nbsp;Perhitungan kemiripan antara </span><span class="font12" style="font-style:italic;">frequent itemsets </span><span class="font12">yang sama dari masing-masing dokumen dengan metode </span><span class="font12" style="font-style:italic;">cosine similarity</span><span class="font12"> sesuai persamaan (2).</span></p></li></ul>
<p><span class="font12">Berdasarkan contoh yang terdapat pada Tabel 1 dan Tabel 2 , kemiripan </span><span class="font12" style="font-style:italic;">frequent itemsets</span><span class="font12"> yang terdapat pada </span><span class="font12" style="font-style:italic;">Dok1</span><span class="font12"> dan </span><span class="font12" style="font-style:italic;">Dok2</span><span class="font12"> dapat dihitung sebagai berikut:</span></p>
<p><span class="font10" style="font-style:italic;">Cos(Q,D)<sub>13i</sub></span></p>
<p><span class="font10">_ &nbsp;&nbsp;&nbsp;(1,51x1,20 +0,85x1,28 + 1,06x1,40)</span></p>
<p><span class="font10">√1,51<sup>2</sup> + 0,85<sup>2</sup> + 1,06<sup>2</sup> x√1,20<sup>2</sup> + 1,28<sup>2</sup> + 1,40<sup>2</sup></span></p>
<p><span class="font10">4,384 &nbsp;&nbsp;&nbsp;_ 4,384</span></p>
<p><span class="font10">= 2,031x2,245 = 4,56 = <sup>0,96</sup></span></p>
<p><span class="font10" style="font-style:italic;">CosSim(Q,D)<sub>25</sub></span></p>
<p><span class="font10">_ &nbsp;&nbsp;(1,40 x 1,76 + 1,06 x 2.82 )</span></p>
<p><span class="font10">√1,40<sup>2</sup> + 1, 06<sup>2</sup> x √1,76<sup>2</sup> + 2,82<sup>2</sup></span></p>
<p><span class="font10">5,453 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;5,453 <sub>nni&gt;</sub></span></p>
<p><span class="font10">= 1,756x3,324 = 5,836 = <sup>0,93</sup></span></p>
<ul style="list-style:none;"><li>
<p><span class="font12">c) &nbsp;&nbsp;&nbsp;Perhitungan kemiripan antara </span><span class="font12" style="font-style:italic;">Dok1</span><span class="font12"> dan </span><span class="font12" style="font-style:italic;">Dok2 </span><span class="font12">dengan metode </span><span class="font12" style="font-style:italic;">jaccard coefficient</span><span class="font12">. Berdasarkan contoh dalam Tabel 1, kemiripan antara dokumen </span><span class="font12" style="font-style:italic;">Dok1</span><span class="font12"> dan dokumen </span><span class="font12" style="font-style:italic;">Dok2</span><span class="font12"> dapat dihitung sebagai berikut:</span></p>
<div>
<p><span class="font10" style="font-style:italic;">Sim(Dok<sub>1</sub>, Dok<sub>2</sub>)</span><span class="font10"> =</span></p>
</div><br clear="all"></li></ul>
<p><span class="font10" style="font-style:italic;">Dok<sub>1</sub></span><span class="font10"> ∩ Dok<sub>2</sub></span></p>
<p><span class="font10">Dok<sub>1</sub> U Dok<sub>2 </sub>0,378</span></p>
<div>
<p><span class="font10">0,96 + 0,93</span></p>
</div><br clear="all">
<div>
<p><span class="font10">5</span></p>
</div><br clear="all">
<ul style="list-style:none;"><li>
<p><span class="font12">a. &nbsp;&nbsp;&nbsp;Pembuatan matrik </span><span class="font12" style="font-style:italic;">similarity M</span><span class="font12">. Setelah semua kemiripan antar dokumen diperoleh, proses selanjutnya adalah membuat matriks kemiripan. Matriks </span><span class="font12" style="font-style:italic;">similarity</span><span class="font12"> atau kemiripan </span><span class="font12" style="font-style:italic;">M</span><span class="font12"> adalah</span></p></li></ul>
<p><span class="font12">suatu matrik yang menggambarkan nilai kemiripan antara dokumen satu dengan yang lainnya. Berikut ini adalah contoh matriks kemiripan dari lima buah dokumen:</span></p>
<table border="1">
<tr><td style="vertical-align:bottom;">
<p><span class="font12">1</span></p></td><td style="vertical-align:top;">
<p><span class="font12">1</span></p>
<p><span class="font12">0</span></p></td><td style="vertical-align:top;">
<p><span class="font12">2</span></p>
<p><span class="font12">5</span></p></td><td style="vertical-align:top;">
<p><span class="font12">3</span></p>
<p><span class="font12">4</span></p></td><td style="vertical-align:top;">
<p><span class="font12">4</span></p>
<p><span class="font12">5</span></p></td><td style="vertical-align:top;">
<p><span class="font12">5</span></p>
<p><span class="font12">10</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font12">2</span></p></td><td style="vertical-align:top;"></td><td style="vertical-align:bottom;">
<p><span class="font12">0</span></p></td><td style="vertical-align:bottom;">
<p><span class="font12">8</span></p></td><td style="vertical-align:bottom;">
<p><span class="font12">6</span></p></td><td style="vertical-align:bottom;">
<p><span class="font12">9</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font12">3</span></p></td><td style="vertical-align:top;"></td><td style="vertical-align:top;"></td><td style="vertical-align:bottom;">
<p><span class="font12">0</span></p></td><td style="vertical-align:bottom;">
<p><span class="font12">7</span></p></td><td style="vertical-align:bottom;">
<p><span class="font12">3</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font12">4</span></p></td><td style="vertical-align:top;"></td><td style="vertical-align:top;"></td><td style="vertical-align:top;"></td><td style="vertical-align:bottom;">
<p><span class="font12">0</span></p></td><td style="vertical-align:bottom;">
<p><span class="font12">9</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font12">5</span></p></td><td style="vertical-align:bottom;">
<p><span class="font12">X.</span></p></td><td style="vertical-align:top;"></td><td style="vertical-align:top;"></td><td style="vertical-align:top;"></td><td style="vertical-align:bottom;">
<p><span class="font12">0</span></p></td></tr>
</table>
<ul style="list-style:none;"><li>
<p><span class="font12">b. &nbsp;&nbsp;&nbsp;Pencarian nilai minimum pada matriks </span><span class="font12" style="font-style:italic;">M</span><span class="font12">, kecuali nilai 0. Nilai minimum pada contoh matriks diatas adalah 3.</span></p></li>
<li>
<p><span class="font12">c. &nbsp;&nbsp;&nbsp;Penggabungan dokumen dengan kemiripan tertinggi menjadi sebuah klaster baru. Pada contoh matriks </span><span class="font12" style="font-style:italic;">M</span><span class="font12"> di atas, nilai kemiripan tertinggi adalah 10, sehingga dokumen 1 dan dokumen 2 dapat digabung menjadi klaster (1,5).</span></p></li>
<li>
<p><span class="font12">d. &nbsp;&nbsp;&nbsp;Pemutakhiran (</span><span class="font12" style="font-style:italic;">update</span><span class="font12">) kemiripan klaster yang baru terbentuk dengan klaster lain. Kemiripan klaster baru dengan suatu klaster adalah nilai kemiripan terendah antara anggota dari klaster baru tersebut. Berdasarkan contoh klaster baru yang terbentuk pada langkah d diatas, berikut adalah contoh perhitungan kemiripan klaster baru dengan klaster lain:</span></p></li></ul>
<p><a href="#bookmark21"><span class="font11" style="font-style:italic;">d</span><span class="font8" style="font-style:italic;">(15)2</span><span class="font11"> = min {</span><span class="font11" style="font-style:italic;">d</span><span class="font8" style="font-style:italic;">12</span><span class="font11">, </span><span class="font11" style="font-style:italic;">d</span><span class="font8" style="font-style:italic;">52</span><span class="font11">} = min {5, 9}= 5</span></a></p>
<p><a href="#bookmark22"><span class="font11" style="font-style:italic;">d</span><span class="font8" style="font-style:italic;">(15)3</span><span class="font11"> = min {</span><span class="font11" style="font-style:italic;">d</span><span class="font8" style="font-style:italic;">13</span><span class="font11">, </span><span class="font11" style="font-style:italic;">d</span><span class="font8" style="font-style:italic;">53</span><span class="font11">} = min {4, 3}= 3</span></a></p>
<p><a href="#bookmark23"><span class="font11" style="font-style:italic;">d</span><span class="font8" style="font-style:italic;">(15)4</span><span class="font11"> = min {</span><span class="font11" style="font-style:italic;">d</span><span class="font8" style="font-style:italic;">14</span><span class="font11">, </span><span class="font11" style="font-style:italic;">d</span><span class="font8" style="font-style:italic;">54</span><span class="font11">} = min {5, 9}= 5</span></a></p>
<p><span class="font12">Seperti yang terlihat pada perhitungan diatas, kemiripan antara klaster baru (1,5) dengan dokumen 2 adalah nilai kemiripan minimum antara dokumen 1 dengan dokumen 2 (yaitu 5) dan dokumen 5 dengan dokumen 2 (yaitu 9). Jadi nilai kemiripan antara klaster baru (1,5) dengan dokumen 2 adalah 5.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font12">e. &nbsp;&nbsp;&nbsp;Pemutakhiran matrik kemiripan </span><span class="font12" style="font-style:italic;">M.</span><span class="font12"> Setelah terbentuk klaster baru dan kemiripan antara klaster baru tersebut dengan klaster atau dokumen lain diperoleh, dilakukan proses pemutakhiran matrik kemiripan </span><span class="font12" style="font-style:italic;">M.</span><span class="font12"> Berikut adalah contoh matrik hasil pemutakhiran matrik M yang terdapat pada langkah b di atas.</span></p></li></ul>
<p><a href="#bookmark24"><span class="font12">23</span></a></p>
<p><a href="#bookmark25"><span class="font12">2 &nbsp;&nbsp;&nbsp;08</span></a></p>
<p><a href="#bookmark26"><span class="font12">30</span></a></p>
<p><span class="font12">4</span></p>
<p><span class="font12">1,5 I</span></p>
<div>
<p><span class="font12">4</span></p>
<p><span class="font12">6</span></p>
<p><span class="font12">7</span></p>
<p><span class="font12">0</span></p>
</div><br clear="all">
<div>
<p><span class="font12">1,5</span></p>
<p><span class="font12">5</span></p>
<p><span class="font12">3</span></p>
<p><span class="font12">5</span></p>
<p><span class="font12">0J</span></p>
</div><br clear="all">
<ul style="list-style:none;"><li>
<p><span class="font12">f. &nbsp;&nbsp;&nbsp;Ulangi langkah d-f sampai di temukan nilai kemiripan maksimum yang sama dengan nilai kemiripan minimum yang ditemukan pada langkah c. Dari contoh matrik M yang terdapat</span></p></li></ul>
<p><span class="font12">pada langkah f diatas, berikut adalah proses lengkap pembuatan klaster yang dilakukan:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1">•</span><span class="font12"> &nbsp;&nbsp;&nbsp;Pemilihan nilai kemiripan terbesar pada matrik </span><span class="font12" style="font-style:italic;">M.</span><span class="font12"> &nbsp;Terpilih kemiripan antara</span></p></li></ul>
<p><span class="font12">dokumen 2 dan dokumen 3, sehingga</span></p>
<p><span class="font12">terbentuk klaster (2,3)</span></p>
<p><span class="font12" style="font-style:italic;">max</span><span class="font12"> (</span><span class="font12" style="font-style:italic;">d</span><span class="font9" style="font-style:italic;">ik</span><span class="font12">) = </span><span class="font12" style="font-style:italic;">d</span><span class="font9" style="font-style:italic;">23</span><span class="font12"> = 8</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1">•</span><span class="font12"> &nbsp;&nbsp;&nbsp;Pemutakhiran kemiripan klaster (2,3) dengan klaster atau dokumen lain.</span></p></li></ul>
<p><span class="font12" style="font-style:italic;">d</span><span class="font9" style="font-style:italic;">(23)4</span><span class="font12"> = min {</span><span class="font12" style="font-style:italic;">d</span><span class="font9" style="font-style:italic;">24</span><span class="font12">, </span><span class="font12" style="font-style:italic;">d</span><span class="font9" style="font-style:italic;">34</span><span class="font12">} = min {6, 7} = 6 </span><span class="font12" style="font-style:italic;">d</span><span class="font9" style="font-style:italic;">(23)(15)</span><span class="font12"> = min {</span><span class="font12" style="font-style:italic;">d</span><span class="font9" style="font-style:italic;">2(15)</span><span class="font12">, </span><span class="font12" style="font-style:italic;">d</span><span class="font9" style="font-style:italic;">3(15)</span><span class="font12">} = min {5, 3} = 3</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1">•</span><span class="font12"> &nbsp;&nbsp;&nbsp;Pemutakhiran matrik M. Setelah diperoleh kemiripan antara klaster baru (2,3) dengan klaster atau dokumen lain, dilanjutkan dengan proses pemutakhiran matrik </span><span class="font12" style="font-style:italic;">M.</span></p></li></ul>
<p><a href="#bookmark27"><span class="font12">2,3 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;41,5</span></a></p>
<p><a href="#bookmark28"><span class="font12">2,3 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;63</span></a></p>
<p><a href="#bookmark29"><span class="font12">4 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;05</span></a></p>
<ul style="list-style:none;"><li>
<p><a href="#bookmark30"><span class="font12">1,5 I0 J</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><span class="font1">•</span><span class="font12"> &nbsp;&nbsp;&nbsp;Pemilihan nilai kemiripan terbesar pada matrik M di atas. Terpilih kemiripan antara klaster (2,3) dengan dokumen 4, sehingga terbentuk klaster (2,3,4)</span></p></li></ul>
<p><span class="font12" style="font-style:italic;">max</span><span class="font12"> (</span><span class="font12" style="font-style:italic;">d</span><span class="font9" style="font-style:italic;">ik</span><span class="font12">) = </span><span class="font12" style="font-style:italic;">d</span><span class="font9" style="font-style:italic;">(23)4</span><span class="font12"> = 6</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1">•</span><span class="font12"> &nbsp;&nbsp;&nbsp;Pemutakhiran kemiripan klaster (2,3,4) dengan klaster atau dokumen lain.</span></p></li></ul>
<p><span class="font12" style="font-style:italic;">d</span><span class="font9" style="font-style:italic;">(234)(15)</span><span class="font12"> = min {</span><span class="font12" style="font-style:italic;">d</span><span class="font9" style="font-style:italic;">(23)(15)</span><span class="font12">, </span><span class="font12" style="font-style:italic;">d</span><span class="font9" style="font-style:italic;">4(15)</span><span class="font12">} = min {3, 5} = 3</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1">•</span><span class="font12"> &nbsp;&nbsp;&nbsp;Oleh karena nilai kemiripan maksimum sama dengan nilai kemiripan minimum maka proses pembentukan klaster dihentikan.</span></p></li></ul>
<p><span class="font12">g. Apabila terdapat dokumen yang belum termasuk klaster manapun, maka dokumen-dokumen ini digunakan untuk membentuk klaster baru.</span></p>
<ul style="list-style:none;"><li>
<h3><a name="bookmark31"></a><span class="font14" style="font-weight:bold;"><a name="bookmark32"></a>3. &nbsp;&nbsp;&nbsp;HASIL DAN PEMBAHASAN</span></h3></li></ul>
<p><span class="font12">Pada bagian ini akan dilakukan evaluasi kinerja dari metode klasterisasi dokumen yang diajukan dengan melihat hasil klasterisasi dan perbandingan dengan algoritma sebelumnya. Metode yang diajukan diimplementasikan dengan bahasa pemrograman Java pada sebuah komputer dengan spesifikasi Intel </span><span class="font12" style="font-style:italic;">Core</span><span class="font12"> i7 1.9 GHz, 4GB.</span></p>
<ul style="list-style:none;"><li>
<h4><a name="bookmark33"></a><span class="font12" style="font-weight:bold;"><a name="bookmark34"></a>3.1 &nbsp;&nbsp;&nbsp;Data Uji</span></h4></li></ul>
<p><span class="font12">Pengukuran kinerja dari algoritma dalam penelitian ini dilakukan dengan menggunakan data</span></p>
<p><span class="font12">uji </span><span class="font12" style="font-style:italic;">Reuters 21578 Dataset</span><span class="font12">. Set data uji coba ini diperoleh dari </span><span class="font12" style="font-style:italic;">UCI Knowledge Discovery in Database</span><span class="font12"> (</span><a href="http://kdd.ics.uci.edu/databases/"><span class="font12">http://kdd.ics.uci.edu/databases/</span></a><span class="font12">). Set data </span><span class="font12" style="font-style:italic;">Reuters 21578</span><span class="font12"> merupakan set data dokumen dalam Bahasa Inggris yang terdiri dari 21.578 dokumen, yang dihimpun dari </span><span class="font12" style="font-style:italic;">Reuters Newswire </span><span class="font12">pada tahun 1987. Tabel 3 memperlihatkan karakteristik dari data uji </span><span class="font12" style="font-style:italic;">Reuters 21578</span><span class="font12"> yang digunakan dalam penelitian ini. Sedangkan Tabel 4 memperlihatkan kategori beserta jumlah dokumen untuk masing-masing kategori dari data uji </span><span class="font12" style="font-style:italic;">Reuters 21578</span><span class="font12">.</span></p>
<div>
<table border="1">
<tr><td colspan="2" style="vertical-align:top;">
<p><span class="font12">Tabel 3. Karakteritik Data Uji </span><span class="font12" style="font-style:italic;">Reuters 21578</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font12">Karakteristik</span></p></td><td style="vertical-align:middle;">
<p><span class="font12" style="font-style:italic;">Reuters 21578</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font12">Jumlah Item / Kata</span></p></td><td style="vertical-align:middle;">
<p><span class="font12">13.639</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font12">Rerata Panjang Dokumen</span></p></td><td style="vertical-align:bottom;">
<p><span class="font12">89</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font12">Jumlah Record</span></p></td><td style="vertical-align:top;">
<p><span class="font12">5.000</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font12">Jumlah Kategori</span></p></td><td style="vertical-align:bottom;">
<p><span class="font12">10</span></p></td></tr>
<tr><td colspan="2" style="vertical-align:bottom;">
<p><span class="font12">Tabel 4. Kategori Data Uji </span><span class="font12" style="font-style:italic;">Reuters 21578</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font12">Topik / Kategori</span></p></td><td style="vertical-align:bottom;">
<p><span class="font12">Jumlah Dokumen</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font12">Acq</span></p></td><td style="vertical-align:bottom;">
<p><span class="font12">1.440</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font12">Coffee</span></p></td><td style="vertical-align:top;">
<p><span class="font12">119</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font12">Crude</span></p></td><td style="vertical-align:middle;">
<p><span class="font12">379</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font12">Earn</span></p></td><td style="vertical-align:middle;">
<p><span class="font12">1.552</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font12">Interest</span></p></td><td style="vertical-align:middle;">
<p><span class="font12">343</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font12">Money-fx</span></p></td><td style="vertical-align:bottom;">
<p><span class="font12">317</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font12">Money-supply</span></p></td><td style="vertical-align:top;">
<p><span class="font12">108</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font12">Ship</span></p></td><td style="vertical-align:top;">
<p><span class="font12">216</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font12">Sugar</span></p></td><td style="vertical-align:top;">
<p><span class="font12">146</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font12">Trade</span></p></td><td style="vertical-align:top;">
<p><span class="font12">380</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font12">Total Dokumen</span></p></td><td style="vertical-align:middle;">
<p><span class="font12">5.000</span></p></td></tr>
</table>
</div><br clear="all">
<ul style="list-style:none;"><li>
<h4><a name="bookmark35"></a><span class="font12" style="font-weight:bold;"><a name="bookmark36"></a>3.2 &nbsp;&nbsp;&nbsp;Metode Evaluasi Hasil Klasterisasi</span></h4></li></ul>
<p><span class="font12">Untuk evaluasi dari hasil proses klasteri-sasi dokumen digunakan pengukuran nilai </span><span class="font12" style="font-style:italic;">F-meas-ure</span><span class="font12"> dan </span><span class="font12" style="font-style:italic;">Purity</span><span class="font12">. </span><span class="font12" style="font-style:italic;">F-measure</span><span class="font12"> merupakan kombinasi </span><span class="font12" style="font-style:italic;">harmonic</span><span class="font12"> dari nilai </span><span class="font12" style="font-style:italic;">recall</span><span class="font12"> dan </span><span class="font12" style="font-style:italic;">precision</span><span class="font12"> yang digunakan dalam sistem temu kembali informasi. Menggunakan data uji yang sudah dijelaskan sebelumnya, setiap klaster yang dihasilkan dapat dianggap sebagai hasil dari suatu </span><span class="font12" style="font-style:italic;">query</span><span class="font12">, sedangkan setiap kumpulan dokumen yang belum diklasifikasi dapat dianggap sebagai kumpulan dokumen yang diharapkan dari </span><span class="font12" style="font-style:italic;">query</span><span class="font12"> tersebut. Jadi nilai </span><span class="font12" style="font-style:italic;">precision P(i,j)</span><span class="font12"> dan nilai </span><span class="font12" style="font-style:italic;">recall R(i,j)</span><span class="font12"> pada setiap klaster ke</span><span class="font12" style="font-style:italic;">-j </span><span class="font12">dari kelas ke</span><span class="font12" style="font-style:italic;">-i</span><span class="font12"> dapat dihitung.</span></p>
<p><span class="font12">Jika </span><span class="font12" style="font-style:italic;">n</span><span class="font9" style="font-style:italic;">i</span><span class="font12"> adalah jumlah dari anggota kelas ke-</span><span class="font12" style="font-style:italic;">i</span><span class="font12">, </span><span class="font12" style="font-style:italic;">n</span><span class="font9" style="font-style:italic;">j</span><span class="font12"> adalah jumlah anggota dari klaster </span><span class="font12" style="font-style:italic;">ke-j</span><span class="font12">, dan </span><span class="font12" style="font-style:italic;">n</span><span class="font9" style="font-style:italic;">ij </span><span class="font12">adalah jumlah dari anggota kelas </span><span class="font12" style="font-style:italic;">ke-i</span><span class="font12"> yang berada pada klaster </span><span class="font12" style="font-style:italic;">ke-j</span><span class="font12">, maka </span><span class="font12" style="font-style:italic;">P(i,j)</span><span class="font12"> dan </span><span class="font12" style="font-style:italic;">R(i,j)</span><span class="font12"> dapat dihitung dengan persamaan (X) dan (X) berikut (Dalli, 2003):</span></p>
<p><span class="font12" style="font-style:italic;">P(j</span><span class="font12"> = </span><span class="font9">τ<sup>2</sup> </span><span class="font12">, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(7)</span></p>
<p><span class="font8" style="font-style:italic;"><sup>n</sup>ι</span></p>
<p><span class="font12" style="font-style:italic;">R(j</span><span class="font12"> = &nbsp;&nbsp;. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(8)</span></p>
<p><span class="font8" style="font-style:italic;"><sup>-</sup>i</span></p>
<p><span class="font12">Nilai </span><span class="font12" style="font-style:italic;">F-measure</span><span class="font12"> kelas ke-</span><span class="font12" style="font-style:italic;">i</span><span class="font12"> pada klaster ke-</span><span class="font12" style="font-style:italic;">j </span><span class="font12">dan nilai keseluruhan </span><span class="font12" style="font-style:italic;">F-measure</span><span class="font12"> dinyatakan pada persamaan-persamaan berikut:</span></p>
<div>
<p><span class="font12" style="font-style:italic;">F(i,j) =</span></p>
</div><br clear="all">
<p><span class="font9" style="text-decoration:underline;">2 × </span><span class="font9" style="font-style:italic;text-decoration:underline;">P(IJ)</span><span class="font9" style="text-decoration:underline;"> × </span><span class="font9" style="font-style:italic;text-decoration:underline;">R(IJ) </span><span class="font9" style="font-style:italic;">P(i,J)</span><span class="font9"> + </span><span class="font9" style="font-style:italic;">R(U)</span></p>
<div>
<p><span class="font12">(9)</span></p>
<p><span class="font12">(10)</span></p>
</div><br clear="all">
<div>
<p><span class="font11" style="font-style:italic;">F = ∑</span><span class="font9" style="font-style:italic;">j- </span><span class="font11" style="font-style:italic;">max{F(i,j)},</span></p>
</div><br clear="all">
<p><span class="font12">dimana </span><span class="font12" style="font-style:italic;">n</span><span class="font12"> adalah jumlah semua dokumen, </span><span class="font12" style="font-style:italic;">n</span><span class="font9" style="font-style:italic;">i</span><span class="font12"> adalah jumlah dokumen pada kelas ke-</span><span class="font12" style="font-style:italic;">i</span><span class="font12">, dan </span><span class="font12" style="font-style:italic;">max{F(i,j)} </span><span class="font12">adalah nilai </span><span class="font12" style="font-style:italic;">F(i,j)</span><span class="font12"> terbesar yang ditemukan pada kelas ke-</span><span class="font12" style="font-style:italic;">i</span><span class="font12"> untuk keseluruhan klaster </span><span class="font12" style="font-style:italic;">ke-j</span><span class="font12">. Secara umum, nilai </span><span class="font12" style="font-style:italic;">F-measure</span><span class="font12"> yang tinggi merepresentasikan hasil klasterisasi yang baik (Steinbach, dkk., 2000).</span></p>
<p><span class="font12">Nilai </span><span class="font12" style="font-style:italic;">Purity</span><span class="font12"> dari suatu klaster merepresentasikan bagian dari suatu klaster sesuai dengan kelas terbesar dari suatu dokumen dimasukkan ke dalam klaster tersebut, maka </span><span class="font12" style="font-style:italic;">Purity</span><span class="font12"> dari klaster ke-</span><span class="font12" style="font-style:italic;">j</span><span class="font12"> didefinisikan sebagai berikut (Zhao dan Karypis, 2004):</span></p>
<div>
<p><span class="font9">1</span></p>
<p><span class="font12" style="font-style:italic;">Puntyo) = ~ max n</span></p>
</div><br clear="all">
<div>
<p><span class="font12">(11)</span></p>
</div><br clear="all">
<p><span class="font12">Nilai </span><span class="font12" style="font-style:italic;">Purity</span><span class="font12"> secara keseluruhan dari proses klasterisasi merupakan penjumlahan dari setiap nilai </span><span class="font12" style="font-style:italic;">Purity</span><span class="font12"> klaster:</span></p>
<p><span class="font12" style="font-style:italic;">Purity = ∑</span><span class="font9" style="font-style:italic;">j- </span><span class="font12" style="font-style:italic;">Purity (j).</span><span class="font12"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(12)</span></p>
<p><span class="font12">Secara umum, nilai </span><span class="font12" style="font-style:italic;">Purity</span><span class="font12"> yang lebih tinggi menunjukkan hasil klasterisasi yang lebih baik.</span></p>
<ul style="list-style:none;"><li>
<h4><a name="bookmark37"></a><span class="font12" style="font-weight:bold;"><a name="bookmark38"></a>3.3 &nbsp;&nbsp;&nbsp;Hasil Uji Coba dan Analisis</span></h4></li></ul>
<p><span class="font12">Dalam uji coba ini akan dibandingkan metode </span><span class="font12" style="font-style:italic;">weighted maximum capturing</span><span class="font12"> (WMC) yang dikembangkan dalam penelitian ini dengan algoritma klasterisasi dokumen berbasis </span><span class="font12" style="font-style:italic;">frequent itemsets</span><span class="font12"> dengan teknik </span><span class="font12" style="font-style:italic;">maximum capturing</span><span class="font12"> (MC) dalam hal akurasi hasil klasterisasi. Perbandingan dilakukan dengan menggunakan data uji coba </span><span class="font12" style="font-style:italic;">Reuters-21578</span><span class="font12"> yang berjumlah 5.000 dokumen. Untuk mengetahui perbandingan akurasi hasil klasterisasi, dibandingkan nilai </span><span class="font12" style="font-style:italic;">F-measure</span><span class="font12"> dan </span><span class="font12" style="font-style:italic;">purity</span><span class="font12"> dari masing-masing algoritma dengan menggunakan jumlah dokumen 2.500 sampai 5.000 dengan interval 250 dokumen.</span></p>
<p><span class="font12">Proses klasterisasi dokumen yang berbasis </span><span class="font12" style="font-style:italic;">frequent itemsets</span><span class="font12"> memerlukan nilai minimum support (minsup) dalam menentukan suatu itemset merupakan </span><span class="font12" style="font-style:italic;">frequent itemsets</span><span class="font12"> atau tidak. Penentuan nilai minsup yang tepat akan berpengaruh terhadap akurasi hasil klasterisasi. Untuk menemukan nilai minsup yang tepat, maka dilakukan dilakukan uji coba parameter </span><span class="font12" style="font-style:italic;">minsup</span><span class="font12"> dengan rentang nilai 0,01 sampai 0,03 dengan interval nilai 0,005 pada 1.000 dokumen uji coba. Hasil uji coba parameter </span><span class="font12" style="font-style:italic;">minsup </span><span class="font12">pada pada metode WMC dan MC dapat dilihat pada Tabel 5. Nilai parameter minsup optimal adalah nilai minsup yang menghasil nilai </span><span class="font12" style="font-style:italic;">F-</span></p>
<p><span class="font12" style="font-style:italic;">measure</span><span class="font12"> tertinggi. Seperti yang terlihat pada Tabel 5, nilai parameter minsup optimal untuk metode MC adalah 0,015 sedangkan untuk metode WMC adalah 0,01.</span></p>
<p><span class="font12">Tabel 5. Hasil Uji Coba Parameter </span><span class="font12" style="font-style:italic;">Minimum Support</span><span class="font12"> (</span><span class="font12" style="font-style:italic;">minsup</span><span class="font12">)</span></p>
<table border="1">
<tr><td style="vertical-align:middle;">
<p><span class="font12" style="font-style:italic;">minsup</span></p></td><td style="vertical-align:middle;">
<p><span class="font12" style="font-style:italic;">F-measure</span></p>
<p><span class="font12">Metode MC</span></p></td><td style="vertical-align:middle;">
<p><span class="font12" style="font-style:italic;">F-measure</span></p>
<p><span class="font12">Metode WMC</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font12">0,010</span></p></td><td style="vertical-align:bottom;">
<p><span class="font12">0,6716</span></p></td><td style="vertical-align:bottom;">
<p><span class="font12" style="font-weight:bold;">0,6943</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font12">0,015</span></p></td><td style="vertical-align:bottom;">
<p><span class="font12" style="font-weight:bold;">0,6819</span></p></td><td style="vertical-align:bottom;">
<p><span class="font12">0,6786</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font12">0,020</span></p></td><td style="vertical-align:bottom;">
<p><span class="font12">0,5908</span></p></td><td style="vertical-align:bottom;">
<p><span class="font12">0,5683</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font12">0,025</span></p></td><td style="vertical-align:bottom;">
<p><span class="font12">0,5467</span></p></td><td style="vertical-align:bottom;">
<p><span class="font12">0,5948</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font12">0,030</span></p></td><td style="vertical-align:bottom;">
<p><span class="font12">0,5410</span></p></td><td style="vertical-align:bottom;">
<p><span class="font12">0,6237</span></p></td></tr>
</table>
<p><span class="font12">Dengan menggunakan nilai parameter minsup yang optimal ini selanjutnya dibandingkan akurasi hasil klasterisasi metode WMC yang dikembangkan dengan metode sebelumnya (MC) dalam menangani sejumlah dokumen yang diberikan. Tabel 6 memperlihatkan hasil uji coba perbandingan akurasi hasil klasterisasi dari masing-masing algoritma yang dilihat dari nilai </span><span class="font12" style="font-style:italic;">F-measure </span><span class="font12">dan </span><span class="font12" style="font-style:italic;">Purity.</span><span class="font12"> Gambar 3 menunjukkan waktu komputasi yang diperlukan masing-masing algoritma dalam menangani sejumlah data yang diberikan.</span></p>
<p><span class="font12">Dalam Tabel 6 terlihat bahwa nilai </span><span class="font12" style="font-style:italic;">F-measure </span><span class="font12">dari algoritma WMC selalu lebih tinggi dari algoritma MC pada setiap jumlah dokumen yang diberikan. Pada Tabel 6 dapat dilihat nilai rata-rata </span><span class="font12" style="font-style:italic;">F-measure</span><span class="font12"> dan </span><span class="font12" style="font-style:italic;">purity</span><span class="font12"> dari proses klasterisasi dokumen dengan algoritma </span><span class="font12" style="font-style:italic;">weighted maximum capturing</span><span class="font12"> (WMC) lebih besar dari nilai rata-rata </span><span class="font12" style="font-style:italic;">F-measure</span><span class="font12"> dan </span><span class="font12" style="font-style:italic;">purity</span><span class="font12"> yang dihasilkan oleh proses klasterisasi dokumen dengan algoritma </span><span class="font12" style="font-style:italic;">maximum capturing</span><span class="font12"> (MC). Dimana nilai rata-rata (</span><span class="font12" style="font-style:italic;">mean</span><span class="font12">) </span><span class="font12" style="font-style:italic;">F-measure</span><span class="font12"> yang dihasilkan oleh algoritma WMC adalah sebesar 0,723 yang lebih tinggi 0,02 dibandingkan algoritma MC (0,703). Rata-rata nilai</span></p>
<p><span class="font12" style="font-style:italic;">F-measure</span><span class="font12"> yang lebih tinggi menunjukkan bahwa akurasi hasil klasterisasi dari algoritma WMC lebih baik dibandingkan algoritma MC. Sejalan dengan nilai </span><span class="font12" style="font-style:italic;">F-measure</span><span class="font12">, nilai </span><span class="font12" style="font-style:italic;">purity</span><span class="font12"> dari algoritma WMC juga selalu lebih tinggi dibandingkan algoritma MC pada setiap jumlah dokumen yang diberikan. Dimana nilai rata-rata </span><span class="font12" style="font-style:italic;">purity</span><span class="font12"> yang dihasilkan oleh algoritma WMC adalah sebesar 0,730 yang lebih tinggi 0,023 dibandingkan algoritma MC (0,707). Nilai </span><span class="font12" style="font-style:italic;">purity</span><span class="font12"> yang tinggi mencerminkan tingkat kemurnian suatu klaster semakin baik, yang berarti klaster tersebut mengandung sebagian besar dokumen yang memang seharusnya menjadi bagian dari klaster tersebut.</span></p>
<p><span class="font12">Untuk mengetahui rasio perbaikan akurasi hasil klasterisasi algoritma WMC terhadap algoritma MC, maka dihitung nilai </span><span class="font12" style="font-style:italic;">improvement ratio</span><span class="font12"> (IR) sebagai berikut:</span></p>
<p><span class="font10" style="font-style:italic;">p </span><span class="font8" style="font-style:italic;">metode WMC_ </span><span class="font10" style="font-style:italic;">p </span><span class="font8" style="font-style:italic;">metode MC</span></p>
<p><span class="font10" style="font-style:italic;">IRr= -------------------</span></p>
<p><span class="font8" style="font-style:italic;">F &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="font10" style="font-style:italic;">p </span><span class="font8" style="font-style:italic;">metode MC</span></p>
<p><span class="font8">0,723- </span><span class="font8" style="font-style:italic;">0,703 _ </span><span class="font8">0,02</span></p>
<p><span class="font8" style="font-style:italic;">0,703 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0,703</span></p>
<div>
<p><span class="font10">= 0,028</span></p>
</div><br clear="all">
<p><span class="font10" style="font-style:italic;">Purity </span><span class="font8" style="font-style:italic;">metode WMC _ </span><span class="font10" style="font-style:italic;">Purity </span><span class="font8" style="font-style:italic;">metode MC</span></p>
<p><span class="font10" style="font-style:italic;">IR</span><span class="font8" style="font-style:italic;">jmrlcy </span><span class="font10" style="font-style:italic;">= &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;p<sub>uτ</sub>ity</span><span class="font8" style="font-style:italic;">metode MC</span></p>
<p><span class="font8" style="font-style:italic;">0,730- 0,707 _ 0,023</span></p>
<p><span class="font8" style="font-style:italic;">0,707 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0707</span></p>
<div>
<p><span class="font10">= 0,033</span></p>
</div><br clear="all">
<p><span class="font12">Berdasarkan perhitungan IR di atas, algoritma WMC yang dikembangkan dalam penelitian ini melakukan perbaikan nilai </span><span class="font12" style="font-style:italic;">F-measure</span><span class="font12"> algoritma awal sebesar 2,8%, dan melakukan perbaikan nilai </span><span class="font12" style="font-style:italic;">purity</span><span class="font12"> algoritma awal sebesar 3,3%. Perubahan yang dilakukan seperti perhitungan kemiripan dokumen dengan memperhatikan bobot dari </span><span class="font12" style="font-style:italic;">frequent itemsets</span><span class="font12">, dan proses klasterisasi yang memperhitungkan kemiripan global terbukti berhasil meningkatkan akurasi hasil klasterisasi.</span></p>
<p><span class="font12">Tabel 6. Perbandingan Nilai </span><span class="font12" style="font-style:italic;">F-measure</span><span class="font12"> dan Purity dari Masing-Masing Metode</span></p>
<table border="1">
<tr><td rowspan="2" style="vertical-align:middle;">
<p><span class="font12">Jumlah Dokumen</span></p></td><td colspan="2" style="vertical-align:bottom;">
<p><span class="font12">F-Measure</span></p></td><td colspan="2" style="vertical-align:bottom;">
<p><span class="font12">Purity</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font12">Metode MC</span></p></td><td style="vertical-align:top;">
<p><span class="font12">Metode WMC</span></p></td><td style="vertical-align:top;">
<p><span class="font12">Metode MC</span></p></td><td style="vertical-align:top;">
<p><span class="font12">Metode WMC</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font12">2.500</span></p></td><td style="vertical-align:bottom;">
<p><span class="font12">0,730</span></p></td><td style="vertical-align:bottom;">
<p><span class="font12">0,758</span></p></td><td style="vertical-align:bottom;">
<p><span class="font12">0,713</span></p></td><td style="vertical-align:bottom;">
<p><span class="font12">0,747</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font12">2.750</span></p></td><td style="vertical-align:bottom;">
<p><span class="font12">0,711</span></p></td><td style="vertical-align:bottom;">
<p><span class="font12">0,731</span></p></td><td style="vertical-align:bottom;">
<p><span class="font12">0,729</span></p></td><td style="vertical-align:bottom;">
<p><span class="font12">0,732</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font12">3.000</span></p></td><td style="vertical-align:bottom;">
<p><span class="font12">0,675</span></p></td><td style="vertical-align:bottom;">
<p><span class="font12">0,677</span></p></td><td style="vertical-align:bottom;">
<p><span class="font12">0,682</span></p></td><td style="vertical-align:bottom;">
<p><span class="font12">0,704</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font12">3.250</span></p></td><td style="vertical-align:bottom;">
<p><span class="font12">0,726</span></p></td><td style="vertical-align:bottom;">
<p><span class="font12">0,749</span></p></td><td style="vertical-align:bottom;">
<p><span class="font12">0,735</span></p></td><td style="vertical-align:bottom;">
<p><span class="font12">0,744</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font12">3.500</span></p></td><td style="vertical-align:bottom;">
<p><span class="font12">0,671</span></p></td><td style="vertical-align:bottom;">
<p><span class="font12">0,694</span></p></td><td style="vertical-align:bottom;">
<p><span class="font12">0,677</span></p></td><td style="vertical-align:bottom;">
<p><span class="font12">0,695</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font12">3.750</span></p></td><td style="vertical-align:bottom;">
<p><span class="font12">0,662</span></p></td><td style="vertical-align:bottom;">
<p><span class="font12">0,699</span></p></td><td style="vertical-align:bottom;">
<p><span class="font12">0,707</span></p></td><td style="vertical-align:bottom;">
<p><span class="font12">0,712</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font12">4.000</span></p></td><td style="vertical-align:bottom;">
<p><span class="font12">0,742</span></p></td><td style="vertical-align:bottom;">
<p><span class="font12">0,761</span></p></td><td style="vertical-align:bottom;">
<p><span class="font12">0,738</span></p></td><td style="vertical-align:bottom;">
<p><span class="font12">0,769</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font12">4.250</span></p></td><td style="vertical-align:bottom;">
<p><span class="font12">0,688</span></p></td><td style="vertical-align:bottom;">
<p><span class="font12">0,694</span></p></td><td style="vertical-align:bottom;">
<p><span class="font12">0,692</span></p></td><td style="vertical-align:bottom;">
<p><span class="font12">0,713</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font12">4.500</span></p></td><td style="vertical-align:bottom;">
<p><span class="font12">0,722</span></p></td><td style="vertical-align:bottom;">
<p><span class="font12">0,724</span></p></td><td style="vertical-align:bottom;">
<p><span class="font12">0,674</span></p></td><td style="vertical-align:bottom;">
<p><span class="font12">0,725</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font12">4.750</span></p></td><td style="vertical-align:bottom;">
<p><span class="font12">0,703</span></p></td><td style="vertical-align:bottom;">
<p><span class="font12">0,722</span></p></td><td style="vertical-align:bottom;">
<p><span class="font12">0,718</span></p></td><td style="vertical-align:bottom;">
<p><span class="font12">0,737</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font12">5.000</span></p></td><td style="vertical-align:bottom;">
<p><span class="font12">0,698</span></p></td><td style="vertical-align:bottom;">
<p><span class="font12">0,742</span></p></td><td style="vertical-align:bottom;">
<p><span class="font12">0,711</span></p></td><td style="vertical-align:bottom;">
<p><span class="font12">0,748</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font12">Rata-Rata</span></p></td><td style="vertical-align:bottom;">
<p><span class="font12">0,703</span></p></td><td style="vertical-align:bottom;">
<p><span class="font12">0,723</span></p></td><td style="vertical-align:bottom;">
<p><span class="font12">0,707</span></p></td><td style="vertical-align:bottom;">
<p><span class="font12">0,730</span></p></td></tr>
</table>
<div><img src="https://jurnal.harianregional.com/media/8408-4.jpg" alt="" style="width:291pt;height:207pt;">
</div><br clear="all">
<p><span class="font12">Gambar 3. Grafik Perbandingan Waktu Komputasi Metode MC dan Metode WMC</span></p>
<p><span class="font12">Pada Gambar 3 terlihat bahwa waktu komputasi yang dibutuhkan dalam proses klasterisasi dokumen berbanding lurus dengan jumlah dokumen yang digunakan. Semakin banyak jumlah dokumen yang akan diklaster maka semakin lama waktu komputasinya, begitu juga sebaliknya. Seperti yang terlihat juga pada Gambar 5, waktu komputasi dari metode WMC lebih lama jika dibandingkan dengan metode MC. Hal ini disebabkan tingginya kompleksitas komputasi dari metode WMC yang dikembangkan yang memerlukan waktu cukup lama dalam melakukan klasterisasi dokumen. Selain karena mengadaptasi metode klasterisasi secara hirarki yang memiliki kompleksitas tinggi, kompleksitas komputasi yang cukup tinggi pada metode WMC juga disebabkan oleh adanya berbagai proses tambahan untuk melakukan perhitungan bobot tiap item pada masing-masing dokumen dan pengukuran kemiripan dengan kombinasi dua metode.</span></p>
<ul style="list-style:none;"><li>
<h3><a name="bookmark39"></a><span class="font14" style="font-weight:bold;"><a name="bookmark40"></a>4. &nbsp;&nbsp;&nbsp;KESIMPULAN</span></h3></li></ul>
<p><span class="font12">Pada paper ini telah diusulkan sebuah metode baru yaitu metode </span><span class="font12" style="font-style:italic;">weighted maximum capturing </span><span class="font12">untuk klasterisasi dokumen berbasis </span><span class="font12" style="font-style:italic;">frequent itemsets</span><span class="font12">. Berdasarkan uji coba yang dilakukan, kualitas hasil klasterisasi dokumen oleh algoritma WMC yang dikembangkan lebih baik dibandingkan algoritma awal (algoritma MC). Perbaikan atau perubahan yang dilakukan pada algoritma WMC telah terbukti mampu meningkatkan akurasi hasil klas-terisasi. Untuk data uji </span><span class="font12" style="font-style:italic;">Reuters 21578</span><span class="font12">, rata-rata nilai </span><span class="font12" style="font-style:italic;">F-measure</span><span class="font12"> dari algoritma WMC sebesar 0,723 yang meningkat 0,02 dari algoritma awal dengan rasio perbaikan 2,8%. Sedangkan rata-rata nilai </span><span class="font12" style="font-style:italic;">purity</span><span class="font12"> dari algoritma WMC sebesar 0,73 yang meningkat 0,023 dari algoritma awal dengan rasio</span></p>
<p><span class="font12">perbaikan 3,3%. Dari sisi waktu komputasi, waktu komputasi dari metode WMC dalam melakukan klasterisasi sejumlah dokumen lebih lama jika dibandingkan metode MC.</span></p>
<p><span class="font12">Lamanya waktu komputasi metode MC disebabkan oleh tingginya kompleksitas komputasi dari metode WMC saat proses pembentukan klaster. Oleh karena itu pengembangan lebih lanjut metode WMC ini masih sangat mungkin dilakukan. Misalnya dengan menggati metode proses pembentukan klaster dengan mengadaptasi metode klasterisasi partisi seperti </span><span class="font12" style="font-style:italic;">k-means</span><span class="font12">, </span><span class="font12" style="font-style:italic;">bisecting k-means</span><span class="font12">, dan lain-lain yang memiliki kompleksitas komputasi lebih rendah dibandingkan metode klasterisasi hirarki.</span></p>
<ul style="list-style:none;"><li>
<h3><a name="bookmark41"></a><span class="font14" style="font-weight:bold;"><a name="bookmark42"></a>5. &nbsp;&nbsp;&nbsp;DAFTAR PUSTAKA</span></h3></li></ul>
<p><span class="font12">Beil, F., Ester, m. &amp;&nbsp;Xu, X. (2002), &quot;Frequent Term-Based Text Clustering&quot;, </span><span class="font12" style="font-style:italic;">Proceeding of The 8th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</span><span class="font12">, hal.436-42.</span></p>
<p><span class="font12">Borgelt, C. (2005), “An Implementation of the FP-growth Algorithm”, Workshop Open Source data Mining Software, OSDM'05, Chicago, IL, 1-5.ACM Press, USA.</span></p>
<p><span class="font12">Dalli, A. (2003), &quot;Adaptation of The </span><span class="font12" style="font-style:italic;">F-measure</span><span class="font12"> to Cluster-Based Lexicon Quality &quot;, </span><span class="font12" style="font-style:italic;">Proceedings of the EACL 2003 Workshop on Evaluation Initiatives in Natural Language Processing: &nbsp;are evaluation</span></p>
<p><span class="font12" style="font-style:italic;">methods metrics and resources reusable</span><span class="font12">, hal.51-56.</span></p>
<p><span class="font12">Fung, B., Wang, K. &amp;&nbsp;Ester, M. (2003), &quot;Hierarchical Document Clustering using Frequent Itemsets&quot;, </span><span class="font12" style="font-style:italic;">Proceeding of The 3rd SIAM International</span></p>
<p><span class="font12">Han, J. &amp;&nbsp;Kamber, M., 2001. </span><span class="font12" style="font-style:italic;">Data Mining:</span></p>
<p><span class="font12" style="font-style:italic;">Concepts and Techniques</span><span class="font12">. San Fransisco: Morgan Kaufmann.</span></p>
<p><span class="font12">Han, J., J. Pei, &amp;&nbsp;Y. Yin. (2000), “Mining Fre-quentPatterns without Candidate Generation”, ACM SIGMOD Int'l Conference on Management of Data.</span></p>
<p><span class="font12">Jain, A.K., Murty, M.N. &amp;&nbsp;Flynn, P.J. (1999), &quot;Data Clustering : A Review&quot;, </span><span class="font12" style="font-style:italic;">ACM Computing Survey Vol. 31, No. 3</span><span class="font12">, hal.264-323.</span></p>
<p><span class="font12">Khrisna, M. &amp;&nbsp;Bhavani, D. (2010), &quot;An Efficient Approach for Text Clusteiring Based on Frequent Itemsets&quot;, </span><span class="font12" style="font-style:italic;">European Journal of Scientif Research Vol. 42</span><span class="font12">, hal.399-410.</span></p>
<p><span class="font12">Li, Y.J., Chung, S.M. &amp;&nbsp;Holt, J.D. (2008), &quot;Text Document Clustering based on Frequent Word Meaning Sequences&quot;, </span><span class="font12" style="font-style:italic;">Data &amp;&nbsp;Knowledge Engineering</span><span class="font12">, hal.381-404.</span></p>
<p><span class="font12">Niwattanakul, S., Singthongchai, J., Naenudron, E.</span></p>
<p><span class="font12">&amp; Wanapu, S., &nbsp;2013. Using Jaccard</span></p>
<p><span class="font12">Coefficient for Keywords Similarity. In </span><span class="font12" style="font-style:italic;">Proceedings of the International MultiConference of Engineers and Computer Scientists 2013 Vol I</span><span class="font12">. Hong Kong, 2013.</span></p>
<p><span class="font12">Steinbach, M., Krypis, G. &amp;&nbsp;Kumar, V. (2000), &quot;A Comparison of Document Clustering Techniques&quot;, </span><span class="font12" style="font-style:italic;">Proceeding Text Mining Workshop, KDD 2000</span><span class="font12">.</span></p>
<p><span class="font12">Tan, P.N., Stainbach, M. &amp;&nbsp;Kumar, V., 2006. </span><span class="font12" style="font-style:italic;">Introduction to Data Mining</span><span class="font12">. 4th ed. New York: Pearson Addison Wesley.</span></p>
<p><span class="font12">Usha, R.M. (2011), &quot;Review on Frequent ItemBased Dynamic Text Clustering&quot;, </span><span class="font12" style="font-style:italic;">International Journal of Computer Science and Information Technology &amp;&nbsp;Security, Vol. 1, No. 2</span><span class="font12">, hal.98-103.</span></p>
<p><span class="font12">Wang, K., Xu, C. &amp;&nbsp;Liu, B. (1999), &quot;Clustering Transactions Using Large Items&quot;, </span><span class="font12" style="font-style:italic;">Proceeding of The 8th International Conference on Information and Knowledge Management</span><span class="font12">, hal.483-90.</span></p>
<p><span class="font12">Zhang, W., Yoshida, T., Tang, X. &amp;&nbsp;Wang, Q. (2010), &quot;Text Clustering using Frequent Itemsets&quot;, </span><span class="font12" style="font-style:italic;">Knowledge-Based System &nbsp;23</span><span class="font12">,</span></p>
<p><span class="font12">hal.379-88.</span></p>
<p><span class="font12">Zhao, Y. &amp;&nbsp;Karypis, G. (2005), &quot;Empirical and theoretical comparisons of selected criterion functions for document clustering&quot;, </span><span class="font12" style="font-style:italic;">Machine Learning 55 (3)</span><span class="font12">, hal.50-62.</span></p>