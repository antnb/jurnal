---
layout: full_article
title: "Sentiment Analysis of Domestic Violence Issues on Twitter Using Multinomial Naïve Bayes and Support Vector Machine"
author: "Uli Rindu Debora, I Putu Agus Eka Pratama, Gusti Made Arya Sasmita"
categories: jitter
canonical_url: https://jurnal.harianregional.com/jitter/full-110096 
citation_abstract_html_url: "https://jurnal.harianregional.com/jitter/id-110096"
citation_pdf_url: "https://jurnal.harianregional.com/jitter/full-110096"  
comments: true
---

<p><span class="font1">JITTER- Jurnal Ilmiah Teknologi dan Komputer Vol. 4, No. 3 December 2023</span></p>
<p><span class="font2" style="font-weight:bold;">Sentiment Analysis of Domestic Violence Issues on Twitter Using Multinomial Naïve Bayes and Support Vector Machine</span></p>
<p><span class="font1" style="font-weight:bold;">Uli Rindu Debora<sup>a1</sup>, I Putu Agus Eka Pratama<sup>a2</sup>, Gusti Made Arya Sasmita<sup>b3 </sup></span><span class="font1"><sup>a</sup>Department of Information Technology, Faculty of Engineering, Udayana University Bukit Jimbaran, Bali, Indonesia</span></p>
<p><span class="font1">e-mail: <sup>1</sup></span><a href="mailto:rindudebora@student.unud.ac.id"><span class="font1" style="text-decoration:underline;">rindudebora@student.unud.ac.id</span></a><span class="font1">, </span><a href="mailto:eka.pratama@unud.ac.id"><span class="font1"><sup>2</sup></span><span class="font1" style="text-decoration:underline;">eka.pratama@unud.ac.id</span></a><span class="font1">, </span><a href="mailto:aryasasmita@it.unud.ac.id"><span class="font1"><sup>3</sup></span><span class="font1" style="text-decoration:underline;">aryasasmita@it.unud.ac.id</span></a></p>
<p><span class="font1" style="font-weight:bold;font-style:italic;">Abstrak</span></p>
<p><span class="font1" style="font-style:italic;">Kasus kekerasan dalam rumah tangga (KDRT) selalu mengundang banyak komentar publik di media sosial Twitter. Penelitian ini bertujuan untuk melakukan analisis klasifikasi sentimen opini masyarakat terkait kasus KDRT yang terus berlangsung di Twitter. Penelitian ini menggunakan algoritma Multinomial Naive Bayes dan SVM untuk menguji akurasi dalam melakukan klasifikasi tweet. Metode penelitian ini mencakup langkah-langkah sebagai berikut: pengumpulan data dari Twitter, pra-pemrosesan data, analisis sentimen, klasifikasi sentimen dengan menggunakan algoritma SVM dan Multinomial Naïve Bayes, serta analisis hasil dari kedua algoritma tersebut. Hasil penelitian menunjukkan bahwa tingkat akurasi tertinggi yang didapatkan algoritma SVM mencapai 73% pada rasio 80:20, sementara algoritma Multinomial Naïve Bayes mendapatkan tingkat akurasi sebesar 70% pada rasio yang sama yaitu 80:20. Dapat disimpulkan bahwa algoritma SVM memiliki tingkat akurasi yang lebih baik daripada algoritma Multinomial Naïve Bayes.</span></p>
<p><span class="font1" style="font-weight:bold;font-style:italic;">Kata kunci: </span><span class="font1" style="font-style:italic;">Analisis Sentimen, Isu KDRT, Multinomial Naïve Bayes, Support Vector Machine, Twitter</span></p>
<p><span class="font1" style="font-weight:bold;font-style:italic;">Abstract</span></p>
<p><span class="font1" style="font-style:italic;">Cases of domestic violence (KDRT) always attract numerous public comments on Twitter's social media platform. This research aims to conduct a sentiment analysis classification regarding ongoing cases of KDRT on Twitter. The study employs the Multinomial Naive Bayes and SVM algorithms to test accuracy in classifying tweets. The research methodology includes the following steps: data collection from Twitter, data preprocessing, sentiment analysis, sentiment classification using SVM and Multinomial Naïve Bayes algorithms, and analysis of results from both algorithms. The research findings indicate that the SVM algorithm achieves the highest accuracy rate, reaching 73% at an 80:20 ratio. In comparison, the Multinomial Naïve Bayes algorithm attains an accuracy rate of 70% at the same ratio. Therefore, it can be concluded that the SVM algorithm exhibits better accuracy compared to the Multinomial Naïve Bayes algorithm.</span></p>
<p><span class="font1" style="font-weight:bold;font-style:italic;">Keywords : </span><span class="font1" style="font-style:italic;">Sentiment Analysis, Domestic Violence Issues, Multinomial Naïve Bayes (MNB), Support Vector Machine (SVM), Twitter</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1" style="font-weight:bold;">1. &nbsp;&nbsp;&nbsp;Introduction</span></p></li></ul>
<p><span class="font1">Domestic violence in Indonesia is a more complex problem than is publicly apparent. Published data and figures reflect only a fraction of the cases that occur. Many cases of domestic violence go unreported or hidden from the public, so we have only a fraction of the real problem in today's picture. It is essential to understand that domestic violence is a deep and complex issue, and further efforts are needed to reveal and address all cases.</span></p>
<p><span class="font1">The National Commission on Violence Against Women (Komnas Perempuan), in its latest annual report, stated that domestic violence cases occupy the highest position as cases of violence against women. Domestic violence cases contributed 79% or 6,480 cases out of a</span></p>
<p><span class="font1">total of 8,234 data on cases of violence against women throughout 2020 obtained by Komnas Perempuan. Cases of violence against women ranked first, with 3,221 cases out of the total domestic violence cases [1]. Considering the statement from the National Commission on Violence Against Women, many victims of domestic violence (KDRT) often include women and children. Males frequently perpetrate this violence, and if it occurs too frequently, it can lead to issues in the development of children, affecting both their physical and mental well-being in the future.</span></p>
<p><span class="font1">Twitter is often used to express feelings about something. It can be both praise and criticism from an emotional point of view. Users write messages about various things, share information, inspire, discuss specific topics, and express happiness and other emotional expressions through status writing and tweets. The author sees millions of information and messages every day through the activities of Twitter social media users. Hence, this final project will analyze research on Sentiment Analysis of Domestic Violence Issues on Twitter social media in Indonesia, using the Naïve Bayes Classifier Algorithm to examine public opinion expressed through tweets.</span></p>
<p><span class="font1">This study implemented two algorithms: Multinomial Naive Bayes and Support Vector Machine (SVM). Multinomial Naive Bayes is one of the algorithms used in text mining. The Naive Bayes algorithm, known as the Bayes' Theorem, involves statistical calculations to predict future probabilities based on past experiences or encountered issues. SVM excels in its ability to handle both linear and non-linear classification problems. In sentiment analysis, where the relationship between features such as words or phrases and sentiment can be highly complex SVM leverages kernel techniques to handle non-linear data.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1" style="font-weight:bold;">2. &nbsp;&nbsp;&nbsp;Research Method / Proposed Method</span></p></li></ul>
<p><span class="font1">Research Methods contains a discussion of the research methodology, which contains the stages or description of the research conducted. The research method is helpful to facilitate the research process.</span></p><img src="https://jurnal.harianregional.com/media/110096-1.jpg" alt="" style="width:269pt;height:132pt;">
<p><span class="font1" style="font-weight:bold;">Figure 1. </span><span class="font1">System Process Flow</span></p>
<p><span class="font1">Figure 1 represents the system’s process flow. In this study, the system process flow begins with the data crawling or data collection process and proceeds to the preprocessing stage involving several processes. Following this, the TF-IDF modeling process takes place and subsequently, the division of data into two parts—training data and test data—can be adjusted according to research needs. Subsequently, the study employs two algorithms Multinomial Naïve Bayes and Support Vector Machine, to perform the classification. Finally, the study compares the results of the two models to identify the best-performing model.</span></p><img src="https://jurnal.harianregional.com/media/110096-2.jpg" alt="" style="width:407pt;height:109pt;">
<p><span class="font1" style="font-weight:bold;">Figure 2. </span><span class="font1">The Data Processing Flow</span></p>
<p><span class="font1">Figure 2 depicts the data processing flow. Data processing begins with collecting data about the case study taken, namely the issue of domestic violence. After that, it continued with preprocessing stages such as removing usernames, cleaning, case folding, tokenization stopwords, normalization, stemming, and un-tokenization. Subsequently, two methods of labeling data are manual labeling and automatic labeling using the Vader Lexicon.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1" style="font-weight:bold;">3. &nbsp;&nbsp;&nbsp;Literature Study</span></p></li></ul>
<p><span class="font1">The literature review discusses theories related to writing research reports.</span></p>
<ul style="list-style:none;"><li><a name="caption1"></a>
<h1><a name="bookmark0"></a><span class="font1" style="font-weight:bold;"><a name="bookmark1"></a>3.1. &nbsp;&nbsp;&nbsp;Sentiment Analysis</span></h1></li></ul>
<p><span class="font1">Sentiment Analysis (SA) involves automatically understanding and processing textual data to extract sentiment information from a sentence or text, portraying it as an opinion. The purpose of sentiment analysis is to see the view or opinion of the text related to a problem or object, whether it tends to have a positive or negative view. Sentiment analysis consists of natural language processing, text analysis, and linguistic computing to identify the sentiment of a document [2].</span></p>
<ul style="list-style:none;"><li>
<h1><a name="bookmark2"></a><span class="font1" style="font-weight:bold;"><a name="bookmark3"></a>3.2. &nbsp;&nbsp;&nbsp;Naïve Bayes Classification</span></h1></li></ul>
<p><span class="font1">The Naïve Bayes method is a classification technique used in data analysis and machine learning. This method employs simple probabilities based on Bayes' Theorem allowing us to classify data into different categories. The Naïve Bayes method calculates the probability of each feature or attribute present in the data to determine the likelihood of a specific event or condition occurring [3].</span></p>
<ul style="list-style:none;"><li>
<h1><a name="bookmark4"></a><span class="font1" style="font-weight:bold;"><a name="bookmark5"></a>3.3. &nbsp;&nbsp;&nbsp;Support Vector Machine</span></h1></li></ul>
<p><span class="font1">Support Vector Machine (SVM) is one of the classification methods included in supervised learning and is part of machine learning that follows the principle of Structural Risk Minimization (SRM). SVM aims to achieve the most optimal hyperplane with the optimum margin in the input space to separate each class effectively [4]. SVMs exhibit lower sensitivity to overfitting than other methods, and they can be utilized for prediction and classification, offering an additional advantage [5].</span></p>
<ul style="list-style:none;"><li>
<h1><a name="bookmark6"></a><span class="font1" style="font-weight:bold;"><a name="bookmark7"></a>3.4. &nbsp;&nbsp;&nbsp;Vader Lexicon</span></h1></li></ul>
<p><span class="font1">VADER (Valence Aware Dictionary and Sentiment Reasoner) is a model responsive to negative and positive polarity and emotional intensity used for sentiment analysis. The NLTK toolkit includes the VADER model, which can directly applied to unlabeled text data. Sentiment analysis performed by VADER relies on a dictionary mapping lexical features to sentiment scores. The sentiment score of a text can only be obtained by summing the weights of each word present in the text [6]. For example, if the text contains words like 'like,' 'peaceful,' and 'love,' it will yield a positive sentiment result.</span></p><img src="https://jurnal.harianregional.com/media/110096-3.jpg" alt="" style="width:333pt;height:77pt;">
<p><span class="font1" style="font-weight:bold;">Figure 3. </span><span class="font1">VADER Lexicon Labeling Flow</span></p>
<p><span class="font1">Figure 3 provides a detailed overview of the labeling process using the VADER lexicon system. The data will be translated into English as the VADER Lexicon only supports English texts. The text undergoes a weighting process based on each word present, assessing three weights: negative, neutral, and positive. Additionally, a compound score is calculated by summing the weights of each word in the text and dividing it by the total number of words.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1" style="font-weight:bold;">4. &nbsp;&nbsp;&nbsp;Result and Discussion</span></p></li></ul>
<p><span class="font1">This section contains a discussion about the comparison of the obtained results. The topics covered in this chapter are related to the comparison between manually labeled results and labeling using the Vader lexicon, as well as the comparison of the evaluation results of the MNB and SVM models.</span></p>
<ul style="list-style:none;"><li>
<h1><a name="bookmark8"></a><span class="font1" style="font-weight:bold;"><a name="bookmark9"></a>4.1. &nbsp;&nbsp;&nbsp;Preprocessing Data</span></h1></li></ul>
<h1><a name="bookmark10"></a><span class="font1"><a name="bookmark11"></a>Data preprocessing constitutes a crucial step in the data mining process. It involves cleaning, transforming, and integrating data to prepare it for analysis. The goal of data preprocessing is to enhance data quality and make it more suitable for specific data mining tasks.</span></h1><img src="https://jurnal.harianregional.com/media/110096-4.jpg" alt="" style="width:274pt;height:108pt;">
<p><span class="font1" style="font-weight:bold;">Figure 4. </span><span class="font1">Preprocessing Stages</span></p>
<p><span class="font1">Figure 4 represents the preprocessing stages of the data conducted in this research The resulting forms at each process will be explained in table 1.</span></p>
<p><span class="font1" style="font-weight:bold;">Table 1. </span><span class="font1">Data Preprocessing</span></p>
<table border="1">
<tr><td style="vertical-align:bottom;">
<p><span class="font1" style="font-weight:bold;">Preprocessing Stages</span></p></td><td style="vertical-align:middle;">
<p><span class="font1" style="font-weight:bold;">After</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font1">Raw Data</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">@cintanyaV @tanyarlfes Pisah dong ~ sudah lah g pernah ngasih uang bulanan, kdrt (fisik verbal mental) ,kelakuannya kaya gt pula</span></p>
<p><a href="https://t.co/8Z03l2AewM"><span class="font1">https://t.co/8Z03l2AewM</span></a></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font1">Remove Username</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">Pisah dong ~ sudah lah g pernah ngasih uang bulanan, kdrt (fisik verbal mental) ,kelakuannya kaya gt pula “ </span><a href="https://t.co/8Z03l2AewM"><span class="font1">https://t.co/8Z03l2AewM</span></a></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font1">Cleaning</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">Pisah dong sudah lah pernah ngasih uang bulanan kdrt fisik verbal mental kelakuannya kaya gt pula</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font1">Case Folding</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">pisah dong sudah lah pernah ngasih uang bulanan kdrt fisik verbal mental kelakuannya kaya gt pula</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font1">Tokenisasi</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">['pisah', 'dong', 'sudah', 'lah', 'pernah', 'ngasih', 'uang', 'bulanan', 'kdrt', 'fisik', 'verbal', 'mental', 'kelakuannya', 'kaya', 'gt', 'pula']</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font1">Stopword</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">['pisah', 'ngasih', 'uang', 'bulanan', 'kdrt', 'fisik', 'verbal', 'mental', 'kelakuannya', 'kaya']</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font1">Normalisation</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">['pisah', 'mengasih', 'uang', 'bulanan', 'kdrt', 'fisik', 'verbal', 'mental', 'kelakuannya', 'kayak']</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font1">Stemming</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">['pisah', 'asih', 'uang', 'bulan', 'kdrt', 'fisik', 'verbal', 'mental', 'laku', 'kayak']</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font1">Untokenizing</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">pisah asih uang bulan kdrt fisik verbal mental laku kayak</span></p></td></tr>
</table>
<p><span class="font1">Table 1 illustrates each stage of preprocessing conducted in this research. It begins with raw data and progresses through the removal of usernames, followed by a cleaning process to eliminate emojis and unnecessary symbols. Subsequently, the data undergoes case folding to convert the text into lowercase. The next step involves tokenization, breaking sentences into tokens. Following that is the Stopword stage, which eliminates common words that typically do not provide significant information in text analysis.</span></p>
<p><span class="font1">According to the colloquial-Indonesian-lexicon dictionary, the process then changes to normalization, transforming all slang or non-formal words into formal ones. Next, the data undergoes stemming, a process that removes prefixes and suffixes to obtain the base form of words. After completing all these processes, the data is untokenized, reverting the tokenized form into complete sentences. The final step involves removing duplicate data identified after the preprocessing phase.</span></p>
<ul style="list-style:none;"><li>
<h1><a name="bookmark12"></a><span class="font1" style="font-weight:bold;"><a name="bookmark13"></a>4.2. &nbsp;&nbsp;&nbsp;Wordcloud Data</span></h1></li></ul>
<p><span class="font1">Wordcloud is a visualization of a collection of words within a text, where the size of the words reflects how frequently they appear. In a word cloud, words that appear more frequently will be displayed with a larger size, while words that appear less often will be shown with a smaller size or may not be displayed at all.</span></p>
<div>
<p><span class="font0" style="font-weight:bold;">Wordcloud Data</span></p><img src="https://jurnal.harianregional.com/media/110096-5.jpg" alt="" style="width:234pt;height:156pt;">
<p><span class="font1" style="font-weight:bold;">Figure 5. </span><span class="font1">Data Visualization</span></p>
<p><span class="font1">Figure 5 represents the most frequently occurring words in the data. As observed, the word &quot;KDRT&quot; has the most significant size among other words, indicating its highest frequency in the data. Additionally, words such as &quot;anak&quot; (child) and &quot;suami&quot; (husband) also have substantial sizes, suggesting that in the context of domestic violence (KDRT), discussions often involve topics related to children and husbands.</span></p>
</div><br clear="all">
<ul style="list-style:none;"><li>
<h1><a name="bookmark14"></a><span class="font1" style="font-weight:bold;"><a name="bookmark15"></a>4.3. &nbsp;&nbsp;&nbsp;Manual Labeling</span></h1></li></ul>
<p><span class="font1">Two individuals performed manual labeling after the data underwent preprocessing stages to mitigate subjectivity. They categorized the labeling into two classes: positive labels and negative labels. The following example illustrates data that received manual labeling.</span></p>
<p><span class="font1" style="font-weight:bold;">Table 2. </span><span class="font1">Manual Labeled Data</span></p>
<table border="1">
<tr><td style="vertical-align:top;">
<p><span class="font1" style="font-weight:bold;">No</span></p></td><td style="vertical-align:top;">
<p><span class="font1" style="font-weight:bold;">Tweet</span></p></td><td style="vertical-align:top;">
<p><span class="font1" style="font-weight:bold;">Label</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font1" style="font-weight:bold;">1.</span></p></td><td style="vertical-align:top;">
<p><span class="font1">baru kejadian semalam. Temen kakak gue abis kena kdrt sama suaminya sampe babak belur. Sama kakak gue dibawa ke rumah sakit.</span></p></td><td style="vertical-align:top;">
<p><span class="font1">Negative</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font1" style="font-weight:bold;">2.</span></p></td><td style="vertical-align:top;">
<p><span class="font1">stop kdrt, mari kira budayakan hidup sehat secara jasmani dan rohani</span></p></td><td style="vertical-align:top;">
<p><span class="font1">Positive</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font1" style="font-weight:bold;">3.</span></p></td><td style="vertical-align:top;">
<p><span class="font1">anehhhh, harus banget pdhl bilar dipenjarain, kenapaaa si lestiii..bilar</span></p></td><td style="vertical-align:top;">
<p><span class="font1">Negative</span></p></td></tr>
</table>
<p><span class="font1">tuh udh kdrt in kamuuuu kenapaaa dicabut laporannya</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1" style="font-weight:bold;">4.</span><span class="font1"> &nbsp;&nbsp;&nbsp;kawal kasus kdrt di bogor rpa perindo apresiasi kinerja polisi &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Positive</span></p></li></ul>
<p><span class="font1">Table 2 illustrates an example of text that two individuals manually labeled. Text receives a positive label if it contains many words with positive meanings, as seen in entries 2 and 4 in the table above. Both texts receive a positive label because the words &quot;sehat&quot; (healthy) and &quot;apresiasi&quot; (appreciation) carry high positive weights. Conversely, texts 1 and 3 receive negative labels due to the presence of words like &quot;babak belur&quot; (beaten badly) and &quot;dipenjarain&quot; (imprisoned), which have high negative weights. &quot;As a result, both texts received an unfavorable label.</span></p>
<ul style="list-style:none;"><li>
<h1><a name="bookmark16"></a><span class="font1" style="font-weight:bold;"><a name="bookmark17"></a>4.4. &nbsp;&nbsp;&nbsp;Labeling by Vader Lexicon</span></h1></li></ul>
<p><span class="font1">The labeling process utilizes the Vader Lexicon algorithm, a model designed for sentiment analysis of text sensitive to polarity (negative/positive). The advantage of using VADER in sentiment analysis lies in its ability to expedite the labeling process, which can be time-consuming when done manually. However, the use of VADER also comes with limitations. The lexicon does not encompass slang or colloquial language commonly used in social media. If the Vader Lexicon does not recognize a word in the text, it may lead to a lack of</span></p>
<p><span class="font1">understanding of the overall context, resulting in labeling errors. Additionally, applying the VADER Lexicon is limited to English-language texts, requiring data translation into English before analysis. Language differences can introduce errors, potentially causing misunderstandings of context.</span></p>
<p><span class="font1" style="font-weight:bold;">Table 3. </span><span class="font1">Data with Vader Lexicon Labels</span></p>
<table border="1">
<tr><td style="vertical-align:bottom;">
<p><span class="font1" style="font-weight:bold;">No.</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1" style="font-weight:bold;">Tweet</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1" style="font-weight:bold;">Scores</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1" style="font-weight:bold;">Compound</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1" style="font-weight:bold;">Sentiment</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font1" style="font-weight:bold;">1.</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">syukuri nder rezeki langgeng tidak selalu hahahihi selama tidak pisah tidak selingkuh tidak kdrt sampai maut memisahkan keluargamu bumbunya lumayan pedas selama tidak mules nikmati aja</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">{'neg': 0.233, 'neu': 0.652, 'pos': 0.115}</span></p></td><td style="vertical-align:top;">
<p><span class="font1">-0,5859</span></p></td><td style="vertical-align:top;">
<p><span class="font1">Negative</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font1" style="font-weight:bold;">2.</span></p></td><td style="vertical-align:top;">
<p><span class="font1">tukang selingkuh kalo gak kdrt meriang kali ya</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">{'neg': 0.315, 'neu': 0.326, 'pos': 0.359}</span></p></td><td style="vertical-align:top;">
<p><span class="font1">0,1027</span></p></td><td style="vertical-align:top;">
<p><span class="font1">Positive</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font1" style="font-weight:bold;">3.</span></p></td><td style="vertical-align:top;">
<p><span class="font1">sharing is caring namun aku berdoa semoga tidak ada lagi yang menjadi korban kdrt</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">{'neg': 0.39, 'neu': 0.244, 'pos': 0.366}</span></p></td><td style="vertical-align:top;">
<p><span class="font1">-0,1027</span></p></td><td style="vertical-align:top;">
<p><span class="font1">Negative</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font1" style="font-weight:bold;">4.</span></p></td><td style="vertical-align:top;">
<p><span class="font1">temenku nikah sama orang sholih eh taunya kdrt</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">{'neg': 0.0, 'neu':</span></p>
<p><span class="font1">0.714,</span></p>
<p><span class="font1">'pos':</span></p>
<p><span class="font1">0.286}</span></p></td><td style="vertical-align:top;">
<p><span class="font1">0,4939</span></p></td><td style="vertical-align:top;">
<p><span class="font1">Positive</span></p></td></tr>
</table>
<p><span class="font1">Table 3 illustrates an example of text labeled using the VADER Lexicon. Data labeled with VADER results in two types of assessments: scores and compound. There are three types of sentiments—negative, neutral, and positive. Meanwhile, the compound represents the overall sentiment value of the analyzed text. This compound score encompasses all aspects of sentiment (negative, neutral, and positive) and provides an overall overview of the sentiment expressed in the entire text.</span></p>
<ul style="list-style:none;"><li>
<h1><a name="bookmark18"></a><span class="font1" style="font-weight:bold;"><a name="bookmark19"></a>4.5. &nbsp;&nbsp;&nbsp;The Comparison of Manual Labeling and Vader Lexicon Labeling</span></h1></li></ul>
<p><span class="font1">The manual labeling process, relying on human judgment, differs from labeling using the VADER Lexicon algorithm. Differences in sentiment assessment in text can arise due to the subjective approach in manual labeling, whereas VADER Lexicon provides an automatic approach. Thus, these different labeling methods can result in variations in the sentiment assessment of a text.</span></p>
<p><span class="font1" style="font-weight:bold;">Table 4. Comparison of Label Results</span></p>
<table border="1">
<tr><td style="vertical-align:bottom;">
<p><span class="font1" style="font-weight:bold;">No.</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1" style="font-weight:bold;">Tweet</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1" style="font-weight:bold;">Label Manual</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1" style="font-weight:bold;">Vader Lexicon</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font1" style="font-weight:bold;">1.</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">jangan percaya sama orang yang suka kdrt tiba bersujud gini bokap juga dulu gini tapi tetep aja ngulang lagi apalagi nangis sambil divideoin</span></p></td><td style="vertical-align:top;">
<p><span class="font1">Negative</span></p></td><td style="vertical-align:top;">
<p><span class="font1">Positive</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font1" style="font-weight:bold;">2.</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">ada lo cewek yang dijodohin ortu trus sampe kejadian kdrt bubar terus mau nikah lagi tetep dijodohin gak boleh sama yang disukai cuma gara alisnya si cowok gak disukain ibunya</span></p></td><td style="vertical-align:top;">
<p><span class="font1">Negative</span></p></td><td style="vertical-align:top;">
<p><span class="font1">Positive</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font1" style="font-weight:bold;">3.</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">salah satu cita cita ku adlh punya rumah perlindungan buat para korban</span></p></td><td style="vertical-align:top;">
<p><span class="font1">Positive</span></p></td><td style="vertical-align:top;">
<p><span class="font1">Negative</span></p></td></tr>
</table>
<p><span class="font1">KDRT yg kabur dr rumah biar mereka gak homeless buat para korban, semangat ya</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1" style="font-weight:bold;">4.</span><span class="font1"> &nbsp;&nbsp;&nbsp;Nih ya soal isu KDRT, dukungan dari Positive &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Negative</span></p></li></ul>
<p><span class="font1">komunitas dan LSM itu banget penting.</span></p>
<p><span class="font1">Mereka biasanya kasih support buat</span></p>
<p><span class="font1">korban KDRT.</span></p>
<p><span class="font1">Table 4 illustrates texts that obtained different labels through two applied labeling methods. In addition to differences in assessment approaches, another factor contributing to variations in labeling results is that VADER Lexicon labels text in English. This condition introduces the potential for differences in text interpretation due to language disparities and nuances that may influence the final labeling outcome.</span></p>
<ul style="list-style:none;"><li>
<h1><a name="bookmark20"></a><span class="font1" style="font-weight:bold;"><a name="bookmark21"></a>4.6. &nbsp;&nbsp;&nbsp;Comparison of Manual Data</span></h1></li></ul>
<p><span class="font1">Applying manually labeled data generated from the preprocessing stage involves the process; the model testing phase involves applying Naive Bayes and Support Vector Machine (SVM) algorithms to determine the best model. The evaluation considers the best model with the highest accuracy, and the testing process commences by splitting the data into training and test sets.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark22"></a><span class="font1" style="font-weight:bold;"><a name="bookmark23"></a>4.6.1 &nbsp;&nbsp;&nbsp;Test Result of Manual Data</span></h2></li></ul>
<p><span class="font1">This study divided the data into three different schemes, specifically with ratios of 80:20 70:30, and 60:40. Subsequently, the data splitting process was applied to the Multinomial Naïve Bayes and Support Vector Machine. Through implementing various data splits and using two different algorithms, the goal is to evaluate the performance and responsiveness of the algorithms to the variation in data splitting ratios.</span></p>
<div><img src="https://jurnal.harianregional.com/media/110096-6.jpg" alt="" style="width:159pt;height:132pt;">
<p><span class="font1" style="font-weight:bold;">Figure 6. </span><span class="font1">Confusion Matrix of Manual Data</span></p>
<p><span class="font1">Figure 6 illustrates a visualization of the confusion matrix for both models used. The algorithms attained the highest accuracy at the same data ratio of 80:20, signifying their utilization of only 20% of the total data for testing. For the Multinomial Naïve Bayes algorithm there were 672 True Negatives (TN), 33 True Positives (TP), 10 False Positives (FP), and 286 False Negatives (FN). Meanwhile, for the Support Vector Machine algorithm, there were 634 True Negatives (TN), 101 True Positives (TP), 48 False Positives (FP), and 218 False Negatives (FN).</span></p>
</div><br clear="all">
<div><img src="https://jurnal.harianregional.com/media/110096-7.jpg" alt="" style="width:159pt;height:132pt;">
</div><br clear="all">
<table border="1">
<tr><td colspan="8" style="vertical-align:top;">
<p><span class="font1" style="font-weight:bold;">Table 5. Manual Label Data Evaluation Results</span></p></td></tr>
<tr><td rowspan="2" style="vertical-align:middle;">
<p><span class="font1" style="font-weight:bold;">Train:Test</span></p></td><td colspan="3" style="vertical-align:bottom;">
<p><span class="font1" style="font-weight:bold;">Multinomial Naïve Bayes</span></p></td><td colspan="4" style="vertical-align:bottom;">
<p><span class="font1" style="font-weight:bold;">Support Vector Machine</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font1">Accuracy Precision</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">Recall</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">F1-Score</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">Accuracy</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">Precision</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">Recall</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">F1-Score</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font1" style="font-weight:bold;">80:20</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">70% &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;73%</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">54%</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">50%</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">73%</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">71%</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">62%</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">63%</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font1" style="font-weight:bold;">70:30</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">69% &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;67%</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">52%</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">46%</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">72%</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">69%</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">59%</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">58%</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font1" style="font-weight:bold;">60:40</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">69% &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;72%</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">53%</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">47%</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">72%</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">71%</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">60%</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">59%</span></p></td></tr>
</table>
<p><span class="font1">Table 5 presents the results from the two algorithms employed in this study. The Multinomial Naïve Bayes algorithm exhibited its best performance at a data ratio of 80:20 utilizing 80% of the data for training and 20% for testing. Similarly, the Support Vector Machine algorithm showed optimal performance at a data ratio 80:20.</span></p>
<ul style="list-style:none;"><li>
<h1><a name="bookmark24"></a><span class="font1" style="font-weight:bold;"><a name="bookmark25"></a>4.7. &nbsp;&nbsp;&nbsp;Comparison of Vader Lexicon Data</span></h1></li></ul>
<p><span class="font1">During the model testing phase, the VADER Lexicon labels the data. Following this, the Multinomial Naive Bayes and Support Vector Machine (SVM) algorithms perform classification to identify the best model. The model with the highest accuracy is deemed the best during this phase, and the testing process starts by splitting the data into training and test sets.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark26"></a><span class="font1" style="font-weight:bold;"><a name="bookmark27"></a>4.7.1 &nbsp;&nbsp;&nbsp;Test Results of Vader Lexicon Data</span></h2></li></ul>
<p><span class="font1">This segment employs a comparable data division, reflecting the manual data ratios of 80:20, 70:30, and 60:40. Following that, the two algorithms, Multinomial Naïve Bayes and Support Vector Machine, undergo the data splitting process.</span></p>
<p><span class="font1" style="font-weight:bold;">Table 6. </span><span class="font1">Vader Lexicon Data Evaluation Results</span></p>
<table border="1">
<tr><td rowspan="2" style="vertical-align:middle;">
<p><span class="font1" style="font-weight:bold;">Train:Test</span></p></td><td colspan="4" style="vertical-align:bottom;">
<p><span class="font1" style="font-weight:bold;">Multinomial Naïve Bayes</span></p></td><td colspan="4" style="vertical-align:bottom;">
<p><span class="font1" style="font-weight:bold;">Support Vector Machine</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font1">Accuracy</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">Precision</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">Recall</span></p></td><td style="vertical-align:top;">
<p><span class="font1">F1-Score</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">Accuracy</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">Precision</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">Recall</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">F1-Scor e</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font1" style="font-weight:bold;">80:20</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">66%</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">71%</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">61%</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">58%</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">74%</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">74%</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">72%</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">73%</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font1" style="font-weight:bold;">70:30</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">67%</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">73%</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">61%</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">59%</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">74%</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">74%</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">72%</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">73%</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font1" style="font-weight:bold;">60:40</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">68%</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">74%</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">63%</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">61%</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">76%</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">75%</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">74%</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">74%</span></p></td></tr>
</table>
<p><span class="font1">Table 6 shows the results of both algorithms using data labeled with the Vader Lexicon employed in this study. The Multinomial Naïve Bayes algorithm exhibited its best performance at the 60:40 data ratio, utilizing 60% of the data for training and 40% for testing, resulting in the highest accuracy of 68%. Similarly, the Support Vector Machine algorithm achieved its best performance at the 60:40 data ratio, yielding the highest accuracy of 76%.</span></p>
<div><img src="https://jurnal.harianregional.com/media/110096-8.jpg" alt="" style="width:176pt;height:146pt;">
<p><span class="font1" style="font-weight:bold;">Figure 7. </span><span class="font1">Confusion Matrix of Vader Lexicon Data</span></p>
<p><span class="font1">Figure 7 presents a visualization of the confusion matrix for both utilized models. The algorithms attained their highest accuracy at the same data ratio of 60:40, signifying the utilization of only 40% of the data for testing. For the Multinomial Naïve Bayes algorithm, there were 1122 True Negatives (TN), 246 True Positives (TP), 52 False Positives (FP), and 581 False Negatives (FN). Meanwhile, for the Support Vector Machine algorithm, there were 988 True Negatives (TN), 524 True Positives (TP), 186 False Positives (FP), and 303 False Negatives (FN).</span></p>
</div><br clear="all">
<div><img src="https://jurnal.harianregional.com/media/110096-9.jpg" alt="" style="width:176pt;height:146pt;">
</div><br clear="all">
<ul style="list-style:none;"><li>
<p><span class="font1" style="font-weight:bold;">5. &nbsp;&nbsp;&nbsp;Conclusion</span></p></li></ul>
<p><span class="font1">Several conclusions can be drawn from the research results regarding Sentiment Analysis on the issue of Domestic Violence on Twitter using the Naïve Bayes Classifier Algorithm. Firstly, observing and analyzing Twitter users' opinions on the issue of Domestic Violence in Indonesia, and the classification of sentiment in tweet data, can be carried out through several steps, including data collection, preprocessing, sentiment classification, and result analysis.</span></p>
<p><span class="font1">Furthermore, utilizing two labeling methods and two algorithms (SVM and Multinomial Naïve Bayes) yielded the following results. For both algorithms tested with manually labeled data, the highest accuracy was achieved at a ratio of 80:20. In the Multinomial Naïve Bayes algorithm with manual labels, the highest accuracy reached 70%. In contrast, in the Support Vector Machine (SVM) algorithm with manual labels, the highest accuracy reached 73%.</span></p>
<p><span class="font1">Meanwhile, for both algorithms tested using data labeled with Vader Lexicon, the highest accuracy was found at a ratio of 60:40. The highest accuracy for the Multinomial Naïve Bayes algorithm with Vader Lexicon labels reached 68%. For the SVM algorithm with Vader Lexicon labels, it reached 76%.</span></p>
<p><span class="font1" style="font-weight:bold;">References</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1">[1] &nbsp;&nbsp;&nbsp;K. Perempuan, &quot;CATATAN KEKERASAN TERHADAP PEREMPUAN TAHUN 2020,&quot; Komnas Perempuan, 2021.</span></p></li>
<li>
<p><span class="font1">[2] &nbsp;&nbsp;&nbsp;G. Vinodhini and R. Chandrasekaran, &quot;Sentiment Analysis and Opinion Mining: A Survey,&quot; </span><span class="font1" style="font-style:italic;">International Journal of Advanced Research in Computer Science and Software Engineering,</span><span class="font1"> 2012.</span></p></li>
<li>
<p><span class="font1">[3] &nbsp;&nbsp;&nbsp;F. V. Sari and A. Wibowo, &quot;Analisis Sentimen Pelanggan Toko Online JD.ID Menggunakan Metode Naive Bayes Classifier Berbasis Konversi Ikon Emoji,&quot; </span><span class="font1" style="font-style:italic;">Jurnal Simetris,</span><span class="font1"> 2019.</span></p></li>
<li>
<p><span class="font1">[4] &nbsp;&nbsp;&nbsp;F. Maylani, Sriyanto and Nosiel, &quot;Implementasi Metode Data Mining untuk Memprediksi Warna Anak Kucing Pada Proses Pengembangbiakan Kucing Ras Menggunakan Algoritma SVM.,&quot; </span><span class="font1" style="font-style:italic;">Seminar Nasional Hasil Penelitian dan Pengabdian Masyarakat,</span><span class="font1"> 2021.</span></p></li>
<li>
<p><span class="font1">[5] &nbsp;&nbsp;&nbsp;A. Beri, &quot;Analisis Sentimental Menggunakan Vader,&quot; Medium, 28 May 2020. [Online]. Available: </span><a href="https://towardsdatascience.com/sentimental-analysis-using-vader-a3415fef7664"><span class="font1">https://towardsdatascience.com/sentimental-analysis-using-vader-a3415fef7664</span></a><span class="font1">. [Accessed 2023].</span></p></li>
<li>
<p><span class="font1">[6] &nbsp;&nbsp;&nbsp;N. Wardhani, Rezkiani and dkk, &quot;Sentiment Analysis Article News Coordinator Minister of Maritime Affairs Using Algorithm Naive Bayes and Support Vector Machine with Particle Swarm Optimization,&quot; </span><span class="font1" style="font-style:italic;">Journal of Theoretical and Applied Information Technology,</span><span class="font1"> 2018.</span></p></li></ul>