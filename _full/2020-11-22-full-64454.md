---
layout: full_article
title: "Quantization-Based Novel Extraction Method Of EEG Signal For Classification"
author: "Ni Putu Dewi Angreni, Agus Muliantara, Yuriko Christian"
categories: jik
canonical_url: https://jurnal.harianregional.com/jik/full-64454 
citation_abstract_html_url: "https://jurnal.harianregional.com/jik/id-64454"
citation_pdf_url: "https://jurnal.harianregional.com/jik/full-64454"  
comments: true
---

<p><span class="font2">p-ISSN: 2301-5373</span></p>
<p><span class="font2">e-ISSN: 2654-5101</span></p>
<p><span class="font2">Jurnal Elektronik Ilmu Komputer Udayana</span></p>
<p><span class="font2">Volume 9 No. 2, November 2020</span></p><a name="caption1"></a>
<h1><a name="bookmark0"></a><span class="font4" style="font-weight:bold;"><a name="bookmark1"></a>Quantization-Based Novel Extraction Method of EEG Signal for Classification</span></h1>
<p><span class="font2">Ni Putu Dewi Angreni<sup>a1</sup></span><span class="font2" style="font-weight:bold;">, </span><span class="font2">Agus Muliantara<sup>a2</sup>, Yuriko Christian<sup>a3</sup></span></p>
<p><span class="font2"><sup>a</sup>Informatics Department, Udayana University</span></p>
<p><span class="font2">Bali, Indonesia </span><a href="mailto:1angrenidewii13@gmail.com"><span class="font2"><sup>1</sup>angrenidewii13@gmail.com</span></a><span class="font2"> </span><a href="mailto:2muliantara@unud.ac.id"><span class="font2"><sup>2</sup>muliantara@unud.ac.id</span></a><span class="font2"> </span><a href="mailto:3yurikochristian@gmail.com"><span class="font2"><sup>3</sup>yurikochristian@gmail.com</span></a></p>
<p><span class="font2" style="font-weight:bold;font-style:italic;">Abstract</span></p>
<p><span class="font2" style="font-style:italic;">In the pattern recognition field, features or objectâ€™s characteristics are one of the key points to recognizing them. The feature extraction process will see that objects have different features, where the features are obtained through the analysis process from the extractor, such as for data statistics, energy, power spectral, and so on. This study aims to enrich the point of view of EEG signal features by quantifying the signal. It will be analyzed whether the features obtained by quantization represent the EEG signal object from different viewpoints. This research uses the DEAP dataset, with the result being a feature vector that will be included in the artificial neural network classifier using the Keras library. The experiment carried out is to try to enter quantized and Non-quantized feature vectors into the classifier. As a result, the accuracy of the classification process with the quantization vector was 75%, and the accuracy in the Nonquantized vector classification process was only 58%. These results indicate the EEG signal quantization feature can represent the EEG signal object.</span></p>
<p><span class="font2" style="font-weight:bold;font-style:italic;">Keywords: </span><span class="font2" style="font-style:italic;">EEG signal, quantization, DEAP, feature extraction, pattern recognition</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark2"></a><span class="font2" style="font-weight:bold;"><a name="bookmark3"></a>1. &nbsp;&nbsp;&nbsp;Introduction</span></h2></li></ul>
<p><span class="font2">Machine Learning (ML) or machine learning is an approach in Artificial Intelligence that is widely used to replace or mimic human behavior to solve problems or automate. In the Machine Learning area, generally, the data used as input in the machine is a feature that can represent or represent an object in the process of classifying the object itself. The classification itself is a method in machine learning that is used by machines to sort or classify objects based on certain characteristics [1]. An object certainly has different characteristics or features when viewed from the process of getting the features or features it has. That way, the detection of an object can not only be seen from one point of view or one feature, but also from another point of view. To detect an object in more detail requires a lot of features. The more the number of features, the more complex and detailed the features will be so that it has an impact on classification.</span></p>
<p><span class="font2">The features of an object are obtained through the feature extraction process which is the process of analyzing the object from a certain point of view, for example from data statistics, changes in frequency from time to time, energy, zero-crossing rate (ZCR), pitch, spectral power and so on [2]. One of the efforts that can be made to enrich the object's features is through a process known as quantization. The general use of quantization is for the conversion of a continuous signal into a discrete signal in the digitization process through a device called an analog-to-digital converter (ADC), where an analog or continuous signal will go through 3 processes consisting of sampling, quantization, and coding. A continuous or analog time signal is interpreted at each time value and taken for the values in a continuous-time interval. Meanwhile, discrete or digital time signals are interpreted only at specific time values and are usually taken at the same time intervals [3]. The quantization process is the process of rounding data values into certain predetermined numbers. The more levels used, the more accurate signal data is stored. However, this will result in large data sizes and a long process.</span></p>
<p><span class="font2">Meanwhile, the coding process provides a code for each quantized signal data based on the occupied level [4].</span></p>
<p><span class="font2">The object of research in this study is the brain wave signal which is commonly known as signal EEG. The EEG signal data used is a secondary dataset, namely the DEAP dataset<sup>1</sup>. The DEAP dataset consists of recorded EEG data from 32 research subjects with a stimulant in the form of 40 music videos given to subjects in each experiment. EEG signal data recording refers to the international system standard 10-20 by using 32 channels. EEG signal itself is one of the biosignals produced by neurons in the brain and transmitted through the surface of the human scalp and can be used to analyze epileptic diseases, sleep disorders, brain paralysis, or emotions. EEG refers to the recording of the brain's spontaneous electrical activity over a short period, usually 20-40 minutes via electrodes attached to a part of the cortex of a person's head [5].</span></p>
<p><span class="font2">In previous research, several studies have been carried out related to the feature extraction of EEG signals from various perspectives. One of them is a study related to feature extraction of EEG signals by performing statistical analysis of signal data to find out signal information that can distinguish signals from one another. There are several statistical features used in this study, namely the peak to peak value, the average value of the amplitude, the mean value of the amplitude, the standard deviation, skewness, kurtosis, the absolute average value of the first and second derivatives, and the normalized value of the mean. These static features are taken from each channel that has been previously selected which is the characteristic of each signal to be clustered [6]. Then, in other studies, EEG signal feature extraction using power spectral was carried out with the consideration that the power spectral can provide information for each frequency from the data processed into the system, where previously the data was still in the time domain. Another consideration is that spectral power provides a faster computation time for real-time identification. [7]</span></p>
<p><span class="font2">Based on the background and previous studies, the focus of this study that distinguishes it from previous studies is that in this study, a feature extraction analysis study of EEG signals was carried out from a new perspective, namely, signal quantization. The purpose of this study is to analyze whether the EEG signal features obtained based on signal quantization can represent the EEG signal itself from different points of view. The EEG signal will be analyzed through its features based on the quantization of the signal that has been successfully implemented. The output of this research is in the form of feature or feature vectors resulting from the quantization process, where the feature vectors will then go through the classification process. This classification acts as a method of evaluating the quantization output using the Neural Network classifier which is implemented with the Keras library. In this process, there are two experiments, namely comparing the classification of the quantization feature vector with the feature vector without quantization. Then the accuracy of each experiment will be sought to determine which experiment gives better performance in the classification process.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark4"></a><span class="font2" style="font-weight:bold;"><a name="bookmark5"></a>2. &nbsp;&nbsp;&nbsp;Research Method</span></h2></li></ul>
<p><span class="font2">This research is divided into several stages including literature study, data collection, feature extraction, classification, and system evaluation. At the literature study stage, the authors search, collect, learn, and understand the information and literature needed in making and implementing research. Furthermore, the data used in this study are secondary data, namely EEG signal data to analyze emotions obtained from the DEAP Dataset. DEAP Dataset is a multi-modal dataset for the analysis of human affective states. The initial stage through which the EEG signal data is passed is a normalization of the Min-Max data. Then, the next stage is the main stage in this research, namely feature extraction which includes the process of frame blocking, windowing, and quantization of the EEG signal to obtain features from different points of view. Furthermore, the feature extraction output is classified. Then, the final stage in the research is an evaluation to calculate the correct results in the study and get an accuracy value. The following is a general EEG signal quantization research design:</span></p><img src="https://jurnal.harianregional.com/media/64454-1.jpg" alt="" style="width:415pt;height:104pt;">
<p><span class="font2" style="font-weight:bold;">Figure 1. </span><span class="font2">Research Design Flowchart</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark6"></a><span class="font2" style="font-weight:bold;"><a name="bookmark7"></a>2.1 &nbsp;&nbsp;&nbsp;Literature Study</span></h2></li></ul>
<p><span class="font2">At this stage, the writer searches to collect, learn, and understand the information and literature needed in making and implementing research. Information and literature are obtained from book literature and other related information sources.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark8"></a><span class="font2" style="font-weight:bold;"><a name="bookmark9"></a>2.2 &nbsp;&nbsp;&nbsp;Data Collection</span></h2></li></ul>
<p><span class="font2">In this study, the EEG signal dataset used is a dataset that has gone through the Python version of the preprocessing stage, where the EEG signal data has been down-sampled to 128 Hz, the artifacts have been removed, and so on.</span></p>
<p><span class="font2">There are 40 channels in this dataset where channels 1-32 are channels for EEG signals placed based on the international system 10-20, and channels 33-40 are data signals for hEOG, vEOG, zEMG, tEMG, GSR, respiration belt, Plethysmograph and. In this study, the authors only use EEG signal recording, namely data signals on channels 1-32 and ignore signals that are not EEG signals. A file with a .dat extension representing one research subject from a total of 32 .dat files will be extracted into 40 CSV files. The number of CSV files is a representation of the number of trials when recording an EEG signal. Then in each trial, there are 40 channel rows used in the dataset and 8064 data sample columns.</span></p>
<p><span class="font2" style="font-weight:bold;">Table 1. </span><span class="font2">DEAP Dataset Content</span></p>
<table border="1">
<tr><td style="vertical-align:bottom;">
<p><span class="font2" style="font-weight:bold;">No</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2" style="font-weight:bold;">Category</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2" style="font-weight:bold;">Value</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2">1</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">Subject</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">32</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2">2</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">Video</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">40 Video</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font2">3</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">Rating Scale</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2" style="font-style:italic;">Arousal, Valence, Dominance, Liking</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2">4</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">Rating Value</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2" style="font-style:italic;">Value scale 1-9</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font2">5</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">Recorded Signals</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">Peripheral physiological signals, Face video (on 22 subjects)</span></p></td></tr>
</table>
<ul style="list-style:none;"><li>
<p><span class="font2" style="font-weight:bold;">2.3 &nbsp;&nbsp;&nbsp;Feature Extraction</span></p>
<ul style="list-style:none;">
<li>
<p><span class="font2" style="font-weight:bold;font-style:italic;">2.3.1 &nbsp;&nbsp;&nbsp;Frame Blocking</span></p></li></ul></li></ul>
<p><span class="font2">The first step carried out in the feature extraction series is frame blocking where the signal is divided into several frames. Each frame contains signal points according to the frame length. The frame length that is usually used for signal processing is between 10-30 ms. Besides, this process is generally done in an overlapping manner for each frame. The overlap length that is commonly used is approximately 30% - 50% of the frame length. Overlapping is done to avoid losing the characteristics of the signal at the intersection of each frame.</span></p>
<p><span class="font2">To calculate the frame blocking process with overlap, the following formula is used.</span></p>
<p><span class="font7" style="font-style:italic;">y(ri)</span><span class="font7"> = </span><span class="font7" style="font-style:italic;">x(n + M')</span><span class="font2"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1)</span></p>
<p><span class="font2">where :</span></p>
<p><span class="font2">M &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;= overlapping frames obtained from multiplying the amount of data with the</span></p>
<p><span class="font2">length of the frame</span></p>
<p><span class="font2">N &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;= number of data</span></p>
<ul style="list-style:none;"><li>
<p><span class="font2">n &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;= data index</span></p></li></ul>
<p><span class="font2">x (n + M) = the value of the recorded signal</span></p>
<p><span class="font2">y (n) &nbsp;&nbsp;&nbsp;&nbsp;= the result of frame blocking.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font2" style="font-weight:bold;font-style:italic;">2.3.2 &nbsp;&nbsp;&nbsp;Windowing</span></p></li></ul>
<p><span class="font2">The next step taken with the EEG signal before entering the main quantization stage is windowing. There are several types of window functions, but the most commonly used is the Hamming window. The Hamming window function is as follows.</span></p>
<p><span class="font7">w(n)= 0.54 - 0.64 </span><span class="font7" style="font-style:italic;">cos(^</span><span class="font6" style="font-style:italic;">^^</span><span class="font7" style="font-style:italic;">) ,0â‰¤nâ‰¤N-1</span><span class="font2"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(2)</span></p>
<p><span class="font2">The output representation of the window function for the input signal is:</span></p>
<p><span class="font7" style="font-style:italic;">y(n) = x(ri).w(ri),0 â‰¤n â‰¤N â€”1</span><span class="font2"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(3)</span></p>
<p><span class="font2">where :</span></p>
<p><span class="font2">N &nbsp;&nbsp;&nbsp;= the duration (in sample units) for each frame or frame length</span></p>
<p><span class="font2">y (n) = the windowing signal sample value</span></p>
<ul style="list-style:none;"><li>
<p><span class="font2">w (n) = the Hamming window function and x (n) is the sample value from the signal</span></p></li></ul>
<p><span class="font2">frame to-i.</span></p>
<p><span class="font2">In this study, after obtaining the Hamming window results on the EEG signal, then the calculation of the average value of the sample frame is carried out using the following equation.</span></p>
<p><span class="font7" style="font-style:italic;">y(k) = </span><span class="font6" style="font-style:italic;">)</span><span class="font7" style="font-style:italic;">âˆ‘</span><span class="font6" style="font-style:italic;">l-o</span><span class="font7" style="font-style:italic;">Xâˆ–k,Î¹âˆ–</span><span class="font2"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(4)</span></p>
<p><span class="font2">where :</span></p>
<p><span class="font2">y (k) &nbsp;&nbsp;= the average sample frame</span></p>
<p><span class="font2">l &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;= the frame length</span></p>
<p><span class="font2">x [k, i] = every ith sample of k frame.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font2" style="font-weight:bold;">2.3.3 Quantization</span></p></li></ul>
<p><span class="font2">Then, the next step that the EEG signal goes through is quantization. The quantization process converts a continuous signal </span><span class="font2" style="font-style:italic;">x(n)</span><span class="font2"> into a discrete signal </span><span class="font2" style="font-style:italic;">x</span><span class="font0" style="font-style:italic;">q</span><span class="font2" style="font-style:italic;">(n)</span><span class="font2">, which is used to represent </span><span class="font2" style="font-style:italic;">x(n)</span><span class="font2">. The quantization mathematical equation is as follows.</span></p>
<p><span class="font7" style="font-style:italic;">X</span><span class="font6" style="font-style:italic;">q</span><span class="font7" style="font-style:italic;">(n) = Q[x(n))</span><span class="font2"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(5)</span></p>
<p><span class="font2">where :</span></p>
<p><span class="font2" style="font-style:italic;">Q</span><span class="font2"> &nbsp;&nbsp;&nbsp;= the quantization process</span></p>
<p><span class="font2" style="font-style:italic;">x</span><span class="font0" style="font-style:italic;">q</span><span class="font2" style="font-style:italic;">(n)</span><span class="font2"> = the quantized signal (discrete-valued).</span></p>
<p><span class="font2">There are two ways in the quantization process, namely rounding and truncation. The way of rounding changes the value of each data to the nearest number. Meanwhile, the truncation method will change the value of each data to the smallest number value.</span></p>
<p><span class="font2">As for the EEG case in this study, the quantization equation used is as follows.</span></p>
<p><a href="#bookmark10"><span class="font7">-1â‰¥y(k)&gt;0.5 ,-1</span></a></p>
<div>
<p><span class="font7" style="font-style:italic;">y<sub>q</sub>(k)</span><span class="font7"> =</span></p>
</div><br clear="all">
<p><a href="#bookmark11"><span class="font7">-0.5 â‰¥ y(k) &gt;0,- 0.5</span></a></p>
<p><a href="#bookmark12"><span class="font7">0 â‰¥ y(k) </span><span class="font7" style="font-style:italic;">&gt;</span><span class="font7">&nbsp;0.5, &nbsp;&nbsp;0.5 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="font3"><sup>(6)</sup></span></a></p>
<p><a href="#bookmark13"><span class="font7">0.5 â‰¥ y(k) â‰¥ 1 ,1</span></a></p>
<p><span class="font2">As seen in the equation above, to obtain the quantization value of the EEG signal four conditions refer to the y (k) value or the average sample frame value, where later the value of y (k) will fulfill one of the four conditions. Determine the four conditions in the equation because in this case the quantization level is divided into 4 levels.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font2" style="font-weight:bold;">2.4 &nbsp;&nbsp;&nbsp;Classification</span></p></li></ul>
<p><span class="font2">The result of the feature extraction process which is a quantization feature will go through the classification process. For the estimated feature vector classification, the authors rely on the Neural Network classifier which is implemented using the Keras library.</span></p>
<p><span class="font2">There are two ways to classify emotions based on EEG signals, namely by selecting several channels based on predetermined criteria or by using all available channels. In signal processing, it is necessary to reduce the number of channels used because a large number of channels take a lot of time and makes data analysis difficult. By selecting certain channels, the computational load required for data analysis and features used is reduced, thereby minimizing computation for feature extraction and classification processes. Taking these things into account, the authors chose channel F8 from a total of 32 EEG signals to obtain the required features. The selection of channel F8 is based on the location of the channel close to emotional impulses [8].</span></p>
<p><span class="font2">In this process, the feature vectors obtained from processing the EEG signal data of one of the research subjects are included in the classifier to classify two types of emotions, namely positive emotions and negative emotions from the liking label on the DEAP dataset. Liking data from subjects in the dataset is numerical data with a scale of values from 1 to 9. Each research subject has 40 liking data according to the number of trials on the DEAP dataset. The determination of the value of positive and negative emotions is carried out by normalizing the liking value. After that, the search for the average value is carried out, where the result of this average value becomes the limit for determining the positive and negative values of emotions.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font2" style="font-weight:bold;">2.5 &nbsp;&nbsp;&nbsp;Evaluation</span></p></li></ul>
<p><span class="font2">Evaluation is carried out to get an accuracy value which reflects how well the system has been made. In this research, the accuracy value will be used by using the equation:</span></p>
<p><span class="font7">P= </span><span class="font6">b </span><span class="font7">x 100% &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="font2">(7)</span></p>
<p><span class="font2">where :</span></p>
<ul style="list-style:none;"><li>
<p><span class="font2">P = the level of accuracy</span></p></li>
<li>
<p><span class="font2">b = the number of correct data</span></p></li>
<li>
<p><span class="font2">n = the total data.</span></p></li></ul>
<p><span class="font2">By obtaining a P-value, it can be stated that if the P-value is greater, the system will be better and vice versa if the P-value is getting smaller, the system cannot recognize the emotion well.</span></p><img src="https://jurnal.harianregional.com/media/64454-2.jpg" alt="" style="width:258pt;height:130pt;">
<p><span class="font2" style="font-weight:bold;">Figure 2. </span><span class="font2">1st Subjectâ€™s EEG Signal</span></p>
<p><span class="font2">This research was conducted by inputting EEG signal data into the system and then carrying out the Min-Max normalization process. Normalization is the process of scaling the attribute values of data so that they can lie within a certain range. With this normalization, the comparison value of data before or after processing becomes balanced or standardized. Then the output from this process will enter the frame blocking stage.</span></p>
<p><span class="font2">Frame blocking itself is the initial stage of the feature extraction process in this study. In frame blocking, EEG data which is the output of the normalization process is divided into 125 frames containing signal points with a frame length of 64. The length of the overlap area used in this study is half of the frame length.</span></p>
<p><span class="font2">The next step in the feature extraction series is windowing the frame blocking results using the Hamming window function. Then, after the Hamming window results are obtained for the EEG sample, the average value of the sample frame will be calculated. Then, the EEG data goes through the main stage of the feature extraction series, namely quantization. In this quantization stage, new feature vectors will be generated from the EEG signal. The following is the form of an EEG signal that has been quantized and without quantization.</span></p><img src="https://jurnal.harianregional.com/media/64454-3.jpg" alt="" style="width:381pt;height:126pt;">
<p><span class="font1" style="font-weight:bold;">O &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;50 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;IOO &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;150 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;200 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;250</span></p>
<p><span class="font2" style="font-weight:bold;">Figure 3. </span><span class="font2">1â€™st Subject EEG Signal Sample Without Quantization</span></p><img src="https://jurnal.harianregional.com/media/64454-4.jpg" alt="" style="width:368pt;height:141pt;">
<ul style="list-style:none;"><li>
<p><span class="font2" style="font-weight:bold;">Figure 4. </span><span class="font2">1â€™st Subject EEG Signal Sample With Quantization</span></p></li></ul>
<p><span class="font2">The feature vectors will then go through a classification process. The classification stage in this study acts as a method of evaluating new features resulting from the quantization process to determine whether the features of the quantization results can represent the EEG signal itself. In the DEAP dataset, four labels are consisting of arousal, valence, dominance, and liking. In this process, the feature vectors obtained from processing the EEG signal data of one of the research subjects are included in the classifier to classify two types of emotions, namely positive emotions and negative emotions from the liking label on the DEAP dataset.</span></p>
<p><span class="font2">Classification is implemented using the Keras library, which is a library that runs on the TensorFlow machine learning platform. The Neural Network architecture used is as follows:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font2">a. &nbsp;&nbsp;&nbsp;First layer: input layer with 250 neurons</span></p></li>
<li>
<p><span class="font2">b. &nbsp;&nbsp;&nbsp;Second layer: hidden layer with 500 neurons</span></p></li>
<li>
<p><span class="font2">c. &nbsp;&nbsp;&nbsp;Third layer: hidden layer with 250 neurons</span></p></li>
<li>
<p><span class="font2">d. &nbsp;&nbsp;&nbsp;Fourth layer: hidden layer with 250 neurons</span></p></li>
<li>
<p><span class="font2">e. &nbsp;&nbsp;&nbsp;Fifth layer: hidden layer with 500 neurons</span></p></li>
<li>
<p><span class="font2">f. &nbsp;&nbsp;&nbsp;Sixth layer: the output layer has 1 neuron with sigmoid activation function</span></p></li></ul>
<p><span class="font2">In this study, 100 epochs of Neural Network architecture were conducted.</span></p>
<p><span class="font2">At the evaluation stage, there are two experiments, namely comparing the classification of the feature vector through quantization with the feature vector without quantization. The following is a table of the accuracy obtained based on the experiments that have been carried out.</span></p>
<p><span class="font2" style="font-weight:bold;">Table 2. </span><span class="font2">Accuracy Table</span></p>
<table border="1">
<tr><td style="vertical-align:bottom;">
<p><span class="font2" style="font-weight:bold;">Quantization</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2" style="font-weight:bold;">Accuracy</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2">Yes</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">75%</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2">No</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">58%</span></p></td></tr>
</table>
<p><span class="font2">As shown in the table above, the feature vector with quantization has a positive impact in representing the EEG signal which is indicated by the acquisition of accuracy of 75%. Then, the feature vector without quantization can represent the EEG signal, but the accuracy is lower than the feature vector with quantization, which is 58%.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark14"></a><span class="font2" style="font-weight:bold;"><a name="bookmark15"></a>4. &nbsp;&nbsp;&nbsp;Conclusion</span></h2></li></ul>
<p><span class="font2">Based on the results of the tests carried out, the conclusion that the writer can draw is that the quantization feature is one of the features that can represent EEG signals, shown by its accuracy in the classification of positive and negative emotions from the liking label on the DEAP dataset with Neural Network classifier with the Keras library. In this study, it was proven that features with quantization have an accuracy of 75% compared to features without quantization which only obtain an accuracy of 58%.</span></p>
<h2><a name="bookmark16"></a><span class="font2" style="font-weight:bold;"><a name="bookmark17"></a>References</span></h2>
<ul style="list-style:none;"><li>
<p><span class="font2">[1] &nbsp;Ahmad, A., 2017. Mengenal artificial intelligence, machine learning, neural network,</span></p></li></ul>
<p><span class="font2">dan deep learning. </span><span class="font2" style="font-style:italic;">no. October</span><span class="font2">.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font2">[2] Koelstra, S., Muhl, C., Soleymani, M., Lee, J.S., Yazdani, A., Ebrahimi, T., Pun, T.,</span></p></li></ul>
<p><span class="font2">Nijholt, A. and Patras, I., 2011. Deap: A database for emotion analysis; using</span></p>
<p><span class="font2">physiological signals. </span><span class="font2" style="font-style:italic;">IEEE transactions on affective computing</span><span class="font2">, </span><span class="font2" style="font-style:italic;">3</span><span class="font2">(1), pp.18-31.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font2">[3] &nbsp;&nbsp;&nbsp;Santosa, E.J., 2017. KLASIFIKASI GENRE MUSIK MENGGUNAKAN METODE</span></p></li></ul>
<p><span class="font2">SUPPORT VECTOR MACHINE (Doctoral dissertation, Universitas Widyatama).</span></p>
<ul style="list-style:none;"><li>
<p><span class="font2">[4] Caballero, D., 2018. Feature extraction algorithms from MRI to evaluate quality</span></p></li></ul>
<p><span class="font2">parameters on meat products by using data mining. </span><span class="font2" style="font-style:italic;">ELCVIA Electronic Letters on Computer Vision and Image Analysis</span><span class="font2">, </span><span class="font2" style="font-style:italic;">16</span><span class="font2">(2), pp.1-4.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font2">[5] Hilmi, A., Wijayanto, I. and Hadiyoso, S., 2017. Analisis perbandingan pola sinyal alfa</span></p></li></ul>
<p><span class="font2">dan beta eeg untuk klasifikasi kondisi rileks pada perokok aktif dengan menggunakan K-nearest Neighbor. </span><span class="font2" style="font-style:italic;">eProceedings of Engineering</span><span class="font2">, </span><span class="font2" style="font-style:italic;">4</span><span class="font2">(3).</span></p>
<ul style="list-style:none;"><li>
<p><span class="font2">[6] &nbsp;&nbsp;&nbsp;Fasich, D.A., 2017. </span><span class="font2" style="font-style:italic;">Klastering Emosi Berdasarkan Gelombang Otak Sinyal EEG</span></p></li></ul>
<p><span class="font2" style="font-style:italic;">Menggunakan Fuzzy C-Means Clustering</span><span class="font2"> (Doctoral dissertation, Institut Teknologi Sepuluh Nopember).</span></p>
<ul style="list-style:none;"><li>
<p><span class="font2">[7] &nbsp;&nbsp;&nbsp;Hidayat, I.T., Djamal, E.C. and Ilyas, R., 2017, August. Brain Computer Interface Untuk Aksi Memutar Lagu Terhadap Tiga Kondisi Emosional Menggunakan Spektral Daya dan Adaptive Backpropagation. In </span><span class="font2" style="font-style:italic;">Seminar Nasional Aplikasi Teknologi Informasi</span></p></li></ul>
<p><span class="font2" style="font-style:italic;">(SNATI)</span><span class="font2">.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font2">[8] &nbsp;&nbsp;&nbsp;Hurriyatul Fitriyah (penulis); Edita Rosana Widasari (penulis). (2017). Dasar-dasar komputasi sinyal digital : dan contoh aplikasinya menggunakan matlab / Hurriyatul Fitriyah, ST., MSc., Edita Rosana Widasari, ST., MT., MEng.. Malang :: UB Press,.</span></p></li></ul>
<p><span class="font2">176</span></p>