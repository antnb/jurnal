---
layout: full_article
title: "ANALISIS SENTIMEN MENGGUNAKAN METODE NAÏVE BAYES CLASSIFIER DENGAN SELEKSI FITUR CHI SQUARE"
author: "JUEN LING, I PUTU EKA N. KENCANA, TJOKORDA BAGUS OKA"
categories: mtk
canonical_url: https://jurnal.harianregional.com/mtk/full-11992 
citation_abstract_html_url: "https://jurnal.harianregional.com/mtk/id-11992"
citation_pdf_url: "https://jurnal.harianregional.com/mtk/full-11992"  
comments: true
---

<p><span class="font13">E-Jurnal Matematika Vol. 3 (3), Agustus 2014, pp. 92-99</span></p>
<p><span class="font13">ISSN: 2303-1751</span></p><a name="caption1"></a>
<h1><a name="bookmark0"></a><span class="font16" style="font-weight:bold;"><a name="bookmark1"></a>ANALISIS SENTIMEN MENGGUNAKAN METODE </span><span class="font16" style="font-weight:bold;font-style:italic;">NAÏVE BAYES CLASSIFIER</span><span class="font16" style="font-weight:bold;"> DENGAN SELEKSI FITUR </span><span class="font16" style="font-weight:bold;font-style:italic;">CHI SQUARE</span></h1>
<p><span class="font15">Juen Ling<sup>1</sup>, I Putu Eka N. Kencana<sup>§2</sup>, Tjokorda Bagus Oka<sup>3</sup></span></p>
<p><span class="font13"><sup>1</sup>Jurusan Matematika, Fakultas MIPA - Universitas Udayana [Email: </span><a href="mailto:juenling260292@gmail.com"><span class="font13">juenling260292@gmail.com</span></a><span class="font13">]</span></p>
<p><span class="font13"><sup>2</sup>Jurusan Matematika, Fakultas MIPA - Universitas Udayana [Email: </span><a href="mailto:i.putu.enk@gmail.com"><span class="font13">i.putu.enk@gmail.com</span></a><span class="font13">] <sup>3</sup>Jurusan Matematika, Fakultas MIPA - Universitas Udayana [Email: </span><a href="mailto:tjokordabagusoka@gmail.com"><span class="font13">tjokordabagusoka@gmail.com</span></a><span class="font13">] </span><span class="font15"><sup>§</sup></span><span class="font13" style="font-style:italic;">Corresponding Author</span></p>
<h3><a name="bookmark2"></a><span class="font14" style="font-weight:bold;"><a name="bookmark3"></a>ABSTRACT</span></h3>
<p><span class="font14" style="font-style:italic;">Sentiment analysis is the computational study of opinions, sentiments, and emotions expressed in texts. The basic task of sentiment analysis is to classify the polarity of the existing texts in documents, sentences, or opinions. Polarity has meaning if there is text in the document, sentence, or the opinion has a positive or negative aspect. In this study, classification of the polarity in sentiment analysis using machine learning techniques, that is Naïve Bayes classifier. Criteria for text classification decisions, learned automatically from learning the data. The need for manual classification is still required because training the data derived from manually labeling, the label (feature) refers to the process of adding a description of each data according to its category. In the process of labeling, feature selection is used and performed by chi-square feature selection, to reduce the disturbance (noise) in the classification. The results showed that the frequency of occurrences of the expected features in the true category and in the false category have an important role in the chi-square feature selection. Then classification by Naïve Bayes classifier obtained an accuracy of 83% and a harmonic average of 90.713%.</span></p>
<p><span class="font14" style="font-weight:bold;">Keywords</span><span class="font14" style="font-style:italic;">: chi square, classification, feature selection, machine learning technique, Naïve Bayes, sentiment analysis.</span></p>
<p><span class="font14">Informasi dalam bentuk teks adalah informasi yang penting dan banyak didapatkan dari berbagai sumber seperti buku, surat kabar, situs web, ataupun pesan </span><span class="font14" style="font-style:italic;">e-mail</span><span class="font14">. Teks merupakan sebuah hamparan bahasa, baik dalam pembicaraan ataupun dalam tulisan, yang memiliki makna, bersifat praktis dan berguna untuk umum serta berhubungan dengan dunia nyata (Bolshakov &amp;&nbsp;Gelbukh [2]). Sebuah teks dapat terdiri dari hanya satu kata ataupun susunan kalimat (Carter &amp;&nbsp;McCarthy [3]). Pengambilan informasi dari teks (</span><span class="font14" style="font-style:italic;">text mining</span><span class="font14">) antara lain dapat meliputi kategorisasi teks atau dokumen, analisis sentimen (</span><span class="font14" style="font-style:italic;">sentiment analysis</span><span class="font14">), pencarian topik yang lebih spesifik (</span><span class="font14" style="font-style:italic;">search engine</span><span class="font14">), serta </span><span class="font14" style="font-style:italic;">spam filtering</span><span class="font14">. Gagasan umum</span></p>
<p><span class="font14" style="font-style:italic;">text mining</span><span class="font14"> adalah untuk mengetahui cakupan atau topik dari permasalahan dalam teks (Maning, </span><span class="font14" style="font-style:italic;">et al.</span><span class="font14"> [6]). T</span><span class="font14" style="font-style:italic;">ext mining</span><span class="font14"> penting dalam analisis sentimen sebagai pengidentifikasi emosional suatu pernyataan, sehingga banyak studi tentang analisis sentimen dilakukan (Zhang, </span><span class="font14" style="font-style:italic;">et al.</span><span class="font14"> [12]).</span></p>
<p><span class="font14">Analisis sentimen adalah studi komputasi dari opini-opini, sentimen, serta emosi yang diekspresikan dalam teks (Liu [5]). Tugas dasar dalam analisis sentimen adalah mengelompokkan polaritas dari teks yang ada dalam dokumen, kalimat, atau pendapat. Polaritas mempunyai arti apakah teks yang ada dalam dokumen, kalimat, atau pendapat memiliki aspek positif atau negatif. Salah satu</span></p>
<p><span class="font14">teknik pembelajaran mesin untuk analisis sentimen adalah </span><span class="font14" style="font-style:italic;">Naïve Bayes classifier</span><span class="font14"> (NBC). NBC merupakan teknik pembelajaran mesin yang berbasis probabilistik. NBC adalah metode sederhana tetapi memiliki akurasi serta performansi yang tinggi dalam pengklasifikasian teks (Routray, </span><span class="font14" style="font-style:italic;">et al.</span><span class="font14"> [9]).</span></p>
<p><span class="font14">Banyak ide telah muncul selama beberapa tahun belakangan tentang teknik pembelajaran mesin untuk permasalahan analisis sentimen. Xhemali, </span><span class="font14" style="font-style:italic;">et al.</span><span class="font14"> [11] berkonsentrasi pada perbandingan tiga metode. Metode-metode tersebut adalah Naïve Bayes, Pohon Keputusan, dan Neural Networks. Hasil penelitian secara keseluruhan menunjukkan bahwa Naïve Bayes </span><span class="font14" style="font-style:italic;">classifier</span><span class="font14"> adalah pilihan terbaik untuk pelatihan domain. Metode berbasis leksikon untuk melakukan analisis sentimen pertama kali diterapkan oleh Zhang </span><span class="font14" style="font-style:italic;">et al.</span><span class="font14"> [12]. Metode ini dapat memberikan presisi yang tinggi tapi </span><span class="font14" style="font-style:italic;">recall</span><span class="font14"> yang rendah. Penelitian lain yang dilakukan Taboada, </span><span class="font14" style="font-style:italic;">et al.</span><span class="font14"> [10] yang menerapkan pendekatan berbasis leksikon untuk mengekstrak sentimen dari teks yang menggunakan kamus kata-kata atau frase dijelaskan dengan orientasi semantik meliputi polaritas dan </span><span class="font14" style="font-style:italic;">strength</span><span class="font14"> dari kata-kata, serta menggabungkan intensifikasi dan negasi. Routray </span><span class="font14" style="font-style:italic;">et al.</span><span class="font14"> [9] dan Khairnar &amp;&nbsp;Kinikar [4] membahas banyak pendekatan dari para peneliti yang berbeda, serta menyatakan bahwa metode pembelajaran mesin menjadi cara yang efisien untuk menganalisis sentimen.</span></p>
<p><span class="font14">Penggabungan yang dilakukan dalam tulisan ini adalah menggabungkan NBC dengan seleksi fitur. Penyeleksian fitur diperlukan dalam proses memilih subset dari fitur-fitur yang relevan untuk digunakan dalam konstruksi model probabilistik NBC. Penyeleksian fitur yang digunakan adalah seleksi fitur </span><span class="font14" style="font-style:italic;">chi square</span><span class="font14">. Dari data yang tersedia, sejumlah data akan digunakan untuk menguji hasil klasifikasi sistem NBC dengan penyeleksian fitur </span><span class="font14" style="font-style:italic;">chi square</span><span class="font14">.</span></p>
<ul style="list-style:none;"><li>
<h3><a name="bookmark4"></a><span class="font14" style="font-weight:bold;"><a name="bookmark5"></a>2. &nbsp;&nbsp;&nbsp;KAJIAN PUSTAKA</span></h3>
<ul style="list-style:none;">
<li>
<p><span class="font14">2.1</span><span class="font14" style="font-style:italic;"> &nbsp;&nbsp;&nbsp;Pre-Processing</span></p></li></ul></li></ul>
<p><span class="font14" style="font-style:italic;">Tokenization</span><span class="font14"> adalah tugas pemotongan urutan karakter dan sebuah set dokumen yang diberikan menjadi potongan-potongan kata atau karakter yang sesuai dengan kebutuhan sistem. Potongan-potongan tersebut dikenal dengan istilah token (Maning, et al. [6]).</span></p>
<p><span class="font14" style="font-style:italic;">Stemming</span><span class="font14"> merupakan salah satu proses dari mengubah token yang berimbuhan menjadi kata dasar, dengan menghilangkan semua imbuhan yang ada pada token tersebut. Pentingnya </span><span class="font14" style="font-style:italic;">stemming</span><span class="font14"> dalam proses pembuatan sistem adalah untuk menghilangkan imbuhan pada awalan dan akhiran. Berdasarkan hasil proses tersebut, akan didapatkan sebuah informasi mengenai banyaknya fitur yang muncul dalam sebuah dokumen</span><span class="font15">.</span></p>
<p><span class="font14" style="font-style:italic;">Stopwords</span><span class="font14"> dapat diartikan sebagai menghilangkan karakter, tanda baca, serta kata-kata umum yang tidak memiliki makna atau informasi yang dibutuhkan. </span><span class="font14" style="font-style:italic;">Stopwords </span><span class="font14">umumnya digunakan dalam pengambilan informasi salah satu contohnya adalah mesin pencari </span><span class="font14" style="font-style:italic;">Google</span><span class="font14">. Pengurangan ukuran indeks dalam teks dengan penghilangan beberapa kata kerja, kata sifat, dan kata keterangan lainnya dapat dimasukkan ke dalam daftar </span><span class="font14" style="font-style:italic;">stopwords.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font14">2.2 &nbsp;&nbsp;&nbsp;Seleksi Fitur </span><span class="font14" style="font-style:italic;">Chi Square</span></p></li></ul>
<p><span class="font14">Seleksi fitur dilakukan untuk mereduksi fitur-fitur yang tidak relevan dalam proses klasifikasi oleh NBC. Terdapat beberapa metode untuk penyeleksian fitur yaitu </span><span class="font14" style="font-style:italic;">Mutual Information</span><span class="font14"> (MI), </span><span class="font14" style="font-style:italic;">chi square</span><span class="font14"> (</span><span class="font3">χ</span><span class="font14"><sup>2</sup>), dan yang umum digunakan adalah </span><span class="font14" style="font-style:italic;">frequency-based. </span><span class="font14">Seleksi fitur </span><span class="font14" style="font-style:italic;">frequency-based</span><span class="font14"> menggunakan jumlah kemunculan </span><span class="font14" style="font-style:italic;">term</span><span class="font14"> atau frekuensi </span><span class="font14" style="font-style:italic;">term </span><span class="font14">yang diurutkan dari yang paling banyak sampai paling sedikit dan diambil beberapa urutan atas untuk digunakan sebagai fitur. Seleksi fitur MI merupakan ukuran yang mengukur kehadiran atau ketidakhadiran sebuah </span><span class="font14" style="font-style:italic;">term</span><span class="font14"> yang memberikan kontribusi kepada kategori yang tepat. Sedangkan seleksi</span></p>
<p><span class="font14">fitur </span><span class="font14" style="font-style:italic;">Chi Square</span><span class="font14"> menggunakan teori statistika untuk menguji independensi sebuah </span><span class="font14" style="font-style:italic;">term </span><span class="font14">dengan kategorinya. Salah satu tujuan penggunaan seleksi fitur adalah untuk menghilangkan fitur pengganggu dalam klasifikasi.</span></p>
<p><span class="font14">Dalam seleksi fitur </span><span class="font14" style="font-style:italic;">Chi Square</span><span class="font14"> berdasarkan teori statistika, dua peristiwa di antaranya adalah, kemunculan dari fitur dan kemunculan dari kategori, yang kemudian setiap nilai </span><span class="font14" style="font-style:italic;">term </span><span class="font14">diurutkan dari yang tertinggi berdasarkan perhitungan berikut [6]:</span></p>
<p><span class="font13"><sup>2</sup></span></p>
<p><span class="font14" style="font-style:italic;">X</span><span class="font14"><sup>2</sup>(</span><span class="font14" style="font-style:italic;">D</span><span class="font14">,</span><span class="font14" style="font-style:italic;">t</span><span class="font14">,</span><span class="font14" style="font-style:italic;">c)</span><span class="font3"> = </span><span class="font5">∑ ∑ </span><span class="font14" style="text-decoration:line-through;">( </span><span class="font9" style="font-style:italic;text-decoration:line-through;">e</span><span class="font8" style="font-style:italic;text-decoration:line-through;">t</span><span class="font9" style="font-style:italic;text-decoration:line-through;">e</span><span class="font8" style="font-style:italic;text-decoration:line-through;">c &nbsp;&nbsp;&nbsp;&nbsp;</span><span class="font9" style="font-style:italic;text-decoration:line-through;">e</span><span class="font8" style="font-style:italic;text-decoration:line-through;">t</span><span class="font9" style="font-style:italic;text-decoration:line-through;">e</span><span class="font8" style="font-style:italic;text-decoration:line-through;">c</span><span class="font14" style="text-decoration:line-through;">)</span></p>
<p><span class="font8" style="font-style:italic;"><sup>e</sup>ι</span><span class="font0"> </span><span class="font7">∈</span><span class="font2">{</span><span class="font10">°.1</span><span class="font2">) </span><span class="font9" style="font-style:italic;">e</span><span class="font8" style="font-style:italic;">c</span><span class="font0"> </span><span class="font7">∈</span><span class="font2">{</span><span class="font10">0.1</span><span class="font2">) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="font14" style="font-style:italic;">E</span><span class="font9" style="font-style:italic;">e,e<sub>c</sub></span></p>
<p><span class="font14">Penyeleksian fitur </span><span class="font14" style="font-style:italic;">Chi Square</span><span class="font14"> dilakukan dengan cara mengurutkan setiap fitur berdasarkan hasil seleksi fitur </span><span class="font14" style="font-style:italic;">Chi Square</span><span class="font14"> dari nilai yang terbesar hingga nilai yang terkecil. Nilai seleksi fitur </span><span class="font14" style="font-style:italic;">Chi Square</span><span class="font14"> yang lebih besar dari nilai signifikan menunjukkan penolakan hipotesis independensi. Sedangkan jika dua peristiwa menunjukkan dependen, maka fitur tersebut menyerupai atau sama dengan label kategori yang sesuai pada kategori.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font14">2.3 &nbsp;&nbsp;&nbsp;Naïve Bayes Classifier</span></p></li></ul>
<p><span class="font14">Naïve Bayes </span><span class="font14" style="font-style:italic;">classifier</span><span class="font14"> merupakan suatu metode klasifikasi yang menggunakan perhitungan probabilitas. Konsep dasar yang digunakan pada Naïve Bayes </span><span class="font14" style="font-style:italic;">classifier</span><span class="font14"> adalah Teorema Bayes yang dinyatakan pertama kali oleh Thomas Bayes [1]. Nilai probabilitas yang digunakan dinyatakan secara sederhana sebagai berikut (Pop [8]):</span></p>
<p><span class="font15" style="font-style:italic;">p</span><span class="font15"> (</span><span class="font15" style="font-style:italic;">C</span><span class="font15"> | </span><span class="font15" style="font-style:italic;">D</span><span class="font15">) </span><span class="font4">= </span><span class="font15" style="font-style:italic;">P(DIC)P(C) p(D)</span></p>
<div>
<p><span class="font15">.</span></p>
</div><br clear="all">
<ul style="list-style:none;"><li>
<p><span class="font14" style="font-style:italic;">2.4 &nbsp;&nbsp;&nbsp;Evaluasi Kinerja</span></p></li></ul>
<p><span class="font14" style="font-style:italic;">Dua dasar ukuran yang sering digunakan untuk mengetahui efektivitas sistem adalah precision atau presisi dan recall. Presisi (P) adalah ukuran banyaknya dokumen yang ditemukan relevan, dinyatakan dalam pecahan sebagai berikut;</span></p>
<p><span class="font13" style="font-weight:bold;font-style:italic;">#(Relevant item, retrieved)</span></p>
<p><span class="font13" style="font-weight:bold;font-style:italic;">Precision =-------------</span></p>
<p><span class="font13" style="font-weight:bold;font-style:italic;">^(Retrieved item)</span></p>
<p><span class="font14" style="font-style:italic;">sedangkan recall (R) adalah ukuran banyaknya dokumen yang relevan dapat ditemukan kembali, dinyatakan dalam pecahan sebagai berikut;</span></p><img src="https://jurnal.harianregional.com/media/11992-1.jpg" alt="" style="width:196pt;height:30pt;">
<ul style="list-style:none;"><li>
<h3><a name="bookmark6"></a><span class="font14" style="font-weight:bold;"><a name="bookmark7"></a>3. &nbsp;&nbsp;&nbsp;METODE PENELITIAN</span></h3></li></ul>
<p><span class="font14" style="font-style:italic;">Data pada penelitian ini berupa opini berbahasa Inggris tentang produk telepon genggam. Dari data yang tersedia, diambil secara acak sebanyak 200 buah opini yang terdiri dari 100 buah opini positif dan 100 buah opini negatif. Data tersebut digunakan sebagai data pembelajaran mesin dan data uji untuk mengevaluasi kinerja sistem.</span></p>
<p><span class="font14" style="font-style:italic;">Adapun langkah-langkah untuk perancangan analisis sentimen yang dibahas adalah sebagai berikut:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font14" style="font-style:italic;">1. &nbsp;&nbsp;&nbsp;Tahap pre-processing data</span></p></li></ul>
<p><span class="font14" style="font-style:italic;">Pada tahap pre-processing data, awal mula data mentah dilakukan proses tokenizer, stemming, serta stopwords. Hasil dari tahapan ini menghasilkan fitur yang digunakan sebagai data pembelajaran mesin oleh NBC.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font14" style="font-style:italic;">2. &nbsp;&nbsp;&nbsp;Tahap penyeleksian fitur dengan seleksi fitur Chi Square</span></p></li></ul>
<p><span class="font14" style="font-style:italic;">Penelitian ini menggunakan seleksi fitur Chi Square. Langkah awal, yaitu menentukan tabel kontingensi masing-masing fitur dengan Tabel 1. Langkah selanjutnya menghitung nilai seleksi fitur Chi Square dengan persamaan berikut (Maning, et al. [6]):</span></p>
<div>
<p><span class="font11" style="font-style:italic;">X<sup>2</sup>(D,t,c)</span></p>
</div><br clear="all">
<p><span class="font11">(</span><span class="font11" style="font-style:italic;">N</span><span class="font8">00 </span><span class="font2">+ </span><span class="font11" style="font-style:italic;">N</span><span class="font11"><sub>11</sub> </span><span class="font2">+ </span><span class="font11" style="font-style:italic;">N</span><span class="font8">10 </span><span class="font2">+ </span><span class="font11" style="font-style:italic;">N</span><span class="font8">0,</span><span class="font11">) </span><span class="font2">× </span><span class="font11">(</span><span class="font11" style="font-style:italic;">N</span><span class="font8">00</span><span class="font11" style="font-style:italic;">N„ </span><span class="font2">- </span><span class="font11" style="font-style:italic;">N<sub>ω</sub>N</span><span class="font11"><sub>1</sub></span><span class="font8">,</span><span class="font11">)</span><span class="font8">2</span></p>
<p><span class="font11">.</span></p>
<p><span class="font11">(</span><span class="font11" style="font-style:italic;">N</span><span class="font8">i, </span><span class="font2">+ </span><span class="font11" style="font-style:italic;">N</span><span class="font8">01</span><span class="font11">) </span><span class="font2">× </span><span class="font11">(</span><span class="font11" style="font-style:italic;">N</span><span class="font8">i, </span><span class="font2">+ </span><span class="font11" style="font-style:italic;">N</span><span class="font11"><sub>w</sub>) </span><span class="font2">× </span><span class="font11">(</span><span class="font11" style="font-style:italic;">N</span><span class="font2"><sub>w</sub> + </span><span class="font11" style="font-style:italic;">N</span><span class="font6" style="font-variant:small-caps;"><sub>m</sub>)</span><span class="font2">× </span><span class="font11">(</span><span class="font11" style="font-style:italic;">N</span><span class="font8">0, </span><span class="font2">+ </span><span class="font11" style="font-style:italic;">N</span><span class="font6" style="font-variant:small-caps;"><sub>m</sub>)</span></p>
<p><span class="font14">Seleksi fitur </span><span class="font14" style="font-style:italic;">Chi Square</span><span class="font14"> digunakan untuk pegamatan kebersesuaian (</span><span class="font14" style="font-style:italic;">goodness of fit</span><span class="font14">) dari kategori dengan </span><span class="font14" style="font-style:italic;">terms</span><span class="font14">. Uji </span><span class="font14" style="font-style:italic;">Chi Square</span><span class="font14"> dalam statistika diterapkan untuk menguji independensi dari dua peristiwa. Sedangkan</span></p>
<p><span class="font14">dalam seleksi fitur berdasarkan teori statistika, dua peristiwa tersebut di antaranya adalah, kemunculan dari fitur dan kemunculan dari kategori.</span></p>
<table border="1">
<tr><td style="vertical-align:bottom;">
<p><span class="font14">Tabel 1. Tabel Kontingensi Seleksi Fitur </span><span class="font14" style="font-style:italic;">Chi Square</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font14" style="font-style:italic;">e</span><span class="font10" style="font-style:italic;">c</span><span class="font3"> — </span><span class="font14">1 &nbsp;&nbsp;</span><span class="font14" style="font-style:italic;">e</span><span class="font10" style="font-style:italic;">c</span><span class="font3"> — </span><span class="font14">0</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font14" style="font-style:italic;">e</span><span class="font10" style="font-style:italic;">t</span><span class="font3"> = </span><span class="font14"><sup>1</sup> &nbsp;&nbsp;</span><span class="font13" style="font-style:italic;">N</span><span class="font9">11 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="font13" style="font-style:italic;">N</span><span class="font9">10</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font13" style="font-style:italic;">e<sub>t</sub></span><span class="font3"> — </span><span class="font14">0 &nbsp;&nbsp;</span><span class="font13" style="font-style:italic;">N</span><span class="font9">oι &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="font13" style="font-style:italic;">N</span><span class="font9">oo</span></p></td></tr>
</table>
<p><span class="font14">Langkah terakhir yaitu mengurutkan semua hasil perhitungan seleksi fitur dari yang terbesar sampai yang terkecil. Penghapusan fitur dilakukan jika penerimaan hipotesis independen terpenuhi.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font14">3. &nbsp;&nbsp;&nbsp;Tahap klasifikasi data</span></p></li></ul>
<p><span class="font14">Naïve Bayes menganggap sebuah dokumen sebagai kumpulan dari kata yang menyusun dokumen tersebut. Naïve Bayes juga tidak memperhatikan urutan kemunculan kata pada dokumen. Adapun algoritma NBC [7] untuk klasifikasi data dapat dilihat pada Gambar 1.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font14">4. &nbsp;&nbsp;&nbsp;Tahap evaluasi kinerja sistem</span></p></li></ul>
<p><span class="font14">Pada tahap evaluasi sistem, perhitungan menggunakan tabel kontingensi yang diberikan pada Tabel 2.</span></p>
<p><span class="font14">Tabel 2. Tabel Kontingensi Evaluasi Kinerja Sistem</span></p>
<table border="1">
<tr><td style="vertical-align:top;">
<p><span class="font14" style="font-style:italic;">#</span></p></td><td style="vertical-align:top;">
<p><span class="font14" style="font-style:italic;">Relevant</span></p></td><td style="vertical-align:top;">
<p><span class="font14" style="font-style:italic;">Not Relevant</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font14" style="font-style:italic;">Retrieved</span></p></td><td style="vertical-align:bottom;">
<p><span class="font14" style="font-style:italic;">True positive (TP)</span></p></td><td style="vertical-align:bottom;">
<p><span class="font14" style="font-style:italic;">False Positive (FP)</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font14" style="font-style:italic;">Not Retrieved</span></p></td><td style="vertical-align:middle;">
<p><span class="font14" style="font-style:italic;">False negative (FN)</span></p></td><td style="vertical-align:bottom;">
<p><span class="font14" style="font-style:italic;">True Negative (TN)</span></p></td></tr>
</table>
<p><span class="font14">Alternatif yang jelas terlintas pada pikiran pembaca dalam menilai sebuah sistem adalah dengan akurasi. Akurasi adalah ketepatan suatu sistem melakukan klasifikasi yang benar. Perhitungan untuk Presisi (</span><span class="font14" style="font-style:italic;">P</span><span class="font14">), </span><span class="font14" style="font-style:italic;">Recall</span><span class="font14"> (</span><span class="font14" style="font-style:italic;">R</span><span class="font14">), dan akurasi dapat dikalkulasi sebagai berikut:</span></p>
<h2><a name="bookmark8"></a><span class="font15" style="font-style:italic;"><a name="bookmark9"></a>P</span><span class="font4"> = &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="font15">;</span></h2>
<p><span class="font15" style="font-style:italic;">TP</span><span class="font4"> + </span><span class="font15" style="font-style:italic;">FP</span></p>
<p><span class="font15" style="font-style:italic;">TP</span><span class="font4"> + </span><span class="font15" style="font-style:italic;">FN ’</span></p>
<div>
<table border="1">
<tr><td style="vertical-align:top;"></td><td rowspan="2" style="vertical-align:middle;">
<p><span class="font14" style="font-weight:bold;font-style:italic;">Learner</span></p>
<p><span class="font13">Untuk setiap kategori: a. Hitung </span><span class="font13" style="font-style:italic;">p</span><span class="font13">(</span><span class="font13" style="font-style:italic;">c</span><span class="font13"> ) b. Hitung </span><span class="font12" style="font-style:italic;">p</span><span class="font12">(</span><span class="font12" style="font-style:italic;">w<sub>k</sub></span><span class="font12"> | </span><span class="font12" style="font-style:italic;">c<sub>j</sub></span><span class="font12">) </span><span class="font13">untuk setiap kata </span><span class="font13" style="font-style:italic;">w </span><span class="font13">pada model</span></p></td><td style="vertical-align:top;"></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font11">Data latih</span></p></td><td style="vertical-align:top;">
<p><span class="font11" style="font-style:italic;">Classifier</span></p></td></tr>
<tr><td style="vertical-align:top;"></td><td style="vertical-align:middle;">
<p><span class="font13" style="font-weight:bold;font-style:italic;">Classifier</span></p>
<p><span class="font13">a. Hitung</span></p>
<p><span class="font13" style="font-style:italic;">p</span><span class="font13">(</span><span class="font13" style="font-style:italic;"><sup>c</sup></span><span class="font17">P∏</span><span class="font13" style="font-style:italic;">p</span><span class="font13">(</span><span class="font13" style="font-style:italic;"><sup>w</sup></span><span class="font13"> i</span><span class="font13" style="font-style:italic;">c</span><span class="font9" style="font-style:italic;">j</span><span class="font13" style="font-style:italic;">) </span><span class="font9" style="font-style:italic;">k</span></p></td><td style="vertical-align:top;"></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font11">_</span></p>
<p><span class="font11">Pengujian data</span></p></td><td style="vertical-align:top;">
<p><span class="font13">untuk setiap kategori b. Tentukan kategori dengan nilai maksimal dari</span></p>
<p><span class="font13" style="font-style:italic;">p</span><span class="font13"> (</span><span class="font13" style="font-style:italic;"><sup>c</sup></span><span class="font9" style="font-style:italic;">j</span><span class="font13">)</span><span class="font17">∏ </span><span class="font13" style="font-style:italic;">p</span><span class="font13"> (</span><span class="font13" style="font-style:italic;">w</span><span class="font13"> | </span><span class="font13" style="font-style:italic;"><sup>c</sup></span><span class="font9" style="font-style:italic;">j</span><span class="font13" style="font-style:italic;">) </span><span class="font9" style="font-style:italic;">k</span></p></td><td style="vertical-align:top;">
<p><span class="font11">Kategori</span></p></td></tr>
</table>
</div><br clear="all">
<div>
<p><span class="font15" style="font-style:italic;">Akurasi</span><span class="font4"> =</span></p>
</div><br clear="all">
<p><span class="font15" style="font-style:italic;">TP</span><span class="font4"> + </span><span class="font15" style="font-style:italic;">TN</span></p>
<p><span class="font15">.</span></p>
<h2><a name="bookmark10"></a><span class="font15" style="font-style:italic;"><a name="bookmark11"></a>TP</span><span class="font4"> + </span><span class="font15" style="font-style:italic;">FP</span><span class="font4"> + </span><span class="font15" style="font-style:italic;">FN</span><span class="font4"> + </span><span class="font15" style="font-style:italic;">TN</span></h2>
<p><span class="font14">Sebuah ukuran yang digunakan sebagai rata-rata terbobot harmonik dari </span><span class="font14" style="font-style:italic;">P</span><span class="font14"> dan </span><span class="font14" style="font-style:italic;">R</span><span class="font14"> adalah sebagai berikut:</span></p>
<p><span class="font15">2</span><span class="font15" style="font-style:italic;">PR</span></p>
<p><span class="font14" style="font-style:italic;"><sup>F</sup>i — &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="font15">.</span></p>
<p><span class="font10">1 </span><span class="font15" style="font-style:italic;">P</span><span class="font4"> + </span><span class="font15" style="font-style:italic;">R</span></p>
<div>
<p><span class="font14">Gambar 1. Proses Klasifikasi dengan NBC</span></p>
</div><br clear="all">
<p><span class="font14">Sisanya yaitu 100 buah opini yang terbagi sama rata antara opini positif dan opini negatif digunakan sebagai data uji.</span></p>
<p><span class="font14">Perancangan basis data dengan menggunakan XAMPP, memuat tiga buah tabel yang independen, </span><span class="font15">yaitu tabel datatraining, corpus, tb_feature</span><span class="font14">. Tabel datatraining memuat keseluruhan data latih mentah. Tabel tb_feature memuat fitur-fitur yang telah diberi label positif atau negatif secara manual. Sedangkan tabel corpus memuat fitur-fitur yang telah diseleksi melalui tahapan yang telah diuraikan pada implementasi seleksi fitur </span><span class="font14" style="font-style:italic;">Chi Square</span><span class="font14">. Pada sistem, proses-proses atau urutan proses dirancang untuk mengklasifikasi data uji dengan melalui beberapa tahapan. Tahapan tersebut merupakan tahapan yang telah diuraikan pada tahap </span><span class="font14" style="font-style:italic;">pre-processing</span><span class="font14"> dan implementasi Naïve Bayes </span><span class="font14" style="font-style:italic;">classifier</span><span class="font14">.</span></p>
<p><span class="font14">Langkah awal yaitu melakukan pelabelan secara manual dari 100 buah data latih. Pada pelabelan fitur tersebut dilakukan proses </span><span class="font14" style="font-style:italic;">stemming</span><span class="font14">. Pelabelan tersebut menghasilkan 117 fitur diantaranya 66 fitur negatif dan 51 fitur positif.</span></p>
<p><span class="font14">Setelah melakukan pelabelan dilanjutkan dengan proses penyeleksian fitur. Seleksi fitur dilakukan dari sebanyak 117 fitur yang diperoleh dari pelabelan. Pada tahap seleksi fitur ada tiga metode yang diketahui, yaitu </span><span class="font14" style="font-style:italic;">Mutual Information</span><span class="font14"> (MI), </span><span class="font14" style="font-style:italic;">chi square</span><span class="font14"> (</span><span class="font3">χ</span><span class="font14"><sup>2</sup>), dan </span><span class="font14" style="font-style:italic;">frequency-based.</span><span class="font14"> Seleksi fitur </span><span class="font14" style="font-style:italic;">frequency-based </span><span class="font14">menggunakan jumlah kemunculan </span><span class="font14" style="font-style:italic;">term</span><span class="font14"> atau frekuensi </span><span class="font14" style="font-style:italic;">term</span><span class="font14"> yang diurutkan dari yang paling banyak sampai paling sedikit dan diambil beberapa urutan atas untuk digunakan sebagai fitur.</span></p>
<p><span class="font14">Metode seleksi fitur </span><span class="font14" style="font-style:italic;">Frequency-based </span><span class="font14">memilih fitur yang paling umum di kategori. Metode seleksi fitur </span><span class="font14" style="font-style:italic;">Frequency-based</span><span class="font14"> dapat didefinisikan baik sebagai frekuensi dokumen (jumlah dokumen di kategori </span><span class="font14" style="font-style:italic;">c</span><span class="font14"> yang mengandung fitur </span><span class="font14" style="font-style:italic;">t</span><span class="font14">) atau sebagai koleksi frekuensi (jumlah token dari </span><span class="font14" style="font-style:italic;">t</span><span class="font14"> yang muncul pada dokumen dalam </span><span class="font14" style="font-style:italic;">c</span><span class="font14">). Seleksi fitur MI merupakan ukuran yang mengukur kehadiran atau ketidakhadiran sebuah </span><span class="font14" style="font-style:italic;">term</span><span class="font14"> yang</span></p>
<p><span class="font14">memberikan kontribusi kepada kategori yang tepat. Sedangkan seleksi fitur </span><span class="font14" style="font-style:italic;">Chi Square </span><span class="font14">menggunakan teori statistika untuk menguji independensi sebuah </span><span class="font14" style="font-style:italic;">term</span><span class="font14"> dengan kategorinya. Salah satu tujuan penggunaan seleksi fitur adalah untuk menghilangkan fitur pengganggu dalam klasifikasi</span><span class="font15">. </span><span class="font14">Maning, </span><span class="font14" style="font-style:italic;">et al</span><span class="font14">. [6] mengatakan untuk kasus seleksi fitur </span><span class="font14" style="font-style:italic;">frequency-based</span><span class="font14"> memiliki kinerja yang buruk dibandingkan MI dan </span><span class="font14" style="font-style:italic;">Chi Square</span><span class="font14">.</span></p>
<p><span class="font14">Perbandingan dari peningkatan akurasi dapat diamati pada Gambar 2, dengan </span><span class="font14" style="font-weight:bold;font-style:italic;">F</span><span class="font10" style="font-weight:bold;font-style:italic;">1-measure </span><span class="font14">merupakan ukuran ketepatan klasifikasi oleh metode Naïve Bayes </span><span class="font14" style="font-style:italic;">Classifier</span><span class="font14"> dengan dilakukannya beberapa metode seleksi fitur yaitu </span><span class="font14" style="font-style:italic;">MI</span><span class="font14">, </span><span class="font14" style="font-style:italic;">Chi Square</span><span class="font14"> dan </span><span class="font14" style="font-style:italic;">frequency-based</span><span class="font14">. Pada Gambar 2, saat 100 buah fitur terpilih, ketepatan klasifikasi oleh metode seleksi fitur </span><span class="font14" style="font-style:italic;">frequency-based</span><span class="font14"> memperoleh di bawah 40%, metode seleksi fitur </span><span class="font14" style="font-style:italic;">MI</span><span class="font14"> memperoleh hasil di atas 60%, dan metode seleksi fitur </span><span class="font14" style="font-style:italic;">chi square </span><span class="font14">memperoleh hasil yang mendekati 60% [6]. Hal ini menunjukkan bahwa metode </span><span class="font14" style="font-style:italic;">frequencybased</span><span class="font14"> tidak seharusnya digunakan.</span></p><img src="https://jurnal.harianregional.com/media/11992-2.jpg" alt="" style="width:218pt;height:174pt;">
<p><span class="font1" style="font-weight:bold;">number of features selected</span></p>
<p><span class="font14">Gambar 2. Perbandingan Metode Seleksi Fitur dalam Ketepatan Klasifikasi</span></p>
<p><span class="font14">Hipotesis awal menyatakan bahwa </span><span class="font14" style="font-style:italic;">term t </span><span class="font14">independen terhadap kategori </span><span class="font14" style="font-style:italic;">c</span><span class="font14">. Sedangkan hipotesis akhir menyatakan bahwa </span><span class="font14" style="font-style:italic;">term t </span><span class="font14">dependen terhadap kategori </span><span class="font14" style="font-style:italic;">c</span><span class="font14">. Hasil seleksi fitur </span><span class="font14" style="font-style:italic;">Chi Square</span><span class="font14"> dari 117 fitur terseleksi menjadi 30 fitur yang terdiri dari 14 fitur</span></p>
<p><span class="font14">negatif dan 16 fitur positif. Proses penyeleksian fitur sebanyak 117 fitur dengan seleksi fitur </span><span class="font14" style="font-style:italic;">Chi Square</span><span class="font14"> yang dibangun dengan bahasa pemrograman Java membutuhkan waktu komputasi hanya dua detik.</span></p>
<p><span class="font14">Diagram alir untuk merepresentasikan langkah-langkah sistem untuk melakukan proses penyeleksian fitur dengan seleksi fitur </span><span class="font14" style="font-style:italic;">Chi Square</span><span class="font14"> dapat dilihat pada Gambar 3 berikut:</span></p><img src="https://jurnal.harianregional.com/media/11992-3.png" alt="" style="width:202pt;height:254pt;">
<p><span class="font14">Gambar 3. Diagram Alir Penyeleksian Fitur dengan </span><span class="font14" style="font-style:italic;">Chi Square</span></p>
<p><span class="font14">Dalam seleksi fitur </span><span class="font14" style="font-style:italic;">Chi Square</span><span class="font14"> frekuensi pada fitur menjadi kurang penting bila fitur tersebut juga muncul beberapa kali pada kategori yang tidak diharapkan. Sehingga bila kedua metode tersebut dibandingkan seleksi fitur </span><span class="font14" style="font-style:italic;">Chi Square</span><span class="font14"> akan lebih baik daripada </span><span class="font14" style="font-style:italic;">frequency-based</span><span class="font14">. Kemunculan frekuensi fitur pada kategori yang diharapkan dan kategori yang tidak diharapkan memiliki peranan penting dalam seleksi fitur </span><span class="font14" style="font-style:italic;">Chi Square</span><span class="font14">. Sedangkan pada </span><span class="font14" style="font-style:italic;">frequency-based</span><span class="font14"> yang memiliki peranan penting hanya kemunculan frekuensi fitur pada kategori yang diharapkan. Apabila penolakan hipotesis awal terpenuhi</span></p>
<p><span class="font14">atau penerimaan hipotesis akhir terpenuhi, fitur tersebut akan digunakan dalam proses klasifikasi NBC.</span></p>
<p><span class="font14">Mengacu pada konsep dasar Naïve Bayes </span><span class="font14" style="font-style:italic;">classifier</span><span class="font14"> yaitu Teorema Bayes yang dinyatakan pertama kali oleh Thomas Bayes [1]:</span></p>
<div>
<p><span class="font15" style="font-style:italic;"><sub>p</sub></span><span class="font15"><sub>(</sub></span><span class="font15" style="font-style:italic;"><sub>C</sub></span><span class="font15"><sub>|</sub></span><span class="font15" style="font-style:italic;"><sub>D</sub></span><span class="font15"><sub>)</sub></span><span class="font4"><sub>=</sub></span><span class="font15" style="font-style:italic;text-decoration:underline;">p</span><span class="font15" style="text-decoration:underline;">(</span><span class="font15" style="font-style:italic;text-decoration:underline;">D</span><span class="font15" style="text-decoration:underline;">|</span><span class="font15" style="font-style:italic;text-decoration:underline;">C</span><span class="font15" style="text-decoration:underline;">)</span><span class="font15" style="font-style:italic;text-decoration:underline;">p</span><span class="font15" style="text-decoration:underline;">(</span><span class="font15" style="font-style:italic;text-decoration:underline;">C</span><span class="font15" style="text-decoration:underline;">)</span><span class="font15"> </span><span class="font15" style="font-style:italic;">p</span><span class="font15">(</span><span class="font15" style="font-style:italic;">D</span><span class="font15">)</span></p>
</div><br clear="all">
<div>
<p><span class="font15">.</span></p>
</div><br clear="all">
<p><span class="font14">Nilai probabilitas dihitung dari kemunculan opini yang setara dengan perkalian nilai probabilitas kemunculan fitur dalam opini tersebut. Adapun diagram alir untuk proses klasifikasi dengan NBC dapat dilihat pada Gambar 4.</span></p>
<p><span class="font11">Mulai i</span></p><img src="https://jurnal.harianregional.com/media/11992-4.png" alt="" style="width:199pt;height:268pt;">
<p><span class="font14">Gambar 4. Diagram Alir Proses Klasifikasi dengan NBC</span></p>
<p><span class="font14">Klasifikasi oleh NBC pada data uji negatif memperoleh ketepatan sebesar 72% sedangkan untuk data uji positif memperoleh 96%. Secara keseluruhan data uji, klasifikasi oleh NBC</span></p>
<p><span class="font14">memperoleh akurasi sebesar 83% dan rata-rata harmonik (</span><span class="font14" style="font-weight:bold;font-style:italic;">F</span><span class="font10" style="font-weight:bold;font-style:italic;">measure</span><span class="font14">) sebesar 90,713%. Pada penelitian ini, NBC melakukan kesalahan klasifikasi sebanyak empat data uji, tidak dapat mengklasifikasi 13 data uji dari total keseluruhan 100 data uji.</span></p>
<p><span class="font14">NBC bekerja dengan baik dalam mengklasifikasi dan juga merupakan teknik pembelajaran mesin yang sederhana dengan hanya menggunakan kemunculan fitur serta frekuensi fitur pada tiap-tiap opini. Secara global klasifikasi oleh NBC dapat digunakan sebagai teknik analisis sentimen pasar produk seperti yang dilakukan pada penelitian ini.</span></p>
<p><span class="font14">Tabel 3. Peringkat Hasil Seleksi Fitur </span><span class="font14" style="font-style:italic;">Chi</span></p>
<p><span class="font14" style="font-style:italic;">Square</span></p>
<table border="1">
<tr><td style="vertical-align:middle;">
<p><span class="font12" style="font-weight:bold;">No</span></p></td><td style="vertical-align:middle;">
<p><span class="font12" style="font-weight:bold;">Fitur</span></p></td><td style="vertical-align:middle;">
<p><span class="font12" style="font-weight:bold;">Kategori</span></p></td><td style="vertical-align:middle;">
<p><span class="font12" style="font-weight:bold;">Frekuensi Fitur</span></p></td><td style="vertical-align:middle;">
<p><span class="font12" style="font-weight:bold;">Nilai chi square</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font13">1</span></p></td><td style="vertical-align:middle;">
<p><span class="font13" style="font-style:italic;">dissapoint</span></p></td><td style="vertical-align:middle;">
<p><span class="font13">negatif</span></p></td><td style="vertical-align:middle;">
<p><span class="font13">29</span></p></td><td style="vertical-align:middle;">
<p><span class="font13">40.84507042</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font13">2</span></p></td><td style="vertical-align:middle;">
<p><span class="font13" style="font-style:italic;">great</span></p></td><td style="vertical-align:middle;">
<p><span class="font13">positif</span></p></td><td style="vertical-align:middle;">
<p><span class="font13">26</span></p></td><td style="vertical-align:middle;">
<p><span class="font13">35.13513514</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font13">3</span></p></td><td style="vertical-align:middle;">
<p><span class="font13" style="font-style:italic;">love</span></p></td><td style="vertical-align:middle;">
<p><span class="font13">positif</span></p></td><td style="vertical-align:middle;">
<p><span class="font13">22</span></p></td><td style="vertical-align:middle;">
<p><span class="font13">28.20512821</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font13">4</span></p></td><td style="vertical-align:middle;">
<p><span class="font13" style="font-style:italic;">recommend</span></p></td><td style="vertical-align:middle;">
<p><span class="font13">positif</span></p></td><td style="vertical-align:middle;">
<p><span class="font13">16</span></p></td><td style="vertical-align:middle;">
<p><span class="font13">15.94613749</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font13">5</span></p></td><td style="vertical-align:middle;">
<p><span class="font13" style="font-style:italic;">good</span></p></td><td style="vertical-align:middle;">
<p><span class="font13">positif</span></p></td><td style="vertical-align:middle;">
<p><span class="font13">16</span></p></td><td style="vertical-align:middle;">
<p><span class="font13">15.94613749</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font13">6</span></p></td><td style="vertical-align:middle;">
<p><span class="font13" style="font-style:italic;">us</span></p></td><td style="vertical-align:middle;">
<p><span class="font13">negatif</span></p></td><td style="vertical-align:middle;">
<p><span class="font13">10</span></p></td><td style="vertical-align:middle;">
<p><span class="font13">11.11111111</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font13">7</span></p></td><td style="vertical-align:middle;">
<p><span class="font13" style="font-style:italic;">excel</span></p></td><td style="vertical-align:middle;">
<p><span class="font13">positif</span></p></td><td style="vertical-align:middle;">
<p><span class="font13">10</span></p></td><td style="vertical-align:middle;">
<p><span class="font13">11.11111111</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font13">8</span></p></td><td style="vertical-align:middle;">
<p><span class="font13" style="font-style:italic;">amaz</span></p></td><td style="vertical-align:middle;">
<p><span class="font13">positif</span></p></td><td style="vertical-align:middle;">
<p><span class="font13">8</span></p></td><td style="vertical-align:middle;">
<p><span class="font13">8.695652174</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font13">9</span></p></td><td style="vertical-align:middle;">
<p><span class="font13" style="font-style:italic;">perfect</span></p></td><td style="vertical-align:middle;">
<p><span class="font13">positif</span></p></td><td style="vertical-align:middle;">
<p><span class="font13">8</span></p></td><td style="vertical-align:middle;">
<p><span class="font13">8.695652174</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font13">10</span></p></td><td style="vertical-align:middle;">
<p><span class="font13" style="font-style:italic;">easi</span></p></td><td style="vertical-align:middle;">
<p><span class="font13">positif</span></p></td><td style="vertical-align:middle;">
<p><span class="font13">8</span></p></td><td style="vertical-align:middle;">
<p><span class="font13">8.695652174</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font13">11</span></p></td><td style="vertical-align:middle;">
<p><span class="font13" style="font-style:italic;">lot</span></p></td><td style="vertical-align:middle;">
<p><span class="font13">positif</span></p></td><td style="vertical-align:middle;">
<p><span class="font13">10</span></p></td><td style="vertical-align:middle;">
<p><span class="font13">8.273748723</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font13">12</span></p></td><td style="vertical-align:middle;">
<p><span class="font13" style="font-style:italic;">return</span></p></td><td style="vertical-align:middle;">
<p><span class="font13">negatif</span></p></td><td style="vertical-align:middle;">
<p><span class="font13">7</span></p></td><td style="vertical-align:middle;">
<p><span class="font13">7.52688172</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font13">13</span></p></td><td style="vertical-align:middle;">
<p><span class="font13" style="font-style:italic;">broken</span></p></td><td style="vertical-align:middle;">
<p><span class="font13">negatif</span></p></td><td style="vertical-align:middle;">
<p><span class="font13">7</span></p></td><td style="vertical-align:middle;">
<p><span class="font13">7.52688172</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font13">14</span></p></td><td style="vertical-align:middle;">
<p><span class="font13" style="font-style:italic;">bad</span></p></td><td style="vertical-align:middle;">
<p><span class="font13">negatif</span></p></td><td style="vertical-align:middle;">
<p><span class="font13">7</span></p></td><td style="vertical-align:middle;">
<p><span class="font13">7.52688172</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font13">15</span></p></td><td style="vertical-align:middle;">
<p><span class="font13" style="font-style:italic;">upset</span></p></td><td style="vertical-align:middle;">
<p><span class="font13">negatif</span></p></td><td style="vertical-align:middle;">
<p><span class="font13">6</span></p></td><td style="vertical-align:middle;">
<p><span class="font13">6.382978723</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font13">16</span></p></td><td style="vertical-align:middle;">
<p><span class="font13" style="font-style:italic;">fix</span></p></td><td style="vertical-align:middle;">
<p><span class="font13">negatif</span></p></td><td style="vertical-align:middle;">
<p><span class="font13">4</span></p></td><td style="vertical-align:middle;">
<p><span class="font13">4.166666667</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font13">17</span></p></td><td style="vertical-align:middle;">
<p><span class="font13" style="font-style:italic;">highli</span></p></td><td style="vertical-align:middle;">
<p><span class="font13">positif</span></p></td><td style="vertical-align:middle;">
<p><span class="font13">4</span></p></td><td style="vertical-align:middle;">
<p><span class="font13">4.166666667</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font13">18</span></p></td><td style="vertical-align:middle;">
<p><span class="font13" style="font-style:italic;">best</span></p></td><td style="vertical-align:middle;">
<p><span class="font13">positif</span></p></td><td style="vertical-align:middle;">
<p><span class="font13">4</span></p></td><td style="vertical-align:middle;">
<p><span class="font13">4.166666667</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font13">19</span></p></td><td style="vertical-align:middle;">
<p><span class="font13" style="font-style:italic;">awesom</span></p></td><td style="vertical-align:middle;">
<p><span class="font13">positif</span></p></td><td style="vertical-align:middle;">
<p><span class="font13">4</span></p></td><td style="vertical-align:middle;">
<p><span class="font13">4.166666667</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font13">20</span></p></td><td style="vertical-align:middle;">
<p><span class="font13" style="font-style:italic;">pai</span></p></td><td style="vertical-align:middle;">
<p><span class="font13">negatif</span></p></td><td style="vertical-align:middle;">
<p><span class="font13">3</span></p></td><td style="vertical-align:middle;">
<p><span class="font13">3.092783505</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font13">21</span></p></td><td style="vertical-align:middle;">
<p><span class="font13" style="font-style:italic;">poor</span></p></td><td style="vertical-align:middle;">
<p><span class="font13">negatif</span></p></td><td style="vertical-align:middle;">
<p><span class="font13">3</span></p></td><td style="vertical-align:middle;">
<p><span class="font13">3.092783505</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font13">22</span></p></td><td style="vertical-align:middle;">
<p><span class="font13" style="font-style:italic;">cheat</span></p></td><td style="vertical-align:middle;">
<p><span class="font13">negatif</span></p></td><td style="vertical-align:middle;">
<p><span class="font13">3</span></p></td><td style="vertical-align:middle;">
<p><span class="font13">3.092783505</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font13">23</span></p></td><td style="vertical-align:middle;">
<p><span class="font13" style="font-style:italic;">old</span></p></td><td style="vertical-align:middle;">
<p><span class="font13">negatif</span></p></td><td style="vertical-align:middle;">
<p><span class="font13">3</span></p></td><td style="vertical-align:middle;">
<p><span class="font13">3.092783505</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font13">24</span></p></td><td style="vertical-align:middle;">
<p><span class="font13" style="font-style:italic;">damag</span></p></td><td style="vertical-align:middle;">
<p><span class="font13">negatif</span></p></td><td style="vertical-align:middle;">
<p><span class="font13">3</span></p></td><td style="vertical-align:middle;">
<p><span class="font13">3.092783505</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font13">25</span></p></td><td style="vertical-align:middle;">
<p><span class="font13" style="font-style:italic;">over</span></p></td><td style="vertical-align:middle;">
<p><span class="font13">negatif</span></p></td><td style="vertical-align:middle;">
<p><span class="font13">3</span></p></td><td style="vertical-align:middle;">
<p><span class="font13">3.092783505</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font13">26</span></p></td><td style="vertical-align:middle;">
<p><span class="font13" style="font-style:italic;">sure</span></p></td><td style="vertical-align:middle;">
<p><span class="font13">positif</span></p></td><td style="vertical-align:middle;">
<p><span class="font13">3</span></p></td><td style="vertical-align:middle;">
<p><span class="font13">3.092783505</span></p></td></tr>
</table>
<table border="1">
<tr><td style="vertical-align:middle;">
<p><span class="font13">27</span></p></td><td style="vertical-align:middle;">
<p><span class="font13" style="font-style:italic;">beauti</span></p></td><td style="vertical-align:middle;">
<p><span class="font13">positif</span></p></td><td style="vertical-align:middle;">
<p><span class="font13">3</span></p></td><td style="vertical-align:middle;">
<p><span class="font13">3.092783505</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font13">28</span></p></td><td style="vertical-align:middle;">
<p><span class="font13" style="font-style:italic;">like</span></p></td><td style="vertical-align:middle;">
<p><span class="font13">positif</span></p></td><td style="vertical-align:middle;">
<p><span class="font13">10</span></p></td><td style="vertical-align:middle;">
<p><span class="font13">2.990033223</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font13">29</span></p></td><td style="vertical-align:middle;">
<p><span class="font13" style="font-style:italic;">unlock</span></p></td><td style="vertical-align:middle;">
<p><span class="font13">negatif</span></p></td><td style="vertical-align:middle;">
<p><span class="font13">5</span></p></td><td style="vertical-align:middle;">
<p><span class="font13">2.836879433</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font13">30</span></p></td><td style="vertical-align:middle;">
<p><span class="font13" style="font-style:italic;">fast</span></p></td><td style="vertical-align:middle;">
<p><span class="font13">positif</span></p></td><td style="vertical-align:middle;">
<p><span class="font13">5</span></p></td><td style="vertical-align:middle;">
<p><span class="font13">2.836879433</span></p></td></tr>
</table>
<p><span class="font14">Daftar hasil perhitungan memuat nilai seleksi fitur </span><span class="font14" style="font-style:italic;">Chi Square</span><span class="font14"> yang berdasarkan hipotesis independensi, dengan hipotesis awal menyatakan bahwa </span><span class="font14" style="font-style:italic;">term t</span><span class="font14"> independen terhadap kategori </span><span class="font14" style="font-style:italic;">c</span><span class="font14">. Apabila nilai seleksi fitur </span><span class="font14" style="font-style:italic;">Chi Square</span><span class="font14"> lebih besar daripada nilai signifikan, sehingga penolakan hipotesis awal akan terpenuhi. Hipotesis akhir yang diperoleh menyatakan bahwa </span><span class="font14" style="font-style:italic;">term t</span><span class="font14"> dependen terhadap kategori </span><span class="font14" style="font-style:italic;">c</span><span class="font14">.</span></p>
<ul style="list-style:none;"><li>
<h3><a name="bookmark12"></a><span class="font14" style="font-weight:bold;"><a name="bookmark13"></a>5. &nbsp;&nbsp;&nbsp;SIMPULAN</span></h3></li></ul>
<p><span class="font14">Berdasarkan hasil yang diperoleh dapat disimpulan bahwa kemunculan frekuensi fitur pada kategori yang diharapkan dan kategori yang tidak diharapkan memiliki peranan penting dalam seleksi fitur </span><span class="font14" style="font-style:italic;">Chi Square,</span><span class="font14"> oleh karena itu seleksi fitur </span><span class="font14" style="font-style:italic;">Chi Square</span><span class="font14"> baik digunakan dalam penyeleksian fitur dibandingkan dengan metode </span><span class="font14" style="font-style:italic;">frequency-based</span><span class="font14">. Serta pembangunan sistem analisis sentimen menggunakan metode NBC dengan bahasa pemrograman Java memperoleh akurasi sebesar 83% dan rata-rata harmonik sebesar 90,713%. Terdapat kesalahan klasifikasi karena pada data uji terdapat fitur yang muncul pada bukan kategorinya. Untuk penelitian selanjutnya yaitu dapat dibandingkan hasil seleksi fitur dari </span><span class="font14" style="font-style:italic;">chi square</span><span class="font14"> terhadap hasil seleksi fitur dari </span><span class="font14" style="font-style:italic;">Mutual Information</span><span class="font14"> berdasarkan segi waktu komputasi dan segi ketepatan klasifikasi. Serta menggabungkan teknik pembelajaran mesin NBC dengan beberapa model </span><span class="font14" style="font-style:italic;">n-</span><span class="font14">gram untuk meneliti hasil ketepatan klasifikasi yang diperoleh.</span></p>
<h3><a name="bookmark14"></a><span class="font14" style="font-weight:bold;"><a name="bookmark15"></a>DAFTAR PUSTAKA</span></h3>
<ul style="list-style:none;"><li>
<p><span class="font14">[1] &nbsp;&nbsp;&nbsp;Aldrich, J., 2008. R. A. Fisher on Bayes and Bayes’ Theorem. </span><span class="font14" style="font-style:italic;">Bayesian Analysis, </span><span class="font14">3(1), pp. 161-170.</span></p></li>
<li>
<p><span class="font14">[2] &nbsp;&nbsp;&nbsp;Bolshakov, I. A. &amp;&nbsp;Gelbukh, A., 2004. </span><span class="font14" style="font-style:italic;">Computational Linguistics.</span><span class="font14"> 1st ed.</span></p></li></ul>
<p><span class="font14">Mexico: Instituto Politécnico Nacional.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font14">[3] &nbsp;&nbsp;&nbsp;Carter, R. &amp;&nbsp;McCarthy, M., 2006. </span><span class="font14" style="font-style:italic;">Cambridge Grammar of English. </span><span class="font14">Cambridge: Cambridge Univ. Press.</span></p></li>
<li>
<p><span class="font14">[4] &nbsp;&nbsp;&nbsp;Khairnar, J. &amp;&nbsp;Kinikar, M., 2013. Machine Learning Algorithms for Opinion Mining and Sentiment Classification. </span><span class="font14" style="font-style:italic;">International Journal of Scientific and Research Publications, </span><span class="font14">June, 3(6), pp. 1-6.</span></p></li>
<li>
<p><span class="font14">[5] &nbsp;&nbsp;&nbsp;Liu, B., 2012. </span><span class="font14" style="font-style:italic;">Sentiment Analysis and Opinion Mining.</span><span class="font14"> San Rafael: Morgan &amp;&nbsp;Claypool Publishers.</span></p></li>
<li>
<p><span class="font14">[6] &nbsp;&nbsp;&nbsp;Maning, C., Raghavan, P. &amp;&nbsp;Schutze, H., 2008. </span><span class="font14" style="font-style:italic;">Introduction to Information Retrieval.</span><span class="font14"> London: Cambridge University Press.</span></p></li>
<li>
<p><span class="font14">[7] &nbsp;&nbsp;&nbsp;Mitchell, T. M., 1997. </span><span class="font14" style="font-style:italic;">Machine Learning.</span><span class="font14"> 1st ed. New York: McGraw-Hill.</span></p></li>
<li>
<p><span class="font14">[8] &nbsp;&nbsp;&nbsp;Pop, I., 2006. An approach of the Naive Bayes classifier for the document classification. </span><span class="font14" style="font-style:italic;">General Mathematics, </span><span class="font14">14(4), p. 135–138.</span></p></li>
<li>
<p><span class="font14">[9] &nbsp;&nbsp;&nbsp;Routray, P., Swain, C. K. &amp;&nbsp;Mishra, S. P., 2013. A Survey on Sentiment Analysis. </span><span class="font14" style="font-style:italic;">International Journal of Computer Applications,</span><span class="font14"> Agustus, 70(10), pp. 1-8.</span></p></li>
<li>
<p><span class="font14">[10] &nbsp;&nbsp;&nbsp;Taboada, M., Brooke, J., Tofiloski, M., Voll, K. &amp;&nbsp;Stede, M., 2011. LexiconBased Methods for Sentiment Analysis. </span><span class="font14" style="font-style:italic;">Computational Linguistics,</span><span class="font14"> 37(2), pp. 267-307.</span></p></li>
<li>
<p><span class="font14">[11] &nbsp;&nbsp;&nbsp;Xhemali, D., J. Hinde, C. &amp;&nbsp;G. Stone, R., 2009. Naïve Bayes vs. Decision Trees vs. Neural Networks in the Classification of Training Web Pages. </span><span class="font14" style="font-style:italic;">International Journal of Computer Science Issues, </span><span class="font14">4(1), pp. 16-23.</span></p></li>
<li>
<p><span class="font14">[12] &nbsp;&nbsp;&nbsp;Zhang, L., Ghosh, R., Dekhil, M., Hsu, M. &amp;&nbsp;Liu,B., 2011. </span><span class="font14" style="font-style:italic;">Combining Lexiconbased and Learning-based Methods for Twitter Sentiment Analysis,</span><span class="font14"> Chicago: Hewlett-Packard Development Company, L.P.</span></p></li></ul>
<p><span class="font13">99</span></p>