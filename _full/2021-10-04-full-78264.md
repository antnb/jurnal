---
layout: full_article
title: "Classification of Sign Language Numbers Using the CNN Method"
author: "I Putu Iduar Perdana, I Ketut Gede Darma Putra, I Putu Arya Dharmaadi"
categories: jitter
canonical_url: https://jurnal.harianregional.com/jitter/full-78264 
citation_abstract_html_url: "https://jurnal.harianregional.com/jitter/id-78264"
citation_pdf_url: "https://jurnal.harianregional.com/jitter/full-78264"  
comments: true
---

<p><span class="font2">JITTER- Jurnal Ilmiah Teknologi dan Komputer Vol. 2, No. 3 Desember 2021</span></p><a name="caption1"></a>
<h1><a name="bookmark0"></a><span class="font5" style="font-weight:bold;"><a name="bookmark1"></a>Classification of Sign Language Numbers Using the CNN Method</span></h1>
<p><span class="font1" style="font-weight:bold;">I Putu Iduar Perdana<sup>a1</sup>, I Ketut Gede Darma Putra<sup>a2</sup>, I Putu Arya Dharmaadi<sup>a3 </sup></span><span class="font1" style="font-style:italic;"><sup>a</sup>Department of Information Technology, Udayana University, Indonesia</span></p>
<p><span class="font1" style="font-style:italic;">Corresponding Author: </span><a href="mailto:1iduarperdana@gmail.com"><span class="font1" style="font-style:italic;"><sup>1</sup>iduarperdana@gmail.com</span></a><span class="font1" style="font-style:italic;">, </span><a href="mailto:2ikgdarmaputra@unud.ac.id"><span class="font1" style="font-style:italic;"><sup>2</sup>ikgdarmaputra@unud.ac.id</span></a><span class="font1" style="font-style:italic;">, </span><a href="mailto:3aryadharmaadi@unud.ac.id"><span class="font1" style="font-style:italic;"><sup>3</sup>aryadharmaadi@unud.ac.id</span></a></p>
<p><span class="font1" style="font-weight:bold;font-style:italic;">Abstrak</span></p>
<p><span class="font1" style="font-style:italic;">Berkomunikasi merupakan kebutuhan semua individu karena setiap individu harus berkomunikasi dengan lingkungan. Berkomnikasi juga membuat seseorang mendapat informasi sehingga dapat dijadikan acuan untuk beradaptasi. penggunaan bahasa verbal dengan berbicara mengeluar suara adalah cara komunikasi individu, namun hal itu tidak dapat dilakukan saat berkomunikasi dengan individu yang memilki keterbatasan dalam mendengar. Keterbatasan tersebut membuat diperlukan cara komunikasi lain yaitu melalui bahasa isyarat. Bahasa isyarat banyak jenisnya salah satunya bahasa isyarat menggunakan tangan membentuk huruf atau angka. Bahasa isyarat terdapat standar, standar yang cukup terkenal adalah standar American Sign Language</span><span class="font1"> (ASL). Masih banyak yang sulit mengenal bahasa isyarat, maka solusinya adalah membuat sistem untuk klasifikasi bahasa isyarat. Penelitian ini akan membuat sistem machine learning untuk pengenalan angka bahasa isyarat standar </span><span class="font1" style="font-style:italic;">American Sign Language</span><span class="font1"> (ASL) serta menerapkan </span><span class="font1" style="font-style:italic;">preprocessing</span><span class="font1"> untuk optimalisasi hasil. Hasil penelitian ini adalah melakukan perbandingan metode </span><span class="font1" style="font-style:italic;">preproscessing</span><span class="font1"> yang diterapkan pada sistem </span><span class="font1" style="font-style:italic;">Convlutional neural network</span><span class="font1"> arsitektur mobilenetv2. Hasil akhir penelitian kombinasi metode </span><span class="font1" style="font-style:italic;">preprocessing Grayscale</span><span class="font1">, HSV, </span><span class="font1" style="font-style:italic;">Global Threshold</span><span class="font1"> menghasilkan akuarasi pengenalan terbaik yaitu 97%.</span></p>
<p><span class="font1" style="font-weight:bold;font-style:italic;">Kata kunci: </span><span class="font1" style="font-style:italic;">American Sign Language</span><span class="font1">, Grayscale, HSV colourspace, Global Threshold</span><span class="font1" style="font-style:italic;">, adaptive Threshold, convolutional neural network, Mobilenetv2</span></p>
<h4><a name="bookmark2"></a><span class="font1" style="font-weight:bold;"><a name="bookmark3"></a>Abstract</span></h4>
<p><span class="font1">Communicating is a need for all individuals because an individual must communicate with the environment. Communicating also enables someone to obtain information so that it can serve as a reference for adaptation. The use of spoken language while speaking out of a voice is an individual means of communication, but it cannot be applied when communicating with persons with hearing limitations. These limitations require another way of communication, namely through sign language. There are many kinds of ASL, one of which is ASL using hands to form letters or numbers. Standard popular Sign language is the American Sign Language (ASL) standard. Many still people difficult to recognize sign language, so a solution is to create a system for sign language classification. This research will create a machine learning system for number recognition in American standard sign language. Sign Language (ASL) as well as applying preprocessing to optimize results. The result of this research is to compare the recognition accuracy of the scenarios of different preprocessing methods applied in the Convolutional neural network system architecture MobileNetV2. The final result of this research is the combination of Grayscale, HSV, and Global Threshold preprocessing method yielding the best recognition accuracy of 97%.</span></p>
<p><span class="font1" style="font-weight:bold;font-style:italic;">Key Word</span><span class="font1" style="font-style:italic;">: American Sign Language</span><span class="font1">, Grayscale, HSV colourspace, Global Threshold</span><span class="font1" style="font-style:italic;">, adaptive Threshold, convolutional neural network, Mobilenetv2</span></p>
<ul style="list-style:none;"><li>
<h4><a name="bookmark4"></a><span class="font1" style="font-weight:bold;"><a name="bookmark5"></a>1. &nbsp;&nbsp;&nbsp;Introduction</span></h4></li></ul>
<p><span class="font1">Communication is essential in the individual life of a person because a person must communicate with their environment. Communicate makes it easier for people to adapt to their environment because when they communicate, they get information for adaptation. Humans communicate by speaking with others, this how-to share information. The sound produced is a medium for communication between individuals, but it is different for people who have limitations in hearing, communicate using verbal language, namely through a voice it cannot do. These limitations require the solution is search media to replace the voice when speaking on communication. A solution for this problem is to replace the voice when talking with sign language or non-verbal language. Sign language or non-verbal language is a language created to help communicate with people who have disabilities. On the site, the European Union of the Deaf A Sign language is no universal sign language in the world. Their monitoring results found that in-country is possible to have more than one sign language. This condition can occur because sign language is a natural language that has linguistic characteristics as well as spoken language. Based on that statement, sign language or non-verbal are many types. Examples are facial expressions, mouth movements, hand movements, and body movements. The non-verbal language that is popular used to communicate with people who have limited hearing is the language that uses fingers as a medium of communication.</span></p>
<p><span class="font1">The sign language that uses hands is familiar used as a medium of communication in various countries. Different standards apply to each country. Example in America that uses a standard called American Sign Language (ASL). The ASL standard is a sign language standard adopted or developed from several other sign languages, namely French Sign Language, Martha's Vineyard Sign Language, and other sign languages. This sign language only uses one hand for its implementation. Using one hand is more efficient than using two hands [1].</span></p>
<p><span class="font1">Even an efficient standard is often misunderstood and does not know the meaning of the ASL standard sign language. This mistake is common for people who have never studied sign language. These problems need solutions that can help people recognize the ASL standard sign language. In this era of increasingly advanced technology, this problem can solve by creating a system that can recognize sign language. The system developed is a system that utilizes machine learning technology. Machine learning technology is very effective for developing object recognition or classification systems [2]–[6]. A recognition system for sign language using machine learning was carried out by [7], research is creating the recognition of ASL sign language letters system using a convolutional neural network. Refers to previous research, this research decided to use a convolutional neural network as the basis of the system. A Recognition system with a convolutional neural network requires an architecture, so the system developed will use the mobilenetv2. The dataset used is a sign language number data set in the form of a dataset collection of hand images that are ASL standard sign language number movements [8]. This research will focus on conducting trials to optimize the recognition system by applying a combination of preprocessing. Preprocessing applied to the system will be compared with the final result, namely recognition accuracy.</span></p>
<ul style="list-style:none;"><li>
<h4><a name="bookmark6"></a><span class="font1" style="font-weight:bold;"><a name="bookmark7"></a>2. &nbsp;&nbsp;&nbsp;Research Method / Proposed Method</span></h4></li></ul>
<p><span class="font1">The research stages will be presented in the form of diagrams, the research stages consist of several stages. The research flow chart can be seen in Figure 1.</span></p><img src="https://jurnal.harianregional.com/media/78264-1.jpg" alt="" style="width:325pt;height:211pt;">
<p><span class="font1">Figure 1. System workflow</span></p>
<p><span class="font1">Workflow the system developed consists of two modules is the training module and the test module. The training module consists of several processes. The process is dataset image input process, preprocessing, training with mobilenetv2, saving the model. The test module is image input process, preprocessing, object recognition, and display of results. The preprocessing process consists of several methods, namely Grayscale, HSV colorspace and background elimination, Global Threshold, and Adaptive Thresholding. All systems can be developing by the python language and the TensorFlow library.</span></p>
<ul style="list-style:none;"><li>
<h4><a name="bookmark8"></a><span class="font1" style="font-weight:bold;"><a name="bookmark9"></a>2.1 &nbsp;&nbsp;&nbsp;Dataset Number ASL</span></h4></li></ul>
<p><span class="font1">The total ASL dataset is a collection of images from 218 volunteers performing 10 ASL figure movements. The dataset is a right-handed image of an individual. The specifications image is the image in color size 100x100 pixels (3-channel RGB) with a white background and the position of the hand in the center [8]. An example of an image from the ASL number dataset can see in Figure 2.</span></p><img src="https://jurnal.harianregional.com/media/78264-2.jpg" alt="" style="width:396pt;height:79pt;">
<div><img src="https://jurnal.harianregional.com/media/78264-3.jpg" alt="" style="width:396pt;height:80pt;">
<p><span class="font1">Figure 2. ASL Dataset</span></p>
</div><br clear="all">
<p><span class="font1">Figure 2 is an example of a dataset image of ASL numbers. The figure shown is an image of a hand that forms the numbers 0 to 9 in sign language. The shape of each number ASL on the data is different. Variationsshape of an image can apply as a reference for the recognition or classification system.</span></p>
<ul style="list-style:none;"><li>
<h4><a name="bookmark10"></a><span class="font1" style="font-weight:bold;"><a name="bookmark11"></a>2.2 &nbsp;&nbsp;&nbsp;Machine Learning</span></h4></li></ul>
<p><span class="font1">Machine learning is a technique derived from artificial intelligence developed to infer data with a mathematical approach. Method machine learning imitates the way humans learn for the recognition or classification of objects. The essence of machine learning is a process that aims to create a (mathematical) model that describes patterns of something object used as references [9]. The application of machine learning requires an architecture for study the characteristics of an object. The architecture for application to machine learning techniques is the Convolutional Neural Network (CNN).</span></p>
<p><span class="font1">Convolutional Neural Network (CNN) is an architecture that can recognize information intended to predict an object. CNN's ability to recognize objects differs from the position of the input data. This ability makes Convolutional Neural Network (CNN) currently widely used in various fields [9]. CNN has components, namely the Convolutional layer, pooling layer, and fully connected layer [10], [11].</span></p>
<p><span class="font1">MobileNetV2 is a series of convolutional neural network (CNN) architectures developed to become the next generation MobileNetV1. Basis Mobilenetv2 architecture builds from Mobilenetv1 but has deferent is in mobilenetv2 performed simple retraining and requires no special operators to improve accuracy. The MobileNetV2 architecture has 32 convolutional layers and 19 residual bottleneck layers. The kernel used is the standard kernel used in many modern architectures, with a kernel size of 3x3. In addition, dropout and batch normalization. The components in the MobileNetV2 architecture are Depthwise separable convolution, Linear Bottlenecks, and Batch normalization [12].</span></p>
<ul style="list-style:none;"><li>
<h4><a name="bookmark12"></a><span class="font1" style="font-weight:bold;"><a name="bookmark13"></a>2.3 &nbsp;&nbsp;&nbsp;Preprocessing</span></h4></li></ul>
<p><span class="font1">Preprocessing is a process carried out to improve image quality using different methods. The preprocessing process methods include the Grayscale, HSV colorspace and background elimination, Global Threshold, and Adaptive Gaussian Thresholding methods.</span></p>
<ul style="list-style:none;"><li>
<h4><a name="bookmark14"></a><span class="font1" style="font-weight:bold;"><a name="bookmark15"></a>2.3.1 &nbsp;&nbsp;&nbsp;Grayscale</span></h4></li></ul>
<p><span class="font1">Grayscale is a method used to convert an RGB image into a grayscale image. This method has the concept of finding the average of the RGB image matrix [13]. The formula to get a Grayscale image can see in formula 1.</span></p>
<h3><a name="bookmark16"></a><span class="font9" style="font-style:italic;"><a name="bookmark17"></a>r</span><span class="font3"> + </span><span class="font9" style="font-style:italic;">g</span><span class="font3">+</span><span class="font9" style="font-style:italic;">b</span></h3>
<div>
<p><span class="font1">(2)</span></p>
</div><br clear="all">
<h3><a name="bookmark18"></a><span class="font9" style="font-style:italic;"><a name="bookmark19"></a>s</span><span class="font3"> = &nbsp;&nbsp;</span><span class="font9">3</span></h3>
<p><span class="font1">The S parameter is the result of image grayscale, while the RGB parameter is the image color value. The application of grayscale to the dataset image can see in Figure 3.</span></p>
<div><img src="https://jurnal.harianregional.com/media/78264-4.jpg" alt="" style="width:108pt;height:108pt;">
<p><span class="font1">Figure 3. Grayscale Image</span></p>
</div><br clear="all">
<ul style="list-style:none;"><li>
<h4><a name="bookmark20"></a><span class="font1" style="font-weight:bold;"><a name="bookmark21"></a>2.3.2 &nbsp;&nbsp;&nbsp;HSV colorspace and background elimination</span></h4></li></ul>
<p><span class="font1">HSV colorspace and background elimination is a preprocessing method that divides the color of the images into three separate parts, namely Hue, Saturation, and value. The HSV preprocessing method is a method that focuses on separating brightness from chromaticity. Components HSV are divided into three parts. The first is part Hue, which ranges from 0 to 179, the second part is Saturation starts from 0255 and, the last part is value range from 0 to 255 [7]. The application of HSV colorspace and background elimination to the image dataset can see in Figure 4.</span></p>
<div><img src="https://jurnal.harianregional.com/media/78264-5.jpg" alt="" style="width:108pt;height:108pt;">
<p><span class="font1">Figure 4. Image of HSV colorspace and background elimination</span></p>
</div><br clear="all">
<ul style="list-style:none;"><li>
<h4><a name="bookmark22"></a><span class="font1" style="font-weight:bold;"><a name="bookmark23"></a>2.3.3 &nbsp;&nbsp;&nbsp;Global Threshold</span></h4></li></ul>
<p><span class="font1">Global Threshold is a method used to separate images with distributions of object intensity and different background pixels. The process of this method is changing the grayscale image into a binary image [13], [14]. Converting a grayscale image to binary can be done with formula 2.</span></p>
<div>
<p><span class="font9" style="font-style:italic;">g</span><span class="font3"> (</span><span class="font9" style="font-style:italic;">χ.y</span><span class="font3">)=</span></p>
</div><br clear="all">
<h2><a name="bookmark24"></a><span class="font9"><a name="bookmark25"></a>I </span><span class="font8" style="font-style:italic;">I</span><span class="font9" style="font-style:italic;">if</span><span class="font3"> (</span><span class="font9" style="font-style:italic;">x,y</span><span class="font3">)</span><span class="font9" style="font-style:italic;">≥T </span><span class="font9">{o </span><span class="font9" style="font-style:italic;">if</span><span class="font4"> (</span><span class="font9" style="font-style:italic;">χ.y</span><span class="font4">)</span><span class="font3">&lt; </span><span class="font10" style="font-style:italic;font-variant:small-caps;">t</span></h2>
<div>
<p><span class="font1">(2)</span></p>
</div><br clear="all">
<p><span class="font1">The formula shows that g (x, y) is a binary image generated from a grayscale image (x,y) and, T is a threshold value parameter. The application of Global Thresholding to the image dataset can see in Figure 5.</span></p>
<div><img src="https://jurnal.harianregional.com/media/78264-6.png" alt="" style="width:111pt;height:111pt;">
<p><span class="font1">Figure 5. Global Threshold</span></p>
</div><br clear="all">
<ul style="list-style:none;"><li>
<h4><a name="bookmark26"></a><span class="font1" style="font-weight:bold;"><a name="bookmark27"></a>2.3.4 &nbsp;&nbsp;&nbsp;Adaptive Thresholding</span></h4></li></ul>
<p><span class="font1">Adaptive Thresholding is a method of converting grayscale images into binary for condition images with varying contrast and lighting, a condition that makes it very difficult to separate pixels into background or foreground [15]. This method can apply by one of the following three formulas.</span></p>
<h2><a name="bookmark28"></a><span class="font9" style="font-style:italic;"><a name="bookmark29"></a>T </span><span class="font4" style="font-style:italic;">= </span><span class="font9" style="font-style:italic;text-decoration:underline;">∑</span><span class="font0" style="text-decoration:underline;">(</span><span class="font7" style="font-style:italic;text-decoration:underline;">x,y</span><span class="font0" style="text-decoration:underline;">)</span><span class="font9" style="font-style:italic;text-decoration:underline;">∑ </span><span class="font6" style="font-style:italic;text-decoration:underline;">∈</span><span class="font3" style="font-style:italic;text-decoration:underline;"> </span><span class="font9" style="font-style:italic;text-decoration:underline;">Wf</span><span class="font3" style="text-decoration:underline;">(</span><span class="font9" style="font-style:italic;text-decoration:underline;">χ<sup>,</sup>y</span><span class="font3" style="text-decoration:underline;">)</span><span class="font3"> </span><span class="font9" style="font-style:italic;">C</span></h2>
<div>
<p><span class="font1">(3)</span></p>
</div><br clear="all">
<div>
<p><span class="font1">(4)</span></p>
</div><br clear="all">
<p><span class="font9" style="font-style:italic;">N</span><span class="font7" style="font-style:italic;">W</span></p>
<p><span class="font1">Or</span></p>
<h2><a name="bookmark30"></a><span class="font9" style="font-style:italic;"><a name="bookmark31"></a>T</span><span class="font3"> = </span><span class="font9" style="font-style:italic;">median</span><span class="font3">{</span><span class="font9" style="font-style:italic;">f</span><span class="font3"> (</span><span class="font9" style="font-style:italic;">x,y</span><span class="font3">)</span><span class="font9" style="font-style:italic;">,</span><span class="font3">(</span><span class="font9" style="font-style:italic;">x,y</span><span class="font3">) </span><span class="font6" style="font-style:italic;">∈</span><span class="font3" style="font-style:italic;"> </span><span class="font9" style="font-style:italic;">W</span><span class="font3">}</span></h2>
<h2><a name="bookmark32"></a><span class="font9" style="font-style:italic;text-decoration:underline;"><a name="bookmark33"></a>max</span><span class="font3" style="text-decoration:underline;">{</span><span class="font9" style="font-style:italic;text-decoration:underline;">f</span><span class="font3" style="text-decoration:underline;"> (</span><span class="font9" style="font-style:italic;text-decoration:underline;">x,y</span><span class="font3" style="text-decoration:underline;">)</span><span class="font9" style="font-style:italic;text-decoration:underline;">,</span><span class="font3" style="text-decoration:underline;">(</span><span class="font9" style="font-style:italic;text-decoration:underline;">x,y</span><span class="font3" style="text-decoration:underline;">) </span><span class="font6" style="font-style:italic;text-decoration:underline;">∈</span><span class="font3" style="font-style:italic;text-decoration:underline;"> </span><span class="font9" style="font-style:italic;text-decoration:underline;">W</span><span class="font3" style="text-decoration:underline;">}+ </span><span class="font9" style="font-style:italic;text-decoration:underline;">min</span><span class="font3" style="text-decoration:underline;">{</span><span class="font9" style="font-style:italic;text-decoration:underline;">f</span><span class="font3" style="text-decoration:underline;"> (</span><span class="font9" style="font-style:italic;text-decoration:underline;">x,y</span><span class="font3" style="text-decoration:underline;">)</span><span class="font9" style="font-style:italic;text-decoration:underline;">,</span><span class="font3" style="text-decoration:underline;">(</span><span class="font9" style="font-style:italic;text-decoration:underline;">x,y</span><span class="font3" style="text-decoration:underline;">) </span><span class="font6" style="font-style:italic;text-decoration:underline;">∈</span><span class="font3" style="font-style:italic;text-decoration:underline;"> </span><span class="font9" style="font-style:italic;text-decoration:underline;">W</span><span class="font3" style="text-decoration:underline;">}</span></h2>
<h3><a name="bookmark34"></a><span class="font9"><a name="bookmark35"></a>2</span></h3>
<p><span class="font1">(5)</span></p>
<p><span class="font1">Parameter W is the block for processed, parameter NW is the number of pixels in each block W, C is a constant that can be determined freely. If C = 0, it means that the threshold value is equal to the average value of each pixel in the block concerned. The application of Adaptive Thresholding to the image dataset can see in Figure 6.</span></p>
<div><img src="https://jurnal.harianregional.com/media/78264-7.png" alt="" style="width:108pt;height:108pt;">
<p><span class="font1">Figure 6. AdaptiveThreshold</span></p>
</div><br clear="all">
<ul style="list-style:none;"><li>
<h4><a name="bookmark36"></a><span class="font1" style="font-weight:bold;"><a name="bookmark37"></a>3. &nbsp;&nbsp;&nbsp;Result</span></h4></li></ul>
<p><span class="font1">The results and discussion explain the comparison between recognition without preprocessing and preprocessing methods for ASL sign language number classification using convolutional neural network architecture mobilenetv2. The test data used amounted to 100 images divided for each class. The detail in one class is ten images. The results of this research comparison can see in table 1.</span></p>
<table border="1">
<tr><td style="vertical-align:bottom;">
<p><span class="font1" style="font-weight:bold;">Scenario</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1" style="font-weight:bold;">Epoch</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1" style="font-weight:bold;">Accuracy</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font1">Original image</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">50</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">88%</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font1">Grayscale+HSV+Global Threshold</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">50</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">95%</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font1">Grayscale+HSV+Adaptive Thresholding</span></p></td><td style="vertical-align:top;">
<p><span class="font1">50</span></p></td><td style="vertical-align:top;">
<p><span class="font1">97%</span></p></td></tr>
</table>
<p><span class="font1">The results of the trials are resulted in 88% for a condition without applying Preprocessing. The second scenario is a scenario of applied Grayscale, HSV and, Global Threshold resulted in a classification accuracy of 97%. The last scenario is a scenario of applied Grayscale, HSV, and Adaptive Thresholding preprocessing obtained an accuracy of 95%. When viewed from the accuracy of the Grayscale, HSV, and Global Threshold scenarios, we get the best accuracy. Detailed results for the best scenario can see in the Confusion matrix in the image.</span></p><img src="https://jurnal.harianregional.com/media/78264-8.jpg" alt="" style="width:263pt;height:239pt;">
<p><span class="font1">Figure 7. </span><span class="font1" style="font-style:italic;">Confusion matrix</span></p>
<p><span class="font1">Figure 7 is a Confusion matrix for the results of the Grayscale, HSV, Global Threshold scenario. The results obtained are that there are three prediction errors by the system. The error is in the number five class with one wrong. An error resulted in the prediction number is four instead of five. The error is in the number six class with one wrong prediction. An error resulted in the prediction number is four instead of six. The error is in the number nine class with one error prediction. An error resulted in the prediction number is four instead of nine. The comparison of the graph of accuracy and validation accuracy can see in Figure 8. Figure 7 is a Confusion matrix for the results of the Grayscale, HSV, Global Threshold scenario. The results obtained is it found three mistake predictions from system. The first error at number five class with one mistake that is prediction system choose number four instead of number five. The second error at number six class with one mistake prediction that is prediction system choose number four instead of number six. The last error at number nine class with one mistake that is prediction system choose number four instead of number nine. The comparison of the graph of accuracy and validation accuracy can see in Figure 8.</span></p>
<div><img src="https://jurnal.harianregional.com/media/78264-9.jpg" alt="" style="width:392pt;height:84pt;">
<p><span class="font1">(a)</span></p>
<p><span class="font1">(b)</span></p>
<p><span class="font1">(c)</span></p>
<p><span class="font1">Figure 8. Training accuracy and validation accuracy (a) Original Image, (b) Grayscale+HSV+Global Threshold, (c) Grayscale+HSV+Adaptive Thresholding</span></p>
</div><br clear="all">
<p><span class="font1">Figure 8 is a graph comparison of training accuracy and validation accuracy for the three scenarios. The original image scenario graph shows a stable training accuracy graph but unstable validation accuracy. The Grayscale, HSV, and Global Threshold scenario graphs show the stability of the training accuracy graph, and the validation accuracy graph line starts to stabilize from epoch 15. The Grayscale, HSV, Adaptive Threshold scenario graph shows a stable training accuracy graph, and the validation accuracy graph line starts to stabilize from epoch 35. Loss graph training and Loss validation can see in Figure 9.</span></p>
<div><img src="https://jurnal.harianregional.com/media/78264-10.jpg" alt="" style="width:119pt;height:84pt;">
<p><span class="font1">(a)</span></p>
</div><br clear="all">
<div><img src="https://jurnal.harianregional.com/media/78264-11.jpg" alt="" style="width:119pt;height:84pt;">
<p><span class="font1">(b)</span></p>
</div><br clear="all">
<div><img src="https://jurnal.harianregional.com/media/78264-12.jpg" alt="" style="width:119pt;height:84pt;">
<p><span class="font1">(c)</span></p>
</div><br clear="all">
<p><span class="font1">Figure 9. Loss dan Loss validation (a) Original Image, (b) Grayscale+HSV+Global Threshold, (c) Grayscale+HSV+Adaptive Thresholding</span></p>
<p><span class="font1">Figure 9 is a comparison of loss training and loss validation graphs for the three scenarios. The original image scenario graph shows the loss training graph is stable decrease, but for validation accuracy, it is not stable from the beginning to the end. The Grayscale, HSV, Global Threshold scenario graph shows a stable loss training graph, and the loss validation graph line starts to stabilize and continues to decrease from epoch 15. The Grayscale, HSV, Adaptive Threshold graph shows a stable loss training graph, and the loss validation graph line starts to stabilize steadily decreasing from epoch 35.</span></p>
<ul style="list-style:none;"><li>
<h4><a name="bookmark38"></a><span class="font1" style="font-weight:bold;"><a name="bookmark39"></a>4. &nbsp;&nbsp;&nbsp;Conclusion</span></h4></li></ul>
<p><span class="font1">This research has developed a system for the recognition or classification of a sign language number image. The recognition system developing is a system that uses a convolutional neural network with the Mobilenetv2 architecture as the basis. The basis of the system must also be supported by preprocessing to improve the results of recognition or classification accuracy. This reason makes this research focus on developing a combination of preprocessing that can improve accuracy results. This study decided to apply two scenario combinations of Preprocessing, namely a combination of Grayscale, HSV, and Global Threshold and a scenario combination of Grayscale, HSV, and adaptive Threshold. These two combinations will be compared for accuracy once applied to the system. This study uses a dataset with ASL standards. Total dataset of 2062 images divided into ten classes. The experiment this research using the number of test data, namely 100 images. The final result of this study succeeded in developing a system for sign language number recognition with a recognition accuracy of 97%. These results get with a developing system that applies the convolutional neural network architecture of mobilenetv2 by optimizing it with a combination of preprocessing. The preprocessing combination that gives the best improvement is the scenario combination of Grayscale, HSV, and adaptive Threshold preprocessing.</span></p>
<p><span class="font1" style="font-weight:bold;">References</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1">[1] &nbsp;&nbsp;&nbsp;Miskudin Taufik, “Bahasa Isyarat Menyatukan Dunia,” Oct. 13, &nbsp;&nbsp;&nbsp;2020.</span></p></li></ul>
<p><a href="https://itjen.kemdikbud.go.id/public/post/detail/bahasa-isyarat-menyatukan-dunia"><span class="font1">https://itjen.kemdikbud.go.id/public/post/detail/bahasa-isyarat-menyatukan-dunia</span></a><span class="font1"> (accessed Jul. 26, 2021).</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1">[2] &nbsp;&nbsp;&nbsp;X. Luo, X. Qin, Z. Wu, F. Yang, M. Wang, and J. Shang, “Sediment Classification of Small-Size Seabed Acoustic Images Using Convolutional Neural Networks,” </span><span class="font1" style="font-style:italic;">IEEE Access</span><span class="font1">, vol. 7, pp. 98331– 98339, 2019, doi: 10.1109/ACCESS.2019.2927366.</span></p></li>
<li>
<p><span class="font1">[3] &nbsp;&nbsp;&nbsp;V. Borate, S. Patange, V. Vede, and O. Kale, “An Image Classification Based on CNN Approach For Plant Leaf Disease Detection,” vol. 4, no. 6, p. 3, 2018.</span></p></li>
<li>
<p><span class="font1">[4] &nbsp;&nbsp;&nbsp;S. Z. M. Zaki, M. Asyraf Zulkifley, M. Mohd Stofa, N. A. M. Kamari, and N. Ayuni Mohamed, “Classification of tomato leaf diseases using MobileNet v2,” </span><span class="font1" style="font-style:italic;">IJ-AI</span><span class="font1">, vol. 9, no. 2, p. 290, Jun. 2020, doi: 10.11591/ijai.v9.i2.pp290-296.</span></p></li>
<li>
<p><span class="font1">[5] &nbsp;&nbsp;&nbsp;I. K. G. Darma Putra, R. Fauzi, D. Witarsyah, and I. P. D. Jayantha Putra, “Classification of Tomato Plants Diseases Using Convolutional Neural Network,” </span><span class="font1" style="font-style:italic;">International Journal on Advanced Science, Engineering and Information Technology</span><span class="font1">, vol. 10, no. 5, p. 1821, Oct. 2020, doi: 10.18517/ijaseit.10.5.11665.</span></p></li>
<li>
<p><span class="font1">[6] &nbsp;&nbsp;&nbsp;Computer Science and Engineering Department, National Institute of Technology Manipur, Imphal, 795001, India, R. Meitram, and P. Choudhary, “Palm Vein Recognition Based on 2D Gabor Filter and Artificial Neural Network,” </span><span class="font1" style="font-style:italic;">JAIT</span><span class="font1">, vol. 9, no. 3, pp. 68–72, 2018, doi: 10.12720/jait.9.3.68-72.</span></p></li>
<li>
<p><span class="font1">[7] &nbsp;&nbsp;&nbsp;M. Hurroo and M. E. Walizad, “Sign Language Recognition System using Convolutional Neural Network and Computer,” </span><span class="font1" style="font-style:italic;">International Journal of Engineering Research</span><span class="font1">, vol. 9, no. 12, p. 6.</span></p></li>
<li>
<p><span class="font1">[8] &nbsp;&nbsp;&nbsp;A. Mavi, “A New Dataset and Proposed Convolutional Neural Network Architecture for Classification of American Sign Language Digits,” p. 5.</span></p></li>
<li>
<p><span class="font1">[9] &nbsp;&nbsp;&nbsp;J. W. Gotama Putra, </span><span class="font1" style="font-style:italic;">Pengenalan Konsep Pembelajaran Mesin dan Deep Learning</span><span class="font1">, 1.4. 2020. [Online]. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Available:</span></p></li></ul>
<p><a href="https://www.researchgate.net/publication/323700644_Pengenalan_Pembelajaran_Mesin_dan_Dee"><span class="font1">https://www.researchgate.net/publication/323700644_Pengenalan_Pembelajaran_Mesin_dan_Dee</span></a><span class="font1"> p_Learning</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1">[10] &nbsp;&nbsp;&nbsp;Md. M. Kabir, A. Q. Ohi, Md. S. Rahman, and M. F. Mridha, “An Evolution of CNN Object Classifiers on Low-Resolution Images,” in </span><span class="font1" style="font-style:italic;">2020 IEEE 17th International Conference on Smart Communities: Improving Quality of Life Using ICT, IoT and AI (HONET)</span><span class="font1">, Charlotte, NC, USA, Dec. 2020, pp. 209– 213. doi: 10.1109/HONET50430.2020.9322661.</span></p></li>
<li>
<p><span class="font1">[11] &nbsp;&nbsp;&nbsp;F. Sultana, A. Sufian, and P. Dutta, “Advancements in Image Classification using Convolutional Neural Network,” </span><span class="font1" style="font-style:italic;">2018 Fourth International Conference on Research in Computational Intelligence and Communication Networks &nbsp;&nbsp;(ICRCICN)</span><span class="font1">, &nbsp;&nbsp;pp. 122–129, Nov. 2018, doi:</span></p></li></ul>
<p><span class="font1">10.1109/ICRCICN.2018.8718718.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1">[12] &nbsp;&nbsp;&nbsp;M. Sandler, A. Howard, M. Zhu, A. Zhmoginov, and L.-C. Chen, “MobileNetV2: Inverted Residuals and Linear Bottlenecks,” </span><span class="font1" style="font-style:italic;">arXiv:1801.04381 [cs]</span><span class="font1">, Mar. 2019, Accessed: Feb. 02, 2021. [Online]. Available: </span><a href="http://arxiv.org/abs/1801.04381"><span class="font1">http://arxiv.org/abs/1801.04381</span></a></p></li>
<li>
<p><span class="font1">[13] &nbsp;&nbsp;&nbsp;R. C. N. Santi, S. Pd, and M. Kom, “Mengubah Citra Berwarna Menjadi GrayScale dan Citra biner,” vol. 16, p. 6, 2011.</span></p></li>
<li>
<p><span class="font1">[14] &nbsp;&nbsp;&nbsp;K. Bhargavi and S. Jyothi, “A Survey on Threshold Based Segmentation Technique in Image Processing,” vol. 3, no. 12, p. 7, 2014.</span></p></li>
<li>
<p><span class="font1">[15] &nbsp;&nbsp;&nbsp;N. P. Sutramiani, Ik. G. Darmaputra, and M. Sudarma, “Local Adaptive Thresholding Pada Preprocessing Citra Lontar Aksara Bali,” </span><span class="font1" style="font-style:italic;">JTE</span><span class="font1">, vol. 14, no. 1, Jun. 2015, doi: 10.24843/MITE.2015.v14i01p06.</span></p></li></ul>