---
layout: full_article
title: "Klasifikasi kebakaran hutan menggunakan algoritma C4.5 dan Rough Set"
author: "Arif budiman"
categories: jik
canonical_url: https://jurnal.harianregional.com/jik/full-83447 
citation_abstract_html_url: "https://jurnal.harianregional.com/jik/id-83447"
citation_pdf_url: "https://jurnal.harianregional.com/jik/full-83447"  
comments: true
---

<p><span class="font2">Jurnal Ilmu Komputer VOL. 15. Nomor 1</span></p>
<p><span class="font2">p-ISSN: 1979-5661</span></p>
<p><span class="font2">e-ISSN: 2622-321X</span></p><a name="caption1"></a>
<h2><a name="bookmark0"></a><span class="font4" style="font-weight:bold;"><a name="bookmark1"></a>Klasifikasi Kebakaran Hutan Menggunakan Algoritma C4.5 dan Rough Set</span></h2>
<p><span class="font2">Arif Budiman<sup>a1 a</sup>Fakultas Ekonomi, Universitas Muhammadiyah Berau Tanjung Redeb, Indonesia </span><a href="mailto:1arif_budiman@umberau.ac.id"><span class="font2" style="text-decoration:underline;"><sup>1</sup>arif_budiman@umberau.ac.id</span></a></p>
<p><span class="font2" style="font-weight:bold;font-style:italic;">Abstract</span></p>
<p><span class="font2" style="font-style:italic;">In recent years there have been large-scale forest fires in forested areas of the world. Forest fires are a major environmental problem that has big impact on wildlife, human health, economic. One solution can be taken is using classification algorithm to predict forest fires based on historical forest fire data.</span></p>
<p><span class="font2" style="font-style:italic;">In this research using C4.5 Algorithm combined with Rough Set as feature selection to classify forests fire. Evaluate performance based on created model using confusion matrix to calculate accuracy value.</span></p>
<p><span class="font2" style="font-style:italic;">The results show the C4.5 algorithm with Rough Set as feature selection was found accuracy 98.36%. The use of Rough Set as feature selection can reduce irrelevant attributes effectively.</span></p>
<p><span class="font2" style="font-weight:bold;font-style:italic;">Keywords: </span><span class="font2" style="font-style:italic;">classification,forest fire, c4.5 algoritm, rough set</span></p>
<p><span class="font2" style="font-style:italic;">Abstrak</span></p>
<p><span class="font2" style="font-style:italic;">Beberapa tahun terakhir telah terjadi kebakaran hutan dalam skala yang luas di kawasan berhutan di seluruh dunia. Kebakaran hutan merupakan masalah lingkungan utama yang miliki dampak yang besar terhadap kesehatan manusia, ekosistem satwa liar dan kondisi ekonomi oleh karena sebab itu perlunya dilakukan suatu pecegahan agar masalah tersebut dapat diatasi. Salah satu langkah dapat dilakukan yaitu menggunakan algoritma klasifikasi untuk melakukan prediksi kebakaran hutan berdasarkan riwayat data insiden kebakaran hutan.</span></p>
<p><span class="font2" style="font-style:italic;">Penelitian ini menggunakan Algorima C4.5 yang dikombinasikan dengan Rough Set sebagai seleksi fitur untuk klasifikasi kebakaran hutan. Mengevaluasi performa terhadap model yang telah dibuat digunakan confusion matrix untuk menghitung nilai akurasi.</span></p>
<p><span class="font2" style="font-style:italic;">Hasil pengujian menunjukan algoritma C4.5 dengan Rough Set sebagai seleksi fitur menghasilkan nilai akurasi 98</span><span class="font2">.36</span><span class="font2" style="font-style:italic;">%. Penggunaan Rough Set sebagai seleksi mampu mengurangi atribut yang tidak relevan secara efektif.</span></p>
<p><span class="font2" style="font-weight:bold;font-style:italic;">Kata kunci</span><span class="font2" style="font-style:italic;">: klasifikasi, kebakaran hutan, algorima c4.5, rough set</span></p>
<ul style="list-style:none;"><li>
<h4><a name="bookmark2"></a><span class="font2" style="font-weight:bold;"><a name="bookmark3"></a>1. &nbsp;&nbsp;&nbsp;PENDAHULUAN</span></h4></li></ul>
<p><span class="font2">Beberapa tahun terakhir telah terjadi kebakaran hutan dalam skala yang luas di kawasan berhutan di seluruh dunia[1]. Kebakaran hutan merupakan masalah lingkungan utama yang miliki dampak yang besar terhadap kesehatan manusia, ekosistem satwa liar dan kondisi ekonomi[2]. Kebakaran hutan juga sering terjadi karena pembukaan lahan liar dengan cara membakar hutan untuk digunakan sebagai lahan perkebunan atau pertanian [3].</span></p>
<p><span class="font2">Mengingat dampak yang dapat ditimbulkan akibat kebakaran hutan sangat besar apalagi hal tersebut dapat diperparah saat memasuki musim kemarau maka perlulah dilakukan suatu pecegahan agar masalah tersebut dapat diatasi. Salah satu langkah dapat dilakukan yaitu menggunakan algoritma klasifikasi untuk melakukan prediksi kebakaran hutan berdasarkan riwayat data insiden kebakaran hutan[1][3].</span></p>
<p><span class="font2">Algoritma C4.5 adalah algoritma klasifikasi yang digunakan untuk menghasilkan pohon keputusan. Pohon keputusan yang terbentuk dapat digunakan untuk prediksi, misalnya memprediksi minat dari peserta didik dalam menentukan jenis sekolah[4]. Algoritma C4.5 terbukti menunjukan tingkat akurasi paling baik dibandingkan algoritma klasifikasi lainnya seperti naive</span></p>
<p><span class="font2">bayes dan neural network[5]. Untuk dapat memperoleh hasil klasifikasi yang akurat membutuhkan preprocessing yang baik. Metode diskretisasi data dan seleksi fitur dipilih karena memiliki peran yang sangat penting didalam tahapan preprocessing data[6]</span></p>
<p><span class="font2">. Diskritisasi data adalah pengelompokan atribut yang memiliki nilai kontinyu dengan cara membagi rentang tersebut menjadi satu set interval terbatas secara terpisah dan kemudian diasosiasikan dengan label, untuk disriktisasi data dalam penelitian ini mengunakan k-means untuk mengelompokan atribut yang memiliki data kontinyu[7][8]. Seleksi fitur digunakan untuk memperoleh atribut optimal yang akan digunakan untuk klasifikasi dengan cara mengurangi atribut yang tidak relevan terhadap kelas. Metode seleksi fitur berkontribusi meningkatkan algoritma klasifikasi[6]. Seleksi fitur menggunakan Rough Set dapat meningkatkan nilai akurasi dari algoritma klasifikasi yang digunakan[9]</span></p>
<p><span class="font2">Berdasarkan masalah tersebut penulis menggunakan Algorima C4.5 untuk klasifikasi kebakaran hutan yang dikombinasikan dengan Rough Set sebagai seleksi fitur.</span></p>
<ul style="list-style:none;"><li>
<h4><a name="bookmark4"></a><span class="font2" style="font-weight:bold;"><a name="bookmark5"></a>2. &nbsp;&nbsp;&nbsp;METODE PENELITIAN</span></h4></li></ul>
<p><span class="font2">Penelitian ini menggunakan algoritma C4.5 yang dikombinasikan dengan Rough Set sebagai seleksi fitur. Didalam tahapan preprocessing data digunakan algoritma K-means untuk merubah data bertipe kontinyu menjadi data diskrit. Untuk mengevaluasi model yang telah dibuat digunakan confusion martix untuk menghitung tingkat akurasi. Alur penelitian ini ditampilkan pada gambar 1</span></p><img src="https://jurnal.harianregional.com/media/83447-1.jpg" alt="" style="width:171pt;height:334pt;">
<p><span class="font2" style="font-weight:bold;">Gambar 1. </span><span class="font2">Alur Penelitian</span></p>
<ul style="list-style:none;"><li>
<h4><a name="bookmark6"></a><span class="font2" style="font-weight:bold;"><a name="bookmark7"></a>2.1. &nbsp;&nbsp;&nbsp;Pembersihan Data</span></h4></li></ul>
<p><span class="font2">Pembersihan data adalah tahapan membuang data berganda agar tidak adanya duplikasi data, membuang data yang tidak konsisten, dan memperbaiki kesalahan penulisan yang ditemukan pada data.</span></p>
<ul style="list-style:none;"><li>
<h4><a name="bookmark8"></a><span class="font2" style="font-weight:bold;"><a name="bookmark9"></a>2.2. &nbsp;&nbsp;&nbsp;Diskritisasi Data</span></h4></li></ul>
<p><span class="font2">Diskritisasi data adalah metode yang digunakan untuk mengurangi jumlah nilai yang berbeda untuk atribut yang memiliki nilai kontinyu dan membagi rentang tersebut menjadi satu set interval terbatas secara terpisah dan kemudian mengasosiasikan interval ini dengan label, sehingga mengurangi kebutuhan memori sistem dan meningkatkan efisiensi algoritma[10]. Pada penenlitian ini menggunakan k-means untuk mengelompokan data kontinyu menjadi data diskrit.</span></p>
<p><span class="font2">K-Means adalah metode klasterisasi data berbasis partisi yang menggunakan k sebagai jumlah dari klaster data. metode ini membagi data menjadi beberapa kelompok yang memiliki suatu nilai kedekatan. Klasterisasi data menggunakan k-means dengan cara perhitungan secara terus-menerus terhadap pusat centroid pada masing-masing klaster sampai tidak ada perubahan data yang terjadi.[7][8]. Menghitung nilai centroid pada masing-masing klaster dengan persamaan (1)</span></p>
<div>
<p><span class="font9" style="font-style:italic;">c</span><span class="font7" style="font-style:italic;">i</span><span class="font10"> = </span><span class="font9">min</span><span class="font10">+</span></p>
</div><br clear="all">
<p><span class="font3" style="font-style:italic;">(</span><span class="font9" style="font-style:italic;">i</span><span class="font10"> -</span><span class="font9">1</span><span class="font3">) </span><span class="font9">* </span><span class="font3">(</span><span class="font9">max </span><span class="font10">- </span><span class="font9">min</span><span class="font3">) (</span><span class="font9">max </span><span class="font10">- </span><span class="font9">min</span><span class="font3">)</span></p>
<p><span class="font9" style="font-style:italic;">n</span><span class="font9"> 2*</span><span class="font9" style="font-style:italic;">n</span></p>
<div>
<p><span class="font2">(1)</span></p>
</div><br clear="all">
<p><span class="font2">Keterangan</span></p>
<p><span class="font2">ci : centoroid dari class i</span></p>
<p><span class="font2">max : nilai tertinggi dari class data kontinyu</span></p>
<p><span class="font2">min : nilai terendah dari class data kontinyu n : jumlah dari kelas diskrit</span></p>
<p><span class="font2">selanjutnya dilakukan perhitungan jarak menggunakan euclidean distance. Hasil pengelompokan data berdasarkan jarak terpendek antara data dan centroid yang dikelompokan pada masing-masing klaster. Untuk menghitung euclidean distance menggunakan persamaan 2</span></p>
<div>
<h3><a name="bookmark10"></a><span class="font9" style="font-style:italic;"><a name="bookmark11"></a>d<sub>j</sub></span><span class="font10"> =</span></h3>
</div><br clear="all">
<div>
<p><span class="font8" style="font-style:italic;"><sup>p</sup></span></p><a name="caption2"></a>
<h1><a name="bookmark12"></a><span class="font5"><a name="bookmark13"></a>1 ∑(</span><span class="font11" style="font-style:italic;">x</span><span class="font9" style="font-style:italic;">ik</span></h1>
<p><span class="font6" style="font-style:italic;">∖</span><span class="font9" style="font-style:italic;"> k</span><span class="font10">=</span><span class="font9">1</span></p>
</div><br clear="all">
<div>
<p><span class="font11" style="font-style:italic;">x</span><span class="font9" style="font-style:italic;">ij</span></p>
</div><br clear="all">
<div>
<p><span class="font2">(2)</span></p>
</div><br clear="all">
<p><span class="font2">Keterangan</span></p>
<p><span class="font2">dij : jarak antara objek i dan objek j</span></p>
<ul style="list-style:none;"><li>
<p><span class="font2">p : dimensi data</span></p></li></ul>
<p><span class="font2">xik &nbsp;&nbsp;: kordinat dari objek i dalam dimensi k</span></p>
<p><span class="font2">xij &nbsp;&nbsp;&nbsp;: kordinat dari objek j dalam dimensi k</span></p>
<p><span class="font2">Apabila masih terdapat perpindahan data dalam klaster atau nilai centroid yang berubah maka perlu dilakukan perhitung kembali hingga tidak adanya perubahan data atau menghasilkan data yang konvergen.</span></p>
<ul style="list-style:none;"><li>
<h4><a name="bookmark14"></a><span class="font2" style="font-weight:bold;"><a name="bookmark15"></a>2.3. &nbsp;&nbsp;&nbsp;Seleksi Fitur</span></h4></li></ul>
<p><span class="font2">Seleksi fitur sering digunakan dalam tahap preprocessing data. metode ini mengidentifikasi relevansi dari atribut yang digunakan terhadap class data dan membuang semua atribut yang tidak relevan. Tujuan seleksi fitur adalah mengurangi dimensi data agar algoritma data mining dapat berjalan lebih cepat[8][11]. Pada penelitian ini menggunakan Rough Set untuk memilih atribut terbaik yang akan digunakan untuk klasifikasi.</span></p>
<p><span class="font2">Rough Set telah banyak diterapkan dalam berbagai bidang seperti untuk seleksi fitur, klasifikasi, pencarian pola [12]. Data didalam Rough Set direpresentasikan kedalam bentuk tabel, dimana baris dalam tabel merepresentasikan objek dan kolom merepresentasikan atribut dari</span></p>
<p><span class="font2">objek tersebut. Tabel yang terbentuk dinamakan information system. Information system digambarkan menggunakan persamaan 3</span></p>
<p><span class="font9" style="font-style:italic;">IS</span><span class="font2"> = </span><span class="font9" style="font-style:italic;">(U</span><span class="font9">, </span><span class="font9" style="font-style:italic;">A</span><span class="font9">) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="font2">(3)</span></p>
<p><span class="font2">Keterangan :</span></p>
<p><span class="font2">U &nbsp;&nbsp;&nbsp;: Universe</span></p>
<p><span class="font2">A &nbsp;&nbsp;&nbsp;&nbsp;: Atribut</span></p>
<p><span class="font2">Setelah information system terbentuk, selanjutnya dilakukan perhitungan Discernibility Matrix untuk membandingkan isi sebuah atribut antara suatu objek dengan objek lainnya. Dalam perbandingan data apabila memiliki nilai yang sama maka tidak akan menghasilkan nilai, sebaliknya jika memiliki nilai yang berbeda akan menghasilkan suatu nilai. Langkah terakhir adalah melakukan reduksi untuk menseleksi atribut minimal dari sekumpulan atribut kondisi dengan menggunakan Prime Implicant fungsi Boolean. Kumpulan dari Prime Implicant tersebut kemudian menghasilkan set reduksi yang akan digunakan sebagai seleksi fitur[12]</span></p>
<ul style="list-style:none;"><li>
<p><span class="font2" style="font-weight:bold;">2.4. &nbsp;&nbsp;&nbsp;Penambangan Data</span></p></li></ul>
<p><span class="font2">Algoritma C4.5 merupakan pengembangan dari alogritma ID3, namun yang membedakannya dengan ID3 adalah penggunaan gain ratio untuk melakukan pemisahan bukan menggunakan information gain seperti pada algoritma ID3. Algoritma C4.5 digunakan untuk membentuk pohon keputusan. Dalam Pohon keputusan yang terbentuk terdiri dari akar, cabang dan daun[7][10]. Cara kerja pohon keputusan adalah dengan melakukan penelusuran dari akar menuju cabang hingga menemukan class dari objek tersebut [5][8]. Langkah awal yang dilakukan adalah menghitung nilai entropy dari dataset kebakaran hutan menggunakan permasaan 4.</span></p>
<p><span class="font9" style="font-style:italic;">n</span></p>
<p><span class="font9" style="font-style:italic;">Entropy</span><span class="font9"><sup>(</sup></span><span class="font9" style="font-style:italic;">S</span><span class="font9">) </span><span class="font10">= ∑ <sup>-</sup></span><span class="font9" style="font-style:italic;">p<sub>i</sub> *</span><span class="font9"> Iog<sub>2</sub> </span><span class="font9" style="font-style:italic;">p<sub>i</sub></span><span class="font2"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(4)</span></p>
<p><span class="font9" style="font-style:italic;">i</span><span class="font1"> =</span><span class="font7">1</span></p>
<p><span class="font2">Keterangan :</span></p>
<p><span class="font2">S &nbsp;&nbsp;&nbsp;: himpuanan kasus</span></p>
<p><span class="font2">n &nbsp;&nbsp;&nbsp;&nbsp;: jumlah partisi s</span></p>
<p><span class="font2">pi &nbsp;&nbsp;&nbsp;&nbsp;: proporsi S</span><span class="font0">i </span><span class="font2">terhadap S</span></p>
<p><span class="font2">Setelah nilai entropi ditemukan, Selanjutnya dilakukan perhitungan nilai information gain dari dataset kebakaran hutan menggunakan persamaan 5.</span></p>
<p><span class="font9">I </span><span class="font9" style="font-style:italic;">S</span><span class="font9"> L</span></p>
<p><span class="font9" style="font-style:italic;">Gain</span><span class="font9">(</span><span class="font9" style="font-style:italic;">S</span><span class="font9">, </span><span class="font9" style="font-style:italic;">A</span><span class="font9">) </span><span class="font10">= </span><span class="font9" style="font-style:italic;">Entropy</span><span class="font9"> (</span><span class="font9" style="font-style:italic;">S</span><span class="font9">) - ^----* </span><span class="font9" style="font-style:italic;">Entropy</span><span class="font9"> (</span><span class="font9" style="font-style:italic;">S<sub>1</sub></span><span class="font9">∙) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="font2">(5)</span></p>
<p><span class="font7" style="font-style:italic;">i</span><span class="font1">=</span><span class="font7">1</span><span class="font9">1</span><span class="font9" style="font-style:italic;">S</span><span class="font9">I</span></p>
<p><span class="font2">Keterangan :</span></p>
<ul style="list-style:none;"><li>
<p><span class="font2">n &nbsp;&nbsp;&nbsp;&nbsp;: jumlah partisi atribut</span></p></li></ul>
<p><span class="font2">|S</span><span class="font0">i</span><span class="font2">| &nbsp;&nbsp;&nbsp;: proporsi S</span><span class="font0">i </span><span class="font2">terhadap S</span></p>
<p><span class="font2">|S| &nbsp;&nbsp;: jumlah kasus dalam S</span></p>
<p><span class="font2">Nilai information gain yang telah terbentuk selanjutnya digunakan untuk mencari nilai split information dengan menggunakan persamaan 6</span></p>
<p><span class="font9">&quot; I </span><span class="font9" style="font-style:italic;">S</span><span class="font9"> I I </span><span class="font9" style="font-style:italic;">S</span><span class="font9"> I</span></p>
<p><span class="font9" style="font-style:italic;">Splitinformation</span><span class="font9"> (</span><span class="font9" style="font-style:italic;">S, A</span><span class="font9">) </span><span class="font10">= V —— </span><span class="font9">* log<sub>2</sub> —— </span><span class="font10">∑</span><span class="font9">I </span><span class="font9" style="font-style:italic;">S</span><span class="font9">I I</span><span class="font9" style="font-style:italic;">S</span><span class="font9">I</span></p>
<div>
<p><span class="font2">(6)</span></p>
</div><br clear="all">
<p><span class="font2">Perhitungan terakhir untuk mencari nilai gain ratio dengan cara membagi information gain dengan split information. nilai gain ratio yang telah terbentuk kemudian dibandingan untuk mencari nilai gain ratio tertinggi yang akan digunakan sebagai akar. gain ratio dihitung menggunakan persamaan 7.</span></p>
<p><span class="font9" style="font-style:italic;">GainRatio</span><span class="font9"> (</span><span class="font9" style="font-style:italic;">S, A</span><span class="font9">) =-----</span><span class="font9" style="font-style:italic;">G<sup>ain</sup>(S<sub>1</sub>A)-----</span></p>
<div>
<p><span class="font2">(7)</span></p>
</div><br clear="all">
<p><span class="font9" style="font-style:italic;">Splitinformation</span><span class="font9"> (</span><span class="font9" style="font-style:italic;">S</span><span class="font9">, </span><span class="font9" style="font-style:italic;">A</span><span class="font9">)</span></p>
<p><span class="font2">Setelah akar ditemukan selanjutnya, proses perhitungan kemudian dilanjutkan untuk mencari cabang dan daun hingga menghasilkan sebuah pohon keputusan</span></p>
<ul style="list-style:none;"><li>
<h4><a name="bookmark16"></a><span class="font2" style="font-weight:bold;"><a name="bookmark17"></a>2.5. &nbsp;&nbsp;&nbsp;Evaluasi</span></h4></li></ul>
<p><span class="font2">Dalam penelitian ini menggunakan confusion matrix untuk evaluasi performa dari model yang telah dibuat. Nilai pada Confusion matrix deperolah berdasarkan hasil perbandingan data aktul dan data prediksi yang memiliki nilai benar ataupun salah. Hasil evaluasi confusion matrix ditampilkan pada tabel 1</span></p>
<p><span class="font2" style="font-weight:bold;">Tabel 1. </span><span class="font2">Confusion Matrix</span></p>
<table border="1">
<tr><td rowspan="2" style="vertical-align:bottom;">
<p><span class="font2">Aktual</span></p></td><td colspan="2" style="vertical-align:bottom;">
<p><span class="font2">Prediksi</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2">Positif</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">Negatif</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2">Positif</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">TP</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">FN</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2">Negatif</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">FP</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">TN</span></p></td></tr>
</table>
<p><span class="font2">berdasarkan tabel confussion matrix yang terbentuk selanjutnya dapat dilakukan perhitungan akurasi terhadap algoritma klasifikasi yang digunakan dengan menggunakan persamaan 8</span></p>
<div>
<p><span class="font9" style="font-style:italic;">Akurasi</span><span class="font2"> =</span></p>
</div><br clear="all">
<div>
<p><span class="font9" style="font-style:italic;">TP</span><span class="font2"> + </span><span class="font9" style="font-style:italic;">TN</span></p>
<p><span class="font9" style="font-style:italic;">TP</span><span class="font2"> + </span><span class="font9" style="font-style:italic;">TN</span><span class="font2"> + </span><span class="font9" style="font-style:italic;">FP</span><span class="font2"> + </span><span class="font9" style="font-style:italic;">FN</span></p>
</div><br clear="all">
<div>
<p><span class="font2">×</span><span class="font9">100%</span></p>
</div><br clear="all">
<div>
<p><span class="font2">(8)</span></p>
</div><br clear="all">
<p><span class="font2">Keterangan :</span></p>
<p><span class="font2">TP (True Positive) : Jumlah class aktual positif yang diprediksi benar TN (True Negative) : Jumlah class aktual negatif yang diprediksi benar FP (False Positive) : Jumlah class aktual negatif yang diprediksi salah FN (False Negative) : Jumlah class aktual positif yang diprediksi salah</span></p>
<ul style="list-style:none;"><li>
<p><span class="font2" style="font-weight:bold;">3. &nbsp;&nbsp;&nbsp;HASIL DAN PEMBAHASAN</span></p>
<ul style="list-style:none;">
<li>
<h4><a name="bookmark18"></a><span class="font2" style="font-weight:bold;"><a name="bookmark19"></a>3.1. &nbsp;&nbsp;&nbsp;Seleksi Data</span></h4></li></ul></li></ul>
<p><span class="font2">Dalam penelitian ini menggunakan dataset kebakaran hutan yang diperoleh dari UCI Machine Learning Respository dengan nama “Algerian Forest Fire”, dataset yang dikumpulkan terdiri dari 244 record dengan 11 kategori data yaitu, Temprature (Temp), Relative Humidity (RH), Wind Speed (WS), Rain, Fine Fuel Moisture Code (FFMC), Duff Moisture Code (DMC), Drought Code (DC), Initial Spread Index (ISI), Buildup Index (BUI), Fire Weather Index (FWI), data tersebut dikelompokan menjadi 2 kategori yaitu fire dan not fire. Berikut adalah tabel deksripsi dataset kebakaran hutan ditampilkan pada tabel 2</span></p>
<p><span class="font2" style="font-weight:bold;">Tabel 2. </span><span class="font2">Deskripsi Dataset</span></p>
<table border="1">
<tr><td style="vertical-align:bottom;">
<p><span class="font2">Nama Atribut</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">Rentang Nilai</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2">Temprature (C<sup>o</sup>)</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">22-42</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2">Relative Humidity (%)</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">21-90</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2">Wind Speed (km/jam)</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">6-29</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2">Rain (mm)</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">0-16.8</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2">Fine Fuel Moisture Code</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">28.6-96</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2">Duff Moisture Code</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">0.7-65.9</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2">Drought Code</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">6.9-220.4</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2">Initial Spread Index</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">0-19</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2">Buildup Index</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">1.1-68</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2">Fire Weather Index</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">0-31.1</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font2">Kelas</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Fire atau Not Fire</span></p></td></tr>
</table>
<ul style="list-style:none;"><li>
<h4><a name="bookmark20"></a><span class="font2" style="font-weight:bold;"><a name="bookmark21"></a>3.2. &nbsp;&nbsp;&nbsp;Pemrosesan Data Awal</span><br><br><span class="font2" style="font-weight:bold;"><a name="bookmark22"></a>3.2.1. &nbsp;&nbsp;&nbsp;Pembersihan Data</span></h4></li></ul>
<p><span class="font2">Pembersihan data perlu dilakukan karena masih terdapat data yang tidak lengkap dan terdapat kesalahan dalam penulisan data. Untuk mendapatkan hasil akurasi yang lebih baik dalam proses klasifikasi maka diperlukan penanganan pada nilai atribut yang tidak ada. penulis menggunakan nilai rata untuk menangani missing value pada data yang akan digunakan.</span></p>
<ul style="list-style:none;"><li>
<h4><a name="bookmark23"></a><span class="font2" style="font-weight:bold;"><a name="bookmark24"></a>3.2.2. &nbsp;&nbsp;&nbsp;Diskritisasi data</span></h4></li></ul>
<p><span class="font2">Diskritisasi data dilakukan untuk merubah data kontinyu menjadi data diskrit agar dapat digunakan nantinya saat proses data mining. Diskretisasi dalam penelitian ini menggunakan k-means dimana tiap data kontinyu pada masing-masing atribut dibagi sebanyak 3 klaster. Berikut adalah dataset kebakaran hutan sebelum proses diskritisasi menggunakan k-means seperti ditampilkan pada tabel 3</span></p>
<p><span class="font2" style="font-weight:bold;">Tabel 3. </span><span class="font2">Dataset sebelum pros</span><span class="font2" style="text-decoration:underline;">es diskr</span><span class="font2">itisasi</span></p>
<table border="1">
<tr><td style="vertical-align:bottom;">
<p><span class="font2">Temp</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">RH</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">WS</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">Rain ....</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">BUI</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">FWI</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2">29</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">57</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">18</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">0 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;....</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">3.4</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">0.5</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2">29</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">61</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">13</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">1.3 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;....</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">3.9</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">0.4</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font2">26</span></p></td><td style="vertical-align:top;">
<p><span class="font2">82</span></p></td><td style="vertical-align:top;">
<p><span class="font2">22</span></p></td><td style="vertical-align:top;">
<p><span class="font2">13.1 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;....</span></p></td><td style="vertical-align:top;">
<p><span class="font2">2.7</span></p></td><td style="vertical-align:top;">
<p><span class="font2">0.1</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font2">25</span></p></td><td style="vertical-align:top;">
<p><span class="font2">89</span></p></td><td style="vertical-align:top;">
<p><span class="font2">13</span></p></td><td style="vertical-align:top;">
<p><span class="font2">2.5 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;....</span></p></td><td style="vertical-align:top;">
<p><span class="font2">1.7</span></p></td><td style="vertical-align:top;">
<p><span class="font2">0</span></p></td></tr>
<tr><td colspan="6" style="vertical-align:bottom;">
<p><span class="font2">....n .... &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;.... .... .... .... ....</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font2">24</span></p></td><td style="vertical-align:top;">
<p><span class="font2">64</span></p></td><td style="vertical-align:top;">
<p><span class="font2">15</span></p></td><td style="vertical-align:top;">
<p><span class="font2">0.2 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;....</span></p></td><td style="vertical-align:top;">
<p><span class="font2">4.8</span></p></td><td style="vertical-align:top;">
<p><span class="font2">0.5</span></p></td></tr>
</table>
<p><span class="font2">Datset sebelum proses diskritisasi data memiliki nilai yang beragam pada masing-masing atribut. Hal ini dapat menyulitkan disaat proses klasifikasi menggunakan algoritma C4.5 nantinya oleh karena itu perlu dilakukan penyederhanaan data menggunkan k-means. Berikut ini adalah dataset kebakaran hutan setelah proses diskritisasi menggunakan k-means seperti yang ditunjukan pada tabel 4</span></p>
<p><span class="font2" style="font-weight:bold;">Tabel 4. </span><span class="font2">Dataset setelah pros</span><span class="font2" style="text-decoration:underline;">es diskri</span><span class="font2">tisasi</span></p>
<table border="1">
<tr><td style="vertical-align:bottom;">
<p><span class="font2">Temp</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">RH</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">WS</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">Rain</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">.... BUI</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">FWI</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2">Cluster2</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">Cluster1</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">Cluster1</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">Cluster0</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">.... Cluster2</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">Cluster2</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2">Cluster2</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">Cluster1</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">Cluster2</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">Cluster0</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">.... Cluster2</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">Cluster2</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font2">Cluster2</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Cluster2</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Cluster0</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Cluster2</span></p></td><td style="vertical-align:top;">
<p><span class="font2">.... Cluster2</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Cluster2</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font2">Cluster2</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Cluster2</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Cluster2</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Cluster1</span></p></td><td style="vertical-align:top;">
<p><span class="font2">.... Cluster2</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Cluster2</span></p></td></tr>
<tr><td colspan="6" style="vertical-align:bottom;">
<p><span class="font2">....n .... &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;.... .... .... .... ....</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font2">Cluster2</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Cluster1</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Cluster2</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Cluster0</span></p></td><td style="vertical-align:top;">
<p><span class="font2">.... Cluster2</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Cluster2</span></p></td></tr>
</table>
<p><span class="font2">Dataset tersebut telah diolah menggunakan k-means dengan jumlah k=3 dimana tiap data memiliki kedekan dengan pusat centroid pada masing-masing klaster.</span></p>
<ul style="list-style:none;"><li>
<h4><a name="bookmark25"></a><span class="font2" style="font-weight:bold;"><a name="bookmark26"></a>3.2.3. &nbsp;&nbsp;&nbsp;Seleksi Fitur</span></h4></li></ul>
<p><span class="font2">Seleksi fitur dalam penelitian ini menggunakan Rough Set dimana dataset yang terbentuk setelah proses diskritisasi data direpresentasikan menggunakan persamaan </span><span class="font8" style="font-style:italic;">U</span><span class="font2"> = {</span><span class="font8">x</span><span class="font2">1, </span><span class="font8">x</span><span class="font2">2, ..., </span><span class="font8" style="font-style:italic;">xm} </span><span class="font2">dan </span><span class="font8" style="font-style:italic;">A</span><span class="font2"> = {</span><span class="font8">α</span><span class="font2">1, </span><span class="font8" style="font-style:italic;">a</span><span class="font2" style="font-style:italic;">2, .</span><span class="font2">..,} untuk menghasilkan sebuah tabel information system untuk menggambarkan objek dan atribut. Information system ditampilkan pada tabel 5</span></p>
<p><span class="font2" style="font-weight:bold;">Tabel 5. </span><span class="font2">Information system</span></p>
<table border="1">
<tr><td style="vertical-align:bottom;">
<p><span class="font2" style="font-style:italic;">U</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2" style="font-style:italic;">a1</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2" style="font-style:italic;">a2</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2" style="font-style:italic;">a3</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2" style="font-style:italic;">a4</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2" style="font-style:italic;">am</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2" style="font-style:italic;">a9</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2" style="font-style:italic;">a10</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2" style="font-style:italic;">x1</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">2</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">1</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">1</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">0</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">....</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">2</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">2</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2" style="font-style:italic;">x2</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">2</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">1</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">2</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">0</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">....</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">2</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">2</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2" style="font-style:italic;">X3</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">2</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">2</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">0</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">2</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">....</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">2</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">2</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2" style="font-style:italic;">X4</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">2</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">2</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">2</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">1</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">....</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">2</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">2</span></p></td></tr>
<tr><td colspan="8" style="vertical-align:bottom;">
<p><span class="font2" style="font-style:italic;">Xm .... &nbsp;&nbsp;&nbsp;.... .... .... .... .... ....</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2" style="font-style:italic;">x245</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">2</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">1</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">2</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">0</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">....</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">2</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">2</span></p></td></tr>
</table>
<p><span class="font2">Setelah tabel Information system terbentuk. Selanjutnya dilakukan perbandingan antara objek menggunakan discernibility matrix. Tabel discernibility matrix ditampilkan pada tabel 6</span></p>
<table border="1">
<tr><td colspan="7" style="vertical-align:bottom;">
<p><span class="font2" style="font-weight:bold;">Tabel 6. </span><span class="font2">Discernibility matrix</span></p></td></tr>
<tr><td style="vertical-align:top;"></td><td style="vertical-align:bottom;">
<p><span class="font2" style="font-style:italic;">x1</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2" style="font-style:italic;">x2</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2" style="font-style:italic;">x3</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2" style="font-style:italic;">x4</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2" style="font-style:italic;">xm</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2" style="font-style:italic;">x244</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2" style="font-style:italic;">x1</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">0</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">e</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">b,c,d,e</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">b,c,d,e</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">....</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">c</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2" style="font-style:italic;">x2</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">e</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">0</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">b,c,d,e</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">b,d,e</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">....</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">0</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2" style="font-style:italic;">x3</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">b,c,d,e</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">b,c,d,e</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">0</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">c,d</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">....</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">b,c,d,e</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2" style="font-style:italic;">x4</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">b,c,d,e</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">b,d,e</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">c,d</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">0</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">....</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">b,d,e</span></p></td></tr>
<tr><td colspan="7" style="vertical-align:bottom;">
<p><span class="font2" style="font-style:italic;">xm .... &nbsp;&nbsp;&nbsp;&nbsp;.... .... .... .... ....</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2" style="font-style:italic;">x244</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">c</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">0</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">b,c,d,e</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">b,d,e</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">....</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">0</span></p></td></tr>
</table>
<p><span class="font2">Setelah didapatkan hasil dari Discernibility matrix, tahapan selanjutnya adalah melakukan reduksi atribut. Proses reduksi digunakan untuk memilih atribut yang akan digunakan sebagai fitur pilihan. Berikut adalah beberapa kombinasi fitur terpilih yang ditampilkan pada tabel 7</span></p>
<p><span class="font2" style="font-weight:bold;">Tabel 7. </span><span class="font2">Seleksi Fitur</span></p>
<table border="1">
<tr><td style="vertical-align:top;">
<p><span class="font2">No</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Fitur terpilih</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Jumlah Atribut</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2">1</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">Temperature, RH, WS, FFMC, DC, ISI</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">6</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2">2</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">Temperature, RH, FFMC, DC, ISI</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">5</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2">3</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">Temperature, RH, WS, FFMC, ISI, BUI</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">6</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2">4</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">Temperature, WS, FFMC, ISI, BUI</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">5</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2">5</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">Temperature, RH, FFMC, DMC, DC, ISI</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">6</span></p></td></tr>
</table>
<p><span class="font2" style="font-weight:bold;">3.3. Penambangan Data</span></p>
<p><span class="font2">Untuk dapat menghasilkan prediksi, algoritma C4.5 digunakan untuk menghasilkan pohon keputusan. Untuk memudahkan analisa data kebakaran hutan digunakan alat bantu WEKA. Berikut adalah pohon keputusan yang terbentuk berdasarkan hasil seleksi atribut Temperature, RH, WS, FFMC, DC, ISI yang ditampilkan pada gambar 2.</span></p><img src="https://jurnal.harianregional.com/media/83447-2.jpg" alt="" style="width:401pt;height:207pt;">
<p><span class="font2" style="font-weight:bold;">Gambar 2. </span><span class="font2">Pohon keputusan</span></p>
<p><span class="font2">Pohon keputusan yang diperoleh tersebut kemudian dapat digunakan untuk memprediksi kebakaran hutan.</span></p>
<ul style="list-style:none;"><li>
<h4><a name="bookmark27"></a><span class="font2" style="font-weight:bold;"><a name="bookmark28"></a>3.4. &nbsp;&nbsp;&nbsp;Evaluasi</span></h4></li></ul>
<p><span class="font2">Setelah pohon keputusan terbentuk. Selanjutnya dilakukan pengujian menggunakan confusion matrix untuk mengetahui ketepatan klasifikasi berdasarkan model yang telah terbentuk. Evaluasi confusion matrix ditunjukan pada tabel 8</span></p>
<p><span class="font2" style="font-weight:bold;">Tabel 8. </span><span class="font2">Confusion Matrix</span></p>
<p><span class="font2" style="text-decoration:underline;">Klasifikasi Fire Not Fire</span></p>
<p><span class="font2">Fire &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;136 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2</span></p>
<p><span class="font2">Not Fire &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;4 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;102</span></p>
<p><span class="font2">Berikut adalah perbandingan algoritma C4.5 standar dan Algoritma C4.5 dengan menggunakan</span></p>
<p><span class="font2">Rough Set untuk seleksi fitur. Berikut adalah perbandingan algoritma ditampilkan pada tabel 9</span></p>
<p><span class="font2" style="font-weight:bold;">Tabel 9. </span><span class="font2">Perbandingan algoritma</span></p>
<p><span class="font2">Algoritma &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Akurasi</span></p>
<p><span class="font2">C4.5 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;98.36%</span></p>
<p><span class="font2">C4.5 dan Rough Set &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;98.36%</span></p>
<ul style="list-style:none;"><li>
<h4><a name="bookmark29"></a><span class="font2" style="font-weight:bold;"><a name="bookmark30"></a>4. &nbsp;&nbsp;&nbsp;KESIMPULAN</span></h4></li></ul>
<p><span class="font2">Berdasarkan hasil pengujian menggunakan algorima C4.5 dengan seleksi fitur menggunakan Rough Set untuk klasifikasi kebakaran hutan. Hasil penelitian menunjukan algoritma C4.5 dan Rough Set menghasilkan nilai akurasi 98.36%. Penggunaan Rough Set sebagai seleksi fitur tidak menghasilkan peningkatan nilai akurasi, namun mampu mengurangi atribut yang tidak relevan secara efektif.</span></p>
<h4><a name="bookmark31"></a><span class="font2" style="font-weight:bold;"><a name="bookmark32"></a>References</span></h4>
<ul style="list-style:none;"><li>
<p><span class="font2">[1] &nbsp;&nbsp;&nbsp;D. A. Wood, “Prediction and data mining of burned areas of forest fires: Optimized data matching and mining algorithm provides valuable insight,” </span><span class="font2" style="font-style:italic;">Artif. Intell. Agric.</span><span class="font2">, vol. 5, pp. 24–42, 2021.</span></p></li>
<li>
<p><span class="font2">[2] &nbsp;&nbsp;&nbsp;F. U. Robert Kurniawan, “PERBANDINGAN ALGORITMA LSDBC DAN DBSCAN PADA PEMETAAN DAERAH RAWAN KEBAKARAN HUTAN (Studi Kasus di Pulau Sumatera, Kalimantan, Sulawesi, dan Papua),” </span><span class="font2" style="font-style:italic;">J. Apl. Stat. Komputasi Stat.</span><span class="font2">, vol. 12.2.2020, no. 2086–4132, pp. 25–30, 2020.</span></p></li>
<li>
<p><span class="font2">[3] &nbsp;&nbsp;&nbsp;D. F. Pramesti, Lahan, M. Tanzil Furqon, and C. Dewi, “Implementasi Metode K-Medoids Clustering Untuk Pengelompokan Data,” </span><span class="font2" style="font-style:italic;">J. Pengemb. Teknol. Inf. dan Ilmu Komput.</span><span class="font2">, vol. 1, no. 9, pp. 723–732, 2017.</span></p></li>
<li>
<p><span class="font2">[4] &nbsp;&nbsp;&nbsp;S. Narulita, A. T. Oktaga, and I. Susanti, “PENGUJIAN AKURASI MODEL PREDIKSI MENGGUNAKAN METODE DATA MINING CLASSIFICATION DECISION TREE ALGORITMA C4 . 5,” vol. 1, pp. 15–29, 2021.</span></p></li>
<li>
<p><span class="font2">[5] &nbsp;&nbsp;&nbsp;A. Mukminin and D. Riana, “Komparasi Algoritma C4 . 5 , Naïve Bayes Dan Neural Network Untuk Klasifikasi Tanah,” vol. 4, no. 1, pp. 21–31, 2017.</span></p></li>
<li>
<p><span class="font2">[6] &nbsp;&nbsp;&nbsp;N. Cahyani and M. A. Muslim, “Increasing Accuracy of C4.5 Algorithm by Applying Discretization and Correlation-based Feature Selection for Chronic Kidney Disease Diagnosis,” </span><span class="font2" style="font-style:italic;">J. Telecommun. Electron. Comput. Eng.</span><span class="font2">, vol. 12, no. April, pp. 25–32, 2020.</span></p></li>
<li>
<p><span class="font2">[7] &nbsp;&nbsp;&nbsp;A. Budiman, “Cronic Kidney Disease Prediction Using C4. 5 Algorithm and K-Means,” </span><span class="font2" style="font-style:italic;">JASIKA (Jurnal Apl. Sist. Inf. dan …</span><span class="font2">, vol. 1, no. 1, pp. 76–82, 2020.</span></p></li>
<li>
<p><span class="font2">[8] &nbsp;&nbsp;&nbsp;D. A. Effendy, K. Kusrini, and S. Sudarmawan, “Classification of intrusion detection system (IDS) based on computer network,” </span><span class="font2" style="font-style:italic;">Proc. - 2017 2nd Int. Conf. Inf. Technol. Inf. Syst. Electr. Eng. ICITISEE 2017</span><span class="font2">, vol. 2018-Janua, pp. 90–94, 2018.</span></p></li>
<li>
<p><span class="font2">[9] &nbsp;&nbsp;&nbsp;A. Prabowo, “Analisis Akurasi Algoritma Naive Bayes Dengan Seleksi Fitur Rough Set Pada Klasifikasi Data,” 2021.</span></p></li>
<li>
<p><span class="font2">[10] &nbsp;&nbsp;&nbsp;T. B. Nugroho and E. Sugiharti, “The Improvement of C4 . 5 Algorithm Accuracy in Predicting Forest Fires Using Discretization and AdaBoost,” vol. 3, no. April, pp. 43–52, 2021.</span></p></li>
<li>
<p><span class="font2">[11] &nbsp;&nbsp;&nbsp;R. Rinawati, “Penentuan Penilaian Kredit Menggunakan Metode Naive Bayes Berbasis Particle Swarm Optimization,” </span><span class="font2" style="font-style:italic;">J-SAKTI (Jurnal Sains Komput. dan Inform.</span><span class="font2">, vol. 1, no. 1, p. 48, 2017.</span></p></li>
<li>
<p><span class="font2">[12] &nbsp;&nbsp;&nbsp;M. Rifai, S. Musdalifah, S. Matematika, and J. Matematika, “Klasifikasi pasien kanker payudara menggunakan metode rough set,” vol. 16, pp. 207–220, 2019.</span></p></li></ul>
<p><span class="font8">68</span></p>