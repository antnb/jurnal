---
layout: full_article
title: "Song Recommendations Based on Artists with Cosine Similarity Algorithms and K-Nearest Neighbor"
author: "Muhammad Arief Budiman, Gst. Ayu Vida Mastrika Giri"
categories: jik
canonical_url: https://jurnal.harianregional.com/jik/full-53174 
citation_abstract_html_url: "https://jurnal.harianregional.com/jik/id-53174"
citation_pdf_url: "https://jurnal.harianregional.com/jik/full-53174"  
comments: true
---

<p><span class="font3">p-ISSN: 2301-5373</span></p>
<p><span class="font3">e-ISSN: 2654-5101</span></p>
<p><span class="font3">Jurnal Elektronik Ilmu Komputer Udayana</span></p>
<p><span class="font3">Volume 8, No 4. May 2019</span></p><a name="caption1"></a>
<h1><a name="bookmark0"></a><span class="font4" style="font-weight:bold;"><a name="bookmark1"></a>Song Recommendations Based on Artists with </span><span class="font4" style="font-weight:bold;font-style:italic;">Cosine Similarity</span><span class="font4" style="font-weight:bold;"> Algorithms and </span><span class="font4" style="font-weight:bold;font-style:italic;">K-Nearest Neighbor</span></h1>
<p><span class="font3">Muhammad Arief Budiman <sup>a1</sup>, Gst. Ayu Vida Mastrika Giri <sup>a2</sup></span></p>
<p><span class="font3"><sup>a</sup>Informatics Department, Udayana University Bali, Indonesia </span><a href="mailto:1mdafbn2000@gmail.com"><span class="font3"><sup>1</sup>mdafbn2000@gmail.com</span></a></p>
<p><a href="mailto:2vida.mastrika@cs.unud.ac.id"><span class="font3"><sup>2</sup>vida.mastrika@cs.unud.ac.id</span></a></p>
<p><span class="font3" style="font-weight:bold;font-style:italic;">Abstract</span></p>
<p><span class="font3" style="font-style:italic;">The development of the music industry is currently growing rapidly, millions of music works continue to be issued by various music artists. As for the technologies also follows these developments, examples are mobile phones applications that have music subscription services, namely Spotify, Joox, GrooveShark, and others. Application-based services are increasingly in demand by users for streaming music, free or paid. In this paper, a music recommendation system is proposed, which the system itself can recommend songs based on the similarity of the artist that the user likes or has heard. This research uses Collaborative Filtering method with Cosine Similarity and K-Nearest Neighbor algorithm. From this research, a system that can recommend songs based on artists who are related to one another is generated.</span></p>
<p><span class="font3" style="font-weight:bold;font-style:italic;">Keywords: </span><span class="font3" style="font-style:italic;">Song Recommendation, Cosine Similarity, K-Nearest Neighbor</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark2"></a><span class="font3" style="font-weight:bold;"><a name="bookmark3"></a>1. &nbsp;&nbsp;&nbsp;Introduction</span></h2></li></ul>
<p><span class="font3">In today's digital era, technological development is growing very fast. All human work is helped a lot by the developing technology, such as mobile phones. With a mobile phone, users can do a variety of things they want to do, for examples are listening to music both online and offline, ordering food through the application, making documents, and others.</span></p>
<p><span class="font3">Not only in the field of technology, the development of the music industry is currently growing rapidly, millions of music works continue to be issued by various music artists. As for examples are applications that have music subscription services, namely Spotify, Joox, GrooveShark, and others. Application-based services are increasingly in demand by users for streaming music, free or paid.</span></p>
<p><span class="font3">DailySocial conducted a survey in February 2018 about the habits of the Indonesian people towards music streaming services. This survey involved around 1955 male and female respondents from various age ranges and regions in Indonesia. The survey results show that: 88% listen to music online regularly from the last six months of the survey with 51.05% of them listening to music 1 to 14 hours per week, 52% are subscribed to paid streaming services, where JOOX streaming service is most widely used ie around 70.37% for paid and 68.16% for free, around 56.12% use streaming services because they get free access, while 87.77% use streaming services because of the complete song catalog, and around 44.89% have subscribe for 6 months.</span></p>
<p><span class="font3">However, due to the development of this growing music industry, a lot of song data are available in various song libraries. With so much music data available, it will be difficult for users to find the music they like. Some music service applications provide several features that can make it easier for users to find the music they like, one of that is the music search feature, usually using tagging or labels. Even though the music service application already has this feature, it is proven that it is still ineffective, because if someone wants to find a song by entering the word &quot;jazz&quot;, it will display song data which is a jazz genre or there is the word jazz as its label. However, the results of the song data do not go through the filter or filtering stage</span></p>
<p><span class="font3">regarding jazz songs that the user really wants to hear, so there are a lot of song data that sounds unfamiliar to the user's ear.</span></p>
<p><span class="font3">In the study 'A Music Recommendation System Based on User Behavior' written by Yajie Hun (2011), a system was formed to recommend appropriate songs from existing song collections to users, where this song: liked by users, fresh (new) for the user, and according to the pattern of listening history from the user. The &quot;forgetting curve&quot; is used to assess the freshness of a song and evaluate &quot;favoredness&quot; using the user's history. The author analyzes the user's pattern to estimate the level of interest of the user for the next song and also analyzes the user's behavior towards the song being played as feedback to set the next song recommendation.</span></p>
<p><span class="font3">In the research 'Collaborative Filtering and Its Application' written by Eka Angga Laksana (2014), there are explanations about collaborative filtering, which is one of the techniques in the recommender system that is most often used because it is classified as good in performance. Recommender systems are often used in the field of E-Commerce to form a website personalization. E-Commerce website users will certainly look for a particular product, so it takes the role of the recommender system in displaying products related to the product preferred by the user. Users can rate products they like on a certain scale.</span></p>
<p><span class="font3">In the same year, a study was conducted by Trini Saptariani with the title 'Music Recommendation System Using Latent Semantic Analysis', which in this journal discusses the design of a new music recommendation system based on the Latent Semantic Analysis (LSA) method. This method will be used as a search based on the music history accessed by the user. By comparing user behavior with a structured music database, we will get search results and music recommendations that are more relevant and more personal. This research provides more accurate results because this music recommendation service not only looks at similar genres, but also looks at user habits and the similarity of tags from songs/artists.</span></p>
<p><span class="font3">From the presented problems and studies, a music recommendation system is proposed which can recommend songs based on the similarity of the artist that the user likes. The purpose of this study is to create a recommendation system for songs, so users can listen to the songs they like with different version and other songs they might like.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark4"></a><span class="font3" style="font-weight:bold;"><a name="bookmark5"></a>2. &nbsp;&nbsp;&nbsp;Reseach Methods</span><br><br><span class="font3" style="font-weight:bold;"><a name="bookmark6"></a>2.1 &nbsp;&nbsp;&nbsp;Collaborative Filtering</span></h2></li></ul>
<p><span class="font3">Collaborative Filtering is one of the methods used to develop a recommender system. Product rating is the most important element of this algorithm, where the rating is obtained from most users who explicitly provide an assessment of the item. In essence, the system provides a return to the user by processing these data, and will make it possible to do a statistical calculation which results show which products are given a high rating by the user. Collaborative filtering uses a database obtained from the user. There are two main components in this data in order to make predictions for the recommender system, namely users and items. There are many algorithms for collaborative filtering, more commonly K-Nearest Neighbor (User-CF, Item-CF, etc.).</span></p>
<p><span class="font3">The collaborative filtering approach to the recommendation algorithm involves gathering &quot;a large amount of information about the user's behavior, activities, or preferences and predicting what users will like based on their similarities with other users.&quot; An important point to be made about this method is that the item itself, or its features, which are recommended are not analyzed, instead, this approach assumes that previous information in the user's history is about how they agree with other users (for example User A likes Film A and User B likes Film A, so they will have the same interests) , will be a prediction in determining whether they will enjoy certain items. Collecting data in this approach involves collecting explicit data, such as asking users to rate an item, and collecting implicit data, such as keeping records of how often and for how long the user viewed an item.</span></p>
<p><span class="font3">The collaborative filtering approach builds a model of user behavior (items previously purchased or selected and / or numerical ratings given for the item) as well as similar decisions made by</span></p>
<p><span class="font3">other users. This model is then used to predict items (or rankings for items) that the user might be interested in. The flow of collaborative filtering in general can be seen in Figure 1.</span></p>
<div><img src="https://jurnal.harianregional.com/media/53174-1.jpg" alt="" style="width:271pt;height:180pt;">
<p><span class="font3" style="font-weight:bold;">Figure 1. </span><span class="font3">Collaborative Filtering Stages</span></p>
<p><span class="font3">(Ngo, et al, 2018)</span></p>
</div><br clear="all">
<p><span class="font3">Collaborative filtering uses user actions to recommend other items. In general, this approach can be user-based or item-based. Item-based approaches are usually used more often than user-based approaches. User-based approaches are often more difficult to measure because of the dynamic nature of users, whereas items usually do not change much, and item-based approaches can often be counted offline and presented without being continually retrained.</span></p><img src="https://jurnal.harianregional.com/media/53174-2.jpg" alt="" style="width:254pt;height:180pt;">
<p><span class="font3" style="font-weight:bold;">Figure 2. </span><span class="font3">Categories of the System Recommendation Model</span></p>
<p><span class="font3">(Ngo, et al, 2018)</span></p>
<p><span class="font3">In Figure 2 there is a recommendation system model category. Where in collaborative filtering there is a memory-based system that relies on previous data to determine recommendations for new users. This model uses relatively simple techniques to measure similarity, such as Pearson coefficient or cosine similarity. Similarities to previous data points are used to make recommendations (for example with KNN).</span></p>
<p><span class="font3">As for the item-based system itself, the item community is what will be formed. These communities are created based on user preferences, but in the end the community formed becomes independent of user preferences. This system works when user preferences vary very little over time. After an item's community is set, users who like items in a particular community will be recommended other items in that community.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark7"></a><span class="font3" style="font-weight:bold;"><a name="bookmark8"></a>2.2 &nbsp;&nbsp;&nbsp;Cosine Similarity</span></h2></li></ul>
<p><span class="font3">Cosine similarity is a method that can be used to see the similarity of content between data. In this case, cosine similarity functions to test the size that can be used as an interpretation of the proximity of the distance based on the similarity between artists using existing datasets.</span></p>
<p><span class="font3">The similarity between two items, as usual, is determined by the number of joint events of the</span></p>
<p><span class="font3">two items in another session. Thus, the similarity between items can then be calculated.</span></p>
<p><span class="font3">(Ludewig, et al, 2018)</span></p>
<p><span class="font6"><sup>∑</sup></span></p>
<p><span class="font5">cos( &nbsp;&nbsp;)=</span></p>
<div>
<p><span class="font3">(1)</span></p>
</div><br clear="all">
<p><span class="font6">√∑ &nbsp;&nbsp;( &nbsp;) ․√∑ &nbsp;&nbsp;( &nbsp;)</span></p>
<p><span class="font3">Equation 1 is a calculation of the distance with cosine similarity from the similarity of Q to D. Q and D are test data in the form of artists, which will be compared between Q and D related to similarity between the two artists. In this equation, n is a slice of the two artist data, namely Q and D, so n will determine the amount of data from the 2 artist columns. In the numerator section, the data in artist Q and D columns will be multiplied with each other, for example Qi is the i column data for artist Q, then it will be multiplied by Di which is the i column data for artist D. Whereas in the numerator section, the data in the artist Q column is squared, then added to the next data in that column which has also been squared, and the root of the results will be searched. The same goes for artist column D. After that, the results of the artist Q and D. columns will be multiplied.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark9"></a><span class="font3" style="font-weight:bold;"><a name="bookmark10"></a>2.3 &nbsp;&nbsp;&nbsp;K-Nearest Neighbor</span></h2></li></ul>
<p><span class="font3">The K-Nearest Neighbor (K-NN) model for recommendations is an item-based algorithm that looks for neighbors between items, unlike user-based algorithms that look for neighbors between users.</span></p>
<p><span class="font3">To implement item-based collaborative filtering, K-Nearest Neighbor is the perfect choice model and is also an excellent baseline for developing a recommendation system. K-NN is a nonparametric learning method. This method uses a database where data points are separated into groups to make conclusions for new samples.</span></p>
<p><span class="font3">K-NN does not make any assumptions about the distribution of the underlying data but only depends on the similarity of item features. When K-NN draws conclusions about an item, K-NN will calculate the &quot;distance&quot; between the target item and every other item in the database, then rank the distance and produce the top K closest neighbor of an item as the most similar item recommendation.</span></p>
<p><span class="font3">The algorithm of the K-Nearest Neighbors method is as follows: (Han, et al, 2012) a. Determine the parameter k (number of nearest neighbors).</span></p>
<ul style="list-style:none;"><li>
<p><span class="font3">b. &nbsp;&nbsp;&nbsp;Calculate the distance between the data to be evaluated and all training data.</span></p></li>
<li>
<p><span class="font3">c. &nbsp;&nbsp;&nbsp;Sort the distance formed (in ascending order) and determine the closest distance to the k-order.</span></p></li>
<li>
<p><span class="font3">d. &nbsp;&nbsp;&nbsp;Attach the appropriate class (c).</span></p></li>
<li>
<p><span class="font3">e. &nbsp;&nbsp;&nbsp;Find the number of classes from the nearest neighbor, and specify the class as the data class being evaluated.</span></p></li></ul>
<p><span class="font3">The advantage of the K-Nearest Neighbor algorithm is that it does not require a long time for the training process, when compared to the backpropagation algorithm. (Redjeki, 2013)</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark11"></a><span class="font3" style="font-weight:bold;"><a name="bookmark12"></a>2.4 &nbsp;&nbsp;&nbsp;Data</span></h2></li></ul>
<p><span class="font3">In this study, a dataset from Last.FM was used in the form of listening history of 1257 Last.FM users along with 285 artists who had been listened to by users. In the existing data, if the user has heard a piece of music from an artist then a value of 1 will be given, while if the user has never heard it will be given a value of 0. Examples of research data (listening history) can be seen in table 1.</span></p>
<table border="1">
<tr><td style="vertical-align:top;">
<p><span class="font3">User</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3">a perfect circle</span></p></td><td style="vertical-align:top;">
<p><span class="font3">abba</span></p></td><td style="vertical-align:top;">
<p><span class="font3">ac/dc</span></p></td><td style="vertical-align:top;">
<p><span class="font3">adam green</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font3">1</span></p></td><td style="vertical-align:middle;">
<p><span class="font3">0</span></p></td><td style="vertical-align:middle;">
<p><span class="font3">0</span></p></td><td style="vertical-align:middle;">
<p><span class="font3">0</span></p></td><td style="vertical-align:middle;">
<p><span class="font3">0</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font3">33</span></p></td><td style="vertical-align:middle;">
<p><span class="font3">0</span></p></td><td style="vertical-align:middle;">
<p><span class="font3">0</span></p></td><td style="vertical-align:middle;">
<p><span class="font3">0</span></p></td><td style="vertical-align:middle;">
<p><span class="font3">1</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font3">42</span></p></td><td style="vertical-align:top;">
<p><span class="font3">0</span></p></td><td style="vertical-align:top;">
<p><span class="font3">0</span></p></td><td style="vertical-align:top;">
<p><span class="font3">0</span></p></td><td style="vertical-align:top;">
<p><span class="font3">0</span></p></td></tr>
</table>
<p><span class="font3" style="font-weight:bold;">Table 1. </span><span class="font3">Research Data Samples (User Listening History)</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark13"></a><span class="font3" style="font-weight:bold;"><a name="bookmark14"></a>2.5 &nbsp;&nbsp;&nbsp;System Analysis and Design</span></h2></li></ul>
<p><span class="font3">From the results of the analysis of the problems that have been described previously, we need a music recommendation that uses the user's listening history from various artistst. The designed recommendations can later receive input in the form of an artist's name and will show the output in the form of recommendations of other artists related to the artist's input. The general design process implemented in this music recommendation is illustrated through the</span></p><img src="https://jurnal.harianregional.com/media/53174-3.jpg" alt="" style="width:327pt;height:295pt;">
<p><span class="font3" style="font-weight:bold;">Figure 3. </span><span class="font3">Flow of the Recommendation Process</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark15"></a><span class="font3" style="font-weight:bold;"><a name="bookmark16"></a>3. &nbsp;&nbsp;&nbsp;Result and Discussion</span><br><br><span class="font3" style="font-weight:bold;"><a name="bookmark17"></a>3.1 &nbsp;&nbsp;&nbsp;Similarity Test Results</span></h2></li></ul>
<p><span class="font3">In the recommendation process that is made, data is entered in the form of an artist. Then the similarity between artists will be calculated, which is derived from the user's listening history, with cosine similarity. For example, if several users have all heard the same 5 artists, it will be stated that the artists have similarities. Then, depending on the results of the comparison between artists, the similarity value is obtained.</span></p>
<p><span class="font3">After getting the similarity between artists with each other, a similarity value matrix will be obtained. In Figure 4 is an example of a matrix similarity form.</span></p>
<table border="1">
<tr><td style="vertical-align:bottom;">
<p><span class="font3">[[</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">1' &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;J</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2" style="font-variant:small-caps;">≡- &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<sub>j</sub></span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">0.01791723, .</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">• ■ J</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">0.06506</span></p></td></tr>
<tr><td style="vertical-align:top;"></td><td style="vertical-align:bottom;">
<p><span class="font1">0.05216405,</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">0- &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;b</span></p></td><td style="vertical-align:top;"></td><td style="vertical-align:top;"></td><td style="vertical-align:top;"></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font3">[</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">o. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;,</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">1. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;,</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">θ.05227877, .</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">■ &gt;&nbsp;J</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">0.</span></p></td></tr>
<tr><td style="vertical-align:top;"></td><td style="vertical-align:bottom;">
<p><span class="font1">0.02536731,</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">0. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;h</span></p></td><td style="vertical-align:top;"></td><td style="vertical-align:top;"></td><td style="vertical-align:top;"></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font3">[</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">0.01791723,</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">0.05227877,</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">1. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;j-</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">• ∙ J</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">0.02039967</span></p></td></tr>
<tr><td style="vertical-align:top;"></td><td style="vertical-align:bottom;">
<p><span class="font1">0.13084898,</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">0- &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;b</span></p></td><td style="vertical-align:top;"></td><td style="vertical-align:top;"></td><td style="vertical-align:top;"></td></tr>
</table>
<ul style="list-style:none;"><li>
<p><span class="font3" style="font-weight:bold;">Figure 4.</span><span class="font3"> &nbsp;&nbsp;&nbsp;Example of Similarity Matrix</span></p></li></ul>
<h2><a name="bookmark18"></a><span class="font3" style="font-weight:bold;"><a name="bookmark19"></a>3.2 K-Nearest Neighbor</span></h2>
<p><span class="font3">From the similarity matrix data, K-Nearest Neighbor will be used as a collaborative filtering algorithm to predict recommendations. In this step, the K-NN algorithm measures the distance to determine the “proximity” of the artist instance and find the closest 372eighbour of the instance. After obtaining a similarity value (distance) between the artists, the recommendation for an artist with the closest k-neighbor will be predicted, where the closest value is then sorted from the largest to the smallest, and the top recommendation is chosen from that value. Figures 5 and 6 show the results of the K-Nearest Neighbor algorithm in which indexes and distances to neighbors at each point are generated, which are sorted, based on the closest point index (most similar) in the similarity matrix.</span></p>
<p><a href="#bookmark20"><span class="font6">0 &nbsp;12 &nbsp;34</span></a></p>
<p><a href="#bookmark21"><span class="font6">0 &nbsp;</span><span class="font1">0 &nbsp;277 &nbsp;&nbsp;81 &nbsp;&nbsp;70189</span></a></p>
<p><a href="#bookmark22"><span class="font1">1 &nbsp;1 &nbsp;221 &nbsp;&nbsp;88 &nbsp;165174</span></a></p>
<p><a href="#bookmark23"><span class="font6">2 &nbsp;</span><span class="font1">2 &nbsp;128 &nbsp;172 &nbsp;&nbsp;36190</span></a></p>
<p><a href="#bookmark24"><span class="font6">3 &nbsp;</span><span class="font1">3 &nbsp;255 &nbsp;267 &nbsp;&nbsp;25276</span></a></p>
<p><a href="#bookmark25"><span class="font6">4 &nbsp;</span><span class="font1">4 &nbsp;281 &nbsp;157 &nbsp;158115</span></a></p>
<ul style="list-style:none;"><li>
<p><span class="font3" style="font-weight:bold;">Figure 5.</span><span class="font3"> &nbsp;&nbsp;&nbsp;Examples of Index</span></p></li></ul>
<p><span class="font0" style="font-weight:bold;">a &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;adam</span></p>
<p><span class="font0" style="font-weight:bold;">perfect abba ac/dc &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;aerosmith</span></p>
<p><span class="font0" style="font-weight:bold;">. . &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;qreen</span></p>
<p><span class="font0" style="font-weight:bold;">circle</span></p>
<p><span class="font0" style="font-weight:bold;">a perfect </span><span class="font1"><sub>1 oo</sub>θ<sub>oc</sub>,<sub>o 0i0000c</sub>,<sub>0</sub> o.O17917 0.051554 &nbsp;&nbsp;0.062776</span></p>
<p><span class="font0" style="font-weight:bold;">circle</span></p>
<p><span class="font0" style="font-weight:bold;">abba &nbsp;</span><span class="font1">0.000000 &nbsp;1.000000 &nbsp;0.052279 &nbsp;0.025071 &nbsp;&nbsp;0.061056</span></p>
<p><span class="font0" style="font-weight:bold;">ac/dc &nbsp;</span><span class="font1">0.017917 0.052279 &nbsp;1.000000 &nbsp;0.113154 &nbsp;&nbsp;0.177153</span></p>
<p><span class="font1"><sup>adam</sup> &nbsp;0.051554 &nbsp;0.025071 &nbsp;0.113154 &nbsp;1.000000 &nbsp;&nbsp;0.056637</span></p>
<p><span class="font0" style="font-weight:bold;">green</span></p>
<p><span class="font0" style="font-weight:bold;">aerosmith &nbsp;</span><span class="font1">0.062776 &nbsp;0.061056 &nbsp;0.177153 &nbsp;0.056637 &nbsp;&nbsp;1.000000</span></p>
<ul style="list-style:none;"><li>
<p><span class="font3" style="font-weight:bold;">Figure 6.</span><span class="font3"> &nbsp;&nbsp;&nbsp;Examples of Distance</span></p></li></ul>
<h2><a name="bookmark26"></a><span class="font3" style="font-weight:bold;"><a name="bookmark27"></a>3.3 Final Result</span></h2>
<p><span class="font3">By using the index sorted in Figure 5 in accordance with the similarity value in Figure 6, various other artists' recommendations will be generated in accordance with the artist entered, in Figure 7.</span></p>
<table border="1">
<tr><td style="vertical-align:top;"></td><td style="vertical-align:top;">
<p><span class="font0" style="font-weight:bold;">0</span></p></td><td style="vertical-align:top;">
<p><span class="font0" style="font-weight:bold;">1</span></p></td><td style="vertical-align:top;">
<p><span class="font0" style="font-weight:bold;">2</span></p></td><td style="vertical-align:top;">
<p><span class="font0" style="font-weight:bold;">3</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">a perf ect circle</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">a perfect</span></p>
<p><span class="font0">circlle</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">tool</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">dredg</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">defto∩es</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">abba</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">abba</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">robbie</span></p>
<p><span class="font0">williams</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">elvis pres ley</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">madonna</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">ac/dc</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">ac/dc</span></p></td><td style="vertical-align:top;">
<p><span class="font0">iron maiden</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">m eta I Iica</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">black sabbath</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">adam green</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">adam green</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">the libertines</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">the</span></p>
<p><span class="font0">strokes</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">babyshambles</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">aerosmith</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">aerosmith</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">ιi2</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">led</span></p>
<p><span class="font0">Zeppelin</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">Ienny kravitz</span></p></td></tr>
</table>
<ul style="list-style:none;"><li>
<p><span class="font3" style="font-weight:bold;">Figure 7.</span><span class="font3"> &nbsp;&nbsp;&nbsp;Example of Recommendation Results</span></p></li></ul>
<p><span class="font3">We distributed questionnaires to a number of students at Udayana University, in order to find out the response given regarding this system, by giving a rating, namely:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font3">1. &nbsp;&nbsp;&nbsp;Not Good</span></p></li>
<li>
<p><span class="font3">2. &nbsp;&nbsp;&nbsp;Less Good</span></p></li>
<li>
<p><span class="font3">3. &nbsp;&nbsp;&nbsp;Enough</span></p></li>
<li>
<p><span class="font3">4. &nbsp;&nbsp;&nbsp;Good</span></p></li>
<li>
<p><span class="font3">5. &nbsp;&nbsp;&nbsp;Very Good</span></p></li></ul>
<ul style="list-style:none;"><li>
<p><span class="font3">10 students who filled out the questionnaire, 4 of them chose 4 and 6 chose 5, so that the system resulted in satisfaction rates ranging from good to very good.</span></p></li></ul>
<p><span class="font3">In addition, checking is also done of each result obtained, for example is in the first result. A Perfect Circle is an American rock group, then the results that are recommendations for users who hear the artist A Perfect Circle are various rock groups or other alternatives, which by the system have been quite well recommended.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark28"></a><span class="font3" style="font-weight:bold;"><a name="bookmark29"></a>4. &nbsp;&nbsp;&nbsp;Conclusion</span></h2></li></ul>
<p><span class="font3">From the results of this study, it is evident that the proposed method works well, where it can recommend songs based on the connection of the artist from other users. In addition, questionnaires have also been filled out that have yielded satisfying results and checks have been performed on the artist, which results that the recommended artists have a connection.</span></p>
<h2><a name="bookmark30"></a><span class="font3" style="font-weight:bold;"><a name="bookmark31"></a>References</span></h2>
<ul style="list-style:none;"><li>
<p><span class="font3">[1] &nbsp;&nbsp;&nbsp;Abraham, Sirajuddin, dkk. (2017). Sistem Rekomendasi Artikel Berita Menggunakan Metode K-Nearest Neighbor Berbasis Website.</span></p></li>
<li>
<p><span class="font3">[2] &nbsp;&nbsp;&nbsp;Ekstrand, Michael D. (2011). Collaborative Filtering Recommender Systems.</span></p></li>
<li>
<p><span class="font3">[3] &nbsp;&nbsp;&nbsp;Griesmeyer, Robert. (2011). Music Recommendation and Classification Utilizing Machine Learning and Clustering Methods.</span></p></li>
<li>
<p><span class="font3">[4] &nbsp;&nbsp;&nbsp;Hun, Yajie, dkk. (2011). A Music Recommendation System Based On User Behavior.</span></p></li>
<li>
<p><span class="font3">[5] &nbsp;&nbsp;&nbsp;Laksana, Eka Angga. (2014). Collaborative Filtering dan Aplikasinya.</span></p></li>
<li>
<p><span class="font3">[6] &nbsp;&nbsp;&nbsp;Li, Susan. (2017, September 20). How Did We Build Book Recommender Systems in An Hour Part 2 &nbsp;&nbsp;— k Nearest Neighbors and Matrix Factorization.</span></p></li></ul>
<p><a href="https://towardsdatascience.com"><span class="font3">https://towardsdatascience.com</span></a><span class="font3">.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font3">[7] &nbsp;&nbsp;&nbsp;Liao, Kevin. (2018, November 11). Prototyping a Recommender System Step by Step Part 1: KNN Item-Based Collaborative Filtering. </span><a href="https://towardsdatascience.com"><span class="font3">https://towardsdatascience.com</span></a><span class="font3">.</span></p></li>
<li>
<p><span class="font3">[8] &nbsp;&nbsp;&nbsp;Ludewig, Malte, dkk. (2018). Effective Nearest-Neighbor Music Recommendations.</span></p></li>
<li>
<p><span class="font3">[9] &nbsp;&nbsp;&nbsp;Narayanan, Sivabalan, dkk. (2013). K-nearest Neighborhood Based Music Recommendation System.</span></p></li>
<li>
<p><span class="font3">[10] &nbsp;&nbsp;&nbsp;Ngo, Brendan, dkk. (2018, December 16). Muse: A Music Recommendation System. </span><a href="https://medium.com"><span class="font3">https://medium.com</span></a><span class="font3">.</span></p></li>
<li>
<p><span class="font3">[11] &nbsp;&nbsp;&nbsp;Prasetya, Chandra S. D. (2017). Sistem Rekomendasi Pada E-Commerce Menggunakan K-Nearest Neighbor.</span></p></li>
<li>
<p><span class="font3">[12] &nbsp;&nbsp;&nbsp;Rivki, Muhammad, dkk. (2017). Implementasi Algoritma K-Nearest Neighbor dalam Pengklasifikasian Follower Twitter yang Menggunakan Bahasa Indonesia.</span></p></li>
<li>
<p><span class="font3">[13] &nbsp;&nbsp;&nbsp;Saptariani, Trini, dkk. (2014). Sistem Rekomendasi Musik Menggunakan Latent Semantic Analysis.</span></p></li>
<li>
<p><span class="font3">[14] &nbsp;&nbsp;&nbsp;Srebrenik, Brian. (2018, December 5). Introduction to Music Recommendation and Machine Learning. </span><a href="https://medium.com"><span class="font3">https://medium.com</span></a><span class="font3">.</span></p></li>
<li>
<p><span class="font3">[15] &nbsp;&nbsp;&nbsp;Sulistyono, Wiwied. (2009). Sistem Rekomendasi Musik Untuk Personalisasi Web Menggunakan Metode User-Based Collaborative Filtering.</span></p></li>
<li>
<p><span class="font3">[16] &nbsp;&nbsp;&nbsp;Wang, Hua-Ming, dkk. (2015). Personalized recommendation system K- neighbor algorithm optimization.</span></p></li>
<li>
<p><span class="font3">[17] &nbsp;&nbsp;&nbsp;Wibowo, Hardianto. (2016). Klasifikasi Musik Berdasarkan Aktif Frequensi Menggunakan Metode K-Nearest Neighbor (KNN), In Proceeding SENTRA (Seminar Teknologi dan Rekayasa) (No. 2).</span></p></li></ul>
<p><span class="font3">374</span></p>