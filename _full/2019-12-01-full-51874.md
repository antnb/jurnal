---
layout: full_article
title: "Breast Cancer Classification Using Artificial Neural Network and Feature Selection"
author: "Frisca Olivia Gorianto, I Gede Santi Astawa"
categories: jik
canonical_url: https://jurnal.harianregional.com/jik/full-51874 
citation_abstract_html_url: "https://jurnal.harianregional.com/jik/id-51874"
citation_pdf_url: "https://jurnal.harianregional.com/jik/full-51874"  
comments: true
---

<p><span class="font0">p-ISSN: 2301-5373</span></p>
<p><span class="font0">e-ISSN: 2654-5101</span></p>
<p><span class="font0">Jurnal Elektronik Ilmu Komputer Udayana</span></p>
<p><span class="font0">Volume 8, No 2. November 2019</span></p><a name="caption1"></a>
<h1><a name="bookmark0"></a><span class="font1" style="font-weight:bold;"><a name="bookmark1"></a>Breast Cancer Classification Using Artificial Neural Network and Feature Selection</span></h1>
<p><span class="font0">Frisca Olivia Gorianto<sup>a1</sup>, I Gede Santi Astawa<sup>a2</sup></span></p>
<p><span class="font0"><sup>a</sup>Informatics Department, Udayana University</span></p>
<p><span class="font0">Bali, Indonesia </span><a href="mailto:1fgorianto@gmail.com"><span class="font0" style="text-decoration:underline;"><sup>1</sup>fgorianto@gmail.com</span></a><span class="font0" style="text-decoration:underline;"> </span><a href="mailto:2santiastawa@gmail.com"><span class="font0"><sup>2</sup>santiastawa@gmail.com</span></a></p>
<p><span class="font0" style="font-weight:bold;font-style:italic;">Abstract</span></p>
<p><span class="font0" style="font-style:italic;">Breast cancer is still one of the leading causes of death in the world. Prevention can be done if the cancer can be recognized early on whether the cancer is malignant or benign. In this study, a comparison of malignant and benign cancer classifications was performed using two artificial neural network methods, which are the Feed-Forward Backpropagation method and the Elman Recurrent Neural Network method, before and after the feature selection of the data. The result of the study produced that Feed-Forward Backpropagation method using 2 hidden layers is better after the feature selection was performed on the data with an accuracy value of 99,26%.</span></p>
<p><span class="font0" style="font-weight:bold;font-style:italic;">Keywords: </span><span class="font0" style="font-style:italic;">Feed-Forward Backpropagation, Elman Recurrent Neural Network, Feature Selection, Hidden Layer</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark2"></a><span class="font0" style="font-weight:bold;"><a name="bookmark3"></a>1. &nbsp;&nbsp;&nbsp;Introduction</span></h2></li></ul>
<p><span class="font0">Cancer is one of the most common causes of death in the world, including in Indonesia. Nowadays, breast cancer is the most threatening type of cancer for women throughout the world. Breast cancer is a malignant tumor that is formed from breast cells that grow and develop uncontrollably that it can spread between tissue or organs near the breast or other body parts[1]. Breast cancer can be fatal if it is detected too late. That is why it is good to know whether a growing tumor is a malignant or benign tumor.</span></p>
<p><span class="font0">Classification is the process of finding a set of models that describe and differentiate classes of data[2]. The purpose of classification is to produce model that can be used to predict the class of data that does not have a class label. In general the classification algorithm uses all the features contained in the data to build a model, even though not all of the features are relevant to the results of the classification. If this happens to data that has a very large size and dimensions, it makes the algorithm performance ineffective and inefficient. One thing to deal with this problem is to reduce irrelevant features.</span></p>
<p><span class="font0">An Artificial Neural Networks (ANN) is an information processing system that works similar with neural networks[3]. This study uses ANN because with its ability to obtain meaning from complex or inaccurate data, can be used to extract patterns and trends that are more complicated for use by humans or other computer techniques[4].</span></p>
<p><span class="font0">In previous studies, an initial diagnosis of breast cancer was carried out using Genetic Algorithm which were implemented on the Backpropagation Neural Network[5]. This method has advantages in terms of accuracy but requires a long computational time. In addition there is also breast cancer classification study that use a combination of Neural Network and Association Rule methods[6]. However, this method is considered to be still not optimal due to the average results of the accuracy which shows less than the maximum number.</span></p>
<p><span class="font0">This study will compare Neural Network methods in diagnosing breast cancer. The methods to be compared are Feed-Forward Backpropagation (FFBP) and Elman Recurrent Neural Network (ERN). The data to be used in this study is the Wisconsin Breast Cancer Data Set with a total of 699 records and 10 attributes. In this data there are two classes of cancer represented by the numbers 2 (benign) and 4 (malignant). This study aims to find out which method is better in diagnosing breast cancer based on the highest accuracy value.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark4"></a><span class="font0" style="font-weight:bold;"><a name="bookmark5"></a>2. &nbsp;&nbsp;&nbsp;Research Methods</span></h2></li></ul>
<p><span class="font0">The data used consists of 699 records and there are 19 missing data which means that one of the attributes is unknown. Therefore preprocessing data is done by deleting 19 missing data so that the data becomes 680 records with 237 Malignant class records and 443 Benign class records.</span></p>
<p><span class="font0">ANN processes information in the same way as the human brain. This network consists of a large number of highly interconnected processing elements(neurons) that work in parallel to solve certain problems. Neural networks learn by example. The examples that will be used for training must be chosen carefully because if the training examples used are not right then the network will function incorrectly too.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font0" style="font-weight:bold;font-style:italic;">2.1. &nbsp;&nbsp;&nbsp;Feed-Forward Backpropagation (FFBP)</span></p></li></ul>
<p><span class="font0">One of the artificial neural network training algorithms that is widely used in the field of pattern recognition is backpropagation. This algorithm is generally used in multi-layer feed-forward type ANN, which is composed of several layers and the signal is flowed in the direction from input to output. The backpropagation training algorithm basically consists of three stages[3] : a. Input training data values so that output values are obtained b. Backpropagation of the error value obtained</span></p>
<ul style="list-style:none;"><li>
<p><span class="font0">c. Adjust connection weights to minimize error values.</span></p></li></ul>
<p><span class="font0">The three stages are repeated continuously until you get the desired error value. After the training is completed, only the first stage is needed to utilize the ANN. To train a network a set of data pairs is needed as follows:</span></p>
<p><span class="font3" style="font-style:italic;">{P</span><span class="font2" style="font-style:italic;">1</span><span class="font3" style="font-style:italic;">,t</span><span class="font2" style="font-style:italic;">1}</span><span class="font3" style="font-style:italic;">,{p</span><span class="font2" style="font-style:italic;">2</span><span class="font3" style="font-style:italic;">,t</span><span class="font2" style="font-style:italic;">2 </span><span class="font3" style="font-style:italic;">},-,{p</span><span class="font2" style="font-style:italic;"><sub>n</sub>,</span><span class="font3" style="font-style:italic;">t<sub>n</sub>}</span><span class="font0"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1)</span></p>
<p><span class="font0">where </span><span class="font3" style="font-style:italic;">p<sub>n</sub></span><span class="font0"> is the </span><span class="font3" style="font-style:italic;">n<sup>th</sup></span><span class="font0"> network input value and </span><span class="font3" style="font-style:italic;">t<sub>n</sub></span><span class="font0"> is the target, that is, the output value that should be generated. For each input that enters the network, the output produced by the network will be compared to the target.</span></p>
<p><span class="font0">This algorithm will manage or adjust network parameters to minimize the mean square error, namely:</span></p>
<p><a href="#bookmark6"><span class="font3" style="font-style:italic;">F(x) = E(e<sup>2</sup>) = E[(t-a)<sup>2</sup>]</span><span class="font0">(2)</span></a></p>
<p><span class="font0">where x, e, t and a are weight vector and bias, error vector, target vector and output vector.</span></p>
<p><span class="font0">If the network has several outputs, then the above equation can be developed into:</span></p>
<p><a href="#bookmark7"><span class="font3" style="font-style:italic;">F(x) = E(e<sup>τ</sup>e) = E[(t — a)<sup>τ</sup>(t — a)]</span><span class="font0">(3)</span></a></p>
<p><span class="font0">Mean square error is calculated by :</span></p>
<p><a href="#bookmark8"><span class="font3" style="font-style:italic;">F(x) = e<sup>τ</sup>(k) e(k)</span><span class="font4">(4)</span></a></p>
<ul style="list-style:none;"><li>
<p><span class="font0" style="font-weight:bold;font-style:italic;">2.2. &nbsp;&nbsp;&nbsp;Elman Recurrent Neural Network (ERNN)</span></p></li></ul>
<p><span class="font0">ERNN is often referred to as a modification of </span><span class="font0" style="font-style:italic;">Feed-Forward</span><span class="font0"> and has a more optimal performance in learning time series data. Elman </span><span class="font0" style="font-style:italic;">Recurrent Neural Network</span><span class="font0"> (ERNN) has a feedback connection (feedback) from the previous input, so it is expected to improve the performance of ANN. According to [7], Elman said that ERNN is a modified </span><span class="font0" style="font-style:italic;">feed- forward</span><span class="font0"> with the main difference is the additional layer of context neurons that provide the unit's hidden pattern is fed back to him alone. This recurrent network has two inputs, which are real input and contextual input. There is feedback that can cause iteration processes to be much faster, so that makes the parameter update speed and convergence faster .</span></p><img src="https://jurnal.harianregional.com/media/51874-1.jpg" alt="" style="width:330pt;height:229pt;">
<p><span class="font0" style="font-weight:bold;">Picture 1. Recurrent ANN Layer</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark9"></a><span class="font0" style="font-weight:bold;"><a name="bookmark10"></a>3. &nbsp;&nbsp;&nbsp;Result and Discussion</span></h2></li></ul>
<p><span class="font0">After preprocessing the data, ANN calculations will be performed using MATLAB. ANN is carried out using the Feed-Forward Backpropagation and Elman Recurrent Neural Network methods for the Wisconsin Breast Cancer Data Set. The data is divided in two with a ratio of 60:40 for training data and testing data. Out of a total of 680 records, 408 records are used for training data and 272 records are used for testing data.</span></p>
<p><span class="font0">Feature selection of the data is based on the correlation value using IBM SPSS Statistics. Correlation can take any value in the range of [-1, 1]. The correlation coefficient sign indicates the direction of the relationship, while the value of the correlation (how close to -1 or +1) indicates the strength of the relationship[8]. A value of -1 means perfect negative linear relationship, 0 means no relationship, and +1 means perfect positive linear relationship.</span></p>
<p><span class="font0">In addition to feature selection, this study also made a comparison based on the number of hidden layers used in each method both after and before feature selection. The number of hidden layers to be compared is 1, 2, and 3 hidden layers.</span></p>
<p><span class="font0" style="font-weight:bold;">Table 1. Classification Accuracy Before Feature Selection</span></p>
<table border="1">
<tr><td style="vertical-align:top;"></td><td colspan="3" style="vertical-align:bottom;">
<p><span class="font0" style="font-weight:bold;">Number of Hidden Layers</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0" style="font-weight:bold;">Method</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0" style="font-weight:bold;">1</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0" style="font-weight:bold;">2</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0" style="font-weight:bold;">3</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0">FFBP</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">97,43%</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">98,16%</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">97,79%</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0">ERNN</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">98,53%</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">98,16%</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">97,06%</span></p></td></tr>
</table>
<p><span class="font0" style="font-weight:bold;">Table 2. Attributes Correlation Values</span></p>
<table border="1">
<tr><td style="vertical-align:bottom;">
<p><span class="font0" style="font-weight:bold;">Attribute</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0" style="font-weight:bold;">Correlation with Class</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0">Sample code number</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">-.083</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0">Clump Thickness</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">.714</span></p></td></tr>
</table>
<p><span class="font0">Uniformity of Cell Size &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;.822</span></p>
<table border="1">
<tr><td style="vertical-align:bottom;">
<p><span class="font0">Uniformity of Cell Shape</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">.823</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0">Marginal Adhesion</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">.706</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0">Single Epithelial Cell Size</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">.694</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0">Bare Nuclei</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">.824</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0">Bland Chromatin</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">.761</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0">Normal Nucleoli</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">.721</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0">Mitoses</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">.426</span></p></td></tr>
</table>
<p><span class="font0">In </span><span class="font0" style="font-weight:bold;">Table 2</span><span class="font0">, it can be seen that the correlation value of the Sample code number attribute is close to 0, which means that this attribute is less related to the class of data so that in the next calculation this attribute will be removed from the data. Then do the classification process again using Feed-Forward Backpropagation and Elman Recurrent Neural Network.</span></p>
<p><span class="font0" style="font-weight:bold;">Table 3. Classification Accuracy After Feature Selection</span></p>
<table border="1">
<tr><td style="vertical-align:top;"></td><td colspan="3" style="vertical-align:bottom;">
<p><span class="font0" style="font-weight:bold;">Number of Hidden Layers</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0" style="font-weight:bold;">Method</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0" style="font-weight:bold;">1</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0" style="font-weight:bold;">2</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0" style="font-weight:bold;">3</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0">FFBP</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">98,90%</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">99,26%</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">98,53%</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0">ERNN</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">97,06%</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">96,32%</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">97,79%</span></p></td></tr>
</table>
<p><span class="font0">Breast cancer classification is done by comparing the two methods of ANN, the Feed-Forward Backpropagation and Elman Recurrent Neural Network on the data before and after feature selection based on the attribute correlation values and by the different number of hidden layers. It can be seen in </span><span class="font0" style="font-weight:bold;">Table 1 </span><span class="font0">and </span><span class="font0" style="font-weight:bold;">Table 3 </span><span class="font0">that the number of hidden layers affects the accuracy of the classification even though the difference is not much.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark11"></a><span class="font0" style="font-weight:bold;"><a name="bookmark12"></a>4. &nbsp;&nbsp;&nbsp;Conclusion</span></h2></li></ul>
<p><span class="font0">In this study it can be concluded that the classification of breast cancer using neural network, the best method is using the Feed-Forward Backpropagation after removing irrelevant feature and using two hidden layers because it produces the highest accuracy value, which is 99.26 %.</span></p>
<p><span class="font0">In the FFBP method it can be seen that the average accuracy increases after the selection of irrelevant features. Whereas in the ERNN method that the average accuracy value decreases after the feature selection is done. However, the range of accuracy values that occur is not too large with a range between 96.32% to 99.26% so that it can be concluded that the ANN used in this study is quite stable.</span></p>
<h2><a name="bookmark13"></a><span class="font0" style="font-weight:bold;"><a name="bookmark14"></a>References</span></h2>
<ul style="list-style:none;"><li>
<p><span class="font0">[1] &nbsp;&nbsp;&nbsp;&nbsp;(2018). </span><span class="font0" style="font-style:italic;">InfoDatin Pusat Data dan Informasi Kementerian Kesehatan RI</span><span class="font0">. Available:</span></p></li></ul>
<p><a href="http://www.depkes.go.id/resources/download/pusdatin/infodatin/infodatin%20tuberkulosis%202018.pdf"><span class="font0" style="text-decoration:underline;">http://www.depkes.go.id/resources/download/pusdatin/infodatin/infodatin%20tuberkulosi</span></a><span class="font0" style="text-decoration:underline;"> </span><a href="http://www.depkes.go.id/resources/download/pusdatin/infodatin/infodatin%20tuberkulosis%202018.pdf"><span class="font0" style="text-decoration:underline;">s%202018.pdf</span></a></p>
<ul style="list-style:none;"><li>
<p><span class="font0">[2] &nbsp;&nbsp;&nbsp;&nbsp;A. J. J. F. H. U. Indriani, &quot;Klasifikasi data forum dengan menggunakan metode naïve</span></p></li></ul>
<p><span class="font0">bayes classifier,&quot; 2014.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font0">[3] &nbsp;&nbsp;&nbsp;&nbsp;L. V. Fausett, </span><span class="font0" style="font-style:italic;">Fundamentals of neural networks: architectures, algorithms, and</span></p></li></ul>
<p><span class="font0" style="font-style:italic;">applications</span><span class="font0">. prentice-Hall Englewood Cliffs, 1994.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font0">[4] &nbsp;&nbsp;&nbsp;&nbsp;V. Sharma, S. Rai, A. J. I. J. o. A. r. i. c. s. Dev, and s. engineering, &quot;A comprehensive</span></p></li></ul>
<p><span class="font0">study of artificial neural networks,&quot; vol. 2, no. 10, 2012.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font0">[5] &nbsp;&nbsp;&nbsp;&nbsp;A. M. Zamani, B. Amaliah, and A. Munif, &quot;Implementasi Algoritma Genetika pada</span></p></li></ul>
<p><span class="font0">Struktur Backpropagation Neural Network untuk Klasifikasi Kanker Payudara.&quot;</span></p>
<ul style="list-style:none;"><li>
<p><span class="font0">[6] &nbsp;&nbsp;&nbsp;&nbsp;M. Karabatak and M. C. J. E. s. w. A. Ince, &quot;An expert system for detection of breast</span></p></li></ul>
<p><span class="font0">cancer based on association rules and neural network,&quot; vol. 36, no. 2, pp. 3465-3469, 2009.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font0">[7] &nbsp;&nbsp;&nbsp;&nbsp;J. B. Habarulema, &quot;A contribution to TEC modelling over Southern Africa using GPS</span></p></li></ul>
<p><span class="font0">data,&quot; Rhodes University, 2010.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font0">[8] &nbsp;&nbsp;&nbsp;&nbsp;&quot;SPSS Tutorials: Pearson Correlation,&quot;</span></p></li></ul>
<p><span class="font0">117</span></p>