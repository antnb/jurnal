---
layout: full_article
title: "Classification of Pop and RnB (Rhythm and Blues) Songs with MFCC Feature Extraction and K-NN Classifier"
author: "Zhaqy Hikkammi Gullam Ramadhan, I Made Widiartha"
categories: jik
canonical_url: https://jurnal.harianregional.com/jik/full-64449 
citation_abstract_html_url: "https://jurnal.harianregional.com/jik/id-64449"
citation_pdf_url: "https://jurnal.harianregional.com/jik/full-64449"  
comments: true
---

<p><span class="font1">p-ISSN: 2301-5373</span></p>
<p><span class="font1">e-ISSN: 2654-5101</span></p>
<p><span class="font1">Jurnal Elektronik Ilmu Komputer Udayana</span></p>
<p><span class="font1">Volume 9 No. 4, May 2021</span></p><a name="caption1"></a>
<h1><a name="bookmark0"></a><span class="font4" style="font-weight:bold;"><a name="bookmark1"></a>Classification of Pop And RnB (Rhythm And Blues) Songs With MFCC Feature Extraction And K-NN Classifier</span></h1>
<p><span class="font1">Zhaqy Hikkammi Gullam Ramadhan<sup>a1</sup>, I Made Widiartha<sup>a2</sup></span></p>
<p><span class="font1"><sup>a</sup>Informatics Department, Faculty of Math and Science, Udayana University Bali, Indonesia</span></p>
<p><a href="mailto:1gulamrmd25@gmail.com"><span class="font1"><sup>1</sup>gulamrmd25@gmail.com</span></a><span class="font1"> </span><a href="mailto:2madewidiartha@unud.ac.id"><span class="font1"><sup>2</sup>madewidiartha@unud.ac.id</span></a></p>
<p><span class="font1" style="font-weight:bold;font-style:italic;">Abstract</span></p>
<p><span class="font1" style="font-style:italic;">Classification is a technique for designing functions based on observations of attributes in a data so that data can be mapped that do not have a class which in this study can be called genres, into data that has been classified according to the given rules. In this research, music classification is conducted to determine whether the class or genre of music is pop or RnB (Rhythm and Blues) by using MFCC as the feature extraction method and K-NN as the classification method. The test results in this study obtained an accuracy of 77.5% with an optimal value of k = 31 as a parameter in K-NN.</span></p>
<p><span class="font1" style="font-weight:bold;font-style:italic;">Keywords: </span><span class="font1" style="font-style:italic;">MFCC, K-NN, Pop, RnB, Genre, Accuracy.</span></p>
<ul style="list-style:none;"><li>
<h4><a name="bookmark2"></a><span class="font1" style="font-weight:bold;"><a name="bookmark3"></a>1. &nbsp;&nbsp;&nbsp;Introduction</span></h4></li></ul>
<p><span class="font1" style="font-style:italic;">Genre</span><span class="font1"> of music is a classification done by someone based on the similarity of rhythm, harmony, and various contents of the music. However, manual music classification like this takes a lot of time because you have to listen to the music one by one, giving genres to music is done manually by an expert [1]. So a more effective classification or classification is needed.</span></p>
<p><span class="font1">Music genre is the most common way to organize digital music databases [2i]. Associating a genre with a piece of music can help music listeners find the music they're looking for in a huge music catalog. The introduction of musical genres is an important thing that has been studied deeply by the Music Information Retrieval (MIR) community since 2002 [3].</span></p>
<p><span class="font1">Now that there is an increasing number of music in circulation, manually assigning genres to appear online will take time and expertise. Automatic giving of genres can help, reduce, or replace the role of humans in giving genres to a music</span></p>
<ul style="list-style:none;"><li>
<h4><a name="bookmark4"></a><span class="font1" style="font-weight:bold;"><a name="bookmark5"></a>2. &nbsp;&nbsp;&nbsp;Research Method</span><br><br><span class="font1" style="font-weight:bold;"><a name="bookmark6"></a>2.1 &nbsp;&nbsp;&nbsp;Pop and RnB</span></h4></li></ul>
<p><span class="font1">There are 2 types of music that are currently being favored by various groups, starting from teenagers or adults today, namely pop music and RnB (Rhythm and Blues). When we're having a bad day we can listen to some quick pop to get the spirits up. When we are angry and need to feel better, we can listen to soothing songs, in other words pop that can be used according to the mood for the listener because pop prioritizes lyrics that are easy to digest with the listener's mood and tones that are easy to sing. Meanwhile, RnB has a lot to look for because it's simple and easy listening is the same as the pop music genre, but there is no difference. Pop music focuses on easy-to-sing lyrics and notes, RnB prioritizes the lyrics and the beats are sung with rhythm.</span></p>
<p><span class="font1">Many are both types of music, but visuals are also difficult to distinguish. Music that is in the same genre usually has certain similar characteristics related to instrumentation, rhythmic structure, and musical pitch [1]. Different for music composers, both music can be classified by them. But for ordinary people, it will be difficult to reduce visuals that are very similar, so that is the</span></p>
<p><span class="font1">background for me to classify fatigue. Own kind of pop music. Because it contains many songs with various tempo.</span></p>
<p><span class="font1">Music needs to be extracted before it can be classified in order to obtain data in the form of values from the music itself. The mel frequency cepstrum coefficient (MFCC) method can be used to extract features from music. MFCCis a series of short-term power spectrum in the audio file. MFCC models the characteristics of the human voice. The feature vector output from this extraction reaches up to 39 feature vectors [1]. From the results of the extraction, the classification was carried out using K-Nearest Neighbor (K-NN).K-NN is a method that is easy to learn and in terms of learning, this method has the nature of supervised learning, which means this method uses training data which is used as information for classification in later test data [2].</span></p>
<p><span class="font1">In the research entitled &quot;Classification of Music Genres Using the Mel Frequency Cepstrum Coefficients (MFCC) Method and K-Nearest Neighbors Classifier&quot; There are 5 genres with 50 audio data in each genre. The best accuracy obtained from this study is 52.4% with K = 13 [7]. Then in a study entitled &quot;Music Genre Classification Using MFCC, K-NN and SVM Classifier&quot; comparisons of two classification methods, namely K-NN and Support Vector Machine (SVM) of 5 music features (MFCC, Chroma frequencies, spectral center, spectral roll. -off and zero crossing rate) with data from 900 songs divided into 9 music classes or genres (100 songs per class) [3].</span></p>
<p><span class="font1">From some of the studies above, this study will adopt the MFCC and K-NN methods to classify pop and RnB genres and measure how high the accuracy will be with the proportion of training data, test data, and predetermined k parameters.</span></p>
<ul style="list-style:none;"><li>
<h4><a name="bookmark7"></a><span class="font1" style="font-weight:bold;"><a name="bookmark8"></a>3. &nbsp;&nbsp;&nbsp;Research Methodology</span></h4></li></ul>
<p><span class="font1">In this study, the audio data to be classified are secondary data obtained from the GTZAN dataset. Two genres were taken, namely RnB and pop with 100 songs for each genre which can be seen in Table 1.</span></p>
<p><span class="font1" style="font-weight:bold;">Table 1. Data on genre classification research</span></p>
<table border="1">
<tr><td style="vertical-align:middle;">
<p><span class="font1">No.</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">Genre</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">Song title</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font1">1</span></p></td><td style="vertical-align:middle;">
<p><span class="font1" style="font-style:italic;">RnB</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">Rnb.00000.wav - Rnb.00099.wav</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font1">2</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1" style="font-style:italic;">Pop</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">pop.00000.wav - pop.00099.wav</span></p></td></tr>
</table>
<p><span class="font1">Then, the research process is shown in a flow chart regarding the genre classification process which can be seen in Figure 1.</span></p>
<div><img src="https://jurnal.harianregional.com/media/64449-1.jpg" alt="" style="width:188pt;height:135pt;">
</div><br clear="all">
<p><span class="font1" style="font-weight:bold;">Figure 1. </span><span class="font1">Music genre classification flow chart</span></p>
<ul style="list-style:none;"><li>
<h4><a name="bookmark9"></a><span class="font1" style="font-weight:bold;"><a name="bookmark10"></a>3.1 &nbsp;&nbsp;&nbsp;Feature Extraction</span></h4></li></ul>
<p><span class="font1">The purpose of the feature extraction stage is to obtain new data with feature vectors obtained from the extraction of audio data. Several steps are required for the MFCC feature extraction:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1" style="font-weight:bold;">a.</span><span class="font1" style="font-weight:bold;font-style:italic;"> &nbsp;&nbsp;&nbsp;Frame Blocking</span></p></li></ul>
<p><span class="font1" style="font-style:italic;">Frame Blocking</span><span class="font1">is the process of splitting sound into several frames and each frame consists of several samples. The purpose of frame blocking is to form a non-stationary signal into a quasi-stationary signal so that it can be converted from a time domain signal to a frequency domain signal using the Fourier transform.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1" style="font-weight:bold;">b.</span><span class="font1" style="font-weight:bold;font-style:italic;"> &nbsp;&nbsp;&nbsp;Windowing</span></p></li></ul>
<p><span class="font1" style="font-style:italic;">Windowing</span><span class="font1"> is a process to minimize discontinuous signals at the beginning and end of each frame. The concept of windowing is tapering the signal to zero at the beginning and end of each frame which is done like equation (1).</span></p>
<p><span class="font1" style="font-style:italic;">y</span><span class="font1">1 = x1 (n) ω (n)</span></p>
<div>
<p><span class="font1">(1)</span></p>
</div><br clear="all">
<p><span class="font1">Where:</span></p>
<p><span class="font1" style="font-style:italic;">y</span><span class="font1">1 represents the windowing signal sample value, </span><span class="font1" style="font-style:italic;">x</span><span class="font1">1 (n) is the sample value of the ith signal frame, ω is a window function and,</span></p>
<p><span class="font1" style="font-style:italic;">n</span><span class="font1"> represents the length of the frame.</span></p>
<div>
<p><span class="font1" style="font-weight:bold;">c.</span></p>
</div><br clear="all">
<p><span class="font1" style="font-weight:bold;font-style:italic;">Fast Fourier Transform</span><span class="font1" style="font-weight:bold;"> (FFT)</span></p>
<p><span class="font1">The FFT converts each Nth frame of the sample from the time domain into the frequency domain as in equation (2).</span></p>
<p><span class="font7" style="font-style:italic;">2πjkn </span><span class="font3" style="font-style:italic;">xk</span><span class="font0">= </span><span class="font11" style="font-style:italic;">∑</span><span class="font9" style="font-style:italic;">n</span><span class="font11" style="font-style:italic;"><sup>-</sup></span><span class="font9" style="font-style:italic;">i</span><span class="font11" style="font-style:italic;">x<sub>n</sub></span><span class="font9" style="font-style:italic;">e &nbsp;~</span></p>
<div>
<p><span class="font1">(2)</span></p>
</div><br clear="all">
<p><span class="font1">Where:</span></p>
<p><span class="font1" style="font-style:italic;">xk</span><span class="font1">is the number of k frequencies in the signal.</span></p>
<p><span class="font1" style="font-style:italic;">N</span><span class="font1"> represents the number of samples</span></p>
<p><span class="font1" style="font-style:italic;">n</span><span class="font1"> is an iteration of the sample starting at 0</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1" style="font-weight:bold;">d.</span><span class="font1" style="font-weight:bold;font-style:italic;"> &nbsp;&nbsp;&nbsp;Mel Frequency Wrapping</span></p></li></ul>
<p><span class="font1">Equation approach for calculating mel in frequency f (Hz) like equation (3).</span></p>
<h3><a name="bookmark11"></a><span class="font2" style="font-style:italic;"><a name="bookmark12"></a>mel</span><span class="font2">(f) = 2595 x</span><span class="font10">log</span><span class="font9">ιo</span><span class="font10">(1+⅛ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="font1">(3)</span></h3>
<p><span class="font1">Where f is the sample rate.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1" style="font-weight:bold;">e.</span><span class="font1" style="font-weight:bold;font-style:italic;"> &nbsp;&nbsp;&nbsp;Cepstrum</span></p></li></ul>
<p><span class="font1">Converts log mel spectrum to time domain. This result is called the mel frequency cepstrum coefficient (MFCC). Equation (4) is the calculation method.</span></p>
<h2><a name="bookmark13"></a><span class="font3"><a name="bookmark14"></a>Cn =</span><span class="font11">∑</span><span class="font8">K=ι</span><span class="font11">(log S<sub>k</sub>)cos [n(k -</span><span class="font11" style="font-style:italic;"><sup>1</sup>)</span><span class="font8"> ^</span><span class="font11">]</span></h2>
<div>
<p><span class="font1">(4)</span></p>
</div><br clear="all">
<p><span class="font1">The new data obtained from MFCC feature extraction will be used as data for later classification. Because the output of this feature vector can reach up to 39, in this study, the first 13 feature vectors were taken based on and referenced from a previous study[3]. The representation of the vector data that will be obtained from the MFCC feature extraction can be seen in Figure 2.</span></p>
<p><span class="font1" style="font-weight:bold;">Figure 2. The first 10 datasets obtained from MFCC feature extraction</span></p>
<table border="1">
<tr><td rowspan="2" style="vertical-align:top;">
<p><span class="font1" style="text-decoration:underline;">J </span><span class="font1">1</span></p></td><td rowspan="2" style="vertical-align:bottom;">
<p><span class="font5">mfcc seti</span></p></td><td style="vertical-align:top;"></td><td style="vertical-align:top;"></td><td style="vertical-align:top;"></td><td style="vertical-align:top;"></td><td style="vertical-align:top;"></td><td style="vertical-align:top;"></td><td style="vertical-align:top;"></td><td style="vertical-align:top;">
<p><span class="font5"><sup>1</sup></span></p></td><td style="vertical-align:top;">
<p><span class="font5">J &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;K</span></p></td><td style="vertical-align:top;"></td><td style="vertical-align:top;">
<p><span class="font5">M</span></p></td><td style="vertical-align:top;">
<p><span class="font5">N</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font5">mfcc_set2</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">mfcc_set3</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">mfcc_set4</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">mfcc_set5</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">mfcc_set6</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">mfcc_set7</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">mfcc_set8</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">mfcc_set9</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">mfcc seti mfcc seti</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">mfcc_setl</span></p></td><td colspan="2" style="vertical-align:bottom;">
<p><span class="font5">mfcc_setlgenre</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font5">2</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">64.58803</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">24.88193</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">18.0494</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">17.14164</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">11.86315</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">14.99372</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">11.67058</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">12.72655</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">10.94159</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">11.21129 9.839917</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">8.6171</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">8.443376</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">0</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font5">B</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">73.69475</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">37.97397</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">29.93076</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">22.2399</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">18.29775</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">18.15099</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">14.82486</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">13.698</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">13.77611</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">12.17482 10.65445</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">10.41456</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">10.77897</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">0</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font5">4</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">53.91877</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">24.4209</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">13.48785</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">12.49249</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">10.16486</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">10.61788</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">9.116996</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">7.481346</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">7.463811</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">8.099452 7.971764</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">7.952763</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">8.324249</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">0</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font5">5</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">52.38286</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">35.04981</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">22.50965</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">19.21233</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">11.92769</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">13.51561</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">10.2434</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">9.472735</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">9.601945</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">8.89978 8.383839</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">7.740423</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">7.620057</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">0</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font5">6</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">35.69613</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">22.30297</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">19.49447</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">13.12669</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">10.18766</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">11.49882</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">8.80513</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">6.970142</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">7.141929</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">7.063309 6.∞9691</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">6.210162</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">5.872766</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">0</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font5">7</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">141.0836</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">21.35714</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">28.84341</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">14.03005</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">10.09728</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">12.17564</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">9.767021</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">11.3447</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">10.25246</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">11.22731 9.463563</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">9.072463</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">7.846376</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">0</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font5">8</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">70.04388</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">24.04498</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">18.81369</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">13.50171</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">7.872255</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">10.24444</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">7.975812</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">6.55442</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">6.088174</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">6.69709 7.519865</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">6.710766</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">6.911629</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">0</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font5">9</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">60.70252</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">44.83849</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">26.29202</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">25.90134</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">13.48231</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">14.61763</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">11.97436</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">11.52304</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">10.70504</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">13.35045 13.34196</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">14.15349</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">15.48106</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">0</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font5" style="text-decoration:underline;">10</span></p></td><td style="vertical-align:top;">
<p><span class="font5">47.19563</span></p></td><td style="vertical-align:top;">
<p><span class="font5">24.55001</span></p></td><td style="vertical-align:top;">
<p><span class="font5">25.40399</span></p></td><td style="vertical-align:top;">
<p><span class="font5">12.68524</span></p></td><td style="vertical-align:top;">
<p><span class="font5">10.92387</span></p></td><td style="vertical-align:top;">
<p><span class="font5">12.07507</span></p></td><td style="vertical-align:top;">
<p><span class="font5">9.236416</span></p></td><td style="vertical-align:top;">
<p><span class="font5">7.749003</span></p></td><td style="vertical-align:top;">
<p><span class="font5">8.267956</span></p></td><td style="vertical-align:top;">
<p><span class="font5">7.489103 7.757733</span></p></td><td style="vertical-align:top;">
<p><span class="font5">6.921389</span></p></td><td style="vertical-align:top;">
<p><span class="font5">6.348581</span></p></td><td style="vertical-align:top;">
<p><span class="font5">0</span></p></td></tr>
</table>
<ul style="list-style:none;"><li>
<h4><a name="bookmark15"></a><span class="font1" style="font-weight:bold;"><a name="bookmark16"></a>3.2 &nbsp;&nbsp;&nbsp;Classification</span></h4></li></ul>
<p><span class="font1">The classification stage is carried out after obtaining a new dataset from feature extraction.</span></p>
<p><span class="font1">Several steps in the classification with K-NN are:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1">a.</span><span class="font1" style="font-weight:bold;"> &nbsp;&nbsp;&nbsp;Input Dataset</span></p></li></ul>
<p><span class="font1">The dataset that has been obtained from feature extraction will be the input of the classification process.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1">b.</span><span class="font1" style="font-weight:bold;font-style:italic;"> &nbsp;&nbsp;&nbsp;Pre-processing</span></p></li></ul>
<p><span class="font1">Data normalization is carried out with min-max normalization with equation (5) to obtain a balance of comparison values between data [4]</span></p>
<p><span class="font9" style="font-style:italic;">minRange + (x — minValue)(maxRang e — minRange) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;, .</span></p>
<p><span class="font9" style="font-style:italic;">norm(x) =--------------——---- . <sub>τ</sub>. ,</span><span class="font1">--------------- (5)</span></p>
<p><span class="font9" style="font-style:italic;">maxvalue — mιnvalue</span></p>
<p><span class="font1">Where norm (x) is data x that has been normalized, minRange is the minimum limit that we give, maxRange is the maximum limit we give, then minValue and maxValue are the smallest and largest values of all data that have not been normalized, and x is the data which has not been normalized.</span></p>
<ul style="list-style:none;"><li>
<h4><a name="bookmark17"></a><span class="font1"><a name="bookmark18"></a>c.</span><span class="font1" style="font-weight:bold;"> &nbsp;&nbsp;&nbsp;Euclidean Distance Calculation</span></h4></li></ul>
<p><span class="font1">There are many distance calculations in the K-NN method, one of which is Euclidean. The purpose of the calculation is to define the distance between two points, namely the point on the training data (x) and the point on the testing data (y). Calculation of the euclidean dista</span><span class="font1" style="text-decoration:underline;">nce can be don</span><span class="font1">e with equation (6).</span></p>
<div>
<p><span class="font9" style="font-style:italic;">d(xi,yi) =</span><span class="font9"> √</span></p>
</div><br clear="all">
<p><span class="font7" style="font-style:italic;">n</span></p>
<p><span class="font9" style="font-style:italic;">∑(</span><span class="font6" style="font-style:italic;"><sup>χi-</sup>y</span><span class="font9" style="font-style:italic;">)<sup>2</sup></span><span class="font1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(6)</span></p>
<p><span class="font7" style="font-style:italic;">i=0</span></p>
<p><span class="font1">Where, d is the distance between the points on the training data x and the testing data points y that will be classified, then x, y and i represent the attributes and n is the attribute dimensions.</span></p>
<ul style="list-style:none;"><li>
<h4><a name="bookmark19"></a><span class="font1"><a name="bookmark20"></a>d.</span><span class="font1" style="font-weight:bold;font-style:italic;"> &nbsp;&nbsp;&nbsp;Sorting</span><span class="font1" style="font-weight:bold;"> Closest distance</span></h4></li></ul>
<p><span class="font1">The sorting process is carried out after all the distances have been obtained. In the K-NN method, a sorting process is carried out based on the smallest (closest) distance value.</span></p>
<ul style="list-style:none;"><li>
<h4><a name="bookmark21"></a><span class="font1"><a name="bookmark22"></a>e.</span><span class="font1" style="font-weight:bold;"> &nbsp;&nbsp;&nbsp;Class Determination</span></h4></li></ul>
<p><span class="font1">The process of determining the class or genre of music from the previous calculation process. Obtained the output of the class or genre results from the test data through this determination process.</span></p>
<ul style="list-style:none;"><li>
<h4><a name="bookmark23"></a><span class="font1" style="font-weight:bold;"><a name="bookmark24"></a>3.3 &nbsp;&nbsp;&nbsp;Testing and Evaluation</span></h4></li></ul>
<p><span class="font1">The test scenario is carried out to determine the best accuracy resulting from several different K values which will be tested by the K-NN method against the classification of music genres. The values or parameters of K to be tested are 3, 7, 11, 21, 31, 41, 51, and 61. The proportion of training data and test data in this study is 80:20 based on research on the classification that has been done [5]. Testing using the distribution of the proportion of training data and 80:20 test data with several different K parameters can be seen in Table 3.</span></p>
<p><span class="font1">In this study, the Accuracy calculation was performed from the classification results to measure the level of accuracy. Accuracy is the accuracy or accuracy of the amount of data that is predicted correctly which is obtained by equation (5) [6].</span></p>
<p><span class="font9" style="font-style:italic;">TP + TN Accuracy = ———————— TP + FN + FP + TN</span></p>
<div>
<p><span class="font1">(5)</span></p>
</div><br clear="all">
<p><span class="font1">Where:</span></p>
<p><span class="font1">TP = Number of positive objects that are correctly classified (True Positive).</span></p>
<p><span class="font1">TN = Number of misclassified negative objects (True Negative).</span></p>
<p><span class="font1">FP = Number of negative objects that are correctly classified (False Positive).</span></p>
<p><span class="font1">FN = Number of incorrectly classified positive objects (False Negative).</span></p>
<p><span class="font1" style="font-weight:bold;">Table 2. </span><span class="font1">Accuracy Testing with the proportion of 80:20</span></p>
<table border="1">
<tr><td style="vertical-align:bottom;">
<p><span class="font1">Training Data</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">Test Data</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">K value</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">K-NN accuracy</span></p></td></tr>
<tr><td rowspan="9" style="vertical-align:middle;">
<p><span class="font1">80</span></p></td><td rowspan="9" style="vertical-align:middle;">
<p><span class="font1">20</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">3</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">70%</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font1">7</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">72.5%</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font1">11</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">72.5%</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font1">21</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">72.5%</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font1">31</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">72.5%</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font1">41</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">72.5%</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font1">51</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">60%</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font1">61</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">55%</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font1">71</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">50%</span></p></td></tr>
</table><img src="https://jurnal.harianregional.com/media/64449-2.jpg" alt="" style="width:385pt;height:289pt;">
<p><span class="font1" style="font-weight:bold;">Figure 3. </span><span class="font1">Line graph of test accuracy</span></p>
<ul style="list-style:none;"><li>
<h4><a name="bookmark25"></a><span class="font1" style="font-weight:bold;"><a name="bookmark26"></a>4. &nbsp;&nbsp;&nbsp;Conclusion</span></h4></li></ul>
<p><span class="font1">Based on the results of successful research, it can be concluded that the MFCC and K-NN Classifier feature extraction method used to classify Pop and RnB songs with the proportion of 80:20 can produce the highest accuracy of 77.5% with a value of k = 31. From the graph shown on Figure 3 shows an increase occurred at the value of k = 31 and after that there was a significant decrease. It is hoped that in future studies, because not all possible values for the k parameter are tested, the accuracy can be further improved by optimizing the K parameter by methods such as genetic algorithms and others.</span></p>
<h4><a name="bookmark27"></a><span class="font1" style="font-weight:bold;"><a name="bookmark28"></a>References</span></h4>
<ul style="list-style:none;"><li>
<p><span class="font1">[1] &nbsp;&nbsp;&nbsp;George Tzanetakis, Perry Cook, “Musical Genre Classification of Audio Signal” IEEE Transactions On Speech and Audio Processing, Vol.10, No.5, July 2002.</span></p></li>
<li>
<p><span class="font1">[2] &nbsp;&nbsp;&nbsp;Loris Nannia, Yandre M. G. Costab, Alessandra Lumini, Moo Young Kim,Seung Ryul Baek, “Combining visual and acoustic featuresfor music genre classification” Expert System with Applications, Volume 45, pp. 108-117.</span></p></li>
<li>
<p><span class="font1">[3] Gst. Ayu Vida Mastrika Giri, “Klasifikasi dan Retrieval Musik Berdasarkan Genre” Jurnal</span></p></li></ul>
<p><span class="font1">Ilmiah, Ilmu Komputer, Universitas Udayana, Vol X, No. 1, April 2017.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1">[4] Sayf A. Majeed, Hafizah Husain, Salina Abdul Samad Tariq F. Idbeaa, “Mel Frequency</span></p></li></ul>
<p><span class="font1">Cepstral Coefficients (MFCC) Feature Extraction Enhancement In The Application Of Speech Recognition: A Comparison Study” Theoretical and Applied Information Technology, Vol. 79, No. 1, pp. 38-56, September 2015.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1">[5] &nbsp;&nbsp;&nbsp;Tri Holomoan Simanjuntak, Wayan Firdaus Mahmudi, and Sutrisno, &quot;Implementation of Modified K-Nearest Neighbor with K-Value Automation in Soybean Plant Disease Classification&quot; Development of Information Technology and Computer Science, Vol. 1, No. 2, pp. 75-79, February 2017.</span></p></li>
<li>
<p><span class="font1">[6] &nbsp;&nbsp;&nbsp;Nilesh M. Patil, and Dr. Milind U. Nemade, “Music Genre Classification Using MFCC, K-NN, and SVM Classifier” Computer Engineering in Research Trends, Vol. 4, Issue 2, pp. 43-47, February 2017.</span></p></li>
<li>
<p><span class="font1">[7] &nbsp;&nbsp;&nbsp;Darnisa Azzahra Nasution, Hidayah Husnul Khotimah, and Nurul Chamidah, &quot;Comparison of Normalized Data for Classification of Wine Using K-NN Algorithm&quot; Computer Engineering Systems and Science, Vol. 4, No. 1, pp. 78-82, January 2019.</span></p></li>
<li>
<p><span class="font1">[8] &nbsp;&nbsp;&nbsp;Nanang Wahyudi, Sri Wahyuningsih, and Fidia Deny Tisna Amijaya, &quot;Optimization of Coal Classification Based on Calorie using Genetic Modified K-Nearest Neighbor (GMK-NN)&quot; in Exponential, Vol. 10, No. 2, pp. 103-111, November 2019.</span></p></li>
<li>
<p><span class="font1">[9] &nbsp;&nbsp;&nbsp;Yogiek Indra Kurniawan, and Tiyssa Indah Barokah, &quot;Classification of Credit Card Application Determination Using K-Nearest Neighbor&quot; in MATRIK Scientific Journal, Vol. 22, No. 1, pp73-82, April 2020.</span></p></li></ul>
<p><span class="font1">524</span></p>