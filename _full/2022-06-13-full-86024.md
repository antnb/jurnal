---
layout: full_article
title: "Klasifikasi Berita Hoaks Covid-19 Menggunakan Kombinasi Metode K-Nearest Neighbor dan Information Gain"
author: "Marissa Audina, AAIN Eka Karyawati, I Wayan Supriana, I Ketut Gede Suhartana, I Gede Santi Astawa, I Wayan Santiyasa"
categories: jik
canonical_url: https://jurnal.harianregional.com/jik/full-86024 
citation_abstract_html_url: "https://jurnal.harianregional.com/jik/id-86024"
citation_pdf_url: "https://jurnal.harianregional.com/jik/full-86024"  
comments: true
---

<p><span class="font1">p-ISSN: 2301-5373</span></p>
<p><span class="font1">e-ISSN: 2654-5101</span></p>
<p><span class="font1">Jurnal Elektronik Ilmu Komputer Udayana</span></p>
<p><span class="font1">Volume 10, No 4. May 2022</span></p><a name="caption1"></a>
<h1><a name="bookmark0"></a><span class="font3" style="font-weight:bold;"><a name="bookmark1"></a>Klasifikasi Berita Hoaks Covid-19 Menggunakan Kombinasi Metode </span><span class="font3" style="font-weight:bold;font-style:italic;">K-Nearest Neighbor</span><span class="font3" style="font-weight:bold;"> dan </span><span class="font3" style="font-weight:bold;font-style:italic;">Information Gain</span></h1>
<p><span class="font1">Marissa Audina<sup>a1</sup></span><span class="font1" style="font-weight:bold;">, </span><span class="font1">AAIN Eka Karyawati<sup>a2</sup>, I Wayan Supriana <sup>a3</sup>, I Ketut Gede Suhartana <sup>a4</sup>, I Gede Santi Astawa <sup>a5</sup>, I Wayan Santiyasa<sup>a6</sup></span></p>
<p><span class="font1"><sup>a</sup>Program Studi Informatika, Fakultas Matematika dan Ilmu Pengetahuan Alam, Universitas Udayana</span></p>
<p><span class="font1">Bali, Indonesia </span><a href="mailto:1marissaaudina@gmail.com"><span class="font1"><sup>1</sup>marissaaudina@gmail.com</span></a><span class="font1"> </span><a href="mailto:2eka.karyawati@unud.ac.id"><span class="font1"><sup>2</sup>eka.karyawati@unud.ac.id</span></a><span class="font1"> </span><a href="mailto:wayan.supriana@unud.ac.id"><span class="font1"><sup>3</sup>wayan.supriana@unud.ac.id</span></a><span class="font1"> </span><a href="mailto:ikg.suhartana@unud.ac.id"><span class="font1"><sup>4</sup>ikg.suhartana@unud.ac.id</span></a><span class="font1"> </span><a href="mailto:santi.astawa@unud.ac.id"><span class="font1"><sup>5</sup>santi.astawa@unud.ac.id</span></a><span class="font1"> </span><a href="mailto:6santiyasa@unud.ac.id"><span class="font1"><sup>6</sup>santiyasa@unud.ac.id</span></a></p>
<p><span class="font1" style="font-weight:bold;font-style:italic;">Abstract</span></p>
<p><span class="font1" style="font-style:italic;">News is one of information resources that is being used by the public. However, not all news circulating in digital media are facts. Some people take the opportunity to share unfounded and irresponsible news. Since the Covid-19 pandemic hit Indonesia, hoax news about the pandemic has increasingly circulated in digital media. In this study, the author builds a model that can classify hoax news using the K-Nearest Neighbor method combined with the Information Gain feature selection. The data used are factual news data and hoax news data in Indonesian language. Evaluation is done by measuring the performance of the K-Nearest Neighbor model without feature selection and model performance by implementing Information Gain feature selection. The K-Nearest Neighbor model without feature selection with a value of k=5 obtained precision, recall, F1-Score, and accuracy performance of 87.5%, 96.5%, 91.8%, and 91.6%, respectively. While the K-Nearest Neighbor model with a combination of 0.5% Information Gain threshold feature selection with a value of k=3 obtained precision, recall, F1-Score, and accuracy performance of 93.3%, 96.6%, 95%, and 95%, respectively.</span></p>
<p><span class="font1" style="font-weight:bold;font-style:italic;">Keywords: </span><span class="font1" style="font-style:italic;">K-Nearest Neighbor</span><span class="font1">, </span><span class="font1" style="font-style:italic;">Information Gain</span><span class="font1">, TF-IDF, Klasifikasi Teks, Berita Hoaks</span></p>
<ul style="list-style:none;"><li>
<h4><a name="bookmark2"></a><span class="font1" style="font-weight:bold;"><a name="bookmark3"></a>1. &nbsp;&nbsp;&nbsp;Pendahuluan</span></h4></li></ul>
<p><span class="font1">Berita digunakan oleh masyarakat sebagai salah satu sumber informasi. Tidak semua berita yang beredar di media digital adalah fakta. Beberapa individu atau kelompok mengambil kesempatan untuk menyebarkan berita atau informasi yang tidak dapat dipertanggungjawabkan kebenarannya dan terdapat indikasi </span><span class="font1" style="font-style:italic;">hoax</span><span class="font1">.[1] Data dari laman resmi kominfo.go.id menyatakan bahwa sebanyak 800.000 situs terindikasi sebagai situs penyebaran hoaks di Indonesia. Menurut Kamus Besar Bahasa Indonesia, hoaks (bahasa Inggris: </span><span class="font1" style="font-style:italic;">hoax</span><span class="font1">) memiliki makna informasi bohong. Sejak pandemi Covid-19 melanda Indonesia, berita hoaks mengenai pandemi tersebut semakin banyak beredar di media digital. Data terbaru dari Kementerian Komunikasi dan Informatika, sebanyak 5457 sebaran hoaks Covid-19 sudah ditindaklanjuti sejak 23 Januari 2020 hingga 18 Maret 2022 [2].</span></p>
<p><span class="font1">Berita-berita yang didapatkan dari media dapat diklasifikasikan menjadi berita hoaks dan berita fakta. Pengklasifikasian berita tersebut membutuhkan suatu metode atau algoritma agar tidak menggunakan cara manual dan menghabiskan waktu yang lama. Peranan informatika dibutuhkan dalam hal ini untuk membangun suatu model klasifikasi yang dapat mengkategorikan dua jenis berita tersebut. Penelitian mengenai klasifikasi berita hoaks telah dilakukan oleh beberapa peneliti seperti penelitian klasifikasi berita </span><span class="font1" style="font-style:italic;">clickbait</span><span class="font1"> menggunakan </span><span class="font1" style="font-style:italic;">K-Nearest Neighbor </span><span class="font1">yang menghasilkan akurasi terbaik 71% dengan parameter nilai k=11 pada skenario 80% data latih dan 20% data uji [3]. Kemudian penelitian mengenai identifikasi hoaks berbasis </span><span class="font1" style="font-style:italic;">text mining </span><span class="font1">menggunakan </span><span class="font1" style="font-style:italic;">K-Nearest Neighbor</span><span class="font1"> menghasilkan akurasi sebesar 75.4% pada nilai k optimal</span></p>
<p><span class="font1">bernilai 4 [4]. Penelitian selanjutnya adalah analisis sentimen terhadap ulasan pengguna MRT Jakarta menggunakan </span><span class="font1" style="font-style:italic;">Information Gain</span><span class="font1"> dan </span><span class="font1" style="font-style:italic;">Modified K-Nearest Neighbor</span><span class="font1"> dengan peningkatan akurasi 4-5% setelah menggunakan seleksi fitur </span><span class="font1" style="font-style:italic;">Information Gain</span><span class="font1"> [5]</span><span class="font1" style="font-style:italic;">.</span></p>
<p><span class="font1">Berdasarkan penelitian yang dilakukan sebelumnya, pada penelitian ini penulis melakukan klasifikasi berita hoaks menggunakan metode </span><span class="font1" style="font-style:italic;">K-Nearest Neighbor</span><span class="font1"> yang dikombinasikan dengan seleksi fitur </span><span class="font1" style="font-style:italic;">Information Gain</span><span class="font1">. Penulis berharap bahwa dengan menggunakan kombinasi metode ini dapat menghasilkan performa </span><span class="font1" style="font-style:italic;">precision, recall, f1-score,</span><span class="font1"> dan akurasi yang lebih baik dibandingkan penelitian sebelumnya.</span></p>
<ul style="list-style:none;"><li>
<h4><a name="bookmark4"></a><span class="font1" style="font-weight:bold;"><a name="bookmark5"></a>2. &nbsp;&nbsp;&nbsp;Metode Penelitian</span><br><br><span class="font1" style="font-weight:bold;"><a name="bookmark6"></a>2.1 &nbsp;&nbsp;Dataset</span></h4></li></ul>
<p><span class="font1">Jenis data sekunder digunakan pada penelitian ini. Dataset diperoleh dalam bentuk berita yang berkaitan dengan Covid-19. Data berita hoaks bersumber dari</span><a href="https://cekfakta.com/"><span class="font1"> https://cekfakta.com, </span></a><span class="font1">sedangkan data berita fakta bersumber dari</span><a href="https://detik.com/"><span class="font1"> https://detik.com. </span></a><span class="font1">Bagian berita yang digunakan adalah isi berita. Data berjumlah 300 dengan format </span><span class="font1" style="font-style:italic;">file</span><span class="font1"> *.csv yang meliputi 150 berita hoaks dan 150 berita fakta yang bersumber dari media internet. Seluruh data sudah dilabeli oleh lembaga media internet tersebut. Data berita kemudian dibagi dengan presentase data latih sebesar 80% dan data uji sebesar 20%. Data latih tersebut kemudian dibagi lagi menjadi data latih dan data validasi untuk digunakan dalam proses pelatihan model dengan menggunakan </span><span class="font1" style="font-style:italic;">N-Fold Cross Validation</span><span class="font1"> dengan nilai </span><span class="font1" style="font-style:italic;">N</span><span class="font1"> = 10.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1" style="font-weight:bold;">2.2</span><span class="font1" style="font-weight:bold;font-style:italic;"> &nbsp;&nbsp;&nbsp;Preprocessing</span></p></li></ul>
<p><span class="font1">Sebelum melakukan tahap pembobotan, data terlebih dahulu melalui tahapan </span><span class="font1" style="font-style:italic;">preprocessing. Preprocessing</span><span class="font1"> adalah proses yang dilakukan untuk mengolah data ulasan yang belum terstruktur menjadi terstruktur sehingga data dapat dilanjutkan ke proses klasifikasi. Adapun alur </span><span class="font1" style="font-style:italic;">preprocessing</span><span class="font1"> seperti pada Gambar 1.</span></p><img src="https://jurnal.harianregional.com/media/86024-1.jpg" alt="" style="width:146pt;height:206pt;">
<p><span class="font1" style="font-weight:bold;">Gambar 1. </span><span class="font1">Alur </span><span class="font1" style="font-style:italic;">Preprocessing</span></p>
<p><span class="font1">Data dokumen berita akan melalui proses </span><span class="font1" style="font-style:italic;">case folding</span><span class="font1"> yaitu proses untuk membuat bentuk data yang sama yaitu hanya berisi huruf kecil. </span><span class="font1" style="font-style:italic;">Case folding</span><span class="font1"> dilakukan agar data yang ada menjadi sama rata [6]. Kemudian proses </span><span class="font1" style="font-style:italic;">cleansing</span><span class="font1"> untuk menghapus seluruh karakter yang berupa HTML ataupun web yang tidak memiliki makna atau kaitan terhadap analisis sentimen. Pada proses ini juga dilakukan proses penghapusan </span><span class="font1" style="font-style:italic;">punctuation</span><span class="font1"> atau tanda baca. </span><span class="font1" style="font-style:italic;">Tokenization</span><span class="font1"> adalah proses pemisahan kata dalam suatu paragraf atau kalimat sehingga terbagi menjadi token-token tertentu. </span><span class="font1" style="font-style:italic;">Stopword removal</span><span class="font1"> merupakan proses penghapusan kata atau fitur yang tidak berpengaruh dan tidak penting terhadap klasifikasi. Penghapusan ini dilakukan untuk membuat proses klasifikasi berjalan efisien [6]. Kemudian proses normalisasi, yaitu mengubah dan</span></p>
<p><span class="font1">mengembalikan bentuk penulisan tidak baku ke bentuk penulisan yang sesuai dengan KBBI. Pada proses ini digunakan korpus yang berisi kumpulan kata tidak baku dan bentuk baku dari kata tersebut. Proses terakhir adalah </span><span class="font1" style="font-style:italic;">stemming</span><span class="font1"> yang berfungsi agar kata-kata berimbuhan (awalan dan akhiran) dapat diekstraksi ke bentuk akarnya atau dapat dikatakan sebagai kata dasar. </span><span class="font1" style="font-style:italic;">Stemming</span><span class="font1"> dilakukan untuk menyamakan data yang berbeda penulisannya [6].</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1" style="font-weight:bold;">2.3</span><span class="font1" style="font-weight:bold;font-style:italic;"> &nbsp;&nbsp;&nbsp;Term Frequency Inverse-Document Frequency</span><span class="font1" style="font-weight:bold;"> (TF-IDF)</span></p></li></ul>
<p><span class="font1">TF-IDF merupakan metode pembobotan kata untuk menentukan keterhubungan kata pada suatu dokumen [4]. Data yang diproses akan diubah menjadi data numerik dengan metode pembobotan TF-IDF, yang merupakan penggabungan dua konsep yaitu TF dan IDF. </span><span class="font1" style="font-style:italic;">Term Frequency</span><span class="font1"> (TF) merupakan frekuensi dari kemunculan kata dalam sebuah dokumen, sedangkan </span><span class="font1" style="font-style:italic;">Inverse Document Frequency</span><span class="font1"> (IDF) adalah perhitungan dari distribusi kata secara luas pada koleksi dokumen. Kata atau </span><span class="font1" style="font-style:italic;">term</span><span class="font1"> yang muncul di dalam sebagian besar dokumen akan mempunyai nilai IDF mendekati nol. Adapun tahapan dari TF-IDF ditunjukkan oleh Gambar 2.</span></p><img src="https://jurnal.harianregional.com/media/86024-2.jpg" alt="" style="width:139pt;height:271pt;">
<p><span class="font1" style="font-weight:bold;">Gambar 2. </span><span class="font1">TF-IDF</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1">a. &nbsp;&nbsp;&nbsp;Menghitung jumlah kemunculan </span><span class="font1" style="font-style:italic;">term </span><span class="font8" style="font-style:italic;">i</span><span class="font1"> dalam dokumen </span><span class="font8" style="font-style:italic;">j </span><span class="font1" style="font-style:italic;">(</span><span class="font8" style="font-style:italic;">tf<sub>lj</sub></span><span class="font1">).</span></p></li>
<li>
<p><span class="font1">b. &nbsp;&nbsp;&nbsp;Menghitung jumlah dokumen yang mengandung </span><span class="font1" style="font-style:italic;">term </span><span class="font8" style="font-style:italic;">i </span><span class="font1" style="font-style:italic;">(</span><span class="font8" style="font-style:italic;">df<sub>i</sub></span><span class="font1">)</span></p></li>
<li>
<p><span class="font1">c. &nbsp;&nbsp;&nbsp;Menghitung nilai bobot </span><span class="font1" style="font-style:italic;">inverse document frequency</span><span class="font1"> (idf) dengan menggunakan persamaan :</span></p></li></ul>
<p><span class="font7" style="font-style:italic;">N</span></p>
<p><span class="font9" style="font-style:italic;">idf</span><span class="font6" style="font-style:italic;">i</span><span class="font4"> = </span><span class="font9" style="font-style:italic;">log</span><span class="font1"> (—</span><span class="font9">) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="font1">(1)</span></p>
<p><span class="font1">Keterangan :</span></p>
<p><span class="font1">N = jumlah dokumen secara keseluruhan</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1">d. &nbsp;&nbsp;&nbsp;Menghitung nilai bobot TF-IDF dengan menggunakan persamaan :</span></p></li></ul>
<h2><a name="bookmark7"></a><span class="font9" style="font-style:italic;"><a name="bookmark8"></a>w<sub>i</sub></span><span class="font7" style="font-style:italic;">j</span><span class="font9"> = </span><span class="font9" style="font-style:italic;">tf<sub>i</sub></span><span class="font7" style="font-style:italic;">j </span><span class="font9" style="font-style:italic;">x idf<sub>i</sub></span><span class="font1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(2)</span></h2>
<p><span class="font1">Keterangan :</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1" style="font-style:italic;">w<sub>i</sub></span><span class="font7" style="font-style:italic;">j</span><span class="font1"> = bobot </span><span class="font1" style="font-style:italic;">term </span><span class="font8" style="font-style:italic;">i</span><span class="font1"> terhadap dokumen </span><span class="font1" style="font-style:italic;">j </span><span class="font9" style="font-style:italic;">tf<sub>i</sub></span><span class="font7" style="font-style:italic;">j</span><span class="font1"> = frekuensi </span><span class="font1" style="font-style:italic;">term </span><span class="font8" style="font-style:italic;">i</span><span class="font1"> pada dokumen </span><span class="font1" style="font-style:italic;">j </span><span class="font9" style="font-style:italic;">idf<sub>i</sub></span><span class="font1"> = nilai bobot IDF </span><span class="font1" style="font-style:italic;">term </span><span class="font8" style="font-style:italic;">i</span></p></li></ul>
<ul style="list-style:none;"><li>
<p><span class="font1" style="font-weight:bold;">2.4</span><span class="font1" style="font-weight:bold;font-style:italic;"> &nbsp;&nbsp;&nbsp;K-Nearest Neighbor</span><span class="font1" style="font-weight:bold;"> (KNN)</span></p></li></ul>
<p><span class="font1">Metode KNN sering diterapkan pada </span><span class="font1" style="font-style:italic;">data mining</span><span class="font1"> dan </span><span class="font1" style="font-style:italic;">text mining</span><span class="font1">. KNN merupakan metode pengklasifikasian objek berdasarkan tetangga yang paling dekat dengannya. KNN memberikan keanggotaan kelas ke data berdasarkan mayoritas tetangganya, dengan objek yang ditetapkan ke kelas yang paling umum di antara k tetangga terdekatnya (k adalah bilangan bulat positif bernilai kecil). Pada penelitian ini, fitur kata yang sudah melalui proses pembobotan TF-IDF akan menghasilkan suatu matriks yang berisikan bobot nilai TF-IDF dengan dokumen sebagai baris dan fitur kata sebagai kolom. Setiap vektor dokumen dengan nilai bobot fitur pada data latih akan dihitung jaraknya dengan vektor pada data uji. Adapun tahapan metode ditunjukkan oleh Gambar 3.</span></p>
<div><img src="https://jurnal.harianregional.com/media/86024-3.jpg" alt="" style="width:152pt;height:292pt;">
<p><span class="font1" style="font-weight:bold;">Gambar 3. </span><span class="font1">Klasifikasi </span><span class="font1" style="font-style:italic;">K-Nearest Neighbor</span></p>
</div><br clear="all">
<p><span class="font1">Tahapan dari KNN adalah sebagai berikut :</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1">a. &nbsp;&nbsp;&nbsp;Menentukan jumlah tetangga k yang akan digunakan.</span></p></li>
<li>
<p><span class="font1">b. &nbsp;&nbsp;&nbsp;Melakukan perhitungan jarak antara data latih dan data uji menggunakan rumus persamaan </span><span class="font1" style="font-style:italic;">Euclidean distance</span><span class="font1"> di bawah [7]:</span></p>
<div>
<p><span class="font1">(3)</span></p>
</div><br clear="all"></li></ul>
<h3><a name="bookmark9"></a><span class="font9"><a name="bookmark10"></a>d(x, y) = √∑</span><span class="font7">k=ι</span><span class="font9">(<sup>x</sup></span><span class="font7">k </span><span class="font9">- y</span><span class="font7">k</span><span class="font9">)<sup>2</sup></span></h3>
<p><span class="font1">Keterangan :</span></p>
<p><span class="font1">d = jarak</span></p>
<p><span class="font1">x = data uji (</span><span class="font1" style="font-style:italic;">data testing</span><span class="font1">)</span></p>
<p><span class="font1">y = data latih (</span><span class="font1" style="font-style:italic;">data training</span><span class="font1">)</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1">c. &nbsp;&nbsp;&nbsp;Mendapatkan hasil pengklasifikasian</span></p></li></ul>
<ul style="list-style:none;"><li>
<p><span class="font1" style="font-weight:bold;">2.5</span><span class="font1" style="font-weight:bold;font-style:italic;"> &nbsp;&nbsp;&nbsp;Information Gain</span></p></li></ul>
<p><span class="font1" style="font-style:italic;">Information gain</span><span class="font1"> banyak digunakan pada klasifikasi data tekstual sebagai metode seleksi fitur. </span><span class="font1" style="font-style:italic;">Information gain</span><span class="font1"> melakukan perhitungan mengenai pengaruh suatu fitur terhadap keseragaman kelas pada data. Seleksi fitur ini menghitung hadir tidaknya suatu kata yang berkontribusi pada pengambilan keputusan klasifikasi yang benar di kelas apapun [8]. Data tersebut dipecah menjadi sub data dengan nilai fitur tertentu. Jika suatu fitur memperoleh nilai </span><span class="font1" style="font-style:italic;">information gain</span><span class="font1"> yang tinggi, maka fitur tersebut dikatakan memiliki pengaruh pada proses klasifikasi. Adapun tahapan </span><span class="font1" style="font-style:italic;">Information Gain</span><span class="font1"> ditunjukkan oleh Gambar 4.</span></p><img src="https://jurnal.harianregional.com/media/86024-4.jpg" alt="" style="width:160pt;height:314pt;">
<p><span class="font1" style="font-weight:bold;">Gambar 4. </span><span class="font1" style="font-style:italic;">Information Gain</span></p>
<p><span class="font1">Langkah-langkah dari </span><span class="font1" style="font-style:italic;">Information Gain</span><span class="font1"> adalah sebagai berikut :</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1">a. &nbsp;&nbsp;&nbsp;Isi data dan label data sebagai input.</span></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark11"><span class="font1">b. &nbsp;&nbsp;&nbsp;Melakukan perhitungan nilai </span><span class="font1" style="font-style:italic;">Information Gain</span><span class="font1"> dari setiap fitur dengan rumus berikut [9] : </span><span class="font9">Information Gain I(tj) of tj = -∑^<sub>1</sub> — log (—) - E(tj)</span></a></p></li></ul>
<p><a href="#bookmark12"><span class="font8" style="font-style:italic;">n∏</span></a></p>
<p><span class="font1">Dimana E(tj) adalah </span><span class="font1" style="font-style:italic;">entropy</span><span class="font1"> bersyarat yang dihitung dengan persamaan :</span></p>
<p><a href="#bookmark13"><span class="font9">E(tj) = -</span><span class="font8">∑</span><span class="font6">^=</span><span class="font8"><sub>1</sub> {[</span><span class="font6">^(J^)</span><span class="font8">]p(c<sub>r</sub>kj).log[P(c<sub>r</sub></span><span class="font5">∣</span><span class="font8">tj}] + f^] P(cJ→D.log[P(c<sub>r</sub>Htj)]}</span></a></p>
<p><span class="font1">Keterangan : n</span><span class="font0">r &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="font1">: jumlah total dokumen dengan kelas r.</span></p>
<p><span class="font1">n &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;: jumlah total dokumen.</span></p>
<p><span class="font1">n(tj) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;: banyaknya dokumen yang mengandung term tj dari korpus berukuran n ≥ n (tj).</span></p>
<p><span class="font1">P(c</span><span class="font0">r</span><span class="font1">|tj) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;: peluang </span><span class="font1" style="font-style:italic;">term</span><span class="font1"> tj terdapat pada kelas r dalam dokumen.</span></p>
<p><span class="font1">P(C</span><span class="font8">rhtj) &nbsp;&nbsp;&nbsp;</span><span class="font1">: peluang </span><span class="font1" style="font-style:italic;">term</span><span class="font1"> tj tidak terdapat pada kelas r dalam dokumen.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1">c. &nbsp;&nbsp;&nbsp;Mengurutkan fitur-fitur berdasarkan nilai </span><span class="font1" style="font-style:italic;">Information Gain</span><span class="font1"> tertinggi.</span></p></li>
<li>
<p><span class="font1">d. &nbsp;&nbsp;&nbsp;Memilih fitur terbaik sesuai dengan </span><span class="font1" style="font-style:italic;">threshold</span><span class="font1"> yang diberikan.</span></p></li></ul>
<ul style="list-style:none;"><li>
<h4><a name="bookmark14"></a><span class="font1" style="font-weight:bold;"><a name="bookmark15"></a>2.6 &nbsp;&nbsp;&nbsp;Evaluasi</span></h4></li></ul>
<p><span class="font1">Pada tahap evaluasi, </span><span class="font1" style="font-style:italic;">confusion matrix</span><span class="font1"> digunakan untuk menghitung akurasi, </span><span class="font1" style="font-style:italic;">recall, precision, </span><span class="font1">dan </span><span class="font1" style="font-style:italic;">error rate. Confusion matrix</span><span class="font1"> dapat digunakan untuk mengevaluasi kualitas </span><span class="font1" style="font-style:italic;">classifier</span><span class="font1">. Pada </span><span class="font1" style="font-style:italic;">confusion matrix</span><span class="font1"> dua kelas, matriks menunjukkan </span><span class="font1" style="font-style:italic;">true positives, true negatives, false positives, </span><span class="font1">dan </span><span class="font1" style="font-style:italic;">false negatives</span><span class="font1">. C</span><span class="font1" style="font-style:italic;">onfusion matrix</span><span class="font1"> untuk dua kelas ditunjukkan pada Tabel 1 [10].</span></p>
<p><span class="font1" style="font-weight:bold;">Tabel 1. </span><span class="font1" style="font-style:italic;">Confusion Matrix</span></p>
<table border="1">
<tr><td rowspan="2" style="vertical-align:bottom;">
<p><span class="font1" style="font-weight:bold;">Kelas Sebenarnya</span></p></td><td colspan="2" style="vertical-align:middle;">
<p><span class="font1" style="font-weight:bold;">Prediksi Kelas</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font1" style="font-weight:bold;">Positif</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1" style="font-weight:bold;">Negatif</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font1" style="font-weight:bold;">Positif</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">TP</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">FN</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font1" style="font-weight:bold;">Negatif</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">FP</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">TN</span></p></td></tr>
</table>
<p><span class="font1">Keteranganx:</span></p>
<p><span class="font1">TP &nbsp;&nbsp;&nbsp;&nbsp;= </span><span class="font1" style="font-style:italic;">True Positive</span><span class="font1"> (total prediksi benar dari data positif)</span></p>
<p><span class="font1">FN &nbsp;&nbsp;&nbsp;&nbsp;= </span><span class="font1" style="font-style:italic;">False Negative</span><span class="font1"> (total prediksi salah dari data positif)</span></p>
<p><span class="font1">TN &nbsp;&nbsp;&nbsp;&nbsp;= </span><span class="font1" style="font-style:italic;">True Negative</span><span class="font1"> (total prediksi benar dari data negatif)</span></p>
<p><span class="font1">FP &nbsp;&nbsp;&nbsp;&nbsp;= </span><span class="font1" style="font-style:italic;">False Positive</span><span class="font1"> (total prediksi salah dari data negatif)</span></p>
<p><span class="font1">Adapun rumus untuk menghitung </span><span class="font1" style="font-style:italic;">precision, recall, F1-Score,</span><span class="font1"> dan akurasi adalah sebagai berikut:</span></p>
<p><span class="font7" style="font-style:italic;">_ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;TP</span></p>
<p><a href="#bookmark16"><span class="font1" style="font-style:italic;">Precision</span><span class="font10"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=</span></a></p>
<p><a href="#bookmark17"><span class="font7" style="font-style:italic;">(TP+FP) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'</span></a></p>
<div>
<p><span class="font1" style="font-style:italic;">Recall</span></p>
</div><br clear="all">
<p><span class="font7" style="font-style:italic;text-decoration:underline;">TP </span><span class="font7" style="font-style:italic;">(TP+FN)</span></p>
<div>
<p><span class="font1">(7)</span></p>
<p><span class="font1">(8)</span></p>
</div><br clear="all">
<p><span class="font7">_ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2 </span><span class="font7" style="font-style:italic;">x recall x precision</span></p>
<p><a href="#bookmark18"><span class="font1" style="font-style:italic;">F1-Score</span><span class="font10">=</span></a></p>
<p><span class="font7" style="font-style:italic;">(recall+precision)</span></p>
<div>
<p><span class="font1">Akurasi</span></p>
</div><br clear="all">
<div>
<p><span class="font7" style="font-style:italic;text-decoration:underline;">(TP+TN) </span><span class="font7" style="font-style:italic;">(TP+TN+FP+FN)</span></p>
</div><br clear="all">
<div>
<p><span class="font1">(9)</span></p>
</div><br clear="all">
<ul style="list-style:none;"><li>
<h4><a name="bookmark19"></a><span class="font1" style="font-weight:bold;"><a name="bookmark20"></a>3. &nbsp;&nbsp;&nbsp;Hasil dan Pembahasan</span></h4></li></ul>
<p><span class="font1">Sebanyak 80% dari total data digunakan pada tahap pelatihan dan validasi. Beberapa eksperimen dilakukan yaitu model KNN tanpa seleksi fitur, model KNN dengan eksperimen beberapa nilai </span><span class="font1" style="font-style:italic;">threshold Information</span><span class="font1"> Gain, dan pengujian kedua model terbaik dengan menggunakan data baru yaitu 20% data uji yang sudah disiapkan sebelumnya. Perubahan nilai k dilakukan pada metode </span><span class="font1" style="font-style:italic;">K-Nearest Neighbor.</span><span class="font1"> Perubahan nilai k pada eksperimen adalah k=3, k=5, k=7, k=9, dan k=11. Pengujian terhadap </span><span class="font1" style="font-style:italic;">threshold</span><span class="font1"> dilakukan pada seleksi fitur </span><span class="font1" style="font-style:italic;">Information Gain</span><span class="font1">. </span><span class="font1" style="font-style:italic;">Threshold</span><span class="font1"> adalah persentase jumlah fitur yang terseleksi dari seluruh fitur yang telah diurutkan berdasarkan nilai </span><span class="font1" style="font-style:italic;">Information Gain</span><span class="font1"> tertinggi. </span><span class="font1" style="font-style:italic;">Threshold</span><span class="font1"> yang digunakan adalah 50%, 25%, 20%, 10%, 5%, 2%, 1%, 0.5%, 0.2%, dan 0.1%. Pada setiap iterasi 10-</span><span class="font1" style="font-style:italic;">Fold Cross Validation</span><span class="font1">, akan dihitung rata-rata performa </span><span class="font1" style="font-style:italic;">F1-Score</span><span class="font1"> dan akurasi dengan menggunakan persamaan (8) dan (9). Nilai k yang menghasilkan performa </span><span class="font1" style="font-style:italic;">F1-Score</span><span class="font1"> tertinggi dipilih sebagai model terbaik yang kemudian digunakan pada proses </span><span class="font1" style="font-style:italic;">testing</span><span class="font1"> data baru. Nilai k yang</span></p>
<p><span class="font1">menghasilkan </span><span class="font1" style="font-style:italic;">F1-Score</span><span class="font1"> tertinggi memiliki makna bahwa hasil prediksi berita hoaks akan lebih akurat kebenarannya.</span></p>
<p><span class="font1">Setelah dilakukan proses pelatihan dan validasi terhadap model </span><span class="font1" style="font-style:italic;">K-Nearest Neighbor </span><span class="font1">menggunakan 10</span><span class="font1" style="font-style:italic;">-Fold Cross Validation</span><span class="font1">, didapatkan nilai k dengan performa </span><span class="font1" style="font-style:italic;">F1-Score</span><span class="font1"> terbaik yaitu k = 5 dengan nilai </span><span class="font1" style="font-style:italic;">F1-Score</span><span class="font1"> 93.9% serta akurasi 94.2%. Sehingga, nilai k = 5 dipilih sebagai model terbaik dan akan digunakan pada proses pengujian data uji dengan menggunakan data baru yang belum pernah melalui proses pelatihan dan validasi.</span></p>
<p><span class="font1" style="font-weight:bold;">Tabel 2. </span><span class="font1">Hasil Evaluasi Pengujian </span><span class="font1" style="font-style:italic;">K-Nearest Neighbor</span><span class="font1"> tanpa Seleksi Fitur</span></p>
<table border="1">
<tr><td rowspan="2" style="vertical-align:middle;">
<p><span class="font1">Nilai k</span></p></td><td colspan="2" style="vertical-align:bottom;">
<p><span class="font1">Ukuran Evaluasi (Rata-Rata Fold)</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font1">F1-Score</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">Akurasi</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font1">3</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0.908</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0.908</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font1">5</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0.939</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0.942</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font1">7</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0.927</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0.929</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font1">9</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0.934</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0.938</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font1">11</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0.935</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0.938</span></p></td></tr>
</table>
<p><span class="font1">Jumlah keseluruhan fitur adalah 4934 fitur. Pada setiap eksperimen perubahan nilai </span><span class="font1" style="font-style:italic;">threshold</span><span class="font1">, dilakukan juga perubahan nilai k sehingga didapatkan kombinasi </span><span class="font1" style="font-style:italic;">threshold</span><span class="font1"> dan parameter nilai k yang menghasilkan performa terbaik. Kombinasi </span><span class="font1" style="font-style:italic;">threshold</span><span class="font1"> 0.5% dengan parameter nilai k=3 menghasilkan performa terbaik pada proses pelatihan dan validasi yaitu </span><span class="font1" style="font-style:italic;">F1-Score</span><span class="font1"> sebesar 97.3%, serta akurasi sebesar 97.5%, sehingga kombinasi ini dipilih menjadi model terbaik. </span><span class="font1" style="font-style:italic;">Threshold</span><span class="font1"> ini menyeleksi sekitar 25 fitur dengan nilai </span><span class="font1" style="font-style:italic;">Information Gain</span><span class="font1"> tertinggi. Fitur-fitur tersebut terdiri dari beberapa fitur yang dominan pada dokumen kelas hoaks, dan beberapa fitur lainnya dominan pada dokumen kelas fakta. Fitur-fitur tersebut menjadi ciri khas dari kedua kelas berita sehingga model dapat mengklasifikasikan berita dengan baik, ditunjukkan oleh performa akurasi yang dihasilkan.</span></p>
<p><span class="font1" style="font-weight:bold;">Tabel 3. </span><span class="font1">Hasil Evaluasi Pengujian </span><span class="font1" style="font-style:italic;">K-Nearest Neighbor</span><span class="font1"> dengan Seleksi Fitur</span></p>
<table border="1">
<tr><td rowspan="2" style="vertical-align:middle;">
<p><span class="font1">Threshold</span></p></td><td colspan="2" style="vertical-align:bottom;">
<p><span class="font1">Ukuran Evaluasi (Rata-Rata Fold)</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font1">F1-Score</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">Akurasi</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font1">50%</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0.255</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0.575</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font1">25%</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0.271</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0.579</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font1">20%</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0.266</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0.58</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font1">10%</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0.869</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0.875</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font1">5%</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0.912</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0.913</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font1">2%</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0.952</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0.954</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font1">1%</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0.958</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0.958</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font1">0.5%</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0.973</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0.975</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font1">0.2%</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0.937</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0.942</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font1">0.1%</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0.925</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0.929</span></p></td></tr>
</table>
<p><span class="font1">Dua model terbaik yang dipilih adalah model yang menghasilkan </span><span class="font1" style="font-style:italic;">F1-Score</span><span class="font1"> terbaik, yaitu model KNN tanpa seleksi fitur dengan nilai k = 5, dan model KNN dengan kombinasi seleksi fitur </span><span class="font1" style="font-style:italic;">Information Gain threshold</span><span class="font1"> 0.5% dengan nilai k=3. Kedua model tersebut kemudian diuji kembali menggunakan data baru yang belum pernah melewati tahap pelatihan dan validasi sebelumnya.</span></p>
<p><span class="font1">Setelah melakukan pengujian tehadap kedua model dengan menggunakan data baru, hasil performa model ditunjukkan pada Gambar 5.</span></p>
<p><span class="font2" style="font-weight:bold;">HASIL PENGUJIAN MODEL TERBAIK</span></p>
<p><span class="font0" style="font-weight:bold;">■ K-NEAREST NEIGHBOR </span><span class="font0">■ K-NEAREST NEIGHBOR + INFORMATION GAIN</span></p><img src="https://jurnal.harianregional.com/media/86024-5.jpg" alt="" style="width:296pt;height:107pt;">
<p><span class="font1" style="font-weight:bold;">Gambar 5. </span><span class="font1">Hasil Pengujian Model Terbaik</span></p>
<p><span class="font1">Pada Gambar 5 ditunjukkan bahwa kombinasi metode KNN dan </span><span class="font1" style="font-style:italic;">Information Gain</span><span class="font1"> menghasilkan performa yang lebih baik dalam klasifikasi berita hoaks. Terdapat peningkatan pada setiap performa evaluasi model. Model KNN tanpa seleksi fitur dengan nilai k=5 menghasilkan performa </span><span class="font1" style="font-style:italic;">precision</span><span class="font1">, </span><span class="font1" style="font-style:italic;">recall, F1-Score,</span><span class="font1"> dan akurasi secara berturut-turut yaitu 87.5%, 96,5%, 91,8%, dan 91,6%. Sedangkan model KNN dengan kombinasi seleksi fitur </span><span class="font1" style="font-style:italic;">Information Gain threshold</span><span class="font1"> 0.5% dengan nilai k=3 menghasilkan performa </span><span class="font1" style="font-style:italic;">precision</span><span class="font1">, </span><span class="font1" style="font-style:italic;">recall, F1-Score,</span><span class="font1"> dan akurasi secara berturut-turut yaitu 93.3%, 96.6%, 95%, dan 95%. Pada nilai </span><span class="font1" style="font-style:italic;">recall</span><span class="font1"> kedua model, tidak terdapat perbedaan yang signifikan. </span><span class="font1" style="font-style:italic;">Recall</span><span class="font1"> menghitung presentase prediksi kelas hoaks benar terhadap seluruh data yang kelas sebenarnya adalah hoaks. Hal ini menandakan bahwa kedua model terbaik yang diuji sama-sama dapat dengan baik mengklasifikan berita hoaks ke dalam kelas hoaks dengan sedikit kesalahan pada klasifikasi berita kelas hoaks ke dalam kelas fakta.</span></p>
<ul style="list-style:none;"><li>
<h4><a name="bookmark21"></a><span class="font1" style="font-weight:bold;"><a name="bookmark22"></a>4. &nbsp;&nbsp;&nbsp;Kesimpulan</span></h4></li></ul>
<p><span class="font1">Setelah dilakukan validasi model dengan 10-</span><span class="font1" style="font-style:italic;">Fold Cross Validation</span><span class="font1">, nilai k=5 dipilih menjadi model terbaik pada eksperimen metode </span><span class="font1" style="font-style:italic;">K-Nearest Neighbor</span><span class="font1">. Pada pengujian data baru, model </span><span class="font1" style="font-style:italic;">K-Nearest Neighbor</span><span class="font1"> tanpa seleksi fitur dengan nilai k=5 menghasilkan performa </span><span class="font1" style="font-style:italic;">precision</span><span class="font1">, </span><span class="font1" style="font-style:italic;">recall, F1-Score,</span><span class="font1"> dan akurasi secara berturut-turut yaitu 87.5%, 96.5%, 91.8%, dan 91.6%. Pada eksperimen seleksi fitur </span><span class="font1" style="font-style:italic;">Information Gain</span><span class="font1">, kombinasi </span><span class="font1" style="font-style:italic;">threshold</span><span class="font1"> 0.5% dengan parameter nilai k=3 adalah kombinasi yang dipilih menjadi model terbaik. </span><span class="font1" style="font-style:italic;">Threshold</span><span class="font1"> ini menyeleksi sekitar 25 fitur dengan nilai </span><span class="font1" style="font-style:italic;">Information Gain</span><span class="font1"> tertinggi. Pada pengujian data baru, model </span><span class="font1" style="font-style:italic;">K-Nearest Neighbor </span><span class="font1">dengan seleksi fitur </span><span class="font1" style="font-style:italic;">Information Gain</span><span class="font1"> menghasilkan performa </span><span class="font1" style="font-style:italic;">precision</span><span class="font1">, </span><span class="font1" style="font-style:italic;">recall, F1-Score,</span><span class="font1"> dan akurasi secara berturut-turut yaitu 93.3%, 96.6%, 95%, dan 95%. Sehingga, dapat disimpulkan bahwa pada klasifikasi berita hoaks dengan data yang digunakan pada penelitian ini, kombinasi metode </span><span class="font1" style="font-style:italic;">K-Nearest Neighbor</span><span class="font1"> dan </span><span class="font1" style="font-style:italic;">Information Gain</span><span class="font1"> menghasilkan performa </span><span class="font1" style="font-style:italic;">precision</span><span class="font1">, </span><span class="font1" style="font-style:italic;">recall, F1-Score,</span><span class="font1"> dan akurasi yang lebih tinggi dibandingkan dengan metode </span><span class="font1" style="font-style:italic;">K-Nearest Neighbor</span><span class="font1"> tanpa seleksi fitur.</span></p>
<h4><a name="bookmark23"></a><span class="font1" style="font-weight:bold;"><a name="bookmark24"></a>Daftar Pustaka</span></h4>
<ul style="list-style:none;"><li>
<p><span class="font1">[1] &nbsp;&nbsp;&nbsp;&nbsp;C. Juditha, “Interaksi Komunikasi Hoax di Media Sosial serta Antisipasinya,” </span><span class="font1" style="font-style:italic;">J.</span></p></li></ul>
<p><span class="font1" style="font-style:italic;">Pekommas</span><span class="font1">, &nbsp;&nbsp;vol. 3, no. 1, pp. 31–44, &nbsp;&nbsp;2018, [Online]. Available:</span></p>
<p><a href="https://jurnal.kominfo.go.id/index.php/pekommas/article/view/2030104"><span class="font1">https://jurnal.kominfo.go.id/index.php/pekommas/article/view/2030104</span></a><span class="font1">.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1">[2] &nbsp;&nbsp;&nbsp;Kominfo.go.id, “Penanganan Sebaran Konten Hoaks Covid-19 Jumat (18/02/2022),”</span></p></li></ul>
<p><span class="font1">2022. &nbsp;&nbsp;&nbsp;</span><a href="https://kominfo.go.id/content/detail/40067/penanganan-sebaran-konten-hoaks-"><span class="font1">https://kominfo.go.id/content/detail/40067/penanganan-sebaran-konten-hoaks-</span></a></p>
<p><span class="font1">covid-19-jumat-18022022/0/infografis (accessed Mar. 26, 2022).</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1">[3] &nbsp;&nbsp;&nbsp;&nbsp;R. Sagita, U. Enri, and A. Primajaya, “Klasifikasi Berita Clickbait Menggunakan K-Nearest</span></p></li></ul>
<p><span class="font1">Neighbor (KNN),” </span><span class="font1" style="font-style:italic;">JOINS (Journal Inf. Syst.</span><span class="font1">, vol. 5, no. 2, pp. 230–239, 2020, doi: 10.33633/joins.v5i2.3705.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1">[4] &nbsp;&nbsp;&nbsp;&nbsp;I. W. Santiyasa, G. P. A. Brahmantha, I. W. Supriana, I. G. G. A. Kadyanan, I. K. G.</span></p></li></ul>
<p><span class="font1">Suhartana, and I. B. M. Mahendra, “Identification of Hoax Based on Text Mining Using K-Nearest Neighbor Method,” </span><span class="font1" style="font-style:italic;">JELIKU (Jurnal Elektron. Ilmu Komput. Udayana)</span><span class="font1">, vol. 10, no. 2, pp. 217–226, 2021, doi: 10.24843/jlk.2021.v10.i02.p04.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1">[5] &nbsp;&nbsp;&nbsp;A. A. Paramitha, Indriati, and Y. A. Sari, “Analisis Sentimen Terhadap Ulasan Pengguna</span></p></li></ul>
<p><span class="font1">MRT Jakarta Menggunakan Information Gain dan Modified K-Nearest Neighbor,” </span><span class="font1" style="font-style:italic;">J. Pengemb. Teknol. Inf. dan Ilmu Komput.</span><span class="font1">, vol. 4, no. 4, pp. 1125–1132, 2020.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1">[6] &nbsp;&nbsp;&nbsp;&nbsp;K. D. Yonatha Wijaya and A. A. I. N. E. Karyawati, “The Effects of Different Kernels in</span></p></li></ul>
<p><span class="font1">SVM Sentiment Analysis on Mass Social Distancing,” </span><span class="font1" style="font-style:italic;">JELIKU (Jurnal Elektron. Ilmu Komput. Udayana)</span><span class="font1">, vol. 9, no. 2, p. 161, 2020, doi: 10.24843/jlk.2020.v09.i02.p01.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1">[7] &nbsp;&nbsp;&nbsp;H. P. Hadi and T. S. Sukamto, “Klasifikasi Jenis Laporan Masyarakat Dengan K-Nearest</span></p></li></ul>
<p><span class="font1">Neighbor Algorithm,” </span><span class="font1" style="font-style:italic;">JOINS (Journal Inf. Syst.</span><span class="font1">, vol. 5, no. 1, pp. 77–85, 2020, doi: 10.33633/joins.v5i1.3355.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1">[8] &nbsp;&nbsp;&nbsp;A. B. P. Negara, H. Muhardi, and I. M. Putri, “Analisis Sentimen Maskapai Penerbangan</span></p></li></ul>
<p><span class="font1">Menggunakan Metode Naive Bayes dan Seleksi Fitur Information Gain,” </span><span class="font1" style="font-style:italic;">J. Teknol. Inf. dan Ilmu Komput.</span><span class="font1">, vol. 7, no. 3, pp. 599–606, 2020, doi: 10.25126/jtiik.2020711947.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1">[9] &nbsp;&nbsp;&nbsp;C. C. Aggarwal and C. C. Aggarwal, </span><span class="font1" style="font-style:italic;">Machine Learning for Text: An Introduction</span><span class="font1">. 2018.</span></p></li>
<li>
<p><span class="font1">[10] &nbsp;&nbsp;&nbsp;M. A. Imron and B. Prasetiyo, “Improving Algorithm Accuracy K-Nearest Neighbor Using Z-Score Normalization and Particle Swarm Optimization to Predict Customer Churn,” </span><span class="font1" style="font-style:italic;">J. Soft Comput. Explor.</span><span class="font1">, vol. 1, no. 1, pp. 56–62, &nbsp;2020, [Online]. Available:</span></p></li></ul>
<p><a href="https://shmpublisher.com/index.php/joscex/article/view/7%0Ahttps://shmpublisher.com/in"><span class="font1">https://shmpublisher.com/index.php/joscex/article/view/7%0Ahttps://shmpublisher.com/in</span></a><span class="font1"> dex.php/joscex/index.</span></p>
<p><span class="font1" style="font-style:italic;">This page is intentionally left blank.</span></p>
<p><span class="font1">328</span></p>