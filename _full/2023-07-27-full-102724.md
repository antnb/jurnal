---
layout: full_article
title: "Pendekatan Deep Learning dan Gradient Boosting dalam Prediksi Harga Properti Airbnb dengan Analisis Sentimen"
author: "Christopher Digno, Muhammad Iqbal Jauhar, Muhammad Nur Syaifullah"
categories: jik
canonical_url: https://jurnal.harianregional.com/jik/full-102724 
citation_abstract_html_url: "https://jurnal.harianregional.com/jik/id-102724"
citation_pdf_url: "https://jurnal.harianregional.com/jik/full-102724"  
comments: true
---

<p><span class="font3">p-ISSN: 2301-5373</span></p>
<p><span class="font3">e-ISSN: 2654-5101</span></p>
<p><span class="font3">Jurnal Elektronik Ilmu Komputer Udayana</span></p>
<p><span class="font3">Volume 12, No 1. August 2023</span></p><a name="caption1"></a>
<h1><a name="bookmark0"></a><span class="font4" style="font-weight:bold;"><a name="bookmark1"></a>Pendekatan </span><span class="font4" style="font-weight:bold;font-style:italic;">Deep Learning</span><span class="font4" style="font-weight:bold;"> dan </span><span class="font4" style="font-weight:bold;font-style:italic;">Gradient Boosting</span><span class="font4" style="font-weight:bold;"> dalam Prediksi Harga Properti </span><span class="font4" style="font-weight:bold;font-style:italic;">Airbnb</span><span class="font4" style="font-weight:bold;"> dengan Analisis Sentimen</span></h1>
<p><span class="font3">Christopher Digno<sup>a1</sup></span><span class="font3" style="font-weight:bold;">, </span><span class="font3">Muhammad Iqbal Jauhar<sup>a2</sup></span><span class="font3" style="font-weight:bold;">, </span><span class="font3">Muhammad Nur Syaifullah<sup>a3</sup></span></p>
<p><span class="font3"><sup>a</sup>Program Studi Informatika, Fakultas Teknologi Informasi dan Sains Data, Universitas Sebelas Maret Jebres, Surakarta, Indonesia</span></p>
<p><a href="mailto:1digno.christopher@student.uns.ac.id"><span class="font3"><sup>1</sup>digno.christopher@student.uns.ac.id</span></a><span class="font3"> </span><span class="font2" style="font-variant:small-caps;">(c</span><span class="font2">orresponding author)</span></p>
<p><a href="mailto:2iqbaljauhar@student.uns.ac.id"><span class="font3"><sup>2</sup>iqbaljauhar@student.uns.ac.id</span></a></p>
<p><a href="mailto:2muhammad.nur.syaiful@student.uns.ac.id"><span class="font3"><sup>2</sup>muhammad.nur.syaiful@student.uns.ac.id</span></a></p>
<p><span class="font3" style="font-weight:bold;font-style:italic;">Abstrak</span></p>
<p><span class="font3" style="font-style:italic;">Penentuan harga properti sewa Airbnb yang sesuai untuk mendapatkan penjualan yang tertinggi merupakan pekerjaan yang tidak mudah, terlebih pada masa modern sekarang yang dipenuhi dengan pasar bebas dan pertarungan harga yang seringnya tidak sehat. Dalam waktu yang sama, calon penyewa properti juga kesulitan melakukan penilaian atas harga yang ditawarkan oleh pemilik properti. Oleh karena itu, kami menawarkan beberapa model machine learning untuk melakukan prediksi harga Airbnb. Kami berhasil mendapatkan hasil terbaik menggunakan XGBoost dengan MSE (Mean Squared Error) sebesar 0.1414. Selanjutnya, kami juga melakukan pembenahan terhadap metode seleksi fitur yang digunakan pada penelitian sebelumnya dengan menggunakan ElasticNet dan berhasil menurunkan MSE dari 0.1471 menjadi 0.1370.</span></p>
<p><span class="font3" style="font-weight:bold;font-style:italic;">Kata Kunci: </span><span class="font3" style="font-style:italic;">Machine Learning, Deep Neural Network, XGBoost, Price Prediction, Regression</span></p>
<ul style="list-style:none;"><li>
<h3><a name="bookmark2"></a><span class="font3" style="font-weight:bold;"><a name="bookmark3"></a>1. &nbsp;&nbsp;&nbsp;Pendahuluan</span></h3></li></ul>
<p><span class="font3">Pemilik properti pada platform makelar properti </span><span class="font3" style="font-style:italic;">Airbnb</span><span class="font3"> sering kali menemui kesulitan dalam menentukan harga sewa dari properti mereka yang masuk pada </span><span class="font3" style="font-style:italic;">listing</span><span class="font3"> karena pemilihan harga sewa memiliki dampak yang sangat besar pada jumlah tamu yang akan menyewa properti tersebut. Fakta bahwa </span><span class="font3" style="font-style:italic;">Airbnb</span><span class="font3"> memiliki dampak yang besar bagi perekonomian kota metropolitan [1], [2] membuat pemilihan harga sewa menjadi hal yang vital bagi perekonomian daerah tersebut. Di sisi lain, tamu yang ingin menyewa properti di </span><span class="font3" style="font-style:italic;">Airbnb</span><span class="font3"> mungkin tidak bisa melakukan evaluasi harga properti yang optimal karena data yang terbatas.</span></p>
<p><span class="font3">Penelitian ini berupaya untuk membantu menyelesaikan permasalahan mengenai kesulitan penentuan dan evaluasi harga di atas. Kami akan membangun sebuah model prediksi harga menggunakan konsep-konsep </span><span class="font3" style="font-style:italic;">machine learning</span><span class="font3"> (ML)</span><span class="font3" style="font-style:italic;">, deep learning</span><span class="font3"> (DL)</span><span class="font3" style="font-style:italic;">,</span><span class="font3"> dan </span><span class="font3" style="font-style:italic;">natural language processing</span><span class="font3"> (NLP) yang dapat digunakan untuk pemilik properti serta tamu yang tertarik untuk menyewa properti. Data yang akan digunakan untuk membangun model kami adalah data mengenai fitur-fitur properti Airbnb dan daftar ulasan/</span><span class="font3" style="font-style:italic;">review</span><span class="font3"> dari properti tersebut. Kami akan mengulas beberapa metode yang sudah pernah digunakan sebelumnya, seperti regresi linear, model berbasis </span><span class="font3" style="font-style:italic;">tree</span><span class="font3">, </span><span class="font3" style="font-style:italic;">Support Vector Regression</span><span class="font3"> (SVR), </span><span class="font3" style="font-style:italic;">K-means Clustering</span><span class="font3">, dan </span><span class="font3" style="font-style:italic;">Neural Networks</span><span class="font3"> (NN), dan juga mengajukan beberapa metode baru seperti </span><span class="font3" style="font-style:italic;">Deep Neural Network</span><span class="font3"> (DNN), </span><span class="font3" style="font-style:italic;">Extreme Gradient Bossting </span><span class="font3">(</span><span class="font3" style="font-style:italic;">XGBoost</span><span class="font3">), </span><span class="font3" style="font-style:italic;">Bayesian Regression</span><span class="font3">, dan </span><span class="font3" style="font-style:italic;">K-Nearest Neighbors Regressor</span><span class="font3">. Selain melakukan komparasi terhadap beberapa metode tersebut, kami juga akan membandingkan performa dua metode seleksi fitur, yaitu </span><span class="font3" style="font-style:italic;">Lasso</span><span class="font3"> (berbasis L1) dan </span><span class="font3" style="font-style:italic;">ElasticNet</span><span class="font3"> (kombinasi antara penalti L1 dan L2).</span></p>
<p><span class="font3">Terdapat beberapa penelitian terdahulu yang mencoba untuk membangun model prediksi harga baik untuk properti rental berbasis </span><span class="font3" style="font-style:italic;">non-sharing</span><span class="font3"> atau personal. Penelitian oleh Yu dan Wu [3] mengajukan model prediksi harga perumahan menggunakan regresi linear, SVR, dan </span><span class="font3" style="font-style:italic;">Random Forest regressor </span><span class="font3">ditambah dengan analisis fitur, dan menghasilkan RMSE (</span><span class="font3" style="font-style:italic;">root mean squared error</span><span class="font3">) sebesar 0.53, serta implementasi PCA (</span><span class="font3" style="font-style:italic;">Principle Component Analysis</span><span class="font3">) dengan SVC (</span><span class="font3" style="font-style:italic;">State Vector Classifier</span><span class="font3">) yang</span></p>
<p><span class="font3">Digno, Jauhar, Syaifullah.</span></p>
<p><span class="font3">Pendekatan Deep Learning dan Gradient Boosting dalam Prediksi Harga Properti Airbnb dengan Analisis Sentimen menghasilkan akurasi sebesar 69%. Penelitian lain [4] mendapatkan model terbaiknya menggunakan </span><span class="font3" style="font-style:italic;">Regression Tree</span><span class="font3"> dengan RMSE sebesar 1.05 CNY/</span><span class="font3" style="font-style:italic;">m</span><span class="font3"><sup>2</sup>-</span><span class="font3" style="font-style:italic;">day</span><span class="font3">.</span></p>
<p><span class="font3">Di luar banyak penelitian di atas mengenai prediksi properti rental berbasis </span><span class="font3" style="font-style:italic;">non-sharing</span><span class="font3"> dan hotel/sejenisnya, terdapat beberapa penelitian untuk properti rental berbasis </span><span class="font3" style="font-style:italic;">sharing</span><span class="font3">, yang lebih berhubungan dengan </span><span class="font3" style="font-style:italic;">branding Airbnb</span><span class="font3">. Penelitian oleh Kalehbasti, et al. [5] menggunakan beberapa metode regresi untuk memprediksi harga properti </span><span class="font3" style="font-style:italic;">Airbnb</span><span class="font3"> menggunakan L1 </span><span class="font3" style="font-style:italic;">regularization</span><span class="font3">, dengan SVR sebagai model terbaik mereka yang menghasilkan MSE sebesar 0.6692. Beberapa metode regresi lain juga digunakan pada beberapa penelitian lainnya, seperti OLS (</span><span class="font3" style="font-style:italic;">Ordinary Least Squares</span><span class="font3">) [6], [7] dan </span><span class="font3" style="font-style:italic;">Quantile Regression</span><span class="font3"> [7]. Penelitian oleh Yang et al. [8] menawarkan metode Regresi Linear yang jauh lebih sederhana, menggunakan penilaian pengguna pada properti sewa. Selain metode berbasis linear di atas, Li et al. [9] memperkenalkan metode </span><span class="font3" style="font-style:italic;">clustering</span><span class="font3"> berbasis </span><span class="font3" style="font-style:italic;">Multi-scale Affinity</span><span class="font3">.</span></p>
<p><span class="font3">Penelitian ini berupaya untuk menghadirkan metode regresi yang baru dengan mengimplementasikan </span><span class="font3" style="font-style:italic;">Deep Neural Networks, XGBoost</span><span class="font3">, dan beberapa model linear lainnya. Kami juga membandingkan dua jenis metode seleksi fitur, </span><span class="font3" style="font-style:italic;">Lasso</span><span class="font3"> dan </span><span class="font3" style="font-style:italic;">ElasticNet</span><span class="font3">, menggunakan SVR sebagai metode regresi yang saya gunakan sebagai </span><span class="font3" style="font-style:italic;">benchmark</span><span class="font3">.</span></p>
<ul style="list-style:none;"><li>
<h3><a name="bookmark4"></a><span class="font3" style="font-weight:bold;"><a name="bookmark5"></a>2. &nbsp;&nbsp;&nbsp;Metode Penelitian</span></h3></li></ul>
<p><span class="font3">Pada bagian ini, kami akan mengulas langkah-langkah yang kami lakukan dalam penelitian ini. Pertama, kami akan membahas </span><span class="font3" style="font-style:italic;">dataset</span><span class="font3"> yang akan kami gunakan. Kemudian, kami akan menjelaskan bagaimana kami akan melakukan </span><span class="font3" style="font-style:italic;">preprocessing</span><span class="font3"> pada </span><span class="font3" style="font-style:italic;">dataset</span><span class="font3"> tersebut. Selanjutnya kami akan menjelaskan dua eksperimen yang akan kami lakukan pada penelitian ini, yaitu pembuatan dan penyetelan (</span><span class="font3" style="font-style:italic;">tuning</span><span class="font3">) model </span><span class="font3" style="font-style:italic;">machine learning</span><span class="font3"> dan studi komparatif dua jenis seleksi fitur berbasis </span><span class="font3" style="font-style:italic;">Lasso</span><span class="font3"> dan </span><span class="font3" style="font-style:italic;">ElasticNet</span><span class="font3">.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font3" style="font-weight:bold;">2.1.</span><span class="font3" style="font-weight:bold;font-style:italic;"> &nbsp;&nbsp;&nbsp;Dataset</span></p></li></ul>
<p><span class="font3">Dalam penelitian ini, kami akan menggunakan sebuah </span><span class="font3" style="font-style:italic;">dataset</span><span class="font3"> yang disediakan oleh </span><span class="font3" style="font-style:italic;">Inside Airbnb </span><span class="font3">(</span><a href="http://insideairbnb.com/"><span class="font3">http://insideairbnb.com/</span></a><span class="font3">). </span><span class="font3" style="font-style:italic;">Inside Airbnb</span><span class="font3"> merupakan sebuah proyek komunitas yang memiliki tujuan untuk menunjukkan dampak dari </span><span class="font3" style="font-style:italic;">Airbnb</span><span class="font3"> untuk lingkungan suatu kota/daerah. Data yang kami gunakan adalah detail </span><span class="font3" style="font-style:italic;">listing</span><span class="font3"> properti pada </span><span class="font3" style="font-style:italic;">website</span><span class="font3"> dan kumpulan ulasan dari </span><span class="font3" style="font-style:italic;">listing</span><span class="font3"> properti tersebut di kota New York City, New York, Amerika Serikat [10]. Gambar 1 dan Tabel 1 memberikan visualisasi dan beberapa jenis statistik mengenai </span><span class="font3" style="font-style:italic;">dataset</span><span class="font3">.</span></p><img src="https://jurnal.harianregional.com/media/102724-1.jpg" alt="" style="width:182pt;height:182pt;">
<p><span class="font3" style="font-weight:bold;">Gambar 1. </span><span class="font3">Distribusi geografis dari </span><span class="font3" style="font-style:italic;">dataset listing</span><span class="font3"> kota New York City. Gambar merupakan tangkapan layar dari </span><a href="http://insideairbnb.com/new-york-city/"><span class="font3">http://insideairbnb.com/new-york-city/</span></a></p>
<p><span class="font3" style="font-weight:bold;">Tabel 1. </span><span class="font3">Jumlah baris dan fitur (kolom) untuk masing-masing data ulasan dan </span><span class="font3" style="font-style:italic;">listing</span><span class="font3">.</span></p>
<table border="1">
<tr><td style="vertical-align:top;"></td><td style="vertical-align:middle;">
<p><span class="font3" style="font-weight:bold;">Data ulasan</span></p></td><td style="vertical-align:middle;">
<p><span class="font3" style="font-weight:bold;">Data </span><span class="font3" style="font-weight:bold;font-style:italic;">listing</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font3" style="font-weight:bold;">Jumlah baris</span></p></td><td style="vertical-align:middle;">
<p><span class="font3">1.051.974</span></p></td><td style="vertical-align:middle;">
<p><span class="font3">50.220</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font3" style="font-weight:bold;">Jumlah fitur</span></p></td><td style="vertical-align:middle;">
<p><span class="font3">6</span></p></td><td style="vertical-align:middle;">
<p><span class="font3">96</span></p></td></tr>
</table>
<ul style="list-style:none;"><li>
<p><span class="font3" style="font-weight:bold;">2.2.</span><span class="font3" style="font-weight:bold;font-style:italic;"> &nbsp;&nbsp;&nbsp;Preprocessing</span><span class="font3" style="font-weight:bold;"> Data</span></p></li></ul>
<p><span class="font3">Setelah data yang dibutuhkan selesai diunduh, kami kemudian melakukan serangkaian langkah </span><span class="font3" style="font-style:italic;">preprocessing</span><span class="font3">. Langkah-langkah ini dilakukan supaya </span><span class="font3" style="font-style:italic;">dataset</span><span class="font3"> yang kami miliki dapat digunakan untuk melatih model </span><span class="font3" style="font-style:italic;">machine learning</span><span class="font3"> kami. Untuk </span><span class="font3" style="font-style:italic;">preprocessing</span><span class="font3"> awal, kami melakukan beberapa rekayasa pada </span><span class="font3" style="font-style:italic;">dataset listing</span><span class="font3"> kami, antara lain:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font3">a. &nbsp;&nbsp;&nbsp;Menghapus fitur-fitur yang tidak penting/tidak memiliki korelasi terhadap harga, misalnya nama </span><span class="font3" style="font-style:italic;">host</span><span class="font3"> dan deskripsi properti.</span></p></li>
<li>
<p><span class="font3">b. &nbsp;&nbsp;&nbsp;Melakukan </span><span class="font3" style="font-style:italic;">one hot encoding</span><span class="font3"> pada beberapa fitur yang berupa data kategori, kualitatif, dan </span><span class="font3" style="font-style:italic;">array</span><span class="font3">.</span></p></li>
<li>
<p><span class="font3">c. &nbsp;&nbsp;&nbsp;Membersihkan simbol-simbol pada data, seperti simbol mata uang dolar ($).</span></p></li>
<li>
<p><span class="font3">d. &nbsp;&nbsp;&nbsp;Membersihkan nilai-nilai kosong dengan menjadikannya sebagai sebuah nilai tertentu atau membuat baris tersebut.</span></p></li>
<li>
<p><span class="font3">e. &nbsp;&nbsp;&nbsp;Mengubah data tanggal menjadi jumlah hari menuju tanggal tertentu.</span></p></li></ul>
<p><span class="font3">Setelah melakukan beberapa langkah </span><span class="font3" style="font-style:italic;">preprocessing</span><span class="font3"> di atas, dimensi data kami meledak dengan cukup signifikan pada sumbu kolom karena banyak fitur yang dijadikan </span><span class="font3" style="font-style:italic;">one hot encoding</span><span class="font3">. Tabel 2 menunjukkan perbandingan statistik data </span><span class="font3" style="font-style:italic;">listing</span><span class="font3">.</span></p>
<p><span class="font3" style="font-weight:bold;">Tabel 2. </span><span class="font3">Perbandingan jumlah baris dan fitur (kolom) data </span><span class="font3" style="font-style:italic;">listing</span><span class="font3"> sebelum dan sesudah </span><span class="font3" style="font-style:italic;">preprocessing.</span></p>
<table border="1">
<tr><td style="vertical-align:top;"></td><td style="vertical-align:bottom;">
<p><span class="font3" style="font-weight:bold;">Data </span><span class="font3" style="font-weight:bold;font-style:italic;">listing</span><span class="font3" style="font-weight:bold;"> sebelum</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3" style="font-weight:bold;">Data </span><span class="font3" style="font-weight:bold;font-style:italic;">listing</span><span class="font3" style="font-weight:bold;"> sesudah</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font3" style="font-weight:bold;">Jumlah baris</span></p></td><td style="vertical-align:middle;">
<p><span class="font3">50.220</span></p></td><td style="vertical-align:middle;">
<p><span class="font3">49.984</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font3" style="font-weight:bold;">Jumlah fitur</span></p></td><td style="vertical-align:middle;">
<p><span class="font3">96</span></p></td><td style="vertical-align:middle;">
<p><span class="font3">764</span></p></td></tr>
</table>
<ul style="list-style:none;"><li>
<h3><a name="bookmark6"></a><span class="font3" style="font-weight:bold;"><a name="bookmark7"></a>2.2.1. &nbsp;&nbsp;&nbsp;Analisis Sentimen Data Ulasan</span></h3></li></ul>
<p><span class="font3">Supaya data ulasan properti dapat kami gunakan untuk melakukan prediksi harga properti, kami harus melakukan analisis sentimen dari ulasan-ulasan tersebut. Analisis sentimen merupakan sebuah teknik analisis opini yang sering digunakan pada banyak penelitian untuk mengetahui opini seseorang akan suatu hal [11]. Pada umumnya, model analisis sentimen menerima masukan sebuah kalimat dan mengeluarkan sebuah nilai dengan rentang -1 hingga 1 yang berturut-turun dapat diartikan sebagai sentimen yang sangat negatif dan sentimen yang sangat positif.</span></p>
<p><span class="font3">Pada data ulasan penelitian ini, kami melakukan analisis sentimen untuk setiap item ulasan menggunakan pustaka </span><span class="font3" style="font-style:italic;">TextBlob</span><span class="font3"> [12]. Selanjutnya, kami melakukan pengelompokan untuk ulasan pada satu properti yang sama dengan nilai rata-ratanya, serta menghilangkan fitur lain selain </span><span class="font3" style="font-style:italic;">listing ID</span><span class="font3"> dan nilai sentimen. Karena pengelompokan ini, jumlah data ulasan kami menyusut.</span></p>
<p><span class="font3" style="font-weight:bold;">Tabel 3. </span><span class="font3">Perbandingan jumlah baris dan fitur data ulasan sebelum dan setelah analisis sentimen</span></p>
<table border="1">
<tr><td style="vertical-align:top;"></td><td style="vertical-align:middle;">
<p><span class="font3" style="font-weight:bold;">Data ulasan sebelum</span></p></td><td style="vertical-align:middle;">
<p><span class="font3" style="font-weight:bold;">Data ulasan sesudah</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font3" style="font-weight:bold;">Jumlah baris</span></p></td><td style="vertical-align:middle;">
<p><span class="font3">1.051.974</span></p></td><td style="vertical-align:middle;">
<p><span class="font3">39.528</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font3" style="font-weight:bold;">Jumlah fitur</span></p></td><td style="vertical-align:middle;">
<p><span class="font3">6</span></p></td><td style="vertical-align:middle;">
<p><span class="font3">2</span></p></td></tr>
</table>
<ul style="list-style:none;"><li>
<h3><a name="bookmark8"></a><span class="font3" style="font-weight:bold;"><a name="bookmark9"></a>2.2.2. &nbsp;&nbsp;&nbsp;Seleksi Fitur</span></h3></li></ul>
<p><span class="font3" style="font-style:italic;">Dataset listing</span><span class="font3"> dan ulasan yang sudah digabung memiliki jumlah fitur yang sangat besar, yaitu 765. Dari banyak fitur tersebut, tidak semuanya memiliki kontribusi yang besar dalam melakukan prediksi terhadap harga properti. Terlebih lagi, menggunakan data dengan fitur yang terlalu banyak dapat menyebabkan model </span><span class="font3" style="font-style:italic;">machine learning</span><span class="font3"> mendapatkan pengukuran performa yang buruk karena gagal untuk melakukan generalisasi atas data yang ada [13].</span></p>
<p><span class="font3">Metode seleksi fitur yang akan kami gunakan pada </span><span class="font3" style="font-style:italic;">preprocessing</span><span class="font3"> adalah </span><span class="font3" style="font-style:italic;">Lasso</span><span class="font3"> (</span><span class="font3" style="font-style:italic;">Least Absolute Shrinkage and Selection Operator</span><span class="font3">). </span><span class="font3" style="font-style:italic;">Lasso</span><span class="font3"> merupakan sebuah metode analisis regresi yang dapat digunakan untuk seleksi fitur dan regularisasi. </span><span class="font3" style="font-style:italic;">Lasso</span><span class="font3"> menggunakan norma L1 untuk melakukan regularisasi, berdampak ke hasil koefisien yang lebih jarang (</span><span class="font3" style="font-style:italic;">sparse</span><span class="font3">), dan terkadang menghasilkan nilai koefisien 0 [14]. Persamaan objektif yang dijadikan sebagai tujuan optimasi </span><span class="font3" style="font-style:italic;">Lasso</span><span class="font3"> dapat dilihat pada (1) [14].</span></p>
<p><a href="#bookmark10"><span class="font8">1.2</span></a></p>
<p><a href="#bookmark11"><span class="font8"><sup>m</sup>'<sup>n</sup>k7</span><span class="font6">∣∣</span><span class="font8">y-</span><span class="font8" style="font-style:italic;">^β</span><span class="font6" style="font-style:italic;">∣∖</span><span class="font8"> }</span></a></p>
<p><a href="#bookmark12"><span class="font7" style="font-style:italic;">βeKP<sup>i</sup>N <sup>1</sup></span><span class="font8"><sup>l</sup></span></a></p>
<p><span class="font3">Untuk melakukan seleksi fitur </span><span class="font3" style="font-style:italic;">Lasso</span><span class="font3"> pada data, kami akan menggunakan pustaka </span><span class="font3" style="font-style:italic;">scikit-learn</span><span class="font3"> yang mendukung </span><span class="font3" style="font-style:italic;">Lasso regularizer</span><span class="font3"> dan </span><span class="font3" style="font-style:italic;">feature selection</span><span class="font3">. Selain itu, untuk memastikan performa model linear yang dibangun, kami akan melakukan </span><span class="font3" style="font-style:italic;">hyperparameter tuning</span><span class="font3"> menggunakan banyak nilai </span><span class="font3" style="font-style:italic;">alpha</span><span class="font3">. Setelah menjalankan model dan mendapatkan hasil terbaik, kami menggunakan model tersebut untuk menentukan nilai koefisien </span><span class="font3" style="font-style:italic;">Lasso</span><span class="font3"> yang kemudian digunakan untuk menentukan apakah fitur tersebut sesuai untuk digunakan atau tidak. Pada akhirnya, kami membuang fitur data yang memiliki koefisien sebesar 0. Setelah dilakukan seleksi fitur, jumlah fitur dalam data ditunjukkan pada Tabel 4.</span></p>
<p><span class="font3" style="font-weight:bold;">Tabel 4. </span><span class="font3">Perbandingan jumlah baris dan fitur data sebelum dan sesudah seleksi fitur</span></p>
<table border="1">
<tr><td style="vertical-align:top;"></td><td style="vertical-align:middle;">
<p><span class="font3" style="font-weight:bold;">Data sebelum</span></p></td><td style="vertical-align:middle;">
<p><span class="font3" style="font-weight:bold;">Data sesudah</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font3" style="font-weight:bold;">Jumlah baris</span></p></td><td style="vertical-align:middle;">
<p><span class="font3">49.976</span></p></td><td style="vertical-align:middle;">
<p><span class="font3">49.976</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font3" style="font-weight:bold;">Jumlah fitur</span></p></td><td style="vertical-align:middle;">
<p><span class="font3">764</span></p></td><td style="vertical-align:middle;">
<p><span class="font3">197</span></p></td></tr>
</table>
<p><span class="font3">Selanjutnya pada tahap eksperimen 2, kami akan membandingkan hasil seleksi fitur ini dengan metode seleksi fitur yang menggabungkan norma L1 dan L2, yaitu </span><span class="font3" style="font-style:italic;">ElasticNet</span><span class="font3">.</span></p>
<ul style="list-style:none;"><li>
<h3><a name="bookmark13"></a><span class="font3" style="font-weight:bold;"><a name="bookmark14"></a>2.2.3. &nbsp;&nbsp;&nbsp;Pemisahan dan Normalisasi Data</span></h3></li></ul>
<p><span class="font3">Seperti metode </span><span class="font3" style="font-style:italic;">machine learning</span><span class="font3"> lainnya, data yang digunakan akan dibelah menjadi 3 bagian, yaitu data </span><span class="font3" style="font-style:italic;">training</span><span class="font3">, </span><span class="font3" style="font-style:italic;">validation</span><span class="font3">, dan </span><span class="font3" style="font-style:italic;">testing</span><span class="font3">. Kami menggunakan 10% data untuk </span><span class="font3" style="font-style:italic;">testing</span><span class="font3">, 10% untuk</span></p>
<p><span class="font3" style="font-style:italic;">validation</span><span class="font3"> dan 90% untuk </span><span class="font3" style="font-style:italic;">training</span><span class="font3">. Meskipun proporsinya yang cukup jauh, karena </span><span class="font3" style="font-style:italic;">dataset</span><span class="font3"> yang kami gunakan memiliki data berjumlah besar, strategi pemisahan kami dapat tetap dipakai.</span></p>
<p><span class="font3">Setelah data selesai dipisah, kami melakukan normalisasi data. Normalisasi berarti mengubah semua nilai yang ada dalam sebuah data sehingga semua nilai tersebut memiliki skala yang sama. Dalam </span><span class="font3" style="font-style:italic;">machine learning</span><span class="font3">, data yang memiliki beragam jenis skala akan menghasilkan model yang memiliki bias tinggi ke fitur yang memiliki data berskala besar [15]. Kami akan melakukan normalisasi data menggunakan strategi normalisasi </span><span class="font3" style="font-style:italic;">Min-max</span><span class="font3">, yang mengubah sebuah nilai dalam sebuah fitur berdasarkan nilai maksimal dan minimalnya.</span></p>
<ul style="list-style:none;"><li>
<h3><a name="bookmark15"></a><span class="font3" style="font-weight:bold;"><a name="bookmark16"></a>2.3. &nbsp;&nbsp;&nbsp;Pembuatan dan Penyetelan Model </span><span class="font3" style="font-weight:bold;font-style:italic;">Machine Learning</span></h3></li></ul>
<p><span class="font3">Kami membagi eksperimen pertama kami menjadi dua tahap, yaitu eksperimen menggunakan </span><span class="font3" style="font-style:italic;">Deep Neural Network</span><span class="font3"> dan kumpulan metode regresi tradisional beserta </span><span class="font3" style="font-style:italic;">XGBoost.</span></p>
<ul style="list-style:none;"><li>
<h3><a name="bookmark17"></a><span class="font3" style="font-weight:bold;"><a name="bookmark18"></a>2.3.1. &nbsp;&nbsp;&nbsp;Pembuatan dan Penyetelan Model </span><span class="font3" style="font-weight:bold;font-style:italic;">Deep Neural Network</span></h3></li></ul>
<p><span class="font3" style="font-style:italic;">Deep Neural Network</span><span class="font3"> (DNN) adalah salah satu metode klasifikasi dan regresi yang sering digunakan pada domain </span><span class="font3" style="font-style:italic;">machine learning</span><span class="font3">. Algoritma DNN mirip dengan </span><span class="font3" style="font-style:italic;">Artificial Neural Network</span><span class="font3"> (ANN) yang sama-sama berusaha untuk meniru cara otak manusia melakukan pemrosesan informasi [16]. Perbedaan fundamental DNN dengan </span><span class="font3" style="font-style:italic;">Neural Network</span><span class="font3"> (NN) adalah kompleksitas arsitekturnya. DNN memiliki lebih dari satu </span><span class="font3" style="font-style:italic;">hidden layer</span><span class="font3"> yang ada ditengah-tengah </span><span class="font3" style="font-style:italic;">input</span><span class="font3"> dan </span><span class="font3" style="font-style:italic;">output layer</span><span class="font3">. Masing-masing </span><span class="font3" style="font-style:italic;">layer</span><span class="font3"> memiliki sekumpulan </span><span class="font3" style="font-style:italic;">neuron</span><span class="font3">, yang terhubung dengan </span><span class="font3" style="font-style:italic;">neuron</span><span class="font3"> lainnya dengan konfigurasi tertentu, seperti struktur jaringan saraf yang ada pada manusia. Namun pada implementasinya, banyak penelitian yang menggunakan istilah NN untuk merujuk pada arsitektur </span><span class="font3" style="font-style:italic;">Neural Network </span><span class="font3">dengan lebih dari satu </span><span class="font3" style="font-style:italic;">hidden layer</span><span class="font3"> [17].</span></p>
<p><span class="font3">Pada masing-masing </span><span class="font3" style="font-style:italic;">node</span><span class="font3"> dalam masing-masing </span><span class="font3" style="font-style:italic;">layer</span><span class="font3">, sebuah fungsi transformasi dikenakan pada </span><span class="font3" style="font-style:italic;">input</span><span class="font3">, yang disebut </span><span class="font3" style="font-style:italic;">activation function</span><span class="font3"> [17]. </span><span class="font3" style="font-style:italic;">Activation function</span><span class="font3"> bertujuan untuk memungkinkan DNN</span></p>
<p><span class="font3">menyelesaikan permasalahan non-linear. Ada banyak jenis </span><span class="font3" style="font-style:italic;">activation function</span><span class="font3"> yang dapat digunakan sesuai dengan kebutuhan, namun secara fundamental, </span><span class="font3" style="font-style:italic;">activation function</span><span class="font3"> melakukan transformasi terhadap </span><span class="font3" style="font-style:italic;">input</span><span class="font3"> sesuai dengan sebuah fungsi linear yang ditetapkan [18].</span></p>
<p><span class="font3">Pada penelitian ini, kami akan melakukan implementasi DNN dengan banyak </span><span class="font3" style="font-style:italic;">hidden layer</span><span class="font3"> sejumlah dua, tiga, empat, dan lima. Beberapa pilihan </span><span class="font3" style="font-style:italic;">hidden layer</span><span class="font3"> ini dibuat untuk mempelajari efek jumlah </span><span class="font3" style="font-style:italic;">hidden layer</span><span class="font3"> terhadap kualitas generalisasi yang dilakukan, serta meneliti permasalahan </span><span class="font3" style="font-style:italic;">vanishing gradient</span><span class="font3">. Kami akan melakukan </span><span class="font3" style="font-style:italic;">hyperparameter tuning</span><span class="font3"> menggunakan </span><span class="font3" style="font-style:italic;">Keras Tuner</span><span class="font3"> yang disediakan oleh pustaka DNN yang kami gunakan, </span><span class="font3" style="font-style:italic;">Keras</span><span class="font3">, dengan strategi </span><span class="font3" style="font-style:italic;">Hyperband tuning</span><span class="font3">, sebuah pendekatan </span><span class="font3" style="font-style:italic;">tuner</span><span class="font3"> berbasis bandit yang meraih performa </span><span class="font3" style="font-style:italic;">state of the art</span><span class="font3"> dibanding banyak strategi </span><span class="font3" style="font-style:italic;">hyperparameter tuning</span><span class="font3"> lainnya [19].</span></p><img src="https://jurnal.harianregional.com/media/102724-2.jpg" alt="" style="width:205pt;height:160pt;">
<p><span class="font3" style="font-weight:bold;">Gambar 2. </span><span class="font3">Perbandingan grafik fungsi beberapa </span><span class="font3" style="font-style:italic;">activation function</span><span class="font3">, yaitu (a) </span><span class="font3" style="font-style:italic;">sigmoid</span><span class="font3">, (b) </span><span class="font3" style="font-style:italic;">arctangent</span><span class="font3">, dan (c) </span><span class="font3" style="font-style:italic;">hyperbolic tangent</span><span class="font3">. Gambar diambil dari Bakr and Negm [20].</span></p>
<ul style="list-style:none;"><li>
<h3><a name="bookmark19"></a><span class="font3" style="font-weight:bold;"><a name="bookmark20"></a>2.3.2. &nbsp;&nbsp;&nbsp;Pembuatan dan Penyetelan Model Regresi Tradisional</span></h3></li></ul>
<p><span class="font3">Sebagai pembanding untuk metode DNN, kami akan membangun beberapa model regresi berbasis </span><span class="font3" style="font-style:italic;">machine learning</span><span class="font3"> tradisional. Yang dimaksud dengan </span><span class="font3" style="font-style:italic;">machine learning</span><span class="font3"> tradisional adalah modelmodel </span><span class="font3" style="font-style:italic;">machine learning</span><span class="font3"> yang tidak menggunakan konsep-konsep </span><span class="font3" style="font-style:italic;">deep learning</span><span class="font3">, membutuhkan banyak </span><span class="font3" style="font-style:italic;">feature engineering</span><span class="font3"> dalam proses </span><span class="font3" style="font-style:italic;">learning</span><span class="font3"> [21].</span></p>
<p><span class="font3">Ada beberapa model regresi tradisional yang akan kami implementasi pada eksperimen ini, yaitu </span><span class="font3" style="font-style:italic;">Bayesian Regression</span><span class="font3">, </span><span class="font3" style="font-style:italic;">K-Nearest Neighbors Regressor</span><span class="font3">, dan </span><span class="font3" style="font-style:italic;">XGBoost.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font3">a.</span><span class="font3" style="font-style:italic;"> &nbsp;&nbsp;&nbsp;Bayesian Regression</span></p></li></ul>
<p><span class="font3" style="font-style:italic;">Bayesian Regression</span><span class="font3"> adalah sebuah model regresi yang didasari dengan teori </span><span class="font3" style="font-style:italic;">Bayes</span><span class="font3">, yang mendeskripsikan probabilitas sebuah kejadian, dengan diketahui hal-hal yang mungkin berhubungan dengan kejadian tersebut. </span><span class="font3" style="font-style:italic;">Bayesian Regression</span><span class="font3"> mengadopsi pendekatan probabilitas untuk menentukan nilai-nilai parameter, berkebalikan dengan OLS (</span><span class="font3" style="font-style:italic;">Ordinary Least Squares</span><span class="font3">) yang mengasumsikan parameter yang tetap, cenderung mengabaikan ketidakpastian </span><span class="font3" style="font-style:italic;">estimator</span><span class="font3">.</span></p>
<p><span class="font3">Pada penelitian ini, kami menggunakan varian </span><span class="font3" style="font-style:italic;">Bayesian Ridge Regression</span><span class="font3">, di mana </span><span class="font3" style="font-style:italic;">ridge penalty </span><span class="font3">diberlakukan supaya koefisien dapat diperkecil, mengurangi permasalahan </span><span class="font3" style="font-style:italic;">overfitting</span><span class="font3">.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font3">b.</span><span class="font3" style="font-style:italic;"> &nbsp;&nbsp;&nbsp;K-Nearest Neighbors Regressor</span></p></li></ul>
<p><span class="font3" style="font-style:italic;">K-Nearest Neighbors</span><span class="font3"> (K-NN) </span><span class="font3" style="font-style:italic;">regressor</span><span class="font3"> adalah sebuah model regresi yang melakukan </span><span class="font3" style="font-style:italic;">training</span><span class="font3"> dan prediksi atas nilai target/label berdasarkan rata-rata dari nilai target dari beberapa nilai terdekatnya pada ruang fitur [22]. K-NN tidak memiliki asumsi terkait korelasi/keterkaitan data secara fungsional, namun model regresi K-NN melakukan prediksi berdasarkan pola lokal dari data yang ada.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font3">c.</span><span class="font3" style="font-style:italic;"> &nbsp;&nbsp;&nbsp;XGBoost</span></p></li></ul>
<p><span class="font3" style="font-style:italic;">XGBoost</span><span class="font3"> (</span><span class="font3" style="font-style:italic;">Extreme Gradient Boosting</span><span class="font3">) adalah sebuah model </span><span class="font3" style="font-style:italic;">machine learning</span><span class="font3"> berbasis </span><span class="font3" style="font-style:italic;">gradient boosting decision tree</span><span class="font3">. Secara prinsip, </span><span class="font3" style="font-style:italic;">XGBoost</span><span class="font3"> menggunakan metode </span><span class="font3" style="font-style:italic;">gradient descent</span><span class="font3"> untuk membuat banyak </span><span class="font3" style="font-style:italic;">decision tree</span><span class="font3"> baru berdasarkan </span><span class="font3" style="font-style:italic;">tree</span><span class="font3"> yang ada sebelumnya dengan harapan untuk melakukan minimalisasi fungsi objektif [23]. Dalam fungsi objektif </span><span class="font3" style="font-style:italic;">XGBoost</span><span class="font3">, terdapat persamaan mengenai </span><span class="font3" style="font-style:italic;">loss function</span><span class="font3"> dan </span><span class="font3" style="font-style:italic;">regularization term</span><span class="font3">, yang tentunya berhubungan dengan koefisien penalti. Fungsi objektif ini dijelaskan pada (2) [23].</span></p>
<p><span class="font8">1v<sup>τ</sup> &nbsp;&nbsp;G<sup>2</sup></span></p>
<h2><a name="bookmark21"></a><span class="font8" style="font-variant:small-caps;"><sup><a name="bookmark22"></a>0</sup>≡ = </span><span class="font9" style="font-variant:small-caps;"><sup>-</sup></span><span class="font8" style="font-variant:small-caps;">2∑.</span><span class="font10" style="font-variant:small-caps;">,.<sub>1</sub></span><span class="font8" style="font-variant:small-caps;">⅛⅛ </span><span class="font9" style="font-variant:small-caps;"><sup>+ a,</sup>'</span></h2>
<div>
<p><span class="font3">(2)</span></p>
</div><br clear="all">
<p><span class="font3">Pada penelitian ini, kami menggunakan dua metode pengukuran performa (</span><span class="font3" style="font-style:italic;">performance metrics</span><span class="font3">) untuk mengukur kualitas dari model </span><span class="font3" style="font-style:italic;">machine learning</span><span class="font3"> kami, yaitu MSE dan R<sup>2</sup>. Kami menggunakan pustaka bawaan </span><span class="font3" style="font-style:italic;">TensorFlow</span><span class="font3"> untuk melakukan pengukuran performa.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font3">a. &nbsp;&nbsp;&nbsp;MSE (</span><span class="font3" style="font-style:italic;">Mean Squared Error</span><span class="font3">)</span></p></li></ul>
<p><span class="font3">MSE melakukan penilaian berdasarkan rata-rata dari kuadrat eror, yaitu jarak antara persamaan garis prediksi dan nilai yang sesungguhnya, untuk masing-masing titik observasi. Persamaan dari MSE dinotasikan dengan (3).</span></p>
<p><span class="font8">4 </span><span class="font8" style="font-style:italic;"><sup>n</sup></span></p>
<p><span class="font8" style="font-style:italic;">MSE(Y,r)=-∑(Y<sub>i</sub>-ltf</span><span class="font3"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(3)</span></p>
<p><span class="font7">i = 1</span></p>
<ul style="list-style:none;"><li>
<p><span class="font3">b. &nbsp;R<sup>2</sup> (</span><span class="font3" style="font-style:italic;">Coefficient of Determination</span><span class="font3">)</span></p></li></ul>
<p><span class="font3">Sedikit berbeda dari MSE, R<sup>2</sup> merupakan pengukuran proporsi dari varians variabel dependen yang dapat diprediksi dari variabel independen. Secara sederhana R<sup>2</sup> merupakan MSE yang sudah dinormalisasi dengan skala dari data, sehingga lebih mudah diinterpretasikan. Persamaan R<sup>2 </sup>dinotasikan dengan (4).</span></p>
<p><span class="font8" style="font-style:italic;">R<sup>2</sup> (Y, Y) = 1- </span><span class="font8" style="text-decoration:line-through;">∑<sup>i</sup></span><span class="font7" style="text-decoration:line-through;">=</span><span class="font8" style="text-decoration:line-through;"><sup>1</sup>(<sup>γ</sup> — </span><span class="font8" style="font-style:italic;text-decoration:line-through;"><sup>Yl</sup>\</span><span class="font3"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(4)</span></p>
<p><span class="font8">∑UY</span><span class="font7">i</span><span class="font8">-Y)<sup>2</sup></span></p>
<p><span class="font3">Untuk masing-masing model yang akan kami bangun di atas, sama halnya dengan model DNN, kami akan melakukan </span><span class="font3" style="font-style:italic;">hyperparameter tuning</span><span class="font3"> untuk memastikan bahwa kami dapat meraih hasil terbaik dari masing-masing model yang kami gunakan. Untuk model </span><span class="font3" style="font-style:italic;">Bayesian Regression</span><span class="font3"> dan </span><span class="font3" style="font-style:italic;">K-Nearest Neighbors Regressor</span><span class="font3">, kami akan menggunakan strategi </span><span class="font3" style="font-style:italic;">brute force</span><span class="font3"> untuk </span><span class="font3" style="font-style:italic;">hyperparameter tuning</span><span class="font3">, dengan algoritma sederhana yang kami tulis sendiri. Sedangkan untuk model </span><span class="font3" style="font-style:italic;">XGBoost</span><span class="font3">, kami akan menggunakan pustaka </span><span class="font3" style="font-style:italic;">Hyperopt</span><span class="font3"> dengan algoritma </span><span class="font3" style="font-style:italic;">Bayesian Optimization</span><span class="font3"> yang menggunakan </span><span class="font3" style="font-style:italic;">Bayesian inference</span><span class="font3"> dan model probabilitas untuk menemukan satu set </span><span class="font3" style="font-style:italic;">hyperparameter</span><span class="font3"> yang optimal dengan diberikan sebuah ruang pencarian.</span></p>
<ul style="list-style:none;"><li>
<h3><a name="bookmark23"></a><span class="font3" style="font-weight:bold;"><a name="bookmark24"></a>2.4. Studi Komparatif Seleksi Fitur</span></h3></li></ul>
<p><span class="font3">Dalam bagian sebelumnya mengenai pembangunan model </span><span class="font3" style="font-style:italic;">deep neural network</span><span class="font3"> dan </span><span class="font3" style="font-style:italic;">machine learning</span><span class="font3"> tradisional, kami menggunakan seleksi fitur berbasis </span><span class="font3" style="font-style:italic;">Lasso</span><span class="font3">. Selain </span><span class="font3" style="font-style:italic;">Lasso</span><span class="font3">, ada berbagai macam jenis seleksi fitur lainnya yang dapat kami bandingkan performanya dengan </span><span class="font3" style="font-style:italic;">Lasso</span><span class="font3">. Untuk itu, kami memilih </span><span class="font3" style="font-style:italic;">ElasticNet</span><span class="font3"> sebagai objek studi komparatif kami, karena merupakan pengembangan dari algoritma </span><span class="font3" style="font-style:italic;">Lasso</span><span class="font3"> dengan penambahan metode regularisasi L2, yang sering disebut </span><span class="font3" style="font-style:italic;">Ridge</span><span class="font3">. Kombinasi dari dua metode regularisasi ini bertujuan untuk menghindari kekurangan dari masing-masing metode regularisasi dan menggabungkan kelebihannya. Jika norma L1 melakukan penyusutan koefisien bahkan sampai 0 [14], norma L2 lebih fokus pada melakukan penyusutan koefisien yang lebih kecil namun tidak sampai 0, mengurangi kuantitas fitur </span><span class="font3" style="font-style:italic;">colinear</span><span class="font3">.</span></p>
<p><span class="font3">Sebagai perbandingan dari kedua metode seleksi fitur ini, kami akan melakukan </span><span class="font3" style="font-style:italic;">fitting</span><span class="font3"> model SVR untuk </span><span class="font3" style="font-style:italic;">dataset</span><span class="font3"> yang sudah diseleksi fitur menggunakan </span><span class="font3" style="font-style:italic;">ElasticNet</span><span class="font3"> dan membandingkannya dengan </span><span class="font3" style="font-style:italic;">dataset</span><span class="font3"> yang diseleksi menggunakan </span><span class="font3" style="font-style:italic;">Lasso</span><span class="font3"> dari penelitian Kalehbasti et al [5]. Indikator keberhasilan komparasi ini adalah nilai MSE yang paling rendah (R<sup>2</sup> yang paling tinggi).</span></p>
<ul style="list-style:none;"><li>
<h3><a name="bookmark25"></a><span class="font3" style="font-weight:bold;"><a name="bookmark26"></a>3. &nbsp;&nbsp;&nbsp;Hasil dan Pembahasan</span></h3></li></ul>
<p><span class="font3">Pada bagian ini, kami akan menunjukkan hasil dari beberapa eksperimen kami. Kami juga akan mencoba untuk menjelaskan alasan dari hasil tersebut. Dalam melakukan eksperimen 1 dan 2, kami menggunakan </span><span class="font3" style="font-style:italic;">kernel Jupyter Notebook</span><span class="font3"> dari </span><span class="font3" style="font-style:italic;">Kaggle</span><span class="font3"> varian gratis (tidak berbayar), yang menawarkan layanan </span><span class="font3" style="font-style:italic;">cloud notebook</span><span class="font3"> menggunakan CPU secara gratis. Secara kumulatif dari kedua eksperimen, </span><span class="font3" style="font-style:italic;">kernel</span><span class="font3"> kami menghabiskan waktu kira-kira 18 jam.</span></p>
<ul style="list-style:none;"><li>
<h3><a name="bookmark27"></a><span class="font3" style="font-weight:bold;"><a name="bookmark28"></a>3.1. &nbsp;&nbsp;&nbsp;Eksperimen 1 (Pembuatan dan Penyetelan Model </span><span class="font3" style="font-weight:bold;font-style:italic;">Machine Learning</span><span class="font3" style="font-weight:bold;">)</span></h3></li></ul>
<p><span class="font3">Dalam proses pemisahan data (</span><span class="font3" style="font-style:italic;">dataset train/val/test split</span><span class="font3">), kami menggunakan 10% data / 4.998 baris untuk masing-masing </span><span class="font3" style="font-style:italic;">test</span><span class="font3"> dan </span><span class="font3" style="font-style:italic;">validation set</span><span class="font3"> dan sisanya, 80% data / 39.980 baris, kami gunakan untuk </span><span class="font3" style="font-style:italic;">training set</span><span class="font3">. Kami menggunakan model terbaik dari penelitian Kalehbasti et al. [5], yaitu SVR dengan nilai performa yang ditunjukkan pada </span><span class="font3" style="font-weight:bold;">Tabel 5</span><span class="font3">.</span></p>
<p><span class="font3" style="font-weight:bold;">Tabel 5. </span><span class="font3">Model </span><span class="font3" style="font-style:italic;">baseline</span><span class="font3"> yang akan kami gunakan sebagai perbandingan. Tabel diadaptasi dari penelitian Kalehbasti et al. [5]</span></p>
<table border="1">
<tr><td style="vertical-align:middle;">
<p><span class="font3" style="font-weight:bold;">Model</span></p></td><td style="vertical-align:middle;">
<p><span class="font3" style="font-weight:bold;">MSE</span></p></td><td style="vertical-align:middle;">
<p><span class="font3" style="font-weight:bold;"><sub>R</sub></span><span class="font1" style="font-weight:bold;">2</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font3">SVR (</span><span class="font3" style="font-style:italic;">baseline</span><span class="font3">)</span></p></td><td style="vertical-align:middle;">
<p><span class="font3" style="font-weight:bold;">0.1471</span></p></td><td style="vertical-align:middle;">
<p><span class="font3">0.6901</span></p></td></tr>
</table>
<p><span class="font3" style="font-weight:bold;">Tabel 6 </span><span class="font3">menunjukkan model terbaik untuk masing-masing eksperimen DNN dengan ukuran </span><span class="font3" style="font-style:italic;">layer</span><span class="font3"> (2, 3, 4, dan 5 </span><span class="font3" style="font-style:italic;">layer</span><span class="font3">) beserta konfigurasinya dibandingkan dengan model </span><span class="font3" style="font-style:italic;">baseline</span><span class="font3">. Nilai </span><span class="font3" style="font-style:italic;">performa</span><span class="font3"> untuk masing-masing model dilihat dari </span><span class="font3" style="font-style:italic;">best epoch</span><span class="font3"> untuk masing-masing sesi </span><span class="font3" style="font-style:italic;">training</span><span class="font3">, bukan pada </span><span class="font3" style="font-style:italic;">epoch </span><span class="font3">terakhir.</span></p>
<p><span class="font3">Catatan: Kolom konfigurasi berarti jumlah </span><span class="font3" style="font-style:italic;">dense layer</span><span class="font3"> untuk masing-masing </span><span class="font3" style="font-style:italic;">layer</span><span class="font3"> dipisahkan dengan </span><span class="font3" style="font-style:italic;">dash</span><span class="font3"> (-). Contoh: 250 – 250 – 250 berarti terdapat </span><span class="font3" style="font-style:italic;">input layer</span><span class="font3">, 3 </span><span class="font3" style="font-style:italic;">dense layer</span><span class="font3">, dan </span><span class="font3" style="font-style:italic;">output layer </span><span class="font3">(sejumlah 1 untuk semua model). Kemudian, entri </span><span class="font3" style="font-style:italic;">dropout</span><span class="font3"> berarti terdapat </span><span class="font3" style="font-style:italic;">dropout</span><span class="font3"> layer sebesar 0.2 pada lokasi tersebut.</span></p>
<p><span class="font3" style="font-weight:bold;">Tabel 6. </span><span class="font3">Perbandingan model terbaik dari eksperimen DNN</span></p>
<table border="1">
<tr><td style="vertical-align:middle;">
<p><span class="font3" style="font-weight:bold;">Model</span></p></td><td style="vertical-align:top;">
<p><span class="font3" style="font-weight:bold;">Pengukuran Perfoma</span></p>
<p><span class="font3" style="font-weight:bold;">Konfigurasi &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<sub>MSE &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;R</sub></span><span class="font1" style="font-weight:bold;">2</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font3">DNN 2-</span><span class="font3" style="font-style:italic;">layer</span></p>
<p><span class="font3">DNN 3-</span><span class="font3" style="font-style:italic;">layer</span></p>
<p><span class="font3">DNN 4-</span><span class="font3" style="font-style:italic;">layer</span></p>
<p><span class="font3" style="font-weight:bold;font-style:italic;">Baseline SVR</span></p></td><td style="vertical-align:middle;">
<p><span class="font3">365 – 365 – </span><span class="font3" style="font-style:italic;">dropout</span><span class="font3"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.1558 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.6715</span></p>
<p><span class="font3">455 – 125 – 35 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.1564 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.6703</span></p>
<p><span class="font3">485 – 485 – 305 – 335 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.1541 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.6753</span></p>
<p><span class="font3" style="font-weight:bold;">0.1471 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.6901</span></p></td></tr>
</table>
<p><span class="font3">Tabel 7 menunjukkan model terbaik untuk masing-masing hasil eksperimen metode </span><span class="font3" style="font-style:italic;">machine learning </span><span class="font3">tradisional.</span></p>
<p><span class="font3" style="font-weight:bold;">Tabel 7. </span><span class="font3">Perbandingan model terbaik dari eksperimen </span><span class="font3" style="font-style:italic;">machine learning</span><span class="font3"> tradisional</span></p>
<table border="1">
<tr><td style="vertical-align:middle;">
<p><span class="font3" style="font-weight:bold;">Model</span></p></td><td style="vertical-align:top;">
<p><span class="font3" style="font-weight:bold;">Pengukuran Perfoma</span></p>
<p><span class="font3" style="font-weight:bold;">MSE &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;R<sup>2</sup></span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font3" style="font-style:italic;">Bayesian Regression </span><span class="font3">K-NN </span><span class="font3" style="font-style:italic;">Regression </span><span class="font3" style="font-weight:bold;font-style:italic;">XGBoost </span><span class="font3" style="font-style:italic;">Baseline SVR</span></p></td><td style="vertical-align:middle;">
<p><span class="font3">0.1553 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.6741</span></p>
<p><span class="font3">0.2112 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.5567</span></p>
<p><span class="font3" style="font-weight:bold;">0.1414 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.7031</span></p>
<p><span class="font3">0.1471 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.6901</span></p></td></tr>
</table>
<p><span class="font3">Dari hasil eksperimen DNN di atas, dapat dilihat bahwa tidak ada model DNN yang dapat mengungguli hasil dari model </span><span class="font3" style="font-style:italic;">baseline</span><span class="font3"> SVR. Dari semua model DNN, model 4-</span><span class="font3" style="font-style:italic;">layer</span><span class="font3"> menghasilkan performa yang terbaik, meskipun dengan margin yang sangat sedikit dari model-model lainnya. Dalam permasalahan ini, menambah </span><span class="font3" style="font-style:italic;">layer</span><span class="font3"> dari DNN tidak membantu untuk menambah performanya.</span></p>
<p><span class="font3">Hal ini disebabkan oleh DNN dengan </span><span class="font3" style="font-style:italic;">layer</span><span class="font3"> besar sangat rawan terkena </span><span class="font3" style="font-style:italic;">overfitting</span><span class="font3">, karena banyaknya </span><span class="font3" style="font-style:italic;">trainable parameters</span><span class="font3"> yang ada di dalam arsitekturnya. Kemungkinan permasalahan kedua adalah </span><span class="font3" style="font-style:italic;">learning rate</span><span class="font3"> yang terlalu besar, sehingga menyebabkan </span><span class="font3" style="font-style:italic;">oscillating learning</span><span class="font3">. Hal ini sudah kami coba mitigasi dengan menggunakan </span><span class="font3" style="font-style:italic;">learning rate</span><span class="font3"> yang sangat kecil, yaitu </span><span class="font8">1 </span><span class="font6">⋅</span><span class="font8"> 10<sup>-4</sup></span><span class="font3">, namun tidak menghasilkan kenaikan yang signifikan.</span></p>
<p><span class="font3">Selanjutnya, untuk eksperimen </span><span class="font3" style="font-style:italic;">machine learning</span><span class="font3"> tradisional, model </span><span class="font3" style="font-style:italic;">XGBoost</span><span class="font3"> yang kami buat dapat mengungguli hasil </span><span class="font3" style="font-style:italic;">baseline</span><span class="font3"> dengan nilai MSE sebesar 0.1414, yang bukan merupakan merupakan kenaikan yang signifikan. </span><span class="font3" style="font-style:italic;">XGBoost</span><span class="font3"> sebagai satu-satunya model dari eksperimen ini yang berhasil meraih performa di atas </span><span class="font3" style="font-style:italic;">baseline</span><span class="font3"> menunjukkan kekuatan </span><span class="font3" style="font-style:italic;">XGBoost</span><span class="font3"> sebagai model </span><span class="font3" style="font-style:italic;">ensemble</span><span class="font3"> yang terdiri atas banyak </span><span class="font3" style="font-style:italic;">tree</span><span class="font3">, yang dapat bekerja dengan data yang tidak </span><span class="font3" style="font-style:italic;">linearly separable</span><span class="font3">.</span></p>
<p><span class="font3">Dari dua bagian dari eksperimen pertama di atas, dapat ditunjukkan bahwa </span><span class="font3" style="font-style:italic;">XGBoost</span><span class="font3"> sebagai model yang secara relatif lebih sederhana daripada SVM yang lebih rumit dan DNN yang jauh lebih rumit dapat mendapatkan hasil yang terbaik.</span></p>
<ul style="list-style:none;"><li>
<h3><a name="bookmark29"></a><span class="font3" style="font-weight:bold;"><a name="bookmark30"></a>3.2. &nbsp;&nbsp;&nbsp;Eksperimen 2 (Studi Komparatif Seleksi Fitur)</span></h3></li></ul>
<p><span class="font3">Kami menggunakan skema pemisahan data yang sama dengan eksperimen sebelumnya dan mengubah metode seleksi fitur. Tabel 8 merupakan perbandingan antara dua metode seleksi fitur dengan metode </span><span class="font3" style="font-style:italic;">machine learning</span><span class="font3"> yang sama, yaitu SVM.</span></p>
<table border="1">
<tr><td colspan="3" style="vertical-align:top;">
<p><span class="font3" style="font-weight:bold;">Tabel 8. </span><span class="font3">Perbandingan antara metode seleksi fitur </span><span class="font3" style="font-style:italic;">ElasticNet</span><span class="font3"> dan </span><span class="font3" style="font-style:italic;">Lasso</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font3" style="font-weight:bold;">Metode Seleksi Fitur</span></p></td><td colspan="2" style="vertical-align:middle;">
<p><span class="font3" style="font-weight:bold;">Pengukuran Perfoma</span></p>
<p><span class="font3" style="font-weight:bold;">MSE &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;R<sup>2</sup></span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font3" style="font-weight:bold;font-style:italic;">ElasticNet</span></p></td><td style="vertical-align:middle;">
<p><span class="font3" style="font-weight:bold;">0.1370</span></p></td><td style="vertical-align:middle;">
<p><span class="font3" style="font-weight:bold;">0.7101</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font3" style="font-style:italic;">Baseline Lasso</span></p></td><td style="vertical-align:middle;">
<p><span class="font3">0.1471</span></p></td><td style="vertical-align:middle;">
<p><span class="font3">0.6901</span></p></td></tr>
</table>
<p><span class="font3">Model seleksi fitur </span><span class="font3" style="font-style:italic;">ElasticNet</span><span class="font3"> menunjukkan kemampuan yang lebih tinggi untuk mengidentifikasi fitur yang lebih penting untuk digunakan pada metode </span><span class="font3" style="font-style:italic;">machine learning</span><span class="font3">. Seperti yang telah diulas sebelumnya pada bagian metode, </span><span class="font3" style="font-style:italic;">ElasticNet</span><span class="font3"> merupakan penyempurnaan dari model seleksi fitur berbasis norma penalti L1 (</span><span class="font3" style="font-style:italic;">Lasso</span><span class="font3">) dan L2 (</span><span class="font3" style="font-style:italic;">Ridge</span><span class="font3">), menghasilkan fitur yang diseleksi menggunakan penalti L1 dan L2 yang imbang.</span></p>
<ul style="list-style:none;"><li>
<h3><a name="bookmark31"></a><span class="font3" style="font-weight:bold;"><a name="bookmark32"></a>4. &nbsp;&nbsp;&nbsp;Kesimpulan</span></h3></li></ul>
<p><span class="font3">Penelitian ini memiliki tujuan untuk memperbaiki hasil penelitian mengenai deteksi harga </span><span class="font3" style="font-style:italic;">Airbnb</span><span class="font3"> dari penelitian-penelitian yang ada sebelumnya. Kebaruan yang ditawarkan dari penelitian ini adalah model-model </span><span class="font3" style="font-style:italic;">machine learning</span><span class="font3"> baru, termasuk </span><span class="font3" style="font-style:italic;">Deep Neural Network</span><span class="font3">, </span><span class="font3" style="font-style:italic;">Bayesian Regression</span><span class="font3">, K-NN </span><span class="font3" style="font-style:italic;">Regression</span><span class="font3">, dan </span><span class="font3" style="font-style:italic;">XGBoost</span><span class="font3">. Metode-metode baru tersebut kami </span><span class="font3" style="font-style:italic;">train</span><span class="font3"> menggunakan </span><span class="font3" style="font-style:italic;">dataset</span><span class="font3"> dan </span><span class="font3" style="font-style:italic;">feature engineering</span><span class="font3"> yang sama dengan penelitian sebelumnya, dan kami dapat memberikan hasil yang lebih baik. Dengan pengukuran performa berbasis MSE (</span><span class="font3" style="font-style:italic;">Mean Squared Error</span><span class="font3">) dan R<sup>2</sup>, kami berhasil membuat model </span><span class="font3" style="font-style:italic;">XGBoost</span><span class="font3"> dengan nilai MSE sebesar 0.1414 dan R<sup>2</sup> sebesar 0.7031.</span></p>
<p><span class="font5">Perbandingan Nilai MSEAntarModeI </span><span class="font0">(Lebih kecil lebih baik)</span></p><img src="https://jurnal.harianregional.com/media/102724-3.jpg" alt="" style="width:243pt;height:105pt;">
<p><span class="font3" style="font-weight:bold;">Gambar 3. </span><span class="font3">Perbandingan nilai MSE antar model </span><span class="font3" style="font-style:italic;">machine learning</span><span class="font3"> yang dibuat</span></p>
<p><span class="font3">Kami juga melakukan eksperimen menggunakan metode seleksi fitur baru, yaitu </span><span class="font3" style="font-style:italic;">ElasticNet</span><span class="font3">, yang merupakan penyempurnaan dari metode seleksi yang dipakai sebelumnya, </span><span class="font3" style="font-style:italic;">Lasso</span><span class="font3">. Kami berhasil mendapatkan hasil yang lebih baik dengan metode </span><span class="font3" style="font-style:italic;">machine learning</span><span class="font3"> SVR sebagai </span><span class="font3" style="font-style:italic;">benchmark</span><span class="font3">, dengan MSE sebesar 0.1370 dan R<sup>2</sup> sebesar 0.7101.</span></p><img src="https://jurnal.harianregional.com/media/102724-4.jpg" alt="" style="width:256pt;height:154pt;">
<p><span class="font3" style="font-weight:bold;">Gambar 4. </span><span class="font3">Perbandingan nilai MSE antar metode seleksi fitur yang dibandingkan</span></p>
<p><span class="font3">Penelitian yang kami buat pada eksperimen pertama menggunakan seleksi fitur </span><span class="font3" style="font-style:italic;">LASSO</span><span class="font3"> yang berfokus pada </span><span class="font3" style="font-style:italic;">baseline</span><span class="font3"> dibandingkan dengan model baru sedangkan untuk eksperimen kedua kita menggunakan </span><span class="font3" style="font-style:italic;">ElasticNet</span><span class="font3"> yang berfokus pada perbandingan antara </span><span class="font3" style="font-style:italic;">LASSO</span><span class="font3"> dengan </span><span class="font3" style="font-style:italic;">ElasticNet.</span><span class="font3"> Jadi antara eksperimen pertama dan kedua memiliki konteks yang berbeda.</span></p>
<p><span class="font3">Ada beberapa penelitian lanjutan yang dapat kami usulkan, yaitu (1) pembuatan paradigma </span><span class="font3" style="font-style:italic;">feature engineering</span><span class="font3"> yang sepenuhnya berbeda dengan metode seleksi fitur yang berbeda juga seperti </span><span class="font3" style="font-style:italic;">Principle Component Analysis</span><span class="font3"> (PCA), (2) penelitian mengenai masalah-masalah klasik pada </span><span class="font3" style="font-style:italic;">Deep Neural Network</span><span class="font3"> seperti </span><span class="font3" style="font-style:italic;">vanishing gradient boosting</span><span class="font3"> pada permasalahan ini, dan (3) menggunakan </span><span class="font3" style="font-style:italic;">dataset</span><span class="font3"> yang berbeda sebagai objek penelitian, seperti hotel atau layanan akomodasi berbasis pariwisata lainnya yang mungkin memiliki permasalahan penentuan harga yang sama dengan penelitian kami.</span></p>
<h3><a name="bookmark33"></a><span class="font3" style="font-weight:bold;"><a name="bookmark34"></a>Referensi</span></h3>
<p><span class="font3">Digno, Jauhar, Syaifullah.</span></p>
<p><span class="font3">Pendekatan Deep Learning dan Gradient Boosting dalam Prediksi Harga Properti Airbnb dengan Analisis Sentimen</span></p>
<ul style="list-style:none;"><li>
<p><span class="font3">[8] &nbsp;&nbsp;&nbsp;&nbsp;Y. Yang, N. J. Mueller, and R. R. Croes, “Market accessibility and hotel prices in the</span></p></li></ul>
<p><span class="font3">Caribbean: The moderating effect of quality-signaling factors,” </span><span class="font3" style="font-style:italic;">Tour. Manag.</span><span class="font3">, vol. 56, pp. 40–51, Oct. 2016, doi: 10.1016/j.tourman.2016.03.021.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font3">[9] &nbsp;&nbsp;&nbsp;&nbsp;Y. Li, Q. Pan, T. Yang, and L. Guo, “Reasonable price recommendation on Airbnb using</span></p></li></ul>
<p><span class="font3">Multi-Scale clustering,” </span><span class="font3" style="font-style:italic;">2016 35th Chin. Control Conf. CCC</span><span class="font3">, pp. 7038–7041, Jul. 2016, doi: 10.1109/ChiCC.2016.7554467.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font3">[10] &nbsp;&nbsp;&nbsp;“Airbnb Public Dataset.” </span><a href="http://insideairbnb.com/get-the-data/"><span class="font3">http://insideairbnb.com/get-the-data/</span></a><span class="font3"> (accessed Jun. 13, 2023).</span></p></li>
<li>
<p><span class="font3">[11] &nbsp;&nbsp;&nbsp;M. Wankhade, A. C. S. Rao, and C. Kulkarni, “A survey on sentiment analysis methods,</span></p></li></ul>
<p><span class="font3">applications, and challenges,” </span><span class="font3" style="font-style:italic;">Artif. Intell. Rev.</span><span class="font3">, vol. 55, no. 7, pp. 5731–5780, Oct. 2022, doi: 10.1007/s10462-022-10144-1.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font3">[12] &nbsp;&nbsp;&nbsp;S. Loria, “Textblob: simplified text processing,” 2018.</span></p></li>
<li>
<p><span class="font3">[13] &nbsp;&nbsp;&nbsp;R.-C. Chen, C. Dewi, S.-W. Huang, and R. E. Caraka, “Selecting critical features for data</span></p></li></ul>
<p><span class="font3">classification based on machine learning methods,” </span><span class="font3" style="font-style:italic;">J. Big Data</span><span class="font3">, vol. 7, no. 1, p. 52, Jul. 2020, doi: 10.1186/s40537-020-00327-4.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font3">[14] &nbsp;&nbsp;&nbsp;S. Zhang, F. Zhu, Q. Yu, and X. Zhu, “Identifying DNA-binding proteins based on multi</span></p></li></ul>
<p><span class="font3">features and LASSO feature selection,” </span><span class="font3" style="font-style:italic;">Biopolymers</span><span class="font3">, vol. 112, no. 2, p. e23419, 2021, doi: 10.1002/bip.23419.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font3">[15] &nbsp;&nbsp;&nbsp;M. Kang and J. Tian, “Machine Learning: Data Pre-processing,” in </span><span class="font3" style="font-style:italic;">Prognostics and Health</span></p></li></ul>
<p><span class="font3" style="font-style:italic;">Management of Electronics</span><span class="font3">, John Wiley &amp;&nbsp;Sons, Ltd, 2018, pp. 111–130. doi: 10.1002/9781119515326.ch5.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font3">[16] &nbsp;&nbsp;&nbsp;A. R. N. Aouichaoui, R. Al, J. Abildskov, and G. Sin, “Comparison of Group-Contribution and Machine Learning-based Property Prediction Models with Uncertainty Quantification,” in </span><span class="font3" style="font-style:italic;">Computer Aided Chemical Engineering</span><span class="font3">, M. Türkay and R. Gani, Eds., in 31 European Symposium on Computer Aided Process Engineering, vol. 50. Elsevier, 2021, pp. 755–760. doi: 10.1016/B978-0-323-88506-5.50118-2.</span></p></li>
<li>
<p><span class="font3">[17] &nbsp;&nbsp;&nbsp;I. G. N. A. Indrawan and I. M. Widiartha, “Optimization Artificial Neural Network Using Artificial</span></p></li></ul>
<p><span class="font3">Bee Colony in Letter Recognition Classification,” </span><span class="font3" style="font-style:italic;">JELIKU J. Elektron. Ilmu Komput. Udayana</span><span class="font3">, vol. 8, no. 4, pp. 469–473, 2020, doi: 10.24843/JLK.2020.v08.i04.p13.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font3">[18] &nbsp;&nbsp;&nbsp;J. Lim </span><span class="font3" style="font-style:italic;">et al.</span><span class="font3">, “Development of Dye Exhaustion Behavior Prediction Model using Deep Neural</span></p></li></ul>
<p><span class="font3">Network,” in </span><span class="font3" style="font-style:italic;">Computer Aided Chemical Engineering</span><span class="font3">, Y. Yamashita and M. Kano, Eds., in 14 International Symposium on Process Systems Engineering, vol. 49. Elsevier, 2022, pp. 1825–1830. doi: 10.1016/B978-0-323-85159-6.50304-3.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font3">[19] &nbsp;&nbsp;&nbsp;L. Li, K. Jamieson, G. DeSalvo, A. Rostamizadeh, and A. Talwalkar, “Hyperband: A Novel</span></p></li></ul>
<p><span class="font3">Bandit-Based Approach to Hyperparameter Optimization,” </span><span class="font3" style="font-style:italic;">J. Mach. Learn. Res.</span><span class="font3">, vol. 18, no. 185, pp. 1–52, 2018.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font3">[20] &nbsp;&nbsp;&nbsp;M. H. Bakr and M. H. Negm, “Chapter Three - Modeling and Design of High-Frequency</span></p></li></ul>
<p><span class="font3">Structures Using Artificial Neural Networks and Space Mapping,” in </span><span class="font3" style="font-style:italic;">Advances in Imaging and Electron Physics</span><span class="font3">, M. J. Deen, Ed., in Silicon-Based Millimeter-wave Technology, vol. 174. Elsevier, 2012, pp. 223–260. doi: 10.1016/B978-0-12-394298-2.00003-X.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font3">[21] &nbsp;&nbsp;&nbsp;Y. Kumar </span><span class="font3" style="font-style:italic;">et al.</span><span class="font3">, “Heart Failure Detection Using Quantum-Enhanced Machine Learning and Traditional Machine Learning Techniques for Internet of Artificially Intelligent Medical Things,” </span><span class="font3" style="font-style:italic;">Wirel. Commun. Mob. Comput.</span><span class="font3">, vol. 2021, p. e1616725, Dec. 2021, doi: 10.1155/2021/1616725.</span></p></li>
<li>
<p><span class="font3">[22] &nbsp;&nbsp;&nbsp;Murni, R. Kosasih, A. Fahrurozi, T. Handhika, I. Sari, and D. P. Lestari, “Travel Time</span></p></li></ul>
<p><span class="font3">Estimation for Destination In Bali Using kNN-Regression Method with Tensorflow,” </span><span class="font3" style="font-style:italic;">IOP Conf. Ser. Mater. Sci. Eng.</span><span class="font3">, vol. 854, no. 1, p. 012061, May 2020, doi: 10.1088/1757-899X/854/1/012061.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font3">[23] &nbsp;&nbsp;&nbsp;S. Pan, Z. Zheng, Z. Guo, and H. Luo, “An optimized XGBoost method for predicting reservoir</span></p></li></ul>
<p><span class="font3">porosity using petrophysical logs,” </span><span class="font3" style="font-style:italic;">J. Pet. Sci. Eng.</span><span class="font3">, vol. 208, p. 109520, Jan. 2022, doi: 10.1016/j.petrol.2021.109520.</span></p>
<p><span class="font3">200</span></p>