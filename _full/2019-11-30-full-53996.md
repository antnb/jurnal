---
layout: full_article
title: "AN APPLICATION OF SEGNET FOR DETECTING LANDSLIDE AREAS BY USING FULLY POLARIMETRIC SAR DATA"
author: "I Made Oka Guna Antara, Norikazu Shimizu, Takahiro Osawa, I Wayan Nuarsa"
categories: ecotrophic
canonical_url: https://jurnal.harianregional.com/ecotrophic/full-53996 
citation_abstract_html_url: "https://jurnal.harianregional.com/ecotrophic/id-53996"
citation_pdf_url: "https://jurnal.harianregional.com/ecotrophic/full-53996"  
comments: true
---

<p><span class="font19">An Application Of Segnet For Detecting Landslide Areas By Using Fully Polarimetric Sar Data</span></p>
<p><span class="font12" style="font-weight:bold;">[I Made Oka Guna, dkk.]</span></p>
<div>
<p><span class="font23" style="font-weight:bold;">1. INTRODUCTION</span></p>
<p><span class="font23">The study of landslide location is in Hokkaido, Japan, which occurred due to the Iburi Earthquake 2018. The Earthquake occurred on September 6th, 2018 at 03:08 JST (local time) with magnitude 6.7. The epicenter located at 42.72° North, and 142.0° East, where Atsuma-cho was registered as an area that has maximum intensity of 7. This earthquake induced landslide in several areas (Yamagishi and Yamazaki, 2018).</span></p>
<p><span class="font23">In this study an analysis was carried out using satellite images of ALOS-2/PALSAR-2. ALOS-2/PALSAR-2 is a satellite image of Synthetic Aperture Radar (SAR). SAR synthetically increases the antenna's size or aperture to increase the azimuth resolution through the same pulse compression technique as adopted for range direction. Synthetic aperture processing is a complicated data processing of received signals and phases from moving targets with a small antenna, the effect of which is to should be theoretically</span></p>
</div><br clear="all">
<p><span class="font25" style="font-weight:bold;">AN APPLICATION OF SEGNET FOR DETECTING LANDSLIDE AREAS BY USING FULLY POLARIMETRIC SAR DATA</span></p>
<p><span class="font23" style="font-weight:bold;">I Made Oka Guna Antara<sup>1*)</sup>, Norikazu Shimizu<sup>2)</sup>, Takahiro Osawa<sup>3,4)</sup>, I Wayan Nuarsa<sup>5) </sup></span><span class="font22"><sup>1)</sup>Graduate Student of Environmental Science, Udayana University <sup>2)</sup>Department of Civil and Environmental Engineering, Yamaguchi University <sup>3)</sup>Center for Remote Sensing and Ocean Sciences (CReSOS), Udayana University</span></p>
<p><span class="font22"><sup>4)</sup>Center for Research and Application of Satellite Remote Sensing (YUCARS), Yamaguchi University <sup>5)</sup>Faculty of Agriculture, Udayana University, Denpasar, Indonesia</span></p>
<p><span class="font22">*Email: </span><a href="mailto:okagunaantara@gmail.com"><span class="font22">okagunaantara@gmail.com</span></a></p><a name="caption1"></a>
<h4><a name="bookmark0"></a><span class="font23" style="font-weight:bold;"><a name="bookmark1"></a>ABSTRACT</span></h4>
<p><span class="font23">The study location of landslide is in Hokkaido, Japan which occurred due to the Iburi Earthquake 2018. In this study the landslide has been estimated by the fully Polarimetric SAR (Pol-SAR) technique based on ALOS-2/PALSAR-2 data using the Yamaguchi’s decomposition. The Yamaguchi's decomposition is proposed by Yoshio Yamaguchi et.al. The data has been analyzed using the deep learning process with SegNet architecture with color composite. In this research, the performance of SegNet is fast and efficient in memory usage. However, the result is not good, based on the Intersection over Union (IoU) evaluation obtained the lowest value is 0.0515 and the highest value is 0.1483. That is because of difficulty to make training datasets and of a small number of datasets. The greater difference between accuracy and loss graph along with higher epochs represents overfitting. The overfitting can be caused by the limited amount of training data and failure of the network to generalize the feature set over the training images.</span></p>
<p><span class="font23" style="font-weight:bold;">Keywords</span><span class="font23">: ALOS-2/PALSAR-2, Fully Polarimetric SAR, Yamaguchi Decomposition, SegNet, Landslide</span></p>
<p><span class="font23">converted to the effect of a large antenna, that is a synthetic aperture length (Japan Association of Remote Sensing, 1996).</span></p>
<p><span class="font23">SAR has the ability in all weather and also able to work during the day and night, the superiority of this SAR is due to the use of microwaves that can heal clouds and rain to a certain degree.SAR applications have been applied in various fields, depending on their objectives, such as in the field of oceanography, agriculture, geology, disaster mitigation, and so on.In the past few years, the use of the Polarimetric SAR (Pol-SAR) system has increased which is applied to aircraft or satellites, Pol-SAR has become one of the attention of researchers to be developed.</span></p>
<p><span class="font23">Fully Pol-SAR data has a variety of information when compared with single or dual polarization SAR data, in terms of electromagnetic scattering characteristics to the intended target (Shibayama, T., et.al., 2015).Fully Pol-SAR data provides information in the form of a field scattering matrix, a scattering matrix consisting of</span></p>
<p><span class="font23">magnitude and phase on four polarizations (HH, HV, VH, VV) sent and received horizontally (H) and vertically (V) by the radar antenna.Various methods have been developed previously to obtain information on the surface characteristics of the earth from Fully Pol-SAR data. In 1997 Cloude and Pottier used coherence or covariance matrices to make eigenvector decomposition. Yamaguchi et.al. in 2005 developed an approach for four components, called Yamaguchi's Decomposition. Satellite observations were made on September 8, 2018.The Satellite observation was in September 8<sup>th</sup>, 2018.</span></p>
<p><span class="font23">Here we try to apply Deep Learning with SegNet architecture to the fourcomponent Yamaguchi’s decomposition. Deep learning is part of the field of machine learning, more and more studied in various fields in the early 2010s.A few years after that, the application is growing, producing extraordinary things in solving the perception, such as the problem of seeing and hearing that is now starting like humans, seem natural and intuitive, which was previously impossible for a machine. (Chollet, 2018).</span></p>
<p><span class="font23">Generally, Deep learning utilizes neural network architecture. Definition of &quot;Deep&quot; relates to the number of layers in the network to be used.Deep neural networks are inspired by the biological nervous system, use simple operating elements in parallel, and combine various layers for nonlinear processing (Mathworks, 2018).</span></p>
<p><span class="font23">One of the popular algorithms for deep learning in images and videos is Convolutional Neural Networks (CNN). CNN is similar to other neural networks, consists of input and output layers, and also hidden layers (Mathworks, 2018). Many algorithms are developed based on CNN, for example, autoencoder, LeNet, AlexNet, VGG, GoogLeNet, ResNet, SegNet and other.</span></p>
<p><span class="font23">There are two kind of CNN based on segmentation, first one is instance</span></p>
<p><span class="font23">segmentation and second one is semantic segmentation. Instance segmentation identifies each object in an image (Watanabe and Wolf, 2019), whereas semantic segmentation identifies and classifies every pixel belong to an object in an image explained byGarcia-Garcia et.al. (2018).</span></p>
<p><span class="font23">SegNet is a deep learning architecture, the function is for Semantic Segmentation as a labeler for each pixel image according to the class of the object that has been determined (Garcia-Garcia et al., 2018). The advantage of SegNet is that it can classify every pixel in the image, fast and efficient in memory usage. In starting, SegNet was used for self-driving cars (Badrinarayanan et al., 2017). However, we want to adopt this architecture for this research because of its advantages.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font23" style="font-weight:bold;">2. &nbsp;&nbsp;&nbsp;METHODOLOGY</span></p>
<ul style="list-style:none;">
<li>
<h4><a name="bookmark2"></a><span class="font23" style="font-weight:bold;"><a name="bookmark3"></a>2.1 &nbsp;&nbsp;&nbsp;ALOS-2/PALSAR-2 Observation</span></h4></li></ul></li></ul>
<p><span class="font23">The data observed by ALOS-2/PALSAR-2 with level 1.1 SLC (SingleLook Complex) format is used to analyze landslides that occurred due to earthquakes in Hokkaido, Japan. The ALOS-2/PALSAR-2 is a SAR Satellite, which emits microwave and receives the reflection from an object to get information. ALOS-2/PALSAR-2is L-band satellite, which is does not affected by clouds and rains. The all-weather condition capability is suitable for monitoring disasters rapidly. In addition, L-band can reach to the ground partially with penetrating the canopy of vegetation to get information on the ground surface (JAXA, 2019).The earthquake occurred on 6September 2018 at 3:08 JST, with magnitude 6.7 and maximum intensity of 7 at Atsuma-cho (Yamagishi and Yamazaki, 2018). In Figure 1 shown the research location and in the Table 1 shown summary of ALOS-2/PALSAR-2 observation data.</span></p>
<div><img src="https://jurnal.harianregional.com/media/53996-1.jpg" alt="" style="width:444pt;height:258pt;">
</div><br clear="all">
<p><span class="font23">Figure 1.</span></p>
<p><span class="font23">Research location(Google Earth, 2019)</span></p>
<p><span class="font23">Red rectangle: shape of Satellite ALOS-2 Blue rectangle: cropping by Region of Interest (ROI)</span></p>
<p><span class="font23">Table 1. Summary of ALOS-2/PALSAR-2 observation</span></p>
<table border="1">
<tr><td style="vertical-align:middle;">
<p><span class="font23" style="font-weight:bold;">Observation mode</span></p></td><td style="vertical-align:middle;">
<p><span class="font23" style="font-weight:bold;">Flight Direction</span></p></td><td style="vertical-align:middle;">
<p><span class="font23" style="font-weight:bold;">Operation Mode</span></p></td><td style="vertical-align:middle;">
<p><span class="font23" style="font-weight:bold;">Observation Direction</span></p></td><td style="vertical-align:middle;">
<p><span class="font23" style="font-weight:bold;">Observation Date</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font23">Full Polarimetry</span></p></td><td style="vertical-align:middle;">
<p><span class="font23">Ascending</span></p></td><td style="vertical-align:middle;">
<p><span class="font23">SM2</span></p></td><td style="vertical-align:middle;">
<p><span class="font23">Right-side observation</span></p></td><td style="vertical-align:middle;">
<p><span class="font23">August 8<sup>th</sup>, 2018</span></p></td></tr>
</table>
<ul style="list-style:none;"><li>
<h4><a name="bookmark4"></a><span class="font23" style="font-weight:bold;"><a name="bookmark5"></a>2.2 &nbsp;&nbsp;&nbsp;Four-component Yamaguchi</span><br><br><span class="font23" style="font-weight:bold;"><a name="bookmark6"></a>Decomposition Method</span></h4></li></ul>
<p><span class="font23">The combination of coherent speckle noise and random vector scattering effects from the surface and volume in the SAR remote sensing application requires a multivariate statistical description. That matter used to identify the average or dominant scattering mechanism from the targets, as classification of the scattering data. The main purpose of target decomposition is: to break down the coherence matrix or covariance matrix into several independent matrices to represent scattering of the intended target.</span></p>
<p><span class="font23">In its application there are two parts to target decomposition, namely, first, a coherent decomposition (Cameron, 1990; Krogager, 1990; Touzi et al. 2002) applies</span></p>
<p><span class="font23">when one or two dominant scattering mechanisms are produced. This does not apply to the case of natural targets, moreover, the noise speckle is very influential on the coherent average.</span></p>
<p><span class="font23">Second, incoherent decomposition, described as the use of statistics to produce finer scatter behavior. This method produces Huynen-based methods (Huynen, 1970), vector-based (Cloude, 1986; Cloude and Pottier, 1996) and model-based decomposition methods (Freeman and Durden, 1998; Yamaguchi, 2005).</span></p>
<p><span class="font23">Model-based decomposition method with four scattering components proposed by Yamaguchi et al. (2005). The model is based on the Freeman-Durden model (Freeman and Durden, 1998), which is then expanded based on a certain degree of orientation in the case of vegetation and provides a helical</span></p>
<div>
<p><span class="font23">component in accordance with the symmetric case of non-reflection </span><span class="font25">^ </span><span class="font23" style="font-style:italic;">S</span><span class="font19" style="font-style:italic;">HH</span><span class="font23" style="font-style:italic;">S</span><span class="font19" style="font-style:italic;">HV</span><span class="font25"> ^≠ </span><span class="font23"><sup>0</sup>and </span><span class="font25" style="font-style:italic;">{</span><span class="font24" style="font-style:italic;font-variant:small-caps;">S</span><span class="font21" style="font-style:italic;font-variant:small-caps;">h</span><span class="font26" style="font-style:italic;font-variant:small-caps;"><sub>v</sub>S*<sub>vv</sub></span><span class="font25" style="font-style:italic;"> }≠</span><span class="font23"> 0</span></p>
</div><br clear="all">
<div>
<p><span class="font23">matrix or Sinclair matrix of SAR satellite system can defined as:</span></p>
</div><br clear="all">
<div><a name="caption2"></a>
<h1><a name="bookmark7"></a><span class="font6"><a name="bookmark8"></a>[ </span><span class="font22" style="font-style:italic;">S</span><span class="font6"> 1 </span><span class="font24">=</span></h1>
</div><br clear="all">
<div>
<p><span class="font22" style="font-style:italic;">S<sub>HH</sub></span></p>
<p><span class="font23" style="font-style:italic;"><sup>S</sup></span><span class="font18" style="font-style:italic;">VH</span></p>
</div><br clear="all">
<div>
<p><span class="font22" style="font-style:italic;">S<sub>HV</sub></span></p>
<p><span class="font23" style="font-style:italic;"><sup>S</sup></span><span class="font18" style="font-style:italic;">VV</span></p>
</div><br clear="all">
<div>
<p><span class="font21" style="font-weight:bold;">transmit</span></p>
<table border="1">
<tr><td style="vertical-align:top;"></td><td style="vertical-align:middle;">
<p><span class="font21" style="font-weight:bold;">H</span></p></td><td style="vertical-align:middle;">
<p><span class="font21" style="font-weight:bold;">V</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font21">H</span></p></td><td style="vertical-align:middle;">
<p><span class="font21" style="font-weight:bold;">H</span><span class="font21">H</span></p></td><td style="vertical-align:middle;">
<p><span class="font21" style="font-weight:bold;">V</span><span class="font21">H</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font21">V</span></p></td><td style="vertical-align:middle;">
<p><span class="font21" style="font-weight:bold;">H</span><span class="font21">V</span></p></td><td style="vertical-align:middle;">
<p><span class="font21" style="font-weight:bold;">V</span><span class="font21">V</span></p></td></tr>
</table>
</div><br clear="all">
<div>
<p><span class="font23">(1)</span></p>
</div><br clear="all">
<div>
<p><span class="font23">The data set in the pixel area is expressed as a coherence matrix, as follows:</span></p>
</div><br clear="all">
<div>
<p><span class="font23" style="font-weight:bold;">Figure 1. </span><span class="font23">Transmit and receive in SAR satellite system.</span></p>
<p><span class="font23">H: horizontally; V: vertically</span></p>
</div><br clear="all">
<div>
<p><span class="font3">([ </span><span class="font22" style="font-style:italic;">T</span><span class="font3">1)</span><span class="font3" style="font-style:italic;"><sup>HV</sup></span></p>
</div><br clear="all">
<div>
<table border="1">
<tr><td style="vertical-align:top;">
<p><span class="font18">Γ </span><span class="font22" style="font-style:italic;">τ</span></p>
<p><span class="font18">11</span></p></td><td style="vertical-align:top;">
<p><span class="font23" style="font-style:italic;">T</span></p>
<p><span class="font18">12</span></p></td><td style="vertical-align:top;">
<p><span class="font23" style="font-style:italic;">T</span></p>
<p><span class="font18">13</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font18" style="font-style:italic;">rτι</span><span class="font0"> *</span></p>
<p><span class="font18" style="font-style:italic;">T</span><span class="font18"><sup>12</sup></span></p></td><td style="vertical-align:middle;">
<p><span class="font22" style="font-style:italic;">T</span></p>
<p><span class="font18">22</span></p></td><td style="vertical-align:middle;">
<p><span class="font22" style="font-style:italic;">T</span></p>
<p><span class="font18">23</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font18" style="font-style:italic;">rp*</span></p>
<p><span class="font3">_ </span><span class="font18" style="font-style:italic;">T13</span></p></td><td style="vertical-align:bottom;">
<p><span class="font18" style="font-style:italic;">rp*</span></p>
<p><span class="font22" style="font-style:italic;">T</span><span class="font18">23</span></p></td><td style="vertical-align:bottom;">
<p><span class="font22" style="font-style:italic;">T</span></p>
<p><span class="font18">33</span></p></td></tr>
</table>
</div><br clear="all">
<div>
<p><span class="font23">(2)</span></p>
</div><br clear="all">
<p><span class="font23">Based on the transmit and receive in SAR satellite system in Figure 2.7, scattering</span></p>
<div>
<p><span class="font18" style="font-style:italic;">HV</span></p>
</div><br clear="all">
<div>
<p><span class="font3">2(l</span><span class="font3" style="font-style:italic;"><sup>S</sup></span><span class="font18" style="font-style:italic;">HH</span><span class="font3"> + </span><span class="font3" style="font-style:italic;"><sup>S</sup></span><span class="font18" style="font-style:italic;">VV</span><span class="font3"> I</span></p>
<p><span class="font18" style="font-style:italic;">' HH</span><span class="font3"> — </span><span class="font3" style="font-style:italic;"><sup>S</sup></span><span class="font18" style="font-style:italic;">VV</span><span class="font3"> <sup>)( </sup></span><span class="font3" style="font-style:italic;"><sup>S</sup></span><span class="font18" style="font-style:italic;">HH</span><span class="font3"> + </span><span class="font3" style="font-style:italic;"><sup>S</sup></span><span class="font18" style="font-style:italic;">VV</span><span class="font3"> )</span></p>
</div><br clear="all">
<div><img src="https://jurnal.harianregional.com/media/53996-2.png" alt="" style="width:84pt;height:24pt;">
<p><span class="font18" style="font-style:italic;">HH</span></p>
</div><br clear="all">
<div>
<p><span class="font2"><sub>-</sub></span></p><img src="https://jurnal.harianregional.com/media/53996-3.png" alt="" style="width:74pt;height:25pt;">
</div><br clear="all">
<div><img src="https://jurnal.harianregional.com/media/53996-4.png" alt="" style="width:47pt;height:22pt;">
</div><br clear="all">
<div>
<p><span class="font3">— </span><span class="font23" style="font-style:italic;font-variant:small-caps;">S</span><span class="font20" style="font-style:italic;font-variant:small-caps;">vv</span><span class="font6"> )</span><span class="font3">’)</span></p>
</div><br clear="all">
<div><img src="https://jurnal.harianregional.com/media/53996-5.png" alt="" style="width:71pt;height:95pt;">
</div><br clear="all">
<p><span class="font23">Where * denotes conjugation and &lt;&gt;&nbsp;denotes averaging.</span></p>
<p><span class="font23">Thescattering power double-bounce </span><span class="font23" style="font-style:italic;">(P<sub>d</sub></span><span class="font23">), based on the coherency matrix, is defined as:</span></p>
<p><a href="#bookmark9"><span class="font23" style="font-style:italic;">P</span><span class="font19" style="font-style:italic;">d</span><span class="font25"> = </span><span class="font23" style="font-style:italic;">T</span><span class="font23"><sub>1</sub> </span><span class="font25">- </span><span class="font23" style="font-style:italic;">T</span><span class="font28"> (</span><span class="font23">1</span><span class="font25">+</span><span class="font16">∣</span><span class="font25" style="font-style:italic;">M</span><span class="font19">2</span><span class="font28">)</span></a></p>
<p><a href="#bookmark10"><span class="font22" style="font-style:italic;">P</span><span class="font18" style="font-style:italic;">d</span><span class="font24"> = </span><span class="font23">K </span><span class="font22" style="font-style:italic;">S</span><span class="font18" style="font-style:italic;">HH</span><span class="font24"> — </span><span class="font23" style="font-style:italic;font-variant:small-caps;">S</span><span class="font19" style="font-style:italic;font-variant:small-caps;">vv</span><span class="font24"> Q — 2(</span><span class="font15">∣</span><span class="font22" style="font-style:italic;">S</span><span class="font18" style="font-style:italic;">HV</span><span class="font24"> f) </span><span class="font9">(</span><span class="font22">1 </span><span class="font24">+ </span><span class="font24" style="font-style:italic;">M</span><span class="font9"><sup>2</sup> )</span></a></p>
<p><span class="font23">Scattering power volume </span><span class="font23" style="font-style:italic;">(P<sub>v</sub></span><span class="font23">) is defined as:</span></p>
<p><a href="#bookmark11"><span class="font23" style="font-style:italic;">P</span><span class="font18" style="font-style:italic;">v</span><span class="font4"> = </span><span class="font23" style="font-style:italic;">4T</span><span class="font18" style="font-style:italic;">33</span><span class="font4"> -</span><span class="font23">4</span><span class="font14">∣</span><span class="font23">⅞</span><span class="font14">∣</span><span class="font23">(6)</span></a></p>
<p><a href="#bookmark12"><span class="font23" style="font-style:italic;">P</span><span class="font19" style="font-style:italic;">v</span><span class="font23"> = 8(</span><span class="font14">∣</span><span class="font23" style="font-style:italic;">S</span><span class="font19" style="font-style:italic;">HV</span><span class="font14">∣</span><span class="font23"><sup>2</sup>)-4</span><span class="font14">∣</span><span class="font23" style="font-style:italic;">Im{S</span><span class="font19" style="font-style:italic;">H</span><span class="font23"> (</span><span class="font24" style="font-style:italic;font-variant:small-caps;">S</span><span class="font21" style="font-style:italic;font-variant:small-caps;">hh</span><span class="font25" style="font-style:italic;"> -</span><span class="font23" style="font-style:italic;">Sw</span><span class="font23">))</span><span class="font14">∣</span><span class="font23">(7)</span></a></p>
<p><span class="font23">Scattering power surface (P</span><span class="font20"><sub>s</sub></span><span class="font23">) is defined as:</span></p>
<p><a href="#bookmark13"><span class="font23" style="font-style:italic;">P</span><span class="font19" style="font-style:italic;">s</span><span class="font25"> = </span><span class="font23" style="font-style:italic;">T</span><span class="font23"><sub>1</sub> </span><span class="font25">- </span><span class="font23" style="font-style:italic;">2T„</span><span class="font25"> + </span><span class="font23">2 </span><span class="font17">∣</span><span class="font28">ζ</span><span class="font17">∣</span><span class="font28"> (</span><span class="font23">1 </span><span class="font25">+ </span><span class="font16">∣</span><span class="font25" style="font-style:italic;">β</span><span class="font28"><sup>2</sup>)</span></a></p>
<p><a href="#bookmark14"><span class="font22" style="font-style:italic;">P</span><span class="font18" style="font-style:italic;">s</span><span class="font24"> = &nbsp;&nbsp;</span><span class="font22" style="font-style:italic;">S</span><span class="font18" style="font-style:italic;">HH</span><span class="font24"> + </span><span class="font18" style="font-style:italic;">Sw</span><span class="font24"> Γ) - </span><span class="font22">4(</span><span class="font13">∣</span><span class="font22" style="font-style:italic;">S</span><span class="font18" style="font-style:italic;">HV</span><span class="font24"> i) + </span><span class="font22">2</span><span class="font13">∣</span><span class="font22" style="font-style:italic;">Im(S</span><span class="font18" style="font-style:italic;">Hv</span><span class="font5"> ( </span><span class="font23" style="font-style:italic;font-variant:small-caps;">S</span><span class="font19" style="font-style:italic;font-variant:small-caps;">hh</span><span class="font24"> - </span><span class="font23" style="font-style:italic;font-variant:small-caps;">S</span><span class="font19" style="font-style:italic;font-variant:small-caps;">vv</span><span class="font24"> ))|</span><span class="font9">(</span><span class="font22">1 + </span><span class="font13">∣</span><span class="font24" style="font-style:italic;">β</span><span class="font24"> 2 </span><span class="font9">)</span></a></p>
<p><span class="font23">And, scattering power helix </span><span class="font23" style="font-style:italic;">(P<sub>h</sub></span><span class="font23">) is defined as:</span></p>
<p><a href="#bookmark15"><span class="font23" style="font-style:italic;">P</span><span class="font4"> = </span><span class="font23">2 Kl(10)</span></a></p>
<p><a href="#bookmark16"><span class="font23" style="font-style:italic;">P,</span><span class="font4"> = </span><span class="font23">2</span><span class="font14">∣</span><span class="font23" style="font-style:italic;">Im{S’</span><span class="font18" style="font-style:italic;">Hv</span><span class="font23"> (</span><span class="font23" style="font-style:italic;font-variant:small-caps;">S</span><span class="font20" style="font-style:italic;font-variant:small-caps;">hh</span><span class="font4"> -</span><span class="font23" style="font-style:italic;font-variant:small-caps;">S</span><span class="font20" style="font-style:italic;font-variant:small-caps;">vv</span><span class="font23">))</span><span class="font14">∣</span><span class="font23">(11)</span></a></p>
<div>
<p><span class="font23">Where: </span><span class="font3" style="font-style:italic;">α</span><span class="font3"> =</span></p>
</div><br clear="all">
<div>
<h3><a name="bookmark17"></a><span class="font6" style="text-decoration:underline;"><a name="bookmark18"></a>( </span><span class="font23" style="font-style:italic;text-decoration:underline;">S</span><span class="font18" style="font-style:italic;text-decoration:underline;">HH</span><span class="font10" style="text-decoration:underline;"> <sup>+</sup> </span><span class="font23" style="font-style:italic;text-decoration:underline;">S</span><span class="font18" style="font-style:italic;text-decoration:underline;">VV</span><span class="font6" style="text-decoration:underline;"> ) </span><span class="font6">(</span><span class="font23" style="font-style:italic;">S</span><span class="font18" style="font-style:italic;">HH</span><span class="font3"> - </span><span class="font23" style="font-style:italic;">S</span><span class="font18" style="font-style:italic;">VV</span><span class="font6"> )</span></h3>
</div><br clear="all">
<div>
<p><span class="font23">and </span><span class="font3" style="font-style:italic;">β</span><span class="font3"> =</span></p>
</div><br clear="all">
<div>
<h3><a name="bookmark19"></a><span class="font6" style="text-decoration:underline;"><a name="bookmark20"></a>( </span><span class="font23" style="font-style:italic;text-decoration:underline;">R</span><span class="font18" style="font-style:italic;text-decoration:underline;">h</span><span class="font3" style="text-decoration:underline;"> - </span><span class="font23" style="font-style:italic;text-decoration:underline;">R</span><span class="font18" style="font-style:italic;text-decoration:underline;">v</span><span class="font6" style="text-decoration:underline;"> ) </span><span class="font6">(</span><span class="font23" style="font-style:italic;">R</span><span class="font18" style="font-style:italic;">h</span><span class="font3">+</span><span class="font23" style="font-style:italic;">R</span><span class="font6">)</span></h3>
</div><br clear="all">
<p><span class="font22" style="font-style:italic;">RR</span></p>
<p><span class="font23">The Bragg coefficient </span><span class="font23" style="font-style:italic;"><sup>h</sup></span><span class="font23"> (horizontally) and </span><span class="font23" style="font-style:italic;"><sup>v</sup></span><span class="font23"> (vertically)polarized wave, defined as:</span></p>
<div>
<p><span class="font23" style="font-style:italic;">R</span><span class="font18" style="font-style:italic;">h</span></p>
</div><br clear="all">
<div>
<h2><a name="bookmark21"></a><span class="font23"><a name="bookmark22"></a>cos </span><span class="font24" style="font-style:italic;">θ - ^ε<sub>r</sub></span><span class="font24"> - </span><span class="font23">sin</span><span class="font22"><sup>2</sup> </span><span class="font24" style="font-style:italic;">θ</span></h2>
</div><br clear="all">
<div>
<h2><a name="bookmark23"></a><span class="font23" style="font-style:italic;"><a name="bookmark24"></a>cos</span><span class="font24" style="font-style:italic;">θ</span><span class="font24"> + </span><span class="font24" style="font-style:italic;">Jε<sub>r</sub></span><span class="font24"> - </span><span class="font23">sin</span><span class="font22"><sup>2</sup> </span><span class="font24" style="font-style:italic;">θ</span></h2>
</div><br clear="all">
<div>
<p><span class="font23">(12)</span></p>
</div><br clear="all">
<h2><a name="bookmark25"></a><span class="font6" style="font-style:italic;"><a name="bookmark26"></a>(</span><span class="font24" style="font-style:italic;">ε</span><span class="font23" style="font-style:italic;"><sub>r</sub> </span><span class="font24" style="font-style:italic;">-</span><span class="font23"> 1</span><span class="font6">)</span><span class="font8">{</span><span class="font23">sin</span><span class="font22"><sup>2</sup> </span><span class="font24" style="font-style:italic;">θ</span><span class="font24"> - </span><span class="font24" style="font-style:italic;">ε</span><span class="font23" style="font-style:italic;"><sub>r</sub></span><span class="font7"> (</span><span class="font23">1 </span><span class="font24">+ </span><span class="font23">sin</span><span class="font22"><sup>2</sup> </span><span class="font24" style="font-style:italic;">θ</span><span class="font7">)</span><span class="font8">} </span><span class="font11" style="font-style:italic;">(</span><span class="font24" style="font-style:italic;">ε</span><span class="font23" style="font-style:italic;"><sub>r</sub></span><span class="font23"> cos </span><span class="font24" style="font-style:italic;">θ</span><span class="font24"> + </span><span class="font24" style="font-style:italic;">^ε</span><span class="font23" style="font-style:italic;"><sub>r</sub></span><span class="font24"> - </span><span class="font23">sin</span><span class="font22"><sup>2</sup> </span><span class="font24" style="font-style:italic;">θ</span><span class="font28"> )</span></h2>
<div>
<p><span class="font23">(13)</span></p>
</div><br clear="all">
<p><span class="font23">where</span><span class="font3" style="font-style:italic;"><sup>θ</sup></span><span class="font23"> is the incidence angle and </span><span class="font3" style="font-style:italic;"><sup>ε</sup></span><span class="font18" style="font-style:italic;">r</span><span class="font23"> is the constant of the relative dielectric of the surface.In Figure 2.8 is shown the characteristic of the four-component of Yamaguchi’s decomposition. Table 2 shown scattering mechanism and its correspondence to typical object.</span></p>
<div><img src="https://jurnal.harianregional.com/media/53996-6.jpg" alt="" style="width:227pt;height:202pt;">
<p><span class="font23">Figure 2.</span></p>
<p><span class="font23">The scattering power of four component decomposition( </span><span class="font22" style="font-style:italic;">Ps</span><span class="font23"> , </span><span class="font22" style="font-style:italic;">Pd</span><span class="font23"> , </span><span class="font22" style="font-style:italic;">Pv</span><span class="font23"> , and </span><span class="font22" style="font-style:italic;">Ph</span><span class="font23"> ) (Yamaguchi, 2012;Saepuloh and Bakker, 2017)</span></p>
</div><br clear="all">
<p><span class="font23">T</span><span class="font23" style="text-decoration:underline;">able 2. Scattering mechanism and its correspondence to typical object (Yamaguchi, 2012).</span></p>
<table border="1">
<tr><td style="vertical-align:top;">
<p><span class="font23" style="font-weight:bold;">Scattering</span></p>
<p><span class="font21" style="font-weight:bold;"><sub>Type</sub> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="font23" style="font-weight:bold;">Typical objects</span></p></td><td style="vertical-align:middle;">
<p><span class="font23" style="font-weight:bold;">Other candidates</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font27"><sup>Double-</sup> &nbsp;&nbsp;&nbsp;</span><span class="font23">Objects made by human</span></p>
<p><span class="font23">bounce</span></p></td><td style="vertical-align:middle;">
<p><span class="font23">Isolated trees, vegetation in row</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font23">Volume &nbsp;&nbsp;&nbsp;Vegetations</span></p></td><td style="vertical-align:middle;">
<p><span class="font23">Edges that produce the cross polarized HV component</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font23">Bare soil surface, crop field, Surface</span></p>
<p><span class="font23">snow, volcano ashes</span></p></td><td style="vertical-align:middle;">
<p><span class="font23">Sea surface, water body</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font23">Helix &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Circular polarization state</span></p></td><td style="vertical-align:bottom;">
<p><span class="font23">No-specific condition</span></p></td></tr>
</table>
<div><img src="https://jurnal.harianregional.com/media/53996-7.jpg" alt="" style="width:317pt;height:457pt;">
<p><span class="font23">Figure 3.</span></p>
<p><span class="font23">Flowchart of Yamaguchi’s decomposition (Yamaguchi et al., 2006).</span></p>
</div><br clear="all">
<ul style="list-style:none;"><li>
<h4><a name="bookmark27"></a><span class="font23" style="font-weight:bold;"><a name="bookmark28"></a>2.3 &nbsp;&nbsp;&nbsp;Architecture of SegNet</span></h4></li></ul>
<p><span class="font23">The Deep convolutional neural network for semantic segmentation as known SegNet. Built from the Encoder-Decoder network which is the architecture implementation from VGG16 network with 13 convolutional layers. The encoder network function is to trainable segmentation engine, while decoder function for classification the pixel-wise(Badrinarayanan et al., 2017). In Figure 4. shown the architecture of SegNet.The main idea of SegNet is using max-pooling, it function is to keep greater value in the image and the function of up-sampling is up-samples</span></p>
<p><span class="font23">image to higher scale(Chollet, 2018). In Figure 5 shown the example of max-pooling (a) and up-sampling (b). In Figure 6 shown flowchart to making datasets, (1) data from Yamaguchi’s decomposition as input; (2) generating composite of color from </span><span class="font23" style="font-style:italic;"><sup>Pd</sup></span><span class="font23"> as red, </span><span class="font23" style="font-style:italic;"><sup>Pv</sup></span><span class="font23"> as green, and </span><span class="font23" style="font-style:italic;"><sup>Pv</sup></span><span class="font23"> as blue, </span><span class="font23" style="font-style:italic;"><sup>Ph</sup></span><span class="font23"> in this case is ignored; (3) color composite image; (4) cutting image with size 360x480 pixel for datasets, datasets divided into 60% (162) training, 20%(54) test, and 20% (54) validation datasets from total (270) of datasets; (5) Labelling datasets.</span></p>
<div><img src="https://jurnal.harianregional.com/media/53996-8.jpg" alt="" style="width:436pt;height:123pt;">
<p><span class="font23">Figure 4.</span></p>
<p><span class="font23">The illustration of the SegNet architecture. These is only convolutional, there are no fully connected layers. A decoder up-samples its input using the transferred pool indices from its encoder to produce a sparse feature map(s). It then performs convolution with a trainable filter bank to densify the feature map. The final decoder output feature maps are fed to a soft-max classifier for pixel-wise classification (Badrinarayanan et al., 2017).</span></p>
</div><br clear="all">
<div><img src="https://jurnal.harianregional.com/media/53996-9.jpg" alt="" style="width:201pt;height:121pt;">
<p><span class="font23">(a)</span></p>
<p><span class="font23">Figure 5.</span></p>
<p><span class="font23">(a) Max-pooling: down-sampling with (2x2) filter;</span></p>
<p><span class="font23">(b) Up-sampling with (2x2) filter(Chollet, 2018).</span></p>
</div><br clear="all">
<div><img src="https://jurnal.harianregional.com/media/53996-10.jpg" alt="" style="width:199pt;height:120pt;">
<p><span class="font23">(b)</span></p>
</div><br clear="all">
<div><img src="https://jurnal.harianregional.com/media/53996-11.jpg" alt="" style="width:258pt;height:469pt;">
<p><span class="font23" style="font-weight:bold;">Figure 6.</span></p>
<p><span class="font23">Flowchart to making datasets.</span></p>
</div><br clear="all">
<ul style="list-style:none;"><li>
<p><span class="font23" style="font-weight:bold;">3. &nbsp;&nbsp;&nbsp;RESULT AND DISCUSSION</span></p>
<ul style="list-style:none;">
<li>
<h4><a name="bookmark29"></a><span class="font23" style="font-weight:bold;"><a name="bookmark30"></a>3.1 &nbsp;&nbsp;&nbsp;Experiments</span></h4></li></ul></li></ul>
<p><span class="font23">The first will explain the result of training data proses, in this case training data process with 100 epochs, the result shown in graph in Figure 7. The graph showing</span></p>
<p><span class="font23">overfitting, this because little training data is available (Chollet, 2018). Result of the SegNet implemented in Fully Pol-SAR data shown in Figure 8. In the process to labeling dataset is quite difficult, because of some color is same, for example bare-soil, rice field (before planting or after harvest), and landslide occur.</span></p>
<div><img src="https://jurnal.harianregional.com/media/53996-12.jpg" alt="" style="width:429pt;height:160pt;">
<p><span class="font23" style="font-weight:bold;">(a) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(b)</span></p>
<p><span class="font23">Figure 7.</span></p>
<p><span class="font23">Result of training process. (a) Model accuracy and (b) model loss.</span></p>
</div><br clear="all">
<p><span class="font22" style="font-weight:bold;">Validation Image (SAR data with color composite)</span></p>
<div><img src="https://jurnal.harianregional.com/media/53996-13.jpg" alt="" style="width:273pt;height:94pt;">
<p><span class="font22" style="font-weight:bold;">Estimation Image</span></p>
</div><br clear="all">
<div><img src="https://jurnal.harianregional.com/media/53996-14.jpg" alt="" style="width:126pt;height:94pt;">
</div><br clear="all">
<div><img src="https://jurnal.harianregional.com/media/53996-15.jpg" alt="" style="width:274pt;height:95pt;">
<p><span class="font23">Figure 8.</span></p>
<p><span class="font23">Estimation result of SegNet architecture in this research.</span></p>
</div><br clear="all">
<div><img src="https://jurnal.harianregional.com/media/53996-16.jpg" alt="" style="width:127pt;height:95pt;">
</div><br clear="all">
<div>
<p><span class="font23" style="font-weight:bold;">Information:</span></p>
<p><span class="font23">Landslide = [255,0,0]</span></p>
<p><span class="font23">Bareland = [0,128,130]</span></p>
<p><span class="font23">Forest = [0,255,6]</span></p>
<p><span class="font23">Ricefield = [0,9,255]</span></p><img src="https://jurnal.harianregional.com/media/53996-17.jpg" alt="" style="width:29pt;height:64pt;">
</div><br clear="all">
<div>
<p><span class="font23">Rural_area = [255,192,128] Water_body = [0,255,255] Farming_area = [255,255,0]</span></p>
<p><span class="font23">Unlabelled = [0,0,0]</span></p><img src="https://jurnal.harianregional.com/media/53996-18.jpg" alt="" style="width:29pt;height:64pt;">
</div><br clear="all">
<ul style="list-style:none;"><li>
<h4><a name="bookmark31"></a><span class="font23" style="font-weight:bold;"><a name="bookmark32"></a>3.2 &nbsp;&nbsp;&nbsp;Evaluations</span></h4></li></ul>
<p><span class="font23">The evaluation of result from the architecture implementation, using IoU. The IoU score is used as a standard for measuring performance on segmentation problems in an object.IoU measurement provides information on the similarity between the estimated area and the ground-truth for the object in the</span></p>
<p><span class="font23">measured images(Rahman and Wang, 2016; Rezatofighi et al., 2019), the equation as bellow:</span></p>
<p><span class="font23" style="font-style:italic;">A</span><span class="font3"> ∩ </span><span class="font23" style="font-style:italic;">B I</span></p>
<h3><a name="bookmark33"></a><span class="font23" style="font-style:italic;"><a name="bookmark34"></a>IoU</span><span class="font3"> = &nbsp;&nbsp;&nbsp;&nbsp;= —</span></h3>
<p><span class="font23" style="font-style:italic;">A </span><span class="font15" style="font-style:italic;">∪</span><span class="font3" style="font-style:italic;"> </span><span class="font23" style="font-style:italic;">B U</span></p>
<div>
<p><span class="font23">(14)</span></p>
</div><br clear="all">
<p><span class="font23">where I and U denote the Intersection and Union respectively.</span></p>
<p><span class="font23">In Table 3 shows the percentage of IoU from Figure 9, the result is quite god, it depends on the quality of ground truth and the number of datasets. Ground truth is the label of data, in the process of labeling it quite difficult because of some color have same characteristic with another color, as for</span></p>
<p><span class="font23">example color of landslide with bare soil and water-body. But, perform of SegNet is quite good, faster, and efficiency. Quite good because from original dataset perform a good result (Badrinarayanan et al., 2017), faster and efficient because in this research using PC not high hardware configuration.</span></p>
<div>
<p><span class="font18" style="font-weight:bold;">Real</span></p>
<p><span class="font18" style="font-weight:bold;">Situation</span></p>
<p><span class="font18" style="font-weight:bold;">Ground truth</span></p>
<p><span class="font18" style="font-weight:bold;">(Labeling the real situation)</span></p>
<p><span class="font18" style="font-weight:bold;">SAR data</span></p>
<p><span class="font18" style="font-weight:bold;">(Color composite)</span></p>
<p><span class="font18" style="font-weight:bold;">Estimation</span></p>
<p><span class="font18" style="font-weight:bold;">(Results)</span></p><img src="https://jurnal.harianregional.com/media/53996-19.jpg" alt="" style="width:313pt;height:321pt;">
<p><span class="font21" style="font-weight:bold;">(a)</span></p>
<p><span class="font21" style="font-weight:bold;">(b)</span></p>
<p><span class="font21" style="font-weight:bold;">(c)</span></p>
<p><span class="font23">Figure 9.</span></p>
<p><span class="font23">Quality assessment of SegNet.</span></p>
</div><br clear="all">
<p><span class="font23">Table 3</span><span class="font23" style="font-weight:bold;">. </span><span class="font23">IoU from Ground truth and Estimations</span></p>
<table border="1">
<tr><td style="vertical-align:top;">
<p><span class="font23">Estimations (Results)</span></p></td><td style="vertical-align:top;">
<p><span class="font23">IoU</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font23">(a)</span></p></td><td style="vertical-align:bottom;">
<p><span class="font23">0.1483</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font23">(b)</span></p></td><td style="vertical-align:bottom;">
<p><span class="font23">0.0515</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font23">(c)</span></p></td><td style="vertical-align:top;">
<p><span class="font23">0.1388</span></p></td></tr>
</table>
<ul style="list-style:none;"><li>
<h4><a name="bookmark35"></a><span class="font23" style="font-weight:bold;"><a name="bookmark36"></a>4. &nbsp;&nbsp;&nbsp;CONCLUSION AND SUGGESTIONS</span></h4></li></ul>
<p><span class="font23">In this research, the performance of the SegNet shows, that it is fast and efficient in memory usage. However, the end-result is not good, this is because of quality of training set as well as smaller dataset. Overfitting is also a problem which may occurs when the training data is limited and less varied.</span></p>
<p><span class="font23">There are certain ways to the chances of overfitting. Some of them are- having a larger database, using dropout layer in the network architecture, use of ‘early-stopping’ function etc. The quality of dataset also needs to be taken care of as it directly influences the result. For this we can take help of experts and may be random site survey of some places. For further improvement, transfer learning can be considered to utilize the already trained model on the landslide problem, that will help to reduce the time of training.</span></p>
<h4><a name="bookmark37"></a><span class="font23" style="font-weight:bold;"><a name="bookmark38"></a>REFERENCES</span></h4>
<p><span class="font23">Badrinarayanan, V., Kendall, A., Cipolla, R., 2017. SegNet: A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation. IEEE Trans. Pattern Anal. Mach. Intell. 39, &nbsp;&nbsp;&nbsp;2481–2495.</span></p>
<p><a href="https://doi.org/10.1109/TPAMI.2016.264"><span class="font23">https://doi.org/10.1109/TPAMI.2016.264</span></a><span class="font23"> 4615</span></p>
<p><span class="font23">Cameron, W.L. and L.K. Leung. 1990. Feature motivated polarization scattering matrix &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;decomposition. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="font23" style="font-style:italic;">IEEE</span></p>
<p><span class="font23" style="font-style:italic;">International Conference on &nbsp;Radar</span><span class="font23">.</span></p>
<p><span class="font23">DOI: 10.1109/RADAR.1990.201088</span></p>
<p><span class="font23">Cloude, S. R. 1986. Group theory and polarization algebra. </span><span class="font23" style="font-style:italic;">OPTIK.</span><span class="font23"> 75(1), 26– 36.</span></p>
<p><span class="font23">Cloude, S. R. and Pottier, E. 1996. A review of target decomposition theorems in</span></p>
<p><span class="font23">radar.</span></p>
<p><span class="font23">Chollet, F., 2018. Deep Learning with python, Manning.</span></p>
<p><a href="https://doi.org/10.1017/CBO9781107415"><span class="font23">https://doi.org/10.1017/CBO9781107415</span></a><span class="font23"> 324.004</span></p>
<p><span class="font23">Freeman, A., and Durden, S. L. 1998. A three-component scattering model for polarimetric.</span></p>
<p><span class="font23">Garcia-Garcia, A., Orts-Escolano, S., Oprea, S., Villena-Martinez, V., Martinez-Gonzalez, P., Garcia-Rodriguez, J., 2018. A survey on deep learning techniques for image and video semantic segmentation. Appl. Soft Comput. J. 70, 41–65.</span></p>
<p><a href="https://doi.org/10.1016/j.asoc.2018.05.01"><span class="font23">https://doi.org/10.1016/j.asoc.2018.05.01</span></a><span class="font23"> 8</span></p>
<p><span class="font23">Huynen, J. R. 1970. Phenomenological theory of radar targets. Ph.D. </span><span class="font23" style="font-style:italic;">thesis</span><span class="font23">. University of Technology, Delft, The Netherlands.</span></p>
<p><span class="font23">Japan Association of Remote Sensing. 1996. Synthetic Aperture Radar. Available in URL: &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;http://wtlab.iis.u-</span></p>
<p><span class="font23">tokyo.ac.jp/wataru/lecture/rsgis/rsnote/cp 4/cp4-3.htm accessed April 1st, 2019</span></p>
<p><span class="font23">JAXA. 2019. ALOS-2 Project PALSAR-2. Available &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;in &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;URL:</span></p>
<p><a href="https://www.eorc.jaxa.jp/ALOS-2/en/about/palsar2.htm"><span class="font23">https://www.eorc.jaxa.jp/ALOS-2/en/about/palsar2.htm</span></a><span class="font23"> accessed April 1st, 2019</span></p>
<p><span class="font23">Krogager, E. 1990. New decomposition of the radar target scattering matrix. </span><span class="font23" style="font-style:italic;">Electronics Letters</span><span class="font23">. 26, 1525-1527.</span></p>
<p><span class="font23">Mathworks. 2018. Introducing Deep Learning with MATLAB. Available in URL: </span><a href="https://www.mathworks.com/campaigns/"><span class="font23">https://www.mathworks.com/campaigns/</span></a><span class="font23"> offers/deep-learning-with-matlab.html. accessed April 1st, 2019</span></p>
<p><span class="font23">Rahman, M.A., Wang, Y., 2016. Optimizing intersection-over-union in deep neural networks for image segmentation, in: Lecture Notes in Computer Science (Including Subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics). pp. 234–244. </span><a href="https://doi.org/10.1007/978-3-319-50835-122"><span class="font23">https://doi.org/10.1007/978-3-319-50835-122</span></a></p>
<p><span class="font23">Rezatofighi, H., Tsoi, N., Gwak, J., Sadeghian, A., Reid, I., Savarese, S., 2019. Generalized Intersection over Union: A Metric and A Loss for Bounding Box Regression.</span></p>
<p><span class="font23">Saepuloh, A., Bakker, E., 2017. Identifying Successive Eruption of Guntur Volcanic Complex Using Magnetic Susceptibility and Polarimetric Synthetic Aperture Radar (PolSAR) Data. IOP Conf. Ser. Earth &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Environ. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Sci. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;71.</span></p>
<p><a href="https://doi.org/10.1088/1755-1315/71/1/012004"><span class="font23">https://doi.org/10.1088/1755-1315/71/1/012004</span></a></p>
<p><span class="font23">Shibayama, T., Yamaguchi, Y. and Yamada, H. 2015. Polarimetric scattering properties of landslides in forested areas and the dependence on the local incidence angle. </span><span class="font23" style="font-style:italic;">Remote Sensing</span><span class="font23">. 7(11), pp. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;15424–15442. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;DOI:</span></p>
<p><span class="font23">10.3390/rs71115424.</span></p>
<p><span class="font23">Touzi, R. and Charbonneau, F. 2002. Characterization of symmetric scattering using polarimetric SARs. </span><span class="font23" style="font-style:italic;">Proceedings IGARSS.</span><span class="font23"> 1. 414–416</span></p>
<p><span class="font23">Watanabe, T. and Wolf, D. 2019. Instance Segmentation as Image Segmentation Annotation. Available in URL:</span></p>
<p><a href="http://arxiv.org/abs/1902.05498"><span class="font23">http://arxiv.org/abs/1902.05498</span></a><span class="font23">.</span></p>
<p><span class="font23">accessed April 1st, 2019</span></p>
<p><span class="font23">Yamagishi, H., Yamazaki, F., &nbsp;&nbsp;2018.</span></p>
<p><span class="font23">Landslides by the 2018 Hokkaido Iburi-Tobu Earthquake on September 6. Landslides &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;15, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2521–2524.</span></p>
<p><a href="https://doi.org/10.1007/s10346-018-1092-z"><span class="font23">https://doi.org/10.1007/s10346-018-1092-z</span></a></p>
<p><span class="font23">Yamaguchi, Y., 2012. Disaster monitoring by fully polarimetric SAR data acquired with ALOS-PALSAR. Proc. IEEE 100, 2851–2860.</span></p>
<p><a href="https://doi.org/10.1109/JPROC.2012.219"><span class="font23">https://doi.org/10.1109/JPROC.2012.219</span></a><span class="font23"> 5469</span></p>
<p><span class="font23">Yamaguchi, Y., Yajima, Y., Yamada, H., 2006. A four-component decomposition of POLSAR images based on the coherency matrix. IEEE Geosci. Remote Sens. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Lett. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;292–296.</span></p>
<p><a href="https://doi.org/10.1109/LGRS.2006.8699"><span class="font23">https://doi.org/10.1109/LGRS.2006.8699</span></a><span class="font23"> 86</span></p>
<p><span class="font23">Yamaguchi, Y., Yajima, Y., Yamada, H. 2005. Four-component scattering model for polarimetric SAR image decomposition. </span><span class="font23" style="font-style:italic;">IEEE Trans. Geosci. Remote &nbsp;&nbsp;&nbsp;Sens</span><span class="font23">. &nbsp;&nbsp;&nbsp;43. &nbsp;&nbsp;&nbsp;1699–1706.</span></p>
<p><span class="font20">226</span></p>