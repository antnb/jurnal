---
layout: full_article
title: "Helpdesk Ticket Classification for Technician Assignment Routes Using BiLSTM"
author: "Putu Alan Arismandika, Kadek Yota Ernanda Aryanto, I Made Gede Sunarya"
categories: merpati
canonical_url: https://jurnal.harianregional.com/merpati/full-100221 
citation_abstract_html_url: "https://jurnal.harianregional.com/merpati/id-100221"
citation_pdf_url: "https://jurnal.harianregional.com/merpati/full-100221"  
comments: true
---

<p><span class="font3">JURNAL ILMIAH MERPATI VOL. 11, NO. 1 APRIL 2023</span></p>
<p><span class="font3">p-ISSN: 2252-3006</span></p>
<p><span class="font3">e-ISSN: 2685-2411</span></p><a name="caption1"></a>
<h1><a name="bookmark0"></a><span class="font5" style="font-weight:bold;"><a name="bookmark1"></a>Helpdesk Ticket Classification for Technician Assignment Routes Using BiLSTM</span></h1>
<p><span class="font3" style="font-weight:bold;">Putu Alan Arismandika<sup>a1</sup>, Kadek Yota Ernanda Aryanto<sup>a2</sup>, I Made Gede Sunarya<sup>a3 </sup></span><span class="font3"><sup>a</sup>Computer Science Department, Graduate Program, Ganesha University of Education, Bali, Indonesia</span></p>
<p><span class="font3">e-mail: </span><a href="mailto:1putu.alan.arismandika@gmail.com"><span class="font3" style="text-decoration:underline;"><sup>1</sup>putu.alan.arismandika@gmail.com</span></a><span class="font3">, </span><a href="mailto:2yota.ernanda@undiksha.ac.id"><span class="font3" style="text-decoration:underline;"><sup>2</sup>yota.ernanda@undiksha.ac.id</span></a><span class="font3">, </span><a href="mailto:3sunarya@undiksha.ac.id"><span class="font3" style="text-decoration:underline;"><sup>3</sup>sunarya@undiksha.ac.id</span></a></p>
<p><span class="font3" style="font-weight:bold;font-style:italic;">Abstrak</span></p>
<p><span class="font3" style="font-style:italic;">Sebagian besar bisnis proses perusahaan diakomodir oleh aplikasi. Seringkali aplikasi pada perusahaan mengalami masalah akibat faktor internal maupun eksternal. Masalah aplikasi tersebut dilaporkan melalui media helpdesk. Laporan masalah yang dilaporkan melalui helpdesk tidak langsung masuk kepada teknisi untuk penyelesaiannya melainkan masuk ke operator dan dieskalasi ke teknisi untuk diselesaikan. Proses tersebut berpengaruh pada efisiensi waktu penyelesaian masalah. Penelitian ini mengusulkan penggunaan klasifikasi teks dengan deep learning untuk menyelesaikan pekerjaan operator. Metode yang diusulkan dalam penelitian ini adalah metode BiLSTM. Total data yang digunakan dalam penelitian ini adalah sebanyak 160.000 data laporan masalah helpdesk dengan membagi data sebanyak 128.000 data resolved sebagai data training dan sebanyak 32.000 data on-progress sebagai data testing. Penelitian dilakukan menggunakan 13 label untuk proses rute penugasan teknisi. Pengujian hasil penelitian ini menggunakan confusion matrix yang mendapatkan nilai accuracy sebesar 91.18%, precision 95.05%, dan recall 93.28%.</span></p>
<p><span class="font3" style="font-weight:bold;font-style:italic;">Kata kunci: </span><span class="font3" style="font-style:italic;">Klasifikasi Teks, Deep Learning, BiLSTM, Helpdesk</span></p>
<p><span class="font3" style="font-weight:bold;font-style:italic;">Abstract</span></p>
<p><span class="font3" style="font-style:italic;">Most of the company's business processes are supported by applications. However, these applications often experience problems due to various internal and external factors. When users encounter problems, they submit requests for help to the helpdesk system. Unfortunately, these requests do not go directly to the technicians but instead are first sent to an operator who must then escalate them to a technician. This process can delay problem-solving, reducing efficiency. To address this issue, this study suggests using text classification with deep learning to streamline the operator's work. Specifically, the proposed method uses BiLSTM. The study used a total of 160,000 helpdesk request data, dividing it into 128,000 resolved data for training and 32,000 on-progress data for testing. Thirteen labels were used to represent the route process. This study uses a confusion matrix to measure its performance. The results showed an accuracy of 91.18%, precision of 95.05%, and recall of 93.28%.</span></p>
<p><span class="font3" style="font-weight:bold;font-style:italic;">Keywords: </span><span class="font3" style="font-style:italic;">Text Classification, Deep Learning, BiLSTM, Helpdesk</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark2"></a><span class="font3" style="font-weight:bold;"><a name="bookmark3"></a>1. &nbsp;&nbsp;&nbsp;Introduction</span></h2></li></ul>
<p><span class="font3">The helpdesk system is a system that assists companies in developing and improving their service products. In public service companies, the helpdesk system is beneficial in enhancing services to its customers. Services that use the application often experience problems. Users request to solve the problem of the application by submitting it to the helpdesk system. The requests are then managed by several operators to be translated and grouped based on the problem category. The requests or the ticket problem category will be resolved by a technician who has the authority to solve the problem. The operator carries out the escalation process to the technician after translating and grouping the problems from the reports on the user services system. A large number of incoming problem reports makes the operator's workload high so that problems are often resolved longer than they should. In addition, operators also carry out escalation work manually by reading the problems that have been</span></p>
<p><span class="font3">reported one by one. Apart from requiring a long completion time, costs are also high due to having to recruit workers for more operator assignments.</span></p>
<p><span class="font3">The manual process for escalating requests from operators to technicians can adopt a text classification process. This process can be done with a deep learning approach. The incoming text is first processed and then classified based on technician class. The prediction function on text classification will recognize the class as the escalation destination to a technician who has the authority in solving the problem. The data used as training data in this study is BPJS Ketenagakerjaan helpdesk ticket report data for the period 2019 to May 2022. The test and prediction data used are data after June 2022 to December 2022. This data certainly has repeated text or frequently asked texts that can be used as a reference in the escalation process. The whole text classification process in the user services system requires a method used to classify text with high accuracy. In several studies of text classification with binary class and multiclass, the ability of RNN to have high accuracy in applying text classification compared to other classification methods such as CNN and other deep learning methods. For example, in the classification of sentiment analysis, the RNN method produces higher accuracy than CNN </span><span class="font8">[1]. </span><span class="font3">In several studies, many modifications of text classification have been carried out. In RNN there are several development methods including LSTM, Bi-LSTM, and GRU. In recent study, text classification is often applied to this development method to analyze comments about hotel visitors </span><span class="font8">[2]</span><span class="font3">.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark4"></a><span class="font3" style="font-weight:bold;"><a name="bookmark5"></a>2. &nbsp;&nbsp;&nbsp;&nbsp;Study Method</span></h2></li></ul>
<p><span class="font3">The study method for helpdesk ticket classification using BiLSTM consists of 4 stages, namely study design, data collection, data processing, and model performance measurement.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark6"></a><span class="font3" style="font-weight:bold;"><a name="bookmark7"></a>2.1 &nbsp;&nbsp;&nbsp;Study Design</span></h2></li></ul>
<p><span class="font3">By the explanation in the introduction, the study design is made to assist in determining study planning, problem boundaries, and study can be completed according to schedule</span><span class="font3" style="font-weight:bold;">.</span><span class="font3">The main objective of this study is to accommodate the operator's work as a route manager for helpdesk ticket reports to technicians with Bi-LSTM. In addition, this study also made predictions and tested the accuracy of BiLSTM. The conceptual framework for study flow outlines is the process of making the BiLSTM model based on training data as a reference for classification, input data testing up to the results of classification as a guideline for appointment or assignment of technicians. There are 13 labels used as a reference for the classification process, namely Data Pendukung, Executive Summary, Informasi Profile Kepesertaan, Kepesertaan Bukan Penerima Upah, Kepesertaan Jasa Konstruksi, Kepesertaan Penerima Upah, Keuangan, Network (Jaringan), Pelayanan, Pengawasan dan Pemeriksaan, Permintaan Antar Kantor (Wilayah), User dan Role, dan e-Channel. The conceptual framework is shown in Figure 1.</span></p><img src="https://jurnal.harianregional.com/media/100221-1.png" alt="" style="width:418pt;height:86pt;">
<p><span class="font3">Figure 1 Study design concept flow</span></p>
<p><span class="font3">Data training is data that has been completed by the operator to be used as a model in BiLSTM. Data testing is data that becomes input test. Furthermore, the testing data is classified based on the BiLSTM model which is formed from training data. The resulting label of the classification will be the technician's assignment.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark8"></a><span class="font3" style="font-weight:bold;"><a name="bookmark9"></a>2.2 &nbsp;&nbsp;&nbsp;Data Collection</span></h2></li></ul>
<p><span class="font3">The total amount of data used in this study is 160,000 records. The data is BPJS Ketenagakerjaan helpdesk data for the period January 2019 to May 2022 of 128,000, which</span></p>
<p><span class="font3">have been completed by operators, and data for the period June 2022 to December 2022 of 32,000 data, which have not been completed by operators. Where the training data is data for the period January 2019 to May 2022 as many as 128,000, and testing data is data for the period June 2022 to December 2022 of 32,000. In percentage, the training data consisting of 128,000 records represents 80% of the total data or 80% of 160,000, while the testing data consisting of 32,000 records represents 20% of 160,000.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark10"></a><span class="font3" style="font-weight:bold;"><a name="bookmark11"></a>2.3 &nbsp;&nbsp;&nbsp;Data Preprocessing</span></h2></li></ul>
<p><span class="font3">Stages data pre-processing is carried out to process the data before it is used in the application of the Bi-LSTM method. Processing carried out in text processing techniques adjusts the state of the ticket report data helpdesk such as the presence of unnecessary characters and formatting template ticket helpdesk to then be classified in Bi-LSTM. The text processing technique used is case folding, remove number, remove tab and new line, remove character, stopword, your token, and word embedding.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark12"></a><span class="font3" style="font-weight:bold;"><a name="bookmark13"></a>2.4 &nbsp;&nbsp;&nbsp;Model Performance</span></h2></li></ul>
<p><span class="font3">To validate the correctness of the helpdesk ticket technician assignment route, in this study, a manual validation was used that was filled in by the operator as a validator to determine the technician assignment route process resulting from the BiLSTM classification process is true or false. In this case, the operator is the person who is working to escalate the assignment of helpdesk ticket technician manually. The validation form result is calculated with a confusion matrix. The validation results from the operator on the results from BiLSTM are calculated by FN, FP, TP, and TN to obtain the accuracy of the BiLSTM model.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark14"></a><span class="font3" style="font-weight:bold;"><a name="bookmark15"></a>3. &nbsp;&nbsp;&nbsp;&nbsp;Literature Study</span><br><br><span class="font3" style="font-weight:bold;"><a name="bookmark16"></a>3.1 &nbsp;&nbsp;&nbsp;Helpdesk System</span></h2></li></ul>
<p><span class="font3">Management of information systems and applications problems within a company or institution must be resolved quickly and precisely. These various problems can be accommodated and handled by implementing a reporting system. This reporting system is usually called a helpdesk system. Helpdesk is a single point for interaction between users and technicians, in this case, is the field of application development [3]. Interaction in the helpdesk is usually in the form of text input on a web-based form or a mobile smartphone application. Requests that have been submitted by the user are usually called helpdesk report tickets. In the helpdesk system, the ticket will be checked by a centralized team and forwarded to the relevant team to be resolved. [4]. Checks that are carried out manually by a centralized team are then identified to find out the problems that have been requested by the user. [5].</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark17"></a><span class="font3" style="font-weight:bold;"><a name="bookmark18"></a>3.2 &nbsp;&nbsp;&nbsp;Deep Learning</span></h2></li></ul>
<p><span class="font3">In the last 10 years, studyers have been able to accomplish many different ideas in the application of machine learning. Deep learning is a sub-field of machine learning within machine learning. Machine learning is a part of AI and deep learning is a derivative of machine learning. Deep learning adopts the way the human brain works in processing data and making decisions. In various fields such as image processing, sound and video processing, language and text processing, and video games, deep learning has been applied, and until now the study carried out in this field has approached the human level [6]. The architectures and algorithms of deep learning are so large and varied that they have the potential to continue to be developed. In the last 20 years, there are 6 algorithms that have been developed to date. LSTM and CNN are the earliest developed methods that have high accuracy to solve various problems. CNN and RNN are part of Supervised Learning and SOM and Autoencoders are Unsupervised Learning category in deep learning. Each solution in the problem work, deep learning has its own best performance. For example, CNN is best in the field of image recognition and RNN for NLP [7].</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark19"></a><span class="font3" style="font-weight:bold;"><a name="bookmark20"></a>3.3 &nbsp;&nbsp;&nbsp;Bidirectional LSTM</span></h2></li></ul>
<p><span class="font3">The development of the LSTM method is BiLSTM. In contrast to LSTM, BiLSTM performs data training twice. In LSTM, the data training model is done once and only gets one information, namely information on the previous process. [8]. BiLSTM uses the previous information and the information after it and processes it bidirectionally. BiLSTM has two layers,</span></p>
<p><span class="font3">namely the Layer and Backward Layer. The forward layer serves to get the previous information and the backward layer gets the information afterwards. In some studies, BiLSTM is widely used to obtain representations on data that requires repeated information. For example, in the representation of comment text. Bi-LSTM can accommodate the shortcomings of LSTM in obtaining information while representing information from data.</span></p>
<p><span class="font3">The comparison between the BiLSTM method and other methods such as LSTM, CNN, and RNN in text classification has many advantages. BiLSTM has the ability to access both preceding and subsequent information, and is effective in encoding long-distance word dependencies [9][10]. This means that information from distant words in a sentence can be captured based on their dependencies. In the case of long texts, some words at the beginning or in the middle of a sentence can affect the understanding of words at the end of the sentence. Bi-LSTM allows the model to take into account these long-distance relationships better than other methods such as CNN, RNN, and LSTM. In this study, the user's helpdesk request structure has a long sentence pattern, so BiLSTM is expected to effectively extract information from the request sentence.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark21"></a><span class="font3" style="font-weight:bold;"><a name="bookmark22"></a>3.4 &nbsp;&nbsp;&nbsp;Relevant Studies</span></h2></li></ul>
<p><span class="font3">Study studies relevant to text classification have been carried out by several studyers. Study by J. Zheng entitled A Novel Computer-Aided Emotion Recognition of Text Method Based on WordEmbedding and Bi-LSTM in 2019 states that the text in this study is converted from word features with Word Embedding. The purpose of this study is to classify emotions through word or text-based data. The accuracy result of the detection is above 64.09% [11]. Study by Yunsick Sung, Sejun Jang, Young-Sik Jeong, Jong Hyuk (James J.) Park with the title Malware classification algorithm using advanced Word2vec-based Bi-LSTM for ground control stations in 2020 contains the purpose of utilizing data preprocessing using fasttext for features in the Bi-LSTM method. In the study, the accuracy result was 96.76% or 0.76% greater than the previous study [12]. Study related to the comparison of deep learning methods for text classification has been conducted by Congcong Wang, Paul Nulty, and David Lillis in 2020. The study is entitled A Comparative Study on Word Embeddings in Deep Learning for Text Classification. In this study, studyers compared the performance of CNN and Bi-LSTM in text classification with the preprocessing stage, namely word embedding. The results of the study found that Bi-LSTM produced very good performance in text classification to get the context of the text [13]. Study in the application of text classification in helpdesk systems has also been carried out by M. A. Prihandono, R. Harwahyu and R. F. Sari in 2020 with the study title Performance of Machine Learning Algorithms for IT Incident Management. The study produced the highest accuracy using the LSTM method, which was 98.86% compared to other deep learning methods [14]. Based on some relevant study, it can be understood that the RNN method with its development can be used in problems related to multiclass text classification-based predictions. In the study that has been mentioned, it produces high accuracy results for text classification. In addition, the helpdesk system also produces text classification with good results in the LSTM method. Due to some conclusions from the bibliography and previous study which states that the accuracy of BiLSTM is better than LSTM. Therefore, in this study, it is expected that BiLSTM can produce greater accuracy for technician assignment routes in helpdesk reports than previous study.</span></p>
<p><span class="font3">All relevant previous studies results show that the performance of BiLSTM is better than other methods such as LSTM, CNN, and RNN in text classification. Based on these findings, this study applies the BiLSTM method to improve the accuracy of the ticket escalation process from helpdesk to technicians.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark23"></a><span class="font3" style="font-weight:bold;"><a name="bookmark24"></a>4. &nbsp;&nbsp;&nbsp;&nbsp;Result and Discussion</span><br><br><span class="font3" style="font-weight:bold;"><a name="bookmark25"></a>4.1. &nbsp;&nbsp;Dataset Preprocessing</span></h2></li></ul>
<p><span class="font3">Data preprocessing serves to prepare raw data into data that is ready for processing and also as a basis for creating a BiLSTM model. The dataset will be converted into a sequence of numbers or numeric which aims to be a vector feature of each text and label in the classification process. The datasets that are processed are training data totaling 128,000 and testing data totaling 32,000. The dataset is processed using the same steps. The steps taken in this study are as follows. The first stage of data preprocessing is case folding. Case folding is the process of converting all uppercase letters into lowercase letters [15]. The purpose of this</span></p>
<p><span class="font3">process is so that computer machines can recognize each unique word and can categorize words that have the same meaning or in other words so that all data has the same form The function will convert all words and sentences from the helpdesk ticket report into lowercase letters.</span></p>
<p><span class="font3">The remove number process is a process to remove the numbers in the helpdesk report ticket. Numbers are removed to reduce unique characters in the tokenization process. The number characters are not needed in this study because they do not contain meaning for the escalation process or technician assignment. The number character removal process in Python is processed in the function below. The number character removal function will produce helpdesk report text data without numbers. The remove tab and new line process is a process that removes tabs and enters characters or removes excess spaces and new lines. This process functions so that the text can be easily converted into tokens and index words. The function removes excess spaces and new lines in the helpdesk report text that have been remove number before.</span></p>
<p><span class="font3">Remove Character is the process of removing characters other than letters and punctuation characters. The function removes all characters that are not needed in text processing, such as &quot;@&quot;, &quot;#&quot; and &quot;$&quot;. The stopwords process is the process of removing conjunctions in Indonesian such as &quot;di&quot;, &quot;ke&quot;, &quot;and&quot;, and so on. The process in Python programming is to use the help of the NLTK library which can call Indonesian stopwords. The process in the function above removes all conjunctions in the helpdesk ticket report text. The text processed in stopwords is the text that has been processed in the previous remove character. The snippet of text processing results is shown in Figure 2.</span></p>
<div><img src="https://jurnal.harianregional.com/media/100221-2.jpg" alt="" style="width:426pt;height:116pt;">
<p><span class="font3">Figure 2 Stopwords</span></p>
</div><br clear="all">
<p><span class="font3">Tokenization is the process of converting sentences that have been processed by stopwords into word tokens, and then the word tokens are sorted based on the frequency of words in the sentence [16]. The word with the highest frequency will be sorted into the earliest index and continue until the word with the smallest frequency. After getting the frequency index of the word, the words in the sentence of the helpdesk ticket report will be converted to the frequency index number.</span></p>
<p><span class="font0" style="font-weight:bold;">Stopwords</span></p>
<div>
<p><span class="font0" style="font-weight:bold;">Token</span></p>
</div><br clear="all">
<div>
<p><span class="font0">0</span></p>
</div><br clear="all">
<div>
<p><span class="font1">npp status rekon november</span></p>
</div><br clear="all">
<div>
<p><span class="font0">[3Z 58, 320, 337]</span></p>
</div><br clear="all">
<p><span class="font1">dear admin usmk mohon bantuannya terkait permasalahan data kepesertaan keterangan nik kpj no kpj nik kpj no kpj nama tk hendra nama tk hendra user ar password ketikaja permasalahan koreksi upahblth sd kpj sesuai upah tertukar kpj koreksi upah blth sd kpj ibr diteliti upah dimasukkan sesuai permintaan mohon bantuan pengecekan koreksi upah kesalahan ibmya perhatian bantuannya terima kasih best regards denis afriawanto penata madya ti kanwil sumbagut nik kpj</span></p>
<div>
<p><span class="font0">[4, 7, 11,1, Z 5, 3, 14, 74, 18, 21, 13, 38,13, 21,13, 38, 13, 16, 2Z 948, 16, 2Z 948, 5Z 79, 59, 3,41,19Z 13, 39, 90,1785,13,41, 90, 91,192,13, 236, 90, 714, 39, 1Z 1,19, 108, 41, 90, 216, 9, Z 8, 10,15, 6, 3019, 3319, 37, 36, 47, 257,1427, 21,13]</span></p>
</div><br clear="all">
<p><span class="font3">Figure 3 Word Indexing</span></p>
<p><span class="font3">The padding process is designed to homogenize the shape of the long sequence of vectors generated from word indexing. In this study, the base value of the number sequence is the longest word, which is 550 words. Words that are less than 550 will be added with 0 at the front of the number vector sequence. The token sequence is added with 0 at the front of the sequence so that it has the same size of 550 number sequences. The number sequence will be processed last into text vector features in word embedding so that it can be processed in the BiLSTM model.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark26"></a><span class="font3" style="font-weight:bold;"><a name="bookmark27"></a>4.2. &nbsp;&nbsp;&nbsp;Classification</span></h2></li></ul>
<p><span class="font3">The classification process is a process where the feature vectors from the preprocessing and embedding processes are classified to be predicted with the testing data. After the feature vector is obtained by the word embedding process, the feature vector is then calculated with the Bi-LSTM method. That is by calculating the forget gate, input gate and output gate. The calculation of the forget gate, input gate, and output gate is done forward and backward on the feature vector generated from the calculation in word embedding. The calculation uses sigmoid and tanh. The feature vector will be sequentially be multiplied by the weight matrix and added with a bias. The initial weight and bias values in the Bi-LSTM model are initialized the same as word embedding using uniform glorot [17] [18]. In the BiLSTM classification process, the feature vectors from the training data are processed by forward and backward LSTM [19]. The feature vectors that have been calculated at the forget gate, input gate, and output gate will go through softmax activation to determine the value in performing classification. Softmax will take the largest probability as a prediction to determine the label.</span></p>
<p><span class="font3">The Bi-LSTM model created has an input dimension vector of 550, which is based on the highest number of word sequences and for the output, 256 is chosen as it was done in the embedding process. Model summary created is shown in Figure 4 and Figure 5.</span></p>
<p><span class="font6" style="font-weight:bold;">Model: &quot;$equential_10&quot;</span></p>
<p><span class="font6" style="font-weight:bold;">Layer (type) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Output Shape &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Param #</span></p>
<p><span class="font6" style="font-weight:bold;">embedding_10 (Embedding) (None, 550, 256) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1194752</span></p>
<p><span class="font6" style="font-weight:bold;">spatial_dropoutld_8 (Spatia (None, 550, 256) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0</span></p>
<p><span class="font6" style="font-weight:bold;">IOropoutlD)</span></p>
<p><span class="font6" style="font-weight:bold;">bidirectional_7 (Bidirectio (None, 256) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;394240</span></p>
<p><span class="font6" style="font-weight:bold;">nal)</span></p>
<p><span class="font2" style="font-weight:bold;">densel (Dense) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(None, 13) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3341</span></p>
<p><span class="font2" style="font-weight:bold;">Total params: 1,641,437</span></p>
<p><span class="font2" style="font-weight:bold;">Trainable params: 1,641,437</span></p>
<p><span class="font2" style="font-weight:bold;">Non-trainable params: θ</span></p>
<p><span class="font2" style="font-weight:bold;">None</span></p>
<p><span class="font3">Figure 4 Model Summary</span></p>
<div><img src="https://jurnal.harianregional.com/media/100221-3.jpg" alt="" style="width:242pt;height:178pt;">
<p><span class="font3">Figure 5 Model visualize</span></p>
</div><br clear="all">
<p><span class="font3">In the dense model used, there are 13 labels or classes in the classification. The label used is the field of technicians assigned to resolve helpdesk ticket reports. Feature vector data of 128,000 each has a label. Labels are converted into dummies or one-hot encode.</span></p>
<p><span class="font3">The model that has been designed previously will be measured by conducting a training process on the model to be able to classify and predict based on training data and training results. The training data used is a feature vector of 128,000 data with a vector dimension length of 550. The training process uses batch size scenarios of 64 and 128 and epochs of 10, 20, 50, and 100. A snapshot of the epoch display carried out in this study is shown in Figure 8, Figure 7, Figure 8, and Figure 9,</span></p>
<p><span class="font0" style="font-weight:bold;">Epoch 1/16</span></p>
<p><span class="font0" style="font-weight:bold;">IMUlM [.omaaoannWMOW] - MMt UEtlrp - Ilrtt P.«M - acturo&lt;y: B-BZtKI ■ VPl-Iw B-MPS ■ val.*&lt;&lt;uracy B-IBBB Epoch 2/11</span></p>
<p><span class="font0" style="font-weight:bold;">IBee<sub>1</sub><sup>1</sup>Isee [——-————————J Oieas IsEstop loss: β.3M∙ accuracy: B.BSEB &nbsp;cal loci: B.WPl &nbsp;valaccuracy: B.BP»</span></p>
<p><span class="font0" style="font-weight:bold;">Epoch VI»</span></p>
<p><span class="font0" style="font-weight:bold;">IBWElIiee [——————-—-——J &nbsp;OMSs PiEslrp - lost: O-UBI - accuracy: B-BlBP - val loss: B<sub>1</sub>MU - vol accuracy: PSWZ</span></p>
<p><span class="font0" style="font-weight:bold;">Epoch «/IB</span></p>
<p><span class="font0" style="font-weight:bold;">ISWEiaee [■—■■■—————.——-—-</span><span class="font7" style="font-weight:bold;">∣</span><span class="font0" style="font-weight:bold;"> . </span><span class="font0" style="font-weight:bold;font-variant:small-caps;">mi«<sub>s</sub></span><span class="font0" style="font-weight:bold;"> isZstap lou: a.Pies - accuracy: B-BlM </span><span class="font0" style="font-weight:bold;font-variant:small-caps;">m1_1m&lt;:</span><span class="font0" style="font-weight:bold;"> «.17» - val.accuracy: β.aκ&gt; Epoch WlB</span></p>
<p><span class="font0" style="font-weight:bold;">ISWEiaee [---------] OUBs PaEctep lots: «.»7« accuracy: 0 927B &nbsp;&nbsp;cal lots: B UM &nbsp;&nbsp;vol-accuracy: Θ W7β</span></p>
<p><span class="font0" style="font-weight:bold;">Epoch β∕16</span></p>
<p><span class="font0" style="font-weight:bold;">liiro71Λ</span><span class="font7" style="font-weight:bold;">∣</span><span class="font0" style="font-weight:bold;">nι [—..—_..—.....„——] - MBls PtEttep - 1&lt;HS. B-UM - Mmntcyi B.BM» - val_lMt. B-ZWP ■ .Ol-Wcuraiy- B-BtU Epoch 'Eie</span></p>
<p><span class="font0" style="font-weight:bold;">Ieee<sub>1</sub>Iaee [——.—.-—.—-.——.— ] &nbsp;Mils PWltep lots: B-UB accuracy: «.BUM ralloss: B-MU Val accuracy: e∙&gt;116</span></p>
<p><span class="font0" style="font-weight:bold;">Epoch a/te 1BWE1BW [—........-----...............] - OtEPt PcEtlrp - IlTtS B<sub>1</sub>IBSl - PCCuraPy: U UB-Hlt - Val-Ioss<sup>1</sup> a MPlE - VPl-Occurecy- B MBB</span></p>
<p><span class="font0" style="font-weight:bold;">Epoch s∕ιe</span></p>
<p><span class="font0" style="font-weight:bold;">ISMEiaee [———————————J . 6βιzs Psltcop loss, B-IlU accuracy: B-BSM - val lou: 0-M53 - valjkαιrκy: B-BUB Epoch IIiEto</span></p>
<p><span class="font0" style="font-weight:bold;">IBWEieee (--------------1 EBSls «!/step loss: B-UBB - accuracy: B<sub>1</sub>BSZS cal loss: B-MEP vol accuracy: B-BlPE</span></p>
<div>
<p><span class="font3">Figure 6 10 epochs</span></p><img src="https://jurnal.harianregional.com/media/100221-4.jpg" alt="" style="width:430pt;height:170pt;">
</div><br clear="all">
<div><img src="https://jurnal.harianregional.com/media/100221-5.jpg" alt="" style="width:430pt;height:159pt;">
</div><br clear="all">
<ul style="list-style:none;"><li>
<p><span class="font0" style="font-weight:bold;"><sub>1</sub>- &nbsp;&nbsp;&nbsp;H ∙, ,11</span></p></li></ul>
<p><span class="font0" style="font-weight:bold;">1M∙∕1M∙ I............ &nbsp;—j - AWiS 4»/»tep - Im: O SBl </span><span class="font7" style="font-weight:bold;">∣</span><span class="font0" style="font-weight:bold;"> - UCCVMy = «.m* - </span><span class="font0" style="font-weight:bold;font-variant:small-caps;">v∙1~1j&gt;w</span><span class="font0" style="font-weight:bold;"> ∙∙&gt;M? - w∙J.∙LCUr∙&lt;y: «m»?</span></p>
<p><span class="font0" style="font-weight:bold;">Ipoch Z/M»</span></p>
<p><span class="font0" style="font-weight:bold;">IMB∕1BW (..........-..........—≡^,¾ - «415 4s∕Mep - low 9 16.MJ - βccurBcy; 4.&lt;MI9 v∙l.low B.2994 - *al.accuracy 4 9125</span></p>
<p><span class="font0" style="font-weight:bold;">Epoch 8/5»</span></p>
<p><span class="font0" style="font-weight:bold;">1BM∕18M I———————————J - 72 W S 43√stcp - loss: 9.1*42 accuracy: V 9499 vol low 9.2916 v*l accuracy- 9 9119</span></p>
<p><span class="font0" style="font-weight:bold;">Epoch 9/9»</span></p>
<p><span class="font0" style="font-weight:bold;">1SM∕UMΘ (........-......— ■—........) 722Ss&lt;s∕stap loss: 9.1310 accuracy: β.95J9 val_low β.⅛β48 val accuracy: 9.912 7</span></p>
<p><span class="font0" style="font-weight:bold;">Epoch l⅛∕5β</span></p>
<p><span class="font0" style="font-weight:bold;">IflMZUee I—————————I - 72Ms 4⅛∕st∙p loss: 9.1144 &nbsp;accuracy: B.95∞ &nbsp;vallι&gt;w β.324β &nbsp;val accuracy. 9.9115</span></p>
<p><span class="font0" style="font-weight:bold;">Epoch 11/59</span></p>
<p><span class="font0" style="font-weight:bold;">IflMZUee (——————————] - TMla 4s∕stβp - loss: e.U7B &nbsp;accuracy; fl.0620 &nbsp;vallow fl.3 35* &nbsp;√al accuracy: 9.012 3</span></p>
<p><span class="font0" style="font-weight:bold;">Epoch 12/59</span></p>
<p><span class="font0" style="font-weight:bold;">IflMZieee [—.-.-——.—-—-—----.—j . 7½5c 4s∕sτap - lose: </span><span class="font0" style="font-weight:bold;font-variant:small-caps;">b.m⅛</span><span class="font0" style="font-weight:bold;"> - eccwecy: β.06M - √ai ia≤⅛. β.⅛4ta - MljKflureey: «.one</span></p>
<p><span class="font0" style="font-weight:bold;">Epoch 13/5*</span></p>
<p><span class="font0" style="font-weight:bold;">Epwh MZM</span></p>
<p><span class="font0" style="font-weight:bold;">IMBZIIUie (∙MM*MMM*MMMMMM*Ma] - BflMt 4⅛∕⅜tep - !«u: ∙ ∙1Λ - eccvuty: ∙.WM *βljow fl.MIZB - MljKCttrBcy ∙.WB</span></p>
<p><span class="font0" style="font-weight:bold;">Epoch 59/59</span></p>
<p><span class="font0" style="font-weight:bold;">IBBWZlBee [————_—-——--———-—-( - MUt &lt;s∕step - loss: 9 92^7 - accuracy: 0 999C valjloM: ∙Λ797 - val.accuracy: 9.912 2</span></p>
<p><span class="font3">Figure 8 50 Epochs</span></p>
<p><span class="font0" style="font-weight:bold;">Ipocli 6/IW</span></p>
<p><span class="font0" style="font-weight:bold;">225/225 ( — ■——■■■.....■——.......</span><span class="font7" style="font-weight:bold;">∣</span><span class="font0" style="font-weight:bold;"> . iso» TsZsrapi - la»: 0,243« accuracy: o.9iT4 val la»; 0,3031 - val.accuracy: β.∙9M</span></p>
<p><span class="font0" style="font-weight:bold;">Ipocli ZZlW</span></p>
<p><span class="font0" style="font-weight:bold;">225Z225 [-■ ————— ■ ■....—.._.) &nbsp;ISMl TcZstapi - last: 0.2100 &nbsp;accuracy: B.Wtt &nbsp;val la»: 0.3017 - val.accuracy: 0.9006</span></p>
<p><span class="font0" style="font-weight:bold;">epoch S/IW</span></p>
<p><span class="font0" style="font-weight:bold;font-style:italic;">Iiwm</span><span class="font0" style="font-weight:bold;"> [———————I &nbsp;ISTPp Tc<sub>l</sub><sup>r</sup>StBfi - Iocs: a. IlUS accuracy: 0.9243 &nbsp;val lo»: 0.2967 - val.accuracy: 0.9023</span></p>
<p><span class="font0" style="font-weight:bold;">epoch 9∕1w</span></p>
<p><span class="font0" style="font-weight:bold;">2257225 [------1 ITMc ScZstapi - Iocs: 0.2085 accuracy: ∙.S2M - val_locs: 0.3001 - val.accuracy: 0.9035</span></p>
<p><span class="font0" style="font-weight:bold;">epoch ια∕ιee</span></p>
<p><span class="font0" style="font-weight:bold;">225/225 [---------------------) . ITTls ScZctapi - lose: 0.2016 accuracy: a.0205 &nbsp;&nbsp;val_lo»: β.29611 - val.accuracy: O-OOSB</span></p>
<p><span class="font0" style="font-weight:bold;">epoch ιi7iαe</span></p>
<p><span class="font0" style="font-weight:bold;">225/225 [-———-—————I ITSlC XsZctepi - locc: It. 101» accuracy: a.0326 - val_lo»: S.IOZl - val.accuracy: 0.9038 epoch IlZiM</span></p>
<p><span class="font0" style="font-weight:bold;">225/225 [—.————.———-J &nbsp;ITSOt SsZstapi - loss: 0.1343 - accuracy: 0.9356 - val lo»: 0.3031 - val.accuracy: 0.9050</span></p>
<p><span class="font0" style="font-weight:bold;">epoch UZlM</span></p>
<p><span class="font0" style="font-weight:bold;">225/225 [------------—] ■ 155βs ZsZstapi - loss: 0.0JlO &nbsp;&nbsp;accuracy: ∙.M91 - vol loss: O MTO - vol accuracy: 0.3081</span></p>
<p><span class="font0" style="font-weight:bold;">epoch OSZMO</span></p>
<p><span class="font0" style="font-weight:bold;">225/225 [..............................) . ISMs ZsZslepi - loss- 0.0J2S - accuracy: e.9</span><span class="font7" style="font-weight:bold;">∣</span><span class="font0" style="font-weight:bold;">IB!t - Ml losst β MJJ - vol accuracy: 0.90»/ Epoch M∕l∞</span></p>
<p><span class="font0" style="font-weight:bold;">111/225 I————»...............I - E1A; 14:43 . I<sub>e41i</sub> β.ezW - accuracy: «.»»»/</span></p>
<p><span class="font3">Figure 9 100 epochs</span></p>
<p><span class="font3">From the epoch scenario, all epochs produced an average accuracy of 91%. Where the results are shown in Table 1.</span></p>
<p><span class="font3">Table 1 Recapitulation of Training Model</span></p>
<table border="1">
<tr><td style="vertical-align:top;">
<p><span class="font3" style="font-style:italic;">Batch Size</span></p></td><td style="vertical-align:top;">
<p><span class="font3" style="font-style:italic;">Epoch</span></p></td><td style="vertical-align:top;">
<p><span class="font3" style="font-style:italic;">Accuracy</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font3">64</span></p></td><td style="vertical-align:top;">
<p><span class="font3">10</span></p></td><td style="vertical-align:top;">
<p><span class="font3">91.4%</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font3">64</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3">20</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3">91.1%</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font3">64</span></p></td><td style="vertical-align:top;">
<p><span class="font3">50</span></p></td><td style="vertical-align:top;">
<p><span class="font3">91.2%</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font3">64</span></p></td><td style="vertical-align:top;">
<p><span class="font3">100</span></p></td><td style="vertical-align:top;">
<p><span class="font3">91.1%</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font3">128</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3">10</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3">90.9%</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font3">128</span></p></td><td style="vertical-align:top;">
<p><span class="font3">20</span></p></td><td style="vertical-align:top;">
<p><span class="font3">91.2%</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font3">128</span></p></td><td style="vertical-align:top;">
<p><span class="font3">50</span></p></td><td style="vertical-align:top;">
<p><span class="font3">91.2%</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font3">128</span></p></td><td style="vertical-align:top;">
<p><span class="font3">100</span></p></td><td style="vertical-align:top;">
<p><span class="font3">91.1%</span></p></td></tr>
</table>
<p><span class="font3">From the epochs carried out for epoch 10, linear results were obtained, which moved at 91% at epoch 8. While epochs 20, 50 and 100 occur starting at epoch 30.</span></p>
<p><span class="font3">Prediction is carried out on helpdesk data for the period June 2022 to December 2022 which has not been completed by the operator, which is 32,000 data. The data processing process passed by the testing data is the same as the training data, namely case folding, remove number, remove tab and new line, remove character, stopword, tokenization, and word embedding. The data processing is carried out to obtain feature vectors from the new helpdesk report data which will be used as testing data. Then the feature vector is predicted to get the appropriate label based on the testing data label. The prediction process is done with the</span></p>
<p><span class="font3">argmax function or determining the largest value of the label resulting from the Bi-LSTM calculation process. The media for testing the prediction of testing data used is a web-based application. The application is built using flask. An overview of the helpdesk ticket report technician assignment prediction media is shown in Figure 10.</span></p><img src="https://jurnal.harianregional.com/media/100221-6.jpg" alt="" style="width:423pt;height:226pt;">
<p><span class="font3">Figure 10 Application Interface</span></p>
<p><span class="font3">Based on the model that has been saved and applied in the flask web-based application, the results of the prediction will be saved into a .csv file and then manually validated by the operator. The suitability of the Bi-LSTM prediction will be compared with the actual prediction by the operator and given a &quot;True&quot; sign if the Bi-LSTM prediction and actual prediction produce the same prediction results and given a &quot;False&quot; sign if the prediction results are not the same. The overall results of the Bi-LSTM prediction and the actual prediction from the operator as well as the results of matching the prediction results are attached in the appendix of this study. Validation is done by the operator and approved by the operator coach. In this study, the results of the validation become the performance benchmark of the classification and prediction results of BiLSTM.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark28"></a><span class="font3" style="font-weight:bold;"><a name="bookmark29"></a>4.3 &nbsp;&nbsp;&nbsp;Performance Result</span></h2></li></ul>
<p><span class="font3">Performance measurement using confusion matrix scheme on 13 labels, namely Data Pendukung, Executive Summary, Informasi Profile Kepesertaan, Kepesertaan Bukan Penerima Upah, Kepesertaan Jasa Konstruksi, Kepesertaan Penerima Upah, Keuangan, Network (Jaringan), Pelayanan, Pengawasan dan Pemeriksaan, Permintaan Antar Kantor (Wilayah), User dan Role, dan e-Channel.. Where measurements will be made on accuracy, precision, and recall. From the validation results carried out by the operator based on the prediction results of the BiLSTM model, 2,822 data were obtained which resulted in wrong predictions. This means that there are 29,178 data or 91.2% of 32,000 data that produce correct prediction results or in accordance with the actual predictions of the operator. From these results, each label is calculated TP, TN, FP and FN to measure the overall performance of Bi-LSTM. The results of the calculation of TP, TN, FP and FN as a whole are shown ina</span></p>
<p><span class="font3">Table </span><span class="font4" style="font-style:italic;">2</span><span class="font3">.</span></p>
<p><span class="font3">Table 2 Confusion Matrix Calculation for each Label</span></p>
<p><span class="font3">Label &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;TP &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;TN &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;FP &nbsp;&nbsp;&nbsp;&nbsp;FN &nbsp;&nbsp;&nbsp;Precision &nbsp;&nbsp;&nbsp;Recall</span></p>
<table border="1">
<tr><td style="vertical-align:top;">
<p><span class="font3">Data Pendukung</span></p></td><td style="vertical-align:top;">
<p><span class="font3">166</span></p></td><td style="vertical-align:top;">
<p><span class="font3">31,568</span></p></td><td style="vertical-align:top;">
<p><span class="font3">0</span></p></td><td style="vertical-align:top;">
<p><span class="font3">55</span></p></td><td style="vertical-align:top;">
<p><span class="font3">1</span></p></td><td style="vertical-align:top;">
<p><span class="font3">0.7511</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font3">E-Channel</span></p></td><td style="vertical-align:top;">
<p><span class="font3">1,671</span></p></td><td style="vertical-align:top;">
<p><span class="font3">27,476</span></p></td><td style="vertical-align:top;">
<p><span class="font3">921</span></p></td><td style="vertical-align:top;">
<p><span class="font3">41</span></p></td><td style="vertical-align:top;">
<p><span class="font3">0.6447</span></p></td><td style="vertical-align:top;">
<p><span class="font3">0.9761</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font3">Executive Summary</span></p></td><td style="vertical-align:middle;">
<p><span class="font3">10</span></p></td><td style="vertical-align:middle;">
<p><span class="font3">31,965</span></p></td><td style="vertical-align:middle;">
<p><span class="font3">0</span></p></td><td style="vertical-align:middle;">
<p><span class="font3">0</span></p></td><td style="vertical-align:middle;">
<p><span class="font3">1</span></p></td><td style="vertical-align:middle;">
<p><span class="font3">1</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font3">Informasi Profile</span></p>
<p><span class="font3">Kepesertaan</span></p></td><td style="vertical-align:top;">
<p><span class="font3">5,456</span></p></td><td style="vertical-align:top;">
<p><span class="font3">22,930</span></p></td><td style="vertical-align:top;">
<p><span class="font3">0</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3">1,900</span></p></td><td style="vertical-align:top;">
<p><span class="font3">1</span></p></td><td style="vertical-align:top;">
<p><span class="font3">0.7417</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font3">Kepesertaan Bukan</span></p>
<p><span class="font3">Penerima Upah</span></p></td><td style="vertical-align:top;">
<p><span class="font3">2,154</span></p></td><td style="vertical-align:top;">
<p><span class="font3">28,955</span></p></td><td style="vertical-align:top;">
<p><span class="font3">0</span></p></td><td style="vertical-align:top;">
<p><span class="font3">185</span></p></td><td style="vertical-align:top;">
<p><span class="font3">1</span></p></td><td style="vertical-align:top;">
<p><span class="font3">0.9209</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font3">Kepesertaan Jasa Konstruksi</span></p></td><td style="vertical-align:top;">
<p><span class="font3">651</span></p></td><td style="vertical-align:top;">
<p><span class="font3">31,273</span></p></td><td style="vertical-align:top;">
<p><span class="font3">0</span></p></td><td style="vertical-align:top;">
<p><span class="font3">24</span></p></td><td style="vertical-align:top;">
<p><span class="font3">1</span></p></td><td style="vertical-align:top;">
<p><span class="font3">0.9644</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font3">Kepesertaan</span></p>
<p><span class="font3">Penerima Upah</span></p></td><td style="vertical-align:top;">
<p><span class="font3">4,699</span></p></td><td style="vertical-align:top;">
<p><span class="font3">25,192</span></p></td><td style="vertical-align:top;">
<p><span class="font3">1,901</span></p></td><td style="vertical-align:top;">
<p><span class="font3">208</span></p></td><td style="vertical-align:top;">
<p><span class="font3">0.7120</span></p></td><td style="vertical-align:top;">
<p><span class="font3">0.9576</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font3">Keuangan dan Akuntansi</span></p></td><td style="vertical-align:top;">
<p><span class="font3">698</span></p></td><td style="vertical-align:top;">
<p><span class="font3">31,226</span></p></td><td style="vertical-align:top;">
<p><span class="font3">0</span></p></td><td style="vertical-align:top;">
<p><span class="font3">4</span></p></td><td style="vertical-align:top;">
<p><span class="font3">1</span></p></td><td style="vertical-align:top;">
<p><span class="font3">0.9943</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font3">Network (Jaringan)</span></p></td><td style="vertical-align:top;">
<p><span class="font3">2,505</span></p></td><td style="vertical-align:top;">
<p><span class="font3">29,231</span></p></td><td style="vertical-align:top;">
<p><span class="font3">0</span></p></td><td style="vertical-align:top;">
<p><span class="font3">15</span></p></td><td style="vertical-align:top;">
<p><span class="font3">1</span></p></td><td style="vertical-align:top;">
<p><span class="font3">0.9940</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font3">Pelayanan</span></p></td><td style="vertical-align:middle;">
<p><span class="font3">7,926</span></p></td><td style="vertical-align:middle;">
<p><span class="font3">23,616</span></p></td><td style="vertical-align:middle;">
<p><span class="font3">0</span></p></td><td style="vertical-align:middle;">
<p><span class="font3">340</span></p></td><td style="vertical-align:middle;">
<p><span class="font3">1</span></p></td><td style="vertical-align:middle;">
<p><span class="font3">0.9589</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font3">Pengawasan dan Pemeriksaan</span></p></td><td style="vertical-align:top;">
<p><span class="font3">411</span></p></td><td style="vertical-align:top;">
<p><span class="font3">31,516</span></p></td><td style="vertical-align:top;">
<p><span class="font3">0</span></p></td><td style="vertical-align:top;">
<p><span class="font3">26</span></p></td><td style="vertical-align:top;">
<p><span class="font3">1</span></p></td><td style="vertical-align:top;">
<p><span class="font3">0.9405</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font3">Permintaan Antar</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3">383</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3">30,674</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3">0</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3">26</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3">1</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3">0.9364</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font3">Kantor (Wilayah) User dan Role</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3">2,448</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3">29,448</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3">0</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3">24</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3">1</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3">0.9903</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font3" style="font-weight:bold;">Total</span></p></td><td style="vertical-align:middle;">
<p><span class="font3" style="font-weight:bold;">29,178</span></p></td><td style="vertical-align:middle;">
<p><span class="font3" style="font-weight:bold;">375,070</span></p></td><td style="vertical-align:middle;">
<p><span class="font3" style="font-weight:bold;">2,822</span></p></td><td style="vertical-align:middle;">
<p><span class="font3" style="font-weight:bold;">2,848</span></p></td><td style="vertical-align:middle;">
<p><span class="font3" style="font-weight:bold;">12.3566</span></p></td><td style="vertical-align:middle;">
<p><span class="font3" style="font-weight:bold;">12.1263</span></p></td></tr>
</table>
<p><span class="font3">The classification process in this study is a multi-label classification so that the calculation process of TP, TN, FP and FN is calculated from each label as well as precision and recall which are also calculated from each label. To measure the overall performance of the Bi-LSTM model, the results of TP, TN, FP, and FN are summed up and then divided by the number of 13 labels. The results of the overall accuracy, all precision and all recall are shown in Table 3</span></p>
<p><span class="font3" style="text-decoration:underline;">Table 3 Accuracy, All Precision dan All Recall</span></p>
<p><span class="font3">Accuracy &nbsp;&nbsp;&nbsp;&nbsp;All Precision &nbsp;&nbsp;&nbsp;&nbsp;All Recall</span></p>
<p><span class="font3">0.9118 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.9505 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.9328</span></p>
<p><span class="font3">From Table 3, obtained the results of accuracy, precision, and recall for 32,000 data testing helpdesk ticket reports, namely accuracy of 91.2%, precision of 95%, and recall of 93% respectively.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark30"></a><span class="font3" style="font-weight:bold;"><a name="bookmark31"></a>5. &nbsp;&nbsp;&nbsp;&nbsp;Conclusion</span></h2></li></ul>
<p><span class="font3">Based on the test results of the Helpdesk Ticket Classification for Technician Assignment Routes Using BiLSTM, it can be concluded that the test was conducted using 128,000 completed helpdesk ticket report data as training data and 32,000 incomplete helpdesk ticket report data as testing data. The BiLSTM prediction process was tested using the Flask web application that was created and with a one-by-one helpdesk request input scheme. Out of the 32,000 data used as testing data, there were 29,178 data that were validated correctly, or 91.2% of the total data that were predicted correctly or matched the actual prediction from the operator. Overall, the test results showed an accuracy of 91.2%, precision of 95%, and recall of 93%.</span></p>
<h2><a name="bookmark32"></a><span class="font3" style="font-weight:bold;"><a name="bookmark33"></a>References</span></h2>
<ul style="list-style:none;"><li>
<p><span class="font3">[1] &nbsp;&nbsp;&nbsp;H. Kaur, “SENTIMENT ANALYSIS OF USER REVIEW TEXT THROUGH CNN AND LSTM METHODS,” p. 17, 2020.</span></p></li>
<li>
<p><span class="font3">[2] “T. Wu and G. Zheng, ‘Research on Hotel Comment Emotion Analysis Based on BiLSTM</span></p></li></ul>
<p><span class="font3">and GRU,’ 2021 4th International Conference on Robotics, Control and Automation Engineering (RCAE), 2021, pp. 143-146, doi: 10.1109/RCAE53607.2021.9638802.”.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font3">[3] &nbsp;&nbsp;&nbsp;F. Al-Hawari and H. Barham, “A machine learning based help desk system for IT service management,” </span><span class="font3" style="font-style:italic;">Journal of King Saud University - Computer and Information Sciences</span><span class="font3">, vol. 33, no. 6, pp. 702–718, Jul. 2021, doi: 10.1016/j.jksuci.2019.04.001.</span></p></li>
<li>
<p><span class="font3">[4] &nbsp;&nbsp;&nbsp;A. Mandal, N. Malhotra, S. Agarwal, A. Ray, and G. Sridharaf, “Automated Dispatch of Helpdesk Email Tickets: Pushing the Limits with AI,” p. 8.</span></p></li>
<li>
<p><span class="font3">[5] &nbsp;&nbsp;&nbsp;S. P. Paramesh and K. S. Shreedhara, “IT HELP DESK INCIDENT CLASSIFICATION USING CLASSIFIER ENSEMBLES,” </span><span class="font3" style="font-style:italic;">ICTACT JOURNAL ON SOFT COMPUTING</span><span class="font3">, vol. 09, no. 04, p. 8, 2019.</span></p></li>
<li>
<p><span class="font3">[6] &nbsp;&nbsp;&nbsp;R. Baraniuk, D. Donoho, and M. Gavish, “The science of deep learning,” </span><span class="font3" style="font-style:italic;">Proc. Natl. Acad. Sci. U.S.A.</span><span class="font3">, vol. 117, no. 48, pp. 30029–30032, Dec. 2020, doi: 10.1073/pnas.2020596117.</span></p></li>
<li>
<p><span class="font3">[7] &nbsp;&nbsp;&nbsp;J. Xiao and Z. Zhou, “Research Progress of RNN Language Model,” in </span><span class="font3" style="font-style:italic;">2020 IEEE International Conference on Artificial Intelligence and Computer Applications (ICAICA)</span><span class="font3">, Dalian, China: IEEE, Jun. 2020, pp. 1285–1288. doi: 10.1109/ICAICA50127.2020.9182390.</span></p></li>
<li>
<p><span class="font3">[8] &nbsp;&nbsp;&nbsp;G. Xu, Y. Meng, X. Qiu, Z. Yu, and X. Wu, “Sentiment Analysis of Comment Texts Based on BiLSTM,” </span><span class="font3" style="font-style:italic;">IEEE Access</span><span class="font3">, vol. 7, pp. 51522–51532, &nbsp;&nbsp;2019, doi:</span></p></li></ul>
<p><span class="font3">10.1109/ACCESS.2019.2909919.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font3">[9] &nbsp;&nbsp;&nbsp;P. Hu, J. Tong, J. Wang, Y. Yang, and L. de Oliveira Turci, “A hybrid model based on CNN and Bi-LSTM for urban water demand prediction,” in </span><span class="font3" style="font-style:italic;">2019 IEEE Congress on Evolutionary Computation (CEC)</span><span class="font3">, Wellington, New Zealand: IEEE, Jun. 2019, pp. 1088–1094. doi: 10.1109/CEC.2019.8790060.</span></p></li>
<li>
<p><span class="font3">[10] &nbsp;&nbsp;&nbsp;B. Jang, M. Kim, G. Harerimana, S. Kang, and J. W. Kim, “Bi-LSTM Model to Increase Accuracy in Text Classification: Combining Word2vec CNN and Attention Mechanism,” </span><span class="font3" style="font-style:italic;">Applied Sciences</span><span class="font3">, vol. 10, no. 17, p. 5841, Aug. 2020, doi: 10.3390/app10175841.</span></p></li>
<li>
<p><span class="font3">[11] &nbsp;&nbsp;&nbsp;J. Zheng, “A Novel Computer-Aided Emotion Recognition of Text Method Based on WordEmbedding and Bi-LSTM,” in </span><span class="font3" style="font-style:italic;">2019 International Conference on Artificial Intelligence and Advanced Manufacturing (AIAM)</span><span class="font3">, Dublin, Ireland: IEEE, Oct. 2019, pp. 176–180. doi: 10.1109/AIAM48774.2019.00042.</span></p></li>
<li>
<p><span class="font3">[12] &nbsp;&nbsp;&nbsp;Y. Sung, S. Jang, Y.-S. Jeong, and J. H. (James J. ) Park, “Malware classification algorithm using advanced Word2vec-based Bi-LSTM for ground control stations,” </span><span class="font3" style="font-style:italic;">Computer Communications</span><span class="font3">, vol. 153, pp. 342–348, Mar. 2020, doi: 10.1016/j.comcom.2020.02.005.</span></p></li>
<li>
<p><span class="font3">[13] &nbsp;&nbsp;&nbsp;C. Wang, P. Nulty, and D. Lillis, “A Comparative Study on Word Embeddings in Deep Learning for Text Classification,” in </span><span class="font3" style="font-style:italic;">Proceedings of the 4th International Conference on Natural Language Processing and Information Retrieval</span><span class="font3">, Seoul Republic of Korea: ACM, Dec. 2020, pp. 37–46. doi: 10.1145/3443279.3443304.</span></p></li>
<li>
<p><span class="font3">[14] &nbsp;&nbsp;&nbsp;M. A. Prihandono, R. Harwahyu, and R. F. Sari, “Performance of Machine Learning Algorithms for IT Incident Management,” p. 6.</span></p></li>
<li>
<p><span class="font3">[15] &nbsp;&nbsp;&nbsp;U. Hasanah, T. Astuti, R. Wahyudi, Z. Rifai, and R. A. Pambudi, “An Experimental Study of Text Preprocessing Techniques for Automatic Short Answer Grading in Indonesian,” in </span><span class="font3" style="font-style:italic;">2018 3rd International Conference on Information Technology, Information System and Electrical Engineering (ICITISEE)</span><span class="font3">, Yogyakarta, Indonesia: IEEE, Nov. 2018, pp. 230–234. doi: 10.1109/ICITISEE.2018.8720957.</span></p></li>
<li>
<p><span class="font3">[16] &nbsp;&nbsp;&nbsp;J. H. Thrall </span><span class="font3" style="font-style:italic;">et al.</span><span class="font3">, “Artificial Intelligence and Machine Learning in Radiology: Opportunities, Challenges, Pitfalls, and Criteria for Success,” </span><span class="font3" style="font-style:italic;">Journal of the American College of Radiology</span><span class="font3">, vol. 15, no. 3, pp. 504–508, Mar. 2018, doi: 10.1016/j.jacr.2017.12.026.</span></p></li>
<li>
<p><span class="font3">[17] &nbsp;&nbsp;&nbsp;V. B. de Souza, J. C. Nobre, and K. Becker, “Characterization of Anxiety, Depression, and their Comorbidity from Texts of Social Networks,” in </span><span class="font3" style="font-style:italic;">Anais do XXXV Simpósio Brasileiro de Banco de Dados (SBBD 2020)</span><span class="font3">, Brasil: Sociedade Brasileira de Computação - SBC, Sep. 2020, pp. 121–132. doi: 10.5753/sbbd.2020.13630.</span></p></li>
<li>
<p><span class="font3">[18] &nbsp;&nbsp;&nbsp;A. F. de Sousa Neto, B. L. D. Bezerra, A. H. Toselli, and E. B. Lima, “HTR-Flor: A Deep Learning System for Offline Handwritten Text Recognition,” in </span><span class="font3" style="font-style:italic;">2020 33rd SIBGRAPI Conference on Graphics, Patterns and Images (SIBGRAPI)</span><span class="font3">, Recife/Porto de Galinhas, Brazil: IEEE, Nov. 2020, pp. 54–61. doi: 10.1109/SIBGRAPI51738.2020.00016.</span></p></li>
<li>
<p><span class="font3">[19] &nbsp;&nbsp;&nbsp;P. Singla, M. Duhan, and S. Saroha, “An ensemble method to forecast 24-h ahead solar irradiance using wavelet decomposition and BiLSTM deep learning network,” </span><span class="font3" style="font-style:italic;">Earth Sci Inform</span><span class="font3">, vol. 15, no. 1, pp. 291–306, Mar. 2022, doi: 10.1007/s12145-021-00723-1.</span></p></li></ul>
<p><span class="font3" style="font-style:italic;">Helpdesk Ticket Classification for Technician Assignment Routes Using BiLSTM (Putu Alan</span><span class="font3"> 60</span></p>
<p><span class="font3" style="font-style:italic;">Arismandika)</span></p>