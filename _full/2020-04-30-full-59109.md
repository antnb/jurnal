---
layout: full_article
title: "Detection of Class Regularity with Support Vector Machine methods"
author: "Ni Wayan Emmy Rosiana Dewi, I Gede Aris Gunadi, Gede Indrawan"
categories: lontar
canonical_url: https://jurnal.harianregional.com/lontar/full-59109 
citation_abstract_html_url: "https://jurnal.harianregional.com/lontar/id-59109"
citation_pdf_url: "https://jurnal.harianregional.com/lontar/full-59109"  
comments: true
---

<p><span class="font1" style="font-weight:bold;">LONTAR KOMPUTER VOL. 11, NO. 1 APRIL 2020</span></p>
<p><span class="font1" style="font-weight:bold;">DOI : 10.24843/LKJITI.2020.v11.i01.p03</span></p>
<p><span class="font1" style="font-weight:bold;">Accredited B by RISTEKDIKTI Decree No. 51/E/KPT/2017</span></p>
<p><span class="font1" style="font-weight:bold;">p-ISSN 2088-1541</span></p>
<p><span class="font1" style="font-weight:bold;">e-ISSN 2541-5832</span></p><a name="caption1"></a>
<h1><a name="bookmark0"></a><span class="font3" style="font-weight:bold;"><a name="bookmark1"></a>Detection of Class Regularity with Support Vector Machine methods</span></h1>
<p><span class="font1">Ni Wayan Emmy Rosiana Dewi<sup>a1</sup>, I Gede Aris Gunadi <sup>a2</sup>, Gede Indrawan<sup>a3</sup></span></p>
<p><span class="font1"><sup>a</sup>Department of Computer Science, Ganesha University of Education</span></p>
<p><span class="font1">Jl. Udayana No.11, Banyuasri, Kec. Buleleng, Kabupaten Buleleng, Bali, Indonesia </span><a href="mailto:1emmy.rosiana@gmail.com"><span class="font1" style="text-decoration:underline;"><sup>1</sup>emmy.rosiana@gmail.com</span><span class="font1"> </span></a><span class="font0" style="font-variant:small-caps;">(c</span><span class="font0">orresponding author)</span></p>
<p><span class="font1"><sup>2</sup></span><a href="mailto:igagunadi@gmail.com"><span class="font1"> </span><span class="font1" style="text-decoration:underline;">igagunadi@gmail.com</span></a></p>
<p><a href="mailto:3gede.indrawan@gmail.com"><span class="font1" style="text-decoration:underline;"><sup>3</sup>gede.indrawan@gmail.com</span></a></p>
<p><span class="font1" style="font-weight:bold;font-style:italic;">Abstract</span></p>
<p><span class="font1" style="font-style:italic;">One of the most factor that affects the achievement and learning motivation of students is a conducive classroom environment. It can be seen from the student's regularity in the class. Teachers can determine whether the class is adequate or not by monitoring the class condition through video. The research tries to apply the extraction of imagery and sound features by using the Centroid extraction method and the MFCC along with classifying the regular or irregular classrooms with the SVM methods which are taken by video installed in a classroom. The video will be split into image data and sound data. The process of image data starts with reading the input, then it goes to the stages of preprocessing, segmentation with K-Means, morphology, and the most important part is to get information before it is classified by the SVM method to get its class regularity. The sound frequency will be extracted by the MFCC method and then it is classified by the SVM method to get the class noise. The results of this research get an accuracy value of 78% in the linear kernel and 70% in the polynomial kernel. This research uses 50 test data consisting of 25 regular data and 25 irregular data taken directly through video recording. These results prove that the SVM method has given good classification results for regular and irregular classes.</span></p>
<p><span class="font1" style="font-weight:bold;font-style:italic;">Keywords: </span><span class="font1" style="font-style:italic;">Class, Centroid, MFCC, SVM, Regular, Irregular</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark2"></a><span class="font1" style="font-weight:bold;"><a name="bookmark3"></a>1. &nbsp;&nbsp;&nbsp;Introduction</span></h2></li></ul>
<p><span class="font1">A classroom is a place for intensive teaching and learning activities. Students and teachers interact, give, and receive lessons in class, to achieve the objectives of national education. One of the factors that influence student achievement and motivation is a conducive classroom environment. A motivating environment will make it easier for students to accept lessons, in addition to be able to develop initiatives (the desire to learn on their own). Achievement of student learning achievement can be improved by evaluating the conditions of student learning activities through video recording media.</span></p>
<p><span class="font1">Monitoring the condition of the classroom through video is also one application of the video that helps the teacher to review whether the class is conducive or not. Image and audio data is captured via video, where each information is processed based on its features. The level of regularity and class noise can affect student’s motivation and learning achievement [1]. Therefore in this study, it is trying to apply image and sound feature extraction by using the Centroid Extraction and Mel Frequency Cepstral Coefficient (MFCC) method and classifying regular or irregular classrooms with the Support Vector Machine (SVM) method which is taken through video attached in a class. This research is a basic research that can be used to build a system which is called integrated smart class. One of them contains a feature of monitoring classroom conditions in real/through video (images and sounds). It aims to make it easier for teachers to monitor when the teacher isn’t there in the class or the student studies independently.</span></p>
<p><span class="font1">Several previous studies related to the classification method using the Support Vector Machine (SVM) have been done. One of these was by I Gede Aris Gunadi and friends, with the title Fake Smile Detection Using Linear Support Vector Machine [2]</span><span class="font1" style="font-style:italic;">.</span><span class="font1"> In this study, the detection of smiles from people's faces, whether smiles are real or fake by using the RoI (Region of Interest) segmentation technique, was done on the cheeks and eyes. The test results show that the accuracy of the system is 86%, while the error rate is 14%. Other research on SVM classification is a study conducted by Raudlatul Munawarah and friends with the title &quot;Application of the Support Vector Machine Method in Hepatitis Diagnosis [3]. This study analyzes the ability of the SVM method to use training data of 100 positive and 100 negative data using linear kernel functions and RBF.8 The percentage results of the classification using linear kernels are 68-83% and kernel RBF by 70-96%.</span></p>
<p><span class="font1">Research on the image of the classroom environment was carried out by researchers Takashi Ozeki and Watanabe, who made a study entitled Analysis of the Behavior of Students Considering Privacy [4]. This study uses the Haar classifier method for smoothed video. Then, check the pixel number of the skin color of the face area detected by this method, then each face is given a number. From the experiments, it was possible to determine the classification correctly when students faced forward even in smoothed videos. Research on image feature extraction has been carried out by Kadek Novar Setiawan and friends using the K-Means GLCM method in obtaining image feature extraction. The application of the k-means method is used in the segmentation process with 4 clusters. The GLCM method is used in the image extraction process, which aims to extract relevant information into the characteristics of each class. Support Vector Machine used as a classification process shows good results in distinguishing normal and abnormal mammogram images by showing an accuracy of up to 80%, so this method is considered good enough to be used in the classification process of mammogram images [5].</span></p>
<p><span class="font1">The research about extraction of sound features using MFCC has been researched by Awais, et al. Their research was using MFCC as extraction feature methods of speech signal with locality sensitive hashing (lsh) as its clarification method. The research got 92.66% accuracy values for the speech recognition process by matching the training data that it has [6]. Other research on sound or audio extraction using the MFCC method was conducted by Mohan B and Ramesh Babu N with the title Speech recognition using MFCC and DTW research. This study extracts sound features using the Mel Frequency Cepstral Coefficients (MFCC) and Dynamic Time Wrapping (DTW) methods, two algorithms, each of which is adapted for feature extraction and pattern matching. Results obtained with one training and continuous testing phase [7].</span></p>
<p><span class="font1">Based on these studies, research about the detection system for the class regularity using the image and sound features with the Support Vector Machine (SVM) method has not been done yet. SVM is a machine learning method that is supervised learning which is still relied on in terms of binary classification and while this SVM method is not used yet in classifying object images and sounds in a classroom together. These two characteristics data are then modeled by the SVM Method as Training and Classifying, whether class conditions are regular or irregular. So it is hoped that This research can contribute in the form of class image datasets and audio class datasets because in the process of data acquisition, it is done directly by using the same data collection standards both from the tool and the angle of video data retrieval, which is separated into images and audio, and Hopefully this research can contribute references for other research in knowing the image and audio classification process by using the SVM method.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark4"></a><span class="font1" style="font-weight:bold;"><a name="bookmark5"></a>2. &nbsp;&nbsp;&nbsp;Research Methods</span></h2></li></ul>
<p><span class="font1">This study took data directly from the condition of the classroom during class hours. Sibangkaja Public Elementary School 4 was a place for collecting data used in this study. The image of this class condition taken using a Fujifilm X-T100 Mirroring Camera recording device; then, the recorded file was stored and then processed with video processing software to take pictures and audio for 5 seconds. Image data in JPEG format (24-bit color depth), resolution of 1980 x 1080 pixels with the highest quality 96 dpi. Audio data then saved in .wav format.</span></p>
<p><span class="font1">An overview of this research presented in the following</span><a href="#bookmark6"><span class="font1"> Figure 1.</span></a></p><img src="https://jurnal.harianregional.com/media/59109-1.jpg" alt="" style="width:428pt;height:183pt;">
<p><span class="font1" style="font-weight:bold;">Figure 1 </span><span class="font1">Overview of the method approach for class regularity detection</span></p>
<p><a name="bookmark6"></a><span class="font1">Class regularity detection uses two inputs derived from images and audio. Each input must produce features that can be used by SVM classification methods to determine the conditions of regular or irregular classes. For example, for the image input, the hair position feature used as a feature, and the audio input use the value of the intensity of the sound frequency produced by students in the class as a feature.</span></p>
<p><span class="font1">The hair position feature is used as a feature value, assuming that if students pay attention in the class, they will regularly sit with the hair position will look regular if drawn in a straight line horizontally. Conversely, if students who are in the class do not focus ahead, of course, the position of each student's hair will look irregular. Characteristics of hair position in the study using the centroid value of each segmentation obtained. As for audio input, the characteristic value is taken from the intensity value of the sound frequency produced. Assume used is the higher the intensity of the sound frequency obtained from the input, the class tends to be irregular, and conversely, the lower the intensity of the sound frequency obtained, the condition of the class tends to be regular.</span></p>
<p><span class="font1">The detailed process of each input, image, and audio can be seen as follows.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark7"></a><span class="font1" style="font-weight:bold;"><a name="bookmark8"></a>2.1. &nbsp;&nbsp;&nbsp;Image Data</span></h2></li></ul>
<p><span class="font1">Image data is an image that is similar to its original form or at a minimum in the form of a planimetry. Images or digital images on a two-dimensional scale are processed and manipulated by the image processing method [8]. The image processing process in this study is seen in</span><a href="#bookmark9"><span class="font1"> Figure 2.</span></a><span class="font1"> In the preprocessing process, the input image in the RGB color space is converted to HSV. This color model is in accordance with human perception of the similarity of colors [9]. The Gaussian blur filtering process is included in the preprocessing image, where the image is blurred and reduced the noise contained in it [10]. The next stage is image segmentation using K-Means. This study will look for students' hair objects using K-Means segmentation. Segmentation is a technique for dividing an image into several regions where each region has a similar attribute [11][12]. K-Means is an unsupervised clustering algorithm and it is used to segment more prominent areas of the background [13]. K-Means can work well on image segmentation, if the image has previously been partially repaired [13]. Furthermore, the segmented image will be processed by image morphology into several steps. First is binrization, which changing the image in binary form, namely an image with two gray level values, black and whites[14]. Then, closing which smoothing the segmentation and cover the missing pixels . The last one is erosion, which moving pixels at object boundaries and opening refine object boundaries, separate objects that were previously hand in hand, and eliminate objects smaller than the size of the structuring [15][16].</span></p>
<p><span class="font1">The process after image morphology is feature extraction by finding the centroid position of each student's hair in the class. The regular position of the hair centroids in each image</span></p>
<p><span class="font1">determines the regularity of the class. So when another image is tested, the Support Vector Machine algorithm will classify whether the image is organized or not.</span></p><img src="https://jurnal.harianregional.com/media/59109-2.jpg" alt="" style="width:384pt;height:181pt;">
<p><span class="font1" style="font-weight:bold;">Figure 2 </span><span class="font1">Image data processing</span></p>
<p><a name="bookmark9"></a><span class="font1">Feature extraction is an essential step in the decision-making process in determining whether the object is in an organized position or not based on the student's position. This feature is also for determining unknown objects in the class. Image data used in this research use the .jpg format. Training data used in this research were 125 data, consisting of 63 regular student data and 62 irregular student data</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark10"></a><span class="font1" style="font-weight:bold;"><a name="bookmark11"></a>2.2. &nbsp;&nbsp;&nbsp;Audio Data</span></h2></li></ul><img src="https://jurnal.harianregional.com/media/59109-3.jpg" alt="" style="width:290pt;height:136pt;">
<p><span class="font1" style="font-weight:bold;">Figure 3 </span><span class="font1">Audio data processing</span></p>
<p><span class="font1">Audio data processing begins with feature extraction, which in this stage, a series of quantities in the input signal section are processed to determine learning patterns or test patterns. The features used in this study are frequency features. For sound signals, the magnitude characteristic is usually the output of some form of spectrum analysis technique, which in this study uses the MFCC (Mel-Frequency Cepstrum Coefficients) method. MFCC is a feature extraction that calculates the cepstral coefficient by considering human hearing [17]. MFCC values used in this study were 20 values from 0-19. The audio format used in this study is .wav.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark12"></a><span class="font1" style="font-weight:bold;"><a name="bookmark13"></a>2.3. &nbsp;&nbsp;&nbsp;Support Vector Machine (SVM)</span></h2></li></ul>
<p><span class="font1">The Support Vector Machine (SVM) developed by Boser, Guyon, Vapnik, and was first presented in 1992 at the Annual Workshop on Computational Learning Theory. The basic concept of SVM is data calculation techniques. By using statistics and learning with expected</span></p>
<p><span class="font1">results in the form of predictive abilities. SVM can be applied to results which is continuous, binary, categorical, logistic, and multinomial by forming a hyperplane margin [18][19]. SVM uses kernel assistance to connect training data input to wider space dimension features and identifies its hyperplane as a dividing space [20].</span></p><img src="https://jurnal.harianregional.com/media/59109-4.jpg" alt="" style="width:395pt;height:215pt;">
<p><span class="font1" style="font-weight:bold;">Figure 4 </span><span class="font1">SVM visualization</span></p>
<p><a name="bookmark14"></a><span class="font1">The concept of classification with SVM can be explained simply as an attempt to find the best hyperplane that functions as a separator of a two-class or multi-class in the input space [21]. </span><a href="#bookmark14"><span class="font1">Figure 4 </span></a><span class="font1">shows some data that are members of two data class pieces, namely +1 and -1. Data incorporated in class -1 is symbolized by a circle, while data in class +1 symbolized by a square [22].</span></p><img src="https://jurnal.harianregional.com/media/59109-5.jpg" alt="" style="width:185pt;height:186pt;">
<p><span class="font1">O class-1 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;□ class+1</span></p>
<p><span class="font1" style="font-weight:bold;">Figure 5 </span><span class="font1">Hyperplane SVM margin</span></p>
<p><a name="bookmark15"></a><span class="font1">The best separator hyperplane (decision boundary) between the two classes can be found by measuring the margins and finding the maximum point. Margin is the distance between the hyperplane and the closest data from each class. The closest data is referred to as a support vector. The solid line in</span><a href="#bookmark15"><span class="font1"> Figure 5 </span></a><span class="font1">to the right shows the best hyperplane, which is located right in the middle of the two classes, while the circle and square data that is crossed by the margin line</span></p>
<p><span class="font1">(dashed line) is the support-vector. Efforts to find the location of this hyperplane are the core of the training process in SVM.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark16"></a><span class="font1" style="font-weight:bold;"><a name="bookmark17"></a>3. &nbsp;&nbsp;&nbsp;Result and Discussion</span></h2></li></ul>
<p><span class="font1">The algorithm proposed in this study was created using the Python programming language. The training data used were 125 data obtained through direct recordings from two different classrooms. The training process is ready after the image pre-processing and feature extraction process is complete.</span></p>
<p><span class="font1">The test carried out using two existing kernels in SVM, namely a linear kernel and a polynomial kernel. The type of kernel is the parameter used to modify the best separator hyperplane in the SVM input space [23]. Choosing the right kernel function is very important because this kernel function will determine the feature space where the classifier function will be searched for. As long as the kernel function is legitimate, SVM would operate correctly, even though we didn’t know what map to use [24]. In the next step, SVM would use hyperplane as a decision boundary efficiently.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1">1. &nbsp;&nbsp;&nbsp;Linear Kernel</span></p></li></ul>
<p><span class="font1">The linear kernel is the most straightforward kernel function. It is used when the data analyzed is linearly separated. Linear kernels are suitable when there are many features because mapping to higher dimensional spaces cannot improve performance as in text classification. In-text classification, both the number of instances (documents) and the number of features (words) are the same. The following is the equation of the SVM linear kernel.</span></p>
<p><span class="font5" style="font-style:italic;">K (x,x') = x. x'</span><span class="font2">.............................................................................................(1)</span></p>
<p><span class="font1">where </span><span class="font1" style="font-style:italic;">x</span><span class="font1"> and </span><span class="font1" style="font-style:italic;">x’</span><span class="font1"> are vectors in the input space.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1">2. &nbsp;&nbsp;&nbsp;Polynomial Kernel</span></p></li></ul>
<p><span class="font1">The kernel polynomial is a kernel function that is used when data is not linearly separated. The polynomial kernel is perfect for problems where all training datasets are normalized, along with the polynomial equation.</span></p>
<p><span class="font5" style="font-style:italic;">K (x,x') = (x.x</span><span class="font4" style="font-style:italic;">' </span><span class="font5" style="font-style:italic;">+ c)<sup>d</sup></span><span class="font2">.....................................................................................(2)</span></p>
<p><span class="font1">It has two parameters: </span><span class="font1" style="font-style:italic;">c</span><span class="font1">, which represents a constant term,and </span><span class="font1" style="font-style:italic;">d</span><span class="font1">, which represents the degree of the kernel.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark18"></a><span class="font1" style="font-weight:bold;"><a name="bookmark19"></a>3.1. &nbsp;&nbsp;&nbsp;Training Data</span></h2></li></ul>
<p><span class="font1">The training process on this system begins by entering all the image and audio data that has been prepared as training data. A total of 125 data are used as training data. After the data is inputted, proceed with the preparation process. Trained data is displayed in sequence, starting from the results of image preprocessing, which consists of the conversion of RGB images into HSV images, image filtering using the Gaussian Blur method, and image segmentation using the K-Means method. Parameters used in segmentation with k-means clustering are K = 5 and 10 iterations. After segmentation with k-means, the Hue, Saturation, and Value channel channels are separated. Post-processing consists of Otsu Thresholding, closing, erosion, and opening after the V channel has been determined. The image that has been through postprocessing is then carried out the process of extracting image features through centroid extraction by finding the coordinates of the center point (x, y) of each object. The stages of the training data image processing can be seen in</span><a href="#bookmark20"><span class="font1"> Figure 6 </span></a><span class="font1">below.</span></p><img src="https://jurnal.harianregional.com/media/59109-6.jpg" alt="" style="width:423pt;height:566pt;">
<p><a name="bookmark20"></a><span class="font1" style="font-weight:bold;">Figure 6 </span><span class="font1">The image processing process to get the centroid characteristics that will determine the coordinates of students' hair (a. Image input, b. Image of HSV results, c. Image of Gaussian Blur filtering result, d. Image of K-Means segementation result, e. Image of V Channel results, f. Image of Otsu Thresholding results, g. Image of Opening results, h. Image of Centroid Feature Extraction)</span></p>
<p><span class="font1">Audio data processing using MFCC is displayed in tabular and graphical form, as shown below. Voice feature extraction with MFCC produces an array of MFCC results of 20 values, which are then used as a feature value in the process of establishing the model during training.</span></p><img src="https://jurnal.harianregional.com/media/59109-7.jpg" alt="" style="width:428pt;height:122pt;">
<p><span class="font1" style="font-weight:bold;">Figure 7 </span><span class="font1">Audio processing with MFCC</span></p>
<p><a name="bookmark21"></a><span class="font1">The graph in</span><a href="#bookmark21"><span class="font1"> Figure 7 </span></a><span class="font1">shows the spectrum of MFCC values generated within 5 seconds while the MFCC values in the table are presented as many as 20 values. Cepstrum, in the form of the coefficient value of the features/features of the sound signal is the result of the MFCC feature extraction method, which is to get the coefficient value as the typical value of the sound signal so that the sound signal pattern is easily recognized. The process of modeling data in the training menu is done after all training data has been entered.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark22"></a><span class="font1" style="font-weight:bold;"><a name="bookmark23"></a>3.2. &nbsp;&nbsp;&nbsp;Testing and Evaluation Data</span></h2></li></ul>
<p><span class="font1">The results of testing the data performed by the system can be seen in</span><a href="#bookmark24"><span class="font1"> Figure 8.</span></a><span class="font1"> Test data that has been prepared through the acquisition phase will be processed to produce a classification of data which is then stored after going through an evaluation process by an expert. Tests carried out using the same 50 test data in each kernel. The use of kernels in SVM aims to classify data that cannot be classified linearly. SVM is the most well-known method with a wide range of data classes that uses the kernel to represent data and can be called a kernel-based method [25].</span></p><img src="https://jurnal.harianregional.com/media/59109-8.jpg" alt="" style="width:413pt;height:245pt;">
<p><span class="font1" style="font-weight:bold;">Figure 8 </span><span class="font1">Testing data interface</span></p><img src="https://jurnal.harianregional.com/media/59109-9.jpg" alt="" style="width:415pt;height:247pt;">
<p><span class="font1" style="font-weight:bold;">Figure 9 </span><span class="font1">Evaluation result interface</span></p>
<p><a name="bookmark25"></a><span class="font1">After testing the data, the result will be evaluated by experts in this case conducted by the teacher to see the comparison of the results of the classification carried out by the system with actual conditions. The evaluation menu interface shown in</span><a href="#bookmark25"><span class="font1"> Figure 9.</span></a><span class="font1"> The test results for each kernel are presented in the confusion matrix as follows.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark26"></a><span class="font1" style="font-weight:bold;"><a name="bookmark27"></a><a name="bookmark28"></a>3.2.1. &nbsp;&nbsp;&nbsp;Linear Kernel</span></h2></li></ul>
<p><span class="font1" style="font-weight:bold;">Table 1 </span><span class="font1">Confusion matrix table in a Linear kernel with 50 test data</span></p>
<table border="1">
<tr><td colspan="2" style="vertical-align:middle;">
<p><span class="font1" style="font-weight:bold;">N = 50</span></p></td><td colspan="2" style="vertical-align:middle;">
<p><span class="font1" style="font-weight:bold;">Actual</span></p></td></tr>
<tr><td style="vertical-align:top;"></td><td style="vertical-align:top;"></td><td style="vertical-align:bottom;">
<p><span class="font1">Regular</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">Irregular</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font1" style="font-weight:bold;">Predict</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">Regular</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">23</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">8</span></p></td></tr>
<tr><td style="vertical-align:top;"></td><td style="vertical-align:bottom;">
<p><span class="font1">Irregular</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">3</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">16</span></p></td></tr>
</table>
<p><span class="font1">Based on</span><a href="#bookmark26"><span class="font1"> Table 1 </span></a><span class="font1">above, the calculation results obtained are 78% accuracy, 74% precision, 89% recall, and F-measure value of 80% for testing in linear kernels.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark29"></a><span class="font1" style="font-weight:bold;"><a name="bookmark30"></a><a name="bookmark31"></a>3.2.2. &nbsp;&nbsp;&nbsp;Polynomial Kernel</span></h2></li></ul>
<p><span class="font1" style="font-weight:bold;text-decoration:underline;">Table 2 </span><span class="font1" style="text-decoration:underline;">Confusion matrix table in a Polynomial kernel with 50 test data</span></p>
<p><span class="font1" style="font-weight:bold;">n = 50 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Actual</span></p>
<p><span class="font1">Regular &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Irregular</span></p>
<p><span class="font1" style="font-weight:bold;">Predict &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="font1" style="text-decoration:underline;">Regular &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;20 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;9</span></p>
<p><span class="font1">Irregular &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;6 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;15</span></p>
<p><span class="font1">Based on</span><a href="#bookmark29"><span class="font1"> Table 2 </span></a><span class="font1">above, the results obtained are 70% accuracy calculation, 69% precision, 77% recall, and F-measure value of 73% for testing on the polynomial kernel.</span></p>
<p><span class="font1">A comparison of the results of accuracy, precision, recall, and f-measure linear and polynomial kernels can be seen more clearly in the following graph.</span></p><img src="https://jurnal.harianregional.com/media/59109-10.jpg" alt="" style="width:307pt;height:170pt;">
<p><a name="bookmark32"></a><span class="font1" style="font-weight:bold;">Figure 10 </span><span class="font1">Comparison graph of the accuracy, precision, recall, and f-measure of linear and polynomial kernels</span></p>
<p><a href="#bookmark32"><span class="font1">Figure 10 </span></a><span class="font1">shows that the linear kernel produces an average success rate in classifying regular and irregular classes higher than the polynomial kernel, seen from the level of accuracy, precision, recall, and f-measure. Linear kernels detect true data more than actual polynomial kernels by using the same 50 test data for each kernel because the linear kernel separates the data linearly and straight line. The same results are obtained by Supriya Pahwa with the research entitled “Comparison Of Various Kernels Of Support Vector Machine” which in his research stated that linear kernel gives the best performance an average of 88.20% correct classification compared to other types of kernel functions [26].</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark33"></a><span class="font1" style="font-weight:bold;"><a name="bookmark34"></a>4. Conclusion</span></h2></li></ul>
<p><span class="font1">This research aims to classify the condition of the classroom whether regularly or irregularly as we can see problems that occur when the teacher is not in class, students tend to make noise. Based on experiments which were conducted in this research, the number of conclusions can be drawn, that to obtain the information whether the class is regular or not, the image and audio data of the class conditions must go through a processing stage first. The image was processed through the stages of preprocessing, segmentation with K-Means and hair centroid extractions, which were used as features in this study. The method used for sound feature extraction in this research is MFCC. The test was carried out by using 125 training data and 50 data for each kernel, it obtained accuracy on the linear kernel of 78% and 70% polynomial kernel. It can be concluded that SVM works well in linear kernels in classifying regular and irregular classes.</span></p>
<h2><a name="bookmark35"></a><span class="font1" style="font-weight:bold;"><a name="bookmark36"></a>References</span></h2>
<ul style="list-style:none;"><li>
<p><span class="font1">[1] &nbsp;&nbsp;&nbsp;S. Suprihatin, “Upaya Guru Dalam Meningkatkan Motivasi Belajar Siswa,” </span><span class="font1" style="font-style:italic;">PROMOSI</span></p></li></ul>
<p><span class="font1" style="font-style:italic;">(Jurnal Program Studi Pendidikan Ekonomi)</span><span class="font1">, vol. 3, no. 1, pp. 73–82, May 2015.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1">[2] &nbsp;&nbsp;&nbsp;I. Gede Aris Gunadi, A. Harjoko, R. Wardoyo, and N. Ramdhani, “Fake Smile Detection</span></p></li></ul>
<p><span class="font1">Using Linear Support Vector Machine,” in </span><span class="font1" style="font-style:italic;">Proceedings of 2015 International Conference on Data and Software Engineering, ICODSE 2015</span><span class="font1">, pp. 103–107, 2016.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1">[3] &nbsp;&nbsp;&nbsp;R. Munawarah, O. Soesanto, and M. R. Faisal, “Penerapan Metode Support Vector</span></p></li></ul>
<p><span class="font1">Machine Pada Diagnosa Hepatitis,” </span><span class="font1" style="font-style:italic;">Kumpulan JurnaL Ilmu Komputer (KLIK)</span><span class="font1">, vol. 04, no. 01, pp. 73–82, Feb 2016.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1">[4] &nbsp;&nbsp;&nbsp;T. Ozeki and E. Watanabe, “Analysis of the Behavior of Students Considering Privacy,”</span></p></li></ul>
<p><span class="font1">in </span><span class="font1" style="font-style:italic;">The 6th IIEEJ International Conference on Image Electronics and Visual Computing</span><span class="font1">, no. 1P-3, 2019.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1">[5] &nbsp;&nbsp;&nbsp;I. M. S. P. Kadek Novar Setiawan, “Klasifikasi Citra Mammogram Menggunakan Metode</span></p></li></ul>
<p><span class="font1">K-Means, GLCM, dan Support Vector Machine (SVM),” </span><span class="font1" style="font-style:italic;">Jurnal Ilmiah Merpati (Menara Penelitian Akademika Teknologi Informasi)</span><span class="font1">, vol. 6, no. 1, pp. 13–24, 2018.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1">[6] &nbsp;&nbsp;&nbsp;A. Awais, S. Kun, Y. Yu, S. Hayat, A. Ahmed, and T. Tu, “Speaker Recognition Using</span></p></li></ul>
<p><span class="font1">Mel Frequency Cepstral Coefficient and Locality Sensitive Hashing,” in </span><span class="font1" style="font-style:italic;">2018 International Conference on Artificial Intelligence and Big Data, ICAIBD 2018</span><span class="font1">, pp. 271276, 2018.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1">[7] &nbsp;&nbsp;&nbsp;B. J. Mohan and N. Ramesh Babu, “Speech Recognition Using MFCC and DTW,” in</span></p></li></ul>
<p><span class="font1" style="font-style:italic;">2014 International Conference on Advances in Electrical Engineering, ICAEE 2014</span><span class="font1">, pp.1-4, 2014.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1">[8] &nbsp;&nbsp;&nbsp;O. Lézoray and L. Grady, </span><span class="font1" style="font-style:italic;">Image Processing and Analysis with Graphs: Theory and</span></p></li></ul>
<p><span class="font1" style="font-style:italic;">Practice</span><span class="font1">. CRC Press, 2012.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1">[9] &nbsp;&nbsp;&nbsp;M. Loesdau, S. Chabrier, and A. Gabillon, “Hue and saturation in the RGB color space,”</span></p></li></ul>
<p><span class="font1">in </span><span class="font1" style="font-style:italic;">Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)</span><span class="font1">, pp. 203-212, Springer International Publishing, 2014.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1">[10] &nbsp;&nbsp;&nbsp;E. S. Gedraite and M. Hadad, “Investigation on the effect of a Gaussian Blur in image filtering and segmentation,” in </span><span class="font1" style="font-style:italic;">Proceedings Elmar - International Symposium Electronics in Marine</span><span class="font1">, pp. 393-396, 2011.</span></p></li>
<li>
<p><span class="font1">[11] &nbsp;&nbsp;Darma Putra, </span><span class="font1" style="font-style:italic;">Pengolahan Citra Digital</span><span class="font1">. Yogyakarta: Penerbit Andi, 2010.</span></p></li>
<li>
<p><span class="font1">[12] &nbsp;&nbsp;S. S. Dhumal and S. S. Agrawal, “MRI Classification and Segmentation of Cervical</span></p></li></ul>
<p><span class="font1">Cancer to Find the Area of Tumor,” </span><span class="font1" style="font-style:italic;">International Journal for Research in Applied Science &amp;&nbsp;Engineering Technology (IJRASET)</span><span class="font1">, vol. 3, no. VII, pp. 21-26, 2015.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1">[13] &nbsp;&nbsp;&nbsp;A. Mohd, G. K. Ram, and A. Shafeeq, “Skin Cancer Classification Using K-Means Clustering,” </span><span class="font1" style="font-style:italic;">International Journal of Technical Research and Applications</span><span class="font1">, vol. 5, no. 1, pp. 62-65, 2017.</span></p></li>
<li>
<p><span class="font1">[14] &nbsp;&nbsp;&nbsp;H. Kim, E. Ahn, S. Cho, M. Shin, and S. H. Sim, “Comparative Analysis of Image Binarization Methods for Crack Identification in Concrete Structures,” </span><span class="font1" style="font-style:italic;">Cement and Concrete Research</span><span class="font1">, vol. 99, pp. 53-61, Sep. 2017.</span></p></li>
<li>
<p><span class="font1">[15] &nbsp;&nbsp;&nbsp;L. Najman, J. C. Pesquet, and H. Talbot, “When Convex Analysis Meets Mathematical Morphology on Graphs,” </span><span class="font1" style="font-style:italic;">Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)</span><span class="font1">, vol. 9082, pp.473-484, 2015.</span></p></li>
<li>
<p><span class="font1">[16] &nbsp;&nbsp;&nbsp;Y. Chugh, R. Gupta, and R. Kaushik, “Image Enhancement Using Morphological Operators,” </span><span class="font1" style="font-style:italic;">International Journal of Engineering Technology</span><span class="font1">, vol. 3, special Issue, pp. 61-66, 2015.</span></p></li>
<li>
<p><span class="font1">[17] &nbsp;&nbsp;&nbsp;T. Chamidy, “Metode Mel Frequency Cepstral Coeffisients (MFCC) pada Klasifikasi Hidden Markov Model (HMM) untuk Kata Arabic pada Penutur Indonesia,” </span><span class="font1" style="font-style:italic;">Jurnal Matics</span><span class="font1">, vol. 8, no. 1, pp. 33-40, 2016.</span></p></li>
<li>
<p><span class="font1">[18] &nbsp;&nbsp;&nbsp;N. Guenther and M. Schonlau, “Support Vector Machines,” </span><span class="font1" style="font-style:italic;">The Stata Journal: Promoting Communications on Statistics and Stata</span><span class="font1">, vol. 16, no. 4, pp. 119-127, 2016.</span></p></li>
<li>
<p><span class="font1">[19] &nbsp;&nbsp;&nbsp;M. Aykanat, O. Kιl</span><span class="font6">∣</span><span class="font1">Q, B. Kurt, and S. Saryal, “Classification of Lung Sounds Using Convolutional Neural Networks,” </span><span class="font1" style="font-style:italic;">Eurasip Journal on Image and Video Processing</span><span class="font1">, no. 65, 2017.</span></p></li>
<li>
<p><span class="font1">[20] &nbsp;&nbsp;&nbsp;A. F. Indriani and M. A. Muslim, “SVM Optimization Based on PSO and AdaBoost to Increasing Accuracy of CKD Diagnosis,” </span><span class="font1" style="font-style:italic;">Lontar Komputer : Jurnal Ilmiah Teknologi Informasi</span><span class="font1">, vol. 10, no. 2, pp. 119-127, Aug 2019.</span></p></li>
<li>
<p><span class="font1">[21] &nbsp;&nbsp;&nbsp;Y. R. Nugraha, A. P. Wibawa, and I. A. E. Zaeni, “Particle Swarm Optimization-Support Vector Machine (PSO-SVM) Algorithm for Journal Rank Classification,” in </span><span class="font1" style="font-style:italic;">Proceedings -2019 2nd International Conference of Computer and Informatics Engineering: Artificial Intelligence Roles in Industrial Revolution 4.0, IC2IE 2019</span><span class="font1">, 2019, pp. 69-73.</span></p></li>
<li>
<p><span class="font1">[22] &nbsp;&nbsp;&nbsp;P. Rebentrost, M. Mohseni, and S. Lloyd, “Quantum Support Vector Machine for Big Data Classification,” </span><span class="font1" style="font-style:italic;">Physical Review Letters</span><span class="font1">, vol. 113, no. 13, pp. 130503, Sep. 2014.</span></p></li>
<li>
<p><span class="font1">[23] &nbsp;&nbsp;&nbsp;D. P. Kaucha, P. W. C. Prasad, A. Alsadoon, A. Elchouemi, and S. Sreedharan, “Early</span></p></li></ul>
<p><span class="font1">Detection of Lung Cancer using SVM Classifier in Biomedical Image Processing,”in </span><span class="font1" style="font-style:italic;">IEEE International Conference on Power, Control, Signals and Instrumentation Engineering (ICPCSI)</span><span class="font1">, pp. 3143–3148, 2017.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1">[24] &nbsp;&nbsp;R. Fernandes de Mello, M. Antonelli Ponti, R. Fernandes de Mello, and M. Antonelli</span></p></li></ul>
<p><span class="font1">Ponti, “Introduction to Support Vector Machines,” in </span><span class="font1" style="font-style:italic;">Machine Learning</span><span class="font1">, 2018.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1">[25] &nbsp;&nbsp;M. Gönen and E. Alpaydin, “Multiple Kernel Learning Algorithms,” </span><span class="font1" style="font-style:italic;">Journal of Machine</span></p></li></ul>
<p><span class="font1" style="font-style:italic;">Learning Research</span><span class="font1">, vol. 12. pp. 2211–2268, Jul-2011.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1">[26] &nbsp;&nbsp;&nbsp;S. Pahwa and D. Sinwar, “Comparison Of Various Kernels Of Support Vector Machine,” </span><span class="font1" style="font-style:italic;">International Journal for Research in Applied Science &amp;&nbsp;Engineering Technology (IJRASET)</span><span class="font1">, vol. 3, no. VII, pp. 532–536, 2015.</span></p></li></ul>
<p><span class="font1">31</span></p>