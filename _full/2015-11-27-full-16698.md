---
layout: full_article
title: "TERM WEIGHTING BERBASIS INDEKS BUKU DAN KELAS UNTUK PERANGKINGAN DOKUMEN BERBAHASA ARAB"
author: "M. Ali Fauzi, Agus Arifin, Anny Yuniarti"
categories: lontar
canonical_url: https://jurnal.harianregional.com/lontar/full-16698 
citation_abstract_html_url: "https://jurnal.harianregional.com/lontar/id-16698"
citation_pdf_url: "https://jurnal.harianregional.com/lontar/full-16698"  
comments: true
---

<p><span class="font1" style="font-weight:bold;">LONTAR KOMPUTER VOL. 5, NO. 2, AGUSTUS 2014</span></p>
<p><span class="font1" style="font-weight:bold;">ISSN: 2088-1541</span></p><a name="caption1"></a>
<h1><a name="bookmark0"></a><span class="font4" style="font-weight:bold;"><a name="bookmark1"></a>Term Weighting Berbasis Indeks Buku dan Kelas untuk Perangkingan Dokumen Berbahasa Arab</span></h1>
<p><span class="font1" style="font-weight:bold;">M. Ali Fauzi<sup>1</sup>, Dr. Agus Zainal Arifin<sup>2</sup>, S.Kom, M.Kom, Anny Yuniarti<sup>3</sup>, S.Kom, M.Comp.Sc </span><span class="font1">Institut Teknologi Sepuluh Nopember e-mail: </span><a href="mailto:moch.ali.fauzi@gmail.com"><span class="font1">moch.ali.fauzi@gmail.com</span></a></p>
<p><span class="font1" style="font-weight:bold;font-style:italic;">Abstrak</span></p>
<p><span class="font1" style="font-style:italic;">Information Retrieval berdasarkan query tertentu sudah jamak ditemukan pada sistem komputer saat ini. Salah satu metode yang populer digunakan adalah perangkingan dokumen menggunakan space vector model berbasis pada nilai term weighting TF.IDF. Pada penelitian ini, terdapat beberapa buku berbahasa Arab yang memiliki puluhan bahkan ratusan halaman. Masing-masing halaman dari buku tersebut adalah sebuah dokumen yang akan diranking berdasarkan query dari pengguna. TF.IDF hanya melakukan pembobotan berbasis pada dokumen tanpa memperhatikan indeks buku dan kelas yang merupakan induk dokumen tersebut sehingga kinerjanya kurang maksimal jika diimplementasikan pada kasus ini. Oleh karena itu, diusulkan metode baru term weighting yang berbasis pada indeks buku dan kelas. Metode ini memperhatikan frekuensi kemunculan term pada keseluruhan buku dan kelas. Metode yang disebut inverse class frequency (ICF) dan inverse book frequency (IBF) ini digabungkan dengan metode sebelumnya sehingga menjadi TF.IDF.ICF.IBF. Pengujian metode ini menggunakan dataset dari beberapa e-book berbahasa arab. Hasil penelitian menunjukkan bahwa metode yang diajukan terbukti dapat diaplikasikan pada perangkingan dokumen berbahasa arab dan memiliki performa yang lebih bagus dibanding metode sebelumnya dengan nilai F-Measure 75%, precision 76%, dan recall mencapai 74%.</span></p>
<p><span class="font1" style="font-weight:bold;font-style:italic;">Kata kunci: </span><span class="font1" style="font-style:italic;">Perankingan Dokumen, Term Weighting, IBF, Indeks Buku, Indeks Kelas</span></p>
<p><span class="font1" style="font-weight:bold;font-style:italic;">Abstract</span></p>
<p><span class="font1" style="font-style:italic;">Information Retrieval based on specific queries is common to the current computer systems. One of the popular methods used is the document ranking method using vector space models based on TF.IDF term weighting. In this study, there are several books in Arabic that has tens or even hundreds of pages. Each page of the book is a single document that will be ranked based on the user query. TF.IDF only performs term weighting based on the document without regard to the indexes of the book and class of the document. Therefore, a new method of term weighting that based on books and classes indexes proposed. This method favor the frequency of term in whole books and classes. This method that called inverse class frequency (ICF) and inverse book frequency (IBF) then combined with the previous method so that it becomes TF.IDF.ICF.IBF. This new method was tested using a dataset from some Arabic e-books. The experimental results show that the proposed method can be implemented on document ranking method and the performances are better than some previous methods with F-Measure value 75%, precision value 76%, dan recall value 74%.</span></p>
<p><span class="font1" style="font-weight:bold;font-style:italic;">Keywords: </span><span class="font1" style="font-style:italic;">Dokument Ranking, Term Weighting, IBF, Book Index, Class Index</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark2"></a><span class="font1" style="font-weight:bold;"><a name="bookmark3"></a>1. &nbsp;&nbsp;&nbsp;Pendahuluan</span></h2></li></ul>
<p><span class="font1">Tujuan dari sistem temu kembali informasi adalah menemukan informasi yang paling relevan untuk memenuhi kebutuhan informasi pengguna. Salah satu pembahasan temu kembali informasi yang biasa di teliti adalah tentang perangkingan dokumen. Perangkingan dokumen dilakukan untuk mendapatkan dokumen-dokumen yang relevan dengan </span><span class="font1" style="font-style:italic;">query</span><span class="font1"> pengguna diurutkan dari tingkat relevansinya [1][2].</span></p>
<p><span class="font1">Beberapa penelitian yang membahas perangkingan dokumen berbahasa Arab telah dilakukan sebelumnya, seperti perangkingan dengan menggunakan pencocokan </span><span class="font1" style="font-style:italic;">N-gram</span><span class="font1"> terhadap kata dari </span><span class="font1" style="font-style:italic;">query</span><span class="font1"> dan dokumen [3][4], menggunakan modul </span><span class="font1" style="font-style:italic;">crawler</span><span class="font1"> dokumen dengan </span><span class="font1" style="font-style:italic;">feedback</span><span class="font1"> bentuk kata yang tepat [2], dan berdasarkan variasi </span><span class="font1" style="font-style:italic;">orthographic</span><span class="font1"> [5]. Harrag dkk menggunakan </span><span class="font1" style="font-style:italic;">vector space model</span><span class="font1"> berbasis </span><span class="font1" style="font-style:italic;">term weighting</span><span class="font1"> TF.IDF untuk melakukan perangkingan pada dokumen berbahasa Arab. Pada metode ini dokumen direpresentasikan sebagai sebuah vektor yang dibentuk dari nilai-nilai term yang menjadi indeknya [6]. Nilai-nilai </span><span class="font1" style="font-style:italic;">term</span><span class="font1"> tersebut dihitung dengan menggunakan </span><span class="font1" style="font-style:italic;">term weighting</span><span class="font1"> TF.IDF. TF.IDF mengkombinasikan </span><span class="font1" style="font-style:italic;">term frequency</span><span class="font1"> (TF) yang mengukur kepadatan term dalam sebuah dokumen dikalikan dengan inverse document frequency (IDF) yang mengukur keinformatifan sebuah </span><span class="font1" style="font-style:italic;">term</span><span class="font1"> (kelangkaannya pada keseluruhan korpus) [7]. Akan tetapi, term weighting dengan TF.IDF yang hanya berbasis pada dokumen itu tidak cukup untuk menentukan indeks dari suatu dokumen. Penentuan indeks yang akurat juga bergantung pada keinformatifan </span><span class="font1" style="font-style:italic;">term</span><span class="font1"> terhadap kelas (kelangkaanya pada keseluruhan kelas). Term yang sering muncul di banyak kelas seharusnya tidak menjadi </span><span class="font1" style="font-style:italic;">term</span><span class="font1"> yang penting meskipun nilai TF.IDFnya tinggi. Oleh karena itu, Fuji Ren &amp;&nbsp;Mohammad Golam Sohrab mengusulkan penggunaan pembobotan berbasis kelas untuk </span><span class="font1" style="font-style:italic;">term weighting</span><span class="font1"> pada dokumen berbahasa Inggris yang dinamakan </span><span class="font1" style="font-style:italic;">inverse class frequency</span><span class="font1"> (ICF) dan variasinya, </span><span class="font1" style="font-style:italic;">Inverse Class Space density Frequency</span><span class="font1"> (ICSdF) [8]. Dengan ICF dan ICSdF ini </span><span class="font1" style="font-style:italic;">term</span><span class="font1"> yang sering muncul pada banyak kelas akan memiliki nilai yang kecil. Metode ini terbukti memiliki </span><span class="font1" style="font-style:italic;">precision</span><span class="font1"> dan </span><span class="font1" style="font-style:italic;">recall </span><span class="font1">yang lebih tinggi daripada TF.IDF [8].</span></p>
<p><span class="font1">Dalam penelitian ini, dibutuhkan metode perangkingan halaman-halaman buku berbahasa Arab. Buku-buku tersebut memiliki jumlah halaman yang banyak, antara puluhan hingga ratusan halaman. Masing-masing halaman buku adalah sebuah dokumen. Hasil pencarian </span><span class="font1" style="font-style:italic;">query</span><span class="font1"> dari pengguna akan menunjukkan dokumen halaman berapakah dan dari buku manakah yang sesuai dengan </span><span class="font1" style="font-style:italic;">query</span><span class="font1"> pengguna. </span><span class="font1" style="font-style:italic;">Term weighting</span><span class="font1"> yang hanya berbasis pada dokumen dan kelas semacam TF.IDF.ICF tidak cukup untuk menentukan indeks dari suatu dokumen halaman-halaman buku. Buku dapat dikatakan sebagai bentuk lain dari kelas atau kategori. Semua dokumen (halaman) dalam sebuah buku pasti membahas topik yang hampir sama. Seperti pada ICF, beberapa indeks buku seharusnya juga menjadi </span><span class="font1" style="font-style:italic;">term</span><span class="font1"> kunci bagi dokumen-dokumen di dalam buku tersebut. Selain itu, keinformatifan term terhadap buku (kelangkaanya pada keseluruhan buku) juga perlu diperhatikan. Beberapa </span><span class="font1" style="font-style:italic;">term</span><span class="font1"> yang sering muncul pada suatu buku pasti akan memiliki TF.IDF.ICF yang tinggi, akan tetapi </span><span class="font1" style="font-style:italic;">term</span><span class="font1"> itu belum tentu bisa dikatakan sebagai term kunci sebelum dihitung kelangkaanya pada keseluruhan buku. </span><span class="font1" style="font-style:italic;">Term</span><span class="font1"> yang sering muncul pada banyak ragam buku seharusnya tidak memiliki nilai yang tinggi karena tidak mencerminkan indeks buku tersebut.</span></p>
<p><span class="font1">Oleh karena itu, diusulkan metode baru pembobotan </span><span class="font1" style="font-style:italic;">term</span><span class="font1"> berbasis buku untuk perangkingan dokumen bahasa Arab yang dinamakan </span><span class="font1" style="font-style:italic;">inverse book frequency</span><span class="font1"> (IBF) untuk meningkatkan performa perangkingan dokumen yang memiliki hierarki berupa buku-buku yang memiliki banyak halaman. Perhitungan IBF ini akan dikombinasikan juga dengan metode sebelumnya sehingga menjadi TF.IDF.ICF.IBF. Metode ini dapat diterapkan pada dokumen semua bahasa secara umum yang memiliki hierarki berupa buku-buku yang memiliki banyak halaman. Akan tetapi, dilihat dari keperluan penerapan metode ini pada aplikasi pencarian kitab berbahasa Arab serta sumber dataset dan ground truth dari </span><span class="font1" style="font-style:italic;">expert</span><span class="font1"> yang dimiliki adalah dokumen-dokumen berbahasa Arab maka metode ini akan diterapkan pada </span><span class="font1" style="font-style:italic;">Information Retrieval</span><span class="font1"> dokumen berbahasa Arab. Metode TF.IDF.ICF.IBF ini diharapkan </span><span class="font1" style="font-style:italic;">precision</span><span class="font1"> dan </span><span class="font1" style="font-style:italic;">recall</span><span class="font1"> yang lebih tinggi pada perangkingan halaman-halaman buku berbahasa Arab dibandingkan dengan metode sebelumnya.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark4"></a><span class="font1" style="font-weight:bold;"><a name="bookmark5"></a>2. &nbsp;&nbsp;&nbsp;Metodologi Penelitian</span></h2></li></ul>
<p><span class="font1">Secara garis besar, skema metode perankingan dokumen dalam penelitian ini terdiri dari dua tahapan utama, yaitu penentuan indeks dokumen dan perangkingan dokumen berdasarkan </span><span class="font1" style="font-style:italic;">query</span><span class="font1"> dari pengguna. Perangkingan dokumen dilakukan berdasarkan perhitungan </span><span class="font1" style="font-style:italic;">similarity </span><span class="font1">antara </span><span class="font1" style="font-style:italic;">vector</span><span class="font1"> indeks dokumen dan </span><span class="font1" style="font-style:italic;">query</span><span class="font1"> yang berbasis pada pembobotan </span><span class="font1" style="font-style:italic;">term </span><span class="font1">TF.IDF.ICF.IBF. Bagan besar proses perangkingan ini seperti terlihat pada Gambar 1.</span></p>
<p><span class="font1">Sebelum dilakukan proses perangkingan perlu dilakukan tahapan indexing seperti terlihat pada Gambar 1. Pada tahapan ini terdapat beberapa proses yang saling berkesinambungan. proses-proses dalam tahap ini diantaranya </span><span class="font1" style="font-style:italic;">tokenization</span><span class="font1">, </span><span class="font1" style="font-style:italic;">filtering</span><span class="font1">, </span><span class="font1" style="font-style:italic;">stopwords removal</span><span class="font1">, </span><span class="font1" style="font-style:italic;">stemming</span><span class="font1"> dan penghitungan bobot.</span></p><img src="https://jurnal.harianregional.com/media/16698-1.jpg" alt="" style="width:262pt;height:405pt;">
<p><span class="font1" style="font-weight:bold;">Gambar 1. Skema Proses Perangkingan Dokumen</span></p>
<p><span class="font1">Untuk </span><span class="font1" style="font-style:italic;">stemming</span><span class="font1"> akan digunakan </span><span class="font1" style="font-style:italic;">light stemmer</span><span class="font1"> yang sering digunakan dalam </span><span class="font1" style="font-style:italic;">information retrieval</span><span class="font1"> teks Arab [9]. Setelah itu, akan didapatkan sebuah set fitur original dari semua dokumen. Melalui metode </span><span class="font1" style="font-style:italic;">feature selection</span><span class="font1">, set fitur original tersebut akan dipilih sebuah subset yang berisi beberapa fitur terbaik sesuai dengan kriteria tertentu yang dalam penelitian ini adalah nilai TF.IDF.ICF.IBF. Subset terbaik inilah yang disebut sebagai indeks dari dokumen tersebut.</span></p>
<p><span class="font1">Indeks dari dokumen-dokumen tersebut akan dihitung kemiripannya dengan </span><span class="font1" style="font-style:italic;">query</span><span class="font1"> yang dimasukkan oleh pengguna. Perhitungan kemiripan ini dilakukan dengan menggunakan perhitungan </span><span class="font1" style="font-style:italic;">cosine similarity</span><span class="font1"> yang berbasis pada TF.IDF.ICF.IBF. Dokumen-dokumen yang didapatkan akan diurutkan secara </span><span class="font1" style="font-style:italic;">descending</span><span class="font1"> sesuai dengan nilai </span><span class="font1" style="font-style:italic;">cosine similarity</span><span class="font1">nya. Hasil ini menunjukkan hasil perangkingan dokumen sesuai tingkat kemiripannya dengan </span><span class="font1" style="font-style:italic;">query </span><span class="font1">pengguna.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark6"></a><span class="font1" style="font-weight:bold;"><a name="bookmark7"></a>3. &nbsp;&nbsp;&nbsp;Kajian Pustaka</span><br><br><span class="font1" style="font-weight:bold;"><a name="bookmark8"></a>3.1 &nbsp;&nbsp;&nbsp;Pembobotan </span><span class="font1" style="font-weight:bold;font-style:italic;">Term</span></h2></li></ul>
<p><span class="font1">Perangkingan dokumen menggunakan representasi </span><span class="font1" style="font-style:italic;">vector space model</span><span class="font1"> dari kumpulan dataset. Dokumen dalam </span><span class="font1" style="font-style:italic;">vector space model</span><span class="font1"> direpresentasikan dalam </span><span class="font1" style="font-style:italic;">matriks</span><span class="font1"> yang berisi bobot kata pada dokumen. Bobot tersebut menyatakan kepentingan/kontribusi kata terhadap suatu dokumen dan kumpulan dokumen. Kepentingan suatu kata dalam dokumen dapat dilihat dari frekuensi kemunculannya terhadap dokumen. Biasanya kata yang berbeda memiliki frekuensi yang berbeda. Dibawah ini terdapat beberapa metode pembobotan :</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1">1.</span><span class="font1" style="font-style:italic;"> &nbsp;&nbsp;&nbsp;Term Frequency</span><span class="font1"> (TF)</span></p></li></ul>
<p><span class="font1" style="font-style:italic;">Term frequency</span><span class="font1"> merupakan metode yang paling sederhana dalam membobotkan setiap </span><span class="font1" style="font-style:italic;">term</span><span class="font1">. Setiap </span><span class="font1" style="font-style:italic;">term</span><span class="font1"> diasumsikan memiliki kepentingan yang proporsional terhadap jumlah kemunculan </span><span class="font1" style="font-style:italic;">term</span><span class="font1"> pada dokumen. Bobot dari </span><span class="font1" style="font-style:italic;">term</span><span class="font1"> t pada dokumen d yaitu:</span></p>
<p><span class="font1" style="font-style:italic;">TF (d, t) = f (d, t J</span><span class="font1">, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1)</span></p>
<p><span class="font1">dimana </span><span class="font1" style="font-style:italic;">f(d,t)</span><span class="font1"> adalah frekuensi kemunculan </span><span class="font1" style="font-style:italic;">term t</span><span class="font1"> pada dokumen </span><span class="font1" style="font-style:italic;">d</span><span class="font1">.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1">2.</span><span class="font1" style="font-style:italic;"> &nbsp;&nbsp;&nbsp;Inverse Document Frequency</span><span class="font1"> (IDF)</span></p></li></ul>
<p><span class="font1">Bila </span><span class="font1" style="font-style:italic;">term frequency</span><span class="font1"> memperhatiakan kemunculan term di dalam dokumen, maka IDF memperhatikan kemunculan term pada kumpulan dokumen. Latar belakang pembobotan ini adalah term yang jarang muncul pada kumpulan dokumen sangat bernilai. Kepentingan tiap </span><span class="font1" style="font-style:italic;">term</span><span class="font1"> diasumsikan memilki proporsi yang berkebalikan dengan jumlah dokumen yang mengandung </span><span class="font1" style="font-style:italic;">term</span><span class="font1">. Faktor IDF dari </span><span class="font1" style="font-style:italic;">term</span><span class="font1"> t yaitu:</span></p>
<p><span class="font1" style="font-style:italic;">IDF (t) = </span><span class="font1">1 + </span><span class="font1" style="font-style:italic;">IogQNd f d f Qt) ),</span><span class="font1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(2)</span></p>
<p><span class="font1">dimana </span><span class="font1" style="font-style:italic;">Nd</span><span class="font1"> adalah jumlah seluruh dokumen, dan </span><span class="font1" style="font-style:italic;">df(t)</span><span class="font1"> jumlah dokumen yang mengandung </span><span class="font1" style="font-style:italic;">term t</span><span class="font1">.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1">3.</span><span class="font1" style="font-style:italic;"> &nbsp;&nbsp;&nbsp;Inverse Class Frequency</span><span class="font1"> (ICF)</span></p></li></ul>
<p><span class="font1">Jika IDF memperhatikan kemunculan </span><span class="font1" style="font-style:italic;">term</span><span class="font1"> pada kumpulan dokumen, maka ICF memperhatikan kemunculan </span><span class="font1" style="font-style:italic;">term</span><span class="font1"> pada kumpulan kategori/kelas. </span><span class="font1" style="font-style:italic;">Term</span><span class="font1"> yang jarang muncul pada banyak kelas adalah </span><span class="font1" style="font-style:italic;">term</span><span class="font1"> yang bernilai untuk klasifikasi. Kepentingan tiap </span><span class="font1" style="font-style:italic;">term </span><span class="font1">diasumsikan memilki proporsi yang berkebalikan dengan jumlah kelas yang mengandung </span><span class="font1" style="font-style:italic;">term</span><span class="font1">. Faktor ICF dari </span><span class="font1" style="font-style:italic;">term</span><span class="font1"> t yaitu:</span></p>
<p><span class="font1" style="font-style:italic;">ICFQt) = l + logQNc/CfQt)),</span><span class="font1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(3)</span></p>
<p><span class="font1">dimana </span><span class="font1" style="font-style:italic;">Nc</span><span class="font1"> adalah jumlah seluruh kelas, </span><span class="font1" style="font-style:italic;">cf(t)</span><span class="font1"> jumlah kelas yang mengandung </span><span class="font1" style="font-style:italic;">term t</span><span class="font1">.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1">4.</span><span class="font1" style="font-style:italic;"> &nbsp;&nbsp;&nbsp;Inverse Book Frequency</span><span class="font1"> (IBF)</span></p></li></ul>
<p><span class="font1">Jika ICF memperhatikan kemunculan term pada kumpulan kelas, maka IBF memperhatikan kemunculan </span><span class="font1" style="font-style:italic;">term</span><span class="font1"> pada kumpulan kitab/buku. </span><span class="font1" style="font-style:italic;">Term</span><span class="font1"> yang jarang muncul pada banyak buku adalah </span><span class="font1" style="font-style:italic;">term</span><span class="font1"> yang sangat bernilai. Kepentingan tiap </span><span class="font1" style="font-style:italic;">term</span><span class="font1"> diasumsikan memilki proporsi yang berkebalikan dengan jumlah buku yang mengandung </span><span class="font1" style="font-style:italic;">term</span><span class="font1">. Faktor IBF dari </span><span class="font1" style="font-style:italic;">term</span><span class="font1"> t yaitu:</span></p>
<p><span class="font1" style="font-style:italic;">IBFQt)</span><span class="font1"> = 1 + </span><span class="font1" style="font-style:italic;">LogQNbfbfQt) ),</span><span class="font1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(4)</span></p>
<p><span class="font1">dimana </span><span class="font1" style="font-style:italic;">Nb</span><span class="font1"> adalah jumlah seluruh buku, </span><span class="font1" style="font-style:italic;">bf(t)</span><span class="font1"> jumlah buku yang mengandung </span><span class="font1" style="font-style:italic;">term t</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1">5. &nbsp;&nbsp;&nbsp;TF.IDF.ICF.IBF</span></p></li></ul>
<p><span class="font1">TF.IDF.ICF.IBF merupakan perkalian antara TF, IDF, ICF dan IBF. Kombinasi bobot dari term </span><span class="font1" style="font-style:italic;">t</span><span class="font1"> pada dokumen </span><span class="font1" style="font-style:italic;">d</span><span class="font1"> yaitu:</span></p>
<p><span class="font1" style="font-style:italic;">TF. IDF.ICF. IBF Qd<sub>1</sub>1) = TFQd, t) x IDFQt) x ICFQt) x IBFQt),</span><span class="font1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(5)</span></p>
<p><span class="font1">dimana </span><span class="font1" style="font-style:italic;">TF(d,t)</span><span class="font1"> adalah nilai TF </span><span class="font1" style="font-style:italic;">term t</span><span class="font1"> pada dokumen </span><span class="font1" style="font-style:italic;">d</span><span class="font1">, IDF(t) adalah nilai IDF </span><span class="font1" style="font-style:italic;">term t</span><span class="font1">, ICF(t) adalah nilai ICF </span><span class="font1" style="font-style:italic;">term t</span><span class="font1"> dan IBF(t) adalah nilai IBF </span><span class="font1" style="font-style:italic;">term t.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1" style="font-weight:bold;">3.2</span><span class="font1" style="font-weight:bold;font-style:italic;"> &nbsp;&nbsp;&nbsp;Cosine Similarity</span></p></li></ul>
<p><span class="font1">Hasil pembobotan kata pada dokumen digunakan sebagai representasi vektor. Dari representasi bobot tersebut dapat dihitung nilai kemiripan suatu dokumen dengan </span><span class="font1" style="font-style:italic;">query</span><span class="font1">. Nilai kemiripan ini biasa dihitung dengan rumusan </span><span class="font1" style="font-style:italic;">cosine similarity</span><span class="font1">, perhitungan tingkat kemiripan ini dibuat dengan berdasar pada besar sudut kosinus antara dua vektor, dalam hal ini adalah vektor dokumen. Representasi perumusan ini dalam bidang kartesian seperti diperlihatkan pada Gambar 2.</span></p>
<div><img src="https://jurnal.harianregional.com/media/16698-2.jpg" alt="" style="width:168pt;height:151pt;">
<p><span class="font1" style="font-weight:bold;">Gambar 2. Representasi Perumusan Cosine Similarity</span></p>
</div><br clear="all">
<p><span class="font1">Dalam Gambar 2. terdapat tiga vektor dokumen </span><span class="font1" style="font-style:italic;">d1, d2</span><span class="font1"> dan </span><span class="font1" style="font-style:italic;">d3</span><span class="font1"> dan satu vektor </span><span class="font1" style="font-style:italic;">query q</span><span class="font1">. </span><span class="font1" style="font-style:italic;">cosine similarity</span><span class="font1"> menghitung nilai kosinus θ dari </span><span class="font1" style="font-style:italic;">query</span><span class="font1"> dan tiga dokumen lain. Nilai ini menunjukkan derajat kemiripan dokumen dengan </span><span class="font1" style="font-style:italic;">query</span><span class="font1">.</span></p>
<p><span class="font1">Karena berdasarkan kosinus sudut antara dua vektor, maka nilainya berkisar pada 0 sampai dengan 1, dimana 0 menandakan bahwa kedua dokumen tidak mirip sama sekali, dan 1 menandakan bahwa antara </span><span class="font1" style="font-style:italic;">query</span><span class="font1"> dan dokumen benar-benar identik. </span><span class="font1" style="font-style:italic;">Cosine</span><span class="font1"> dinyatakan sebagai berikut [10]:</span></p>
<div>
<p><span class="font8" style="font-style:italic;">cos(q</span><span class="font8">, </span><span class="font8" style="font-style:italic;">d <sub>j</sub></span><span class="font8">) </span><span class="font2">=</span></p>
</div><br clear="all">
<p><span class="font5">∑ </span><span class="font3" style="font-style:italic;">[</span><span class="font8" style="font-style:italic;">TFIDF</span><span class="font8">(</span><span class="font8" style="font-style:italic;">t</span><span class="font7" style="font-style:italic;">k</span><span class="font8">, </span><span class="font8" style="font-style:italic;">q</span><span class="font8">)</span><span class="font3">] </span><span class="font2">• </span><span class="font6" style="font-style:italic;">[</span><span class="font8" style="font-style:italic;">TFIDF</span><span class="font8">(</span><span class="font8" style="font-style:italic;">t<sub>k</sub></span><span class="font8">, </span><span class="font8" style="font-style:italic;">d</span><span class="font7" style="font-style:italic;">j</span><span class="font8"> )</span><span class="font6">] </span><span class="font7" style="font-style:italic;">t<sub>k</sub></span></p>
<p><span class="font8">]∑</span><span class="font8" style="font-style:italic;">TFIDFq</span><span class="font8"><sup>2</sup> ∙J∑</span><span class="font8" style="font-style:italic;">TFIDFd</span><span class="font7" style="font-style:italic;">j</span><span class="font8">l<sup>2</sup></span></p>
<div>
<p><span class="font1">(6)</span></p>
</div><br clear="all">
<p><span class="font1">dimana </span><span class="font1" style="font-style:italic;">cos(q,d</span><span class="font0" style="font-style:italic;">j</span><span class="font1" style="font-style:italic;">)</span><span class="font1"> merupakan nilai kosinus antara </span><span class="font1" style="font-style:italic;">query</span><span class="font1"> dan dokumen </span><span class="font1" style="font-style:italic;">j</span><span class="font1">, sedangkan </span><span class="font1" style="font-style:italic;">TFIDF(t</span><span class="font0" style="font-style:italic;">k</span><span class="font1" style="font-style:italic;">,q) </span><span class="font1">dan </span><span class="font1" style="font-style:italic;">TFID F(t</span><span class="font0" style="font-style:italic;">k</span><span class="font1" style="font-style:italic;">,d</span><span class="font0" style="font-style:italic;">j</span><span class="font1" style="font-style:italic;">)</span><span class="font1"> adalah pembobotan </span><span class="font1" style="font-style:italic;">TFIDF</span><span class="font1"> kata </span><span class="font1" style="font-style:italic;">t</span><span class="font0" style="font-style:italic;">k</span><span class="font1"> pada </span><span class="font1" style="font-style:italic;">query</span><span class="font1"> dan dokumen </span><span class="font1" style="font-style:italic;">j</span><span class="font1">. |</span><span class="font1" style="font-style:italic;">TFIDF</span><span class="font1">q| dan |</span><span class="font1" style="font-style:italic;">TFIDFd</span><span class="font0" style="font-style:italic;">j</span><span class="font1">| adalah panjang dari vektor </span><span class="font1" style="font-style:italic;">query</span><span class="font1"> q dan dokumen. Sebagai contoh ||</span><span class="font1" style="font-style:italic;">d</span><span class="font0" style="font-style:italic;">i</span><span class="font1">||<sup>2</sup> = (</span><span class="font1" style="font-style:italic;">TFIDFt</span><span class="font0" style="font-style:italic;">1</span><span class="font1"><sup>2</sup>+ </span><span class="font1" style="font-style:italic;">TFIDFt</span><span class="font0" style="font-style:italic;">2</span><span class="font1"><sup>2</sup>+ </span><span class="font1" style="font-style:italic;">TFIDFt</span><span class="font0" style="font-style:italic;">3</span><span class="font1"><sup>2</sup>+...+</span><span class="font1" style="font-style:italic;">TFIDFt</span><span class="font0" style="font-style:italic;">k</span><span class="font1"><sup>2</sup>)<sup>1/2</sup>, dimana </span><span class="font1" style="font-style:italic;">TFIDFt</span><span class="font0" style="font-style:italic;">k</span><span class="font1"> adalah bobot kata ke-</span><span class="font1" style="font-style:italic;">t</span><span class="font0" style="font-style:italic;">k</span><span class="font1"> pada vektor dokumen </span><span class="font1" style="font-style:italic;">d</span><span class="font0" style="font-style:italic;">i</span><span class="font1">.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark9"></a><span class="font1" style="font-weight:bold;"><a name="bookmark10"></a>4. &nbsp;&nbsp;&nbsp;Hasil dan Pembahasan</span></h2></li></ul>
<p><span class="font1">Data yang digunakan dalam uji coba ini merupakan </span><span class="font1" style="font-style:italic;">corpus</span><span class="font1"> atau kumpulan dokumen teks berbahasa Arab, yang diambil dari 13 kitab dalam perangkat lunak </span><span class="font1" style="font-style:italic;">Maktabah Syamilah. </span><span class="font1">halaman kitab-kitab sebagai suatu dokumen. Jumlah total dokumen dari seluruh kitab tersebut adalaha 6996 dokumen yang tersebar dalam 5 kategori. Dan dari seluruh dokumen dataset tersebut terdapat 47.447 kata bebeda (</span><span class="font1" style="font-style:italic;">distinct term</span><span class="font1">).</span></p>
<p><span class="font1">Pengujian dilakukan pada 7 </span><span class="font1" style="font-style:italic;">query</span><span class="font1"> yang memiliki lebih dari satu dokumen hasil pencarian yang relevan. Pengujian ini juga dilakukan dengan memakai beberapa variasi </span><span class="font1" style="font-style:italic;">feature selection</span><span class="font1">, yaitu 1000, 500, dan 250 fitur terbaik. </span><span class="font1" style="font-style:italic;">Ground Truth</span><span class="font1"> yang dipakai pada pengujian ini berasal dari data</span></p>
<p><span class="font1" style="font-style:italic;">expert</span><span class="font1"> yang berisi daftar </span><span class="font1" style="font-style:italic;">query</span><span class="font1"> beserta dokumen-dokumen hasil pencarianya yang relevan. Dokumen yang dimaksud di sini adalah halaman tertentu dari sebuah buku.</span></p>
<p><span class="font1">Pada pengujian ini dilakukan pengukuran </span><span class="font1" style="font-style:italic;">precision</span><span class="font1">, </span><span class="font1" style="font-style:italic;">recall</span><span class="font1">, dan </span><span class="font1" style="font-style:italic;">F-Measure</span><span class="font1">. Hasil uji coba dengan menggunakan metode </span><span class="font1" style="font-style:italic;">term weighting</span><span class="font1"> TF.IDF.ICF.IBF dan dibandingkan dengan beberapa metode </span><span class="font1" style="font-style:italic;">term weighting</span><span class="font1"> yang ada sebelumnya. Metode-metode </span><span class="font1" style="font-style:italic;">term weighting</span><span class="font1"> ini bukan hanya diterapkan pada perhitungan </span><span class="font1" style="font-style:italic;">cosine similarity</span><span class="font1">nya, akan tetapi diterapkan juga pada waktu melakukan </span><span class="font1" style="font-style:italic;">feature selection</span><span class="font1">. Untuk metode TF.IDF, </span><span class="font1" style="font-style:italic;">feature selection</span><span class="font1"> yang digunakan adalah metode </span><span class="font1" style="font-style:italic;">mean</span><span class="font1"> TF.IDF, sedangkan untuk TF.IDF.ICF </span><span class="font1" style="font-style:italic;">feature selection</span><span class="font1"> yang digunakan adalah metode </span><span class="font1" style="font-style:italic;">mean</span><span class="font1"> TF.IDF.ICF dan seterusnya.</span></p>
<p><span class="font1">Perbandingan nilai </span><span class="font1" style="font-style:italic;">precision, recall</span><span class="font1">, dan </span><span class="font1" style="font-style:italic;">F-Measure</span><span class="font1"> masing-masing metode dengan menggunakan 1000 fitur terbaik dapat dilihat pada Tabel 1. Sedangkan hasil pengujian untuk feature selection 500 fitur terbaik dapat dilihat pada Tabel 2 dan hasil pengujian untuk feature selection 250 fitur terbaik dapat dilihat pada Tabel 3. Dari Tabel 1, 2, dan 3 dapat dilihat bahwa metode </span><span class="font1" style="font-style:italic;">term weighting</span><span class="font1"> TF.IDF.ICF.IBF terbukti bisa diimplementasikan untuk pencarian query yang memiliki lebih dari satu dokumen relevan. Dibandingkan dengan tiga metode yang lain, metode term weighting TF.IDF.ICF.IBF memiliki </span><span class="font1" style="font-style:italic;">precision, recall</span><span class="font1">, dan </span><span class="font1" style="font-style:italic;">F-Measure</span><span class="font1"> yang lebih tinggi pada semua variasi </span><span class="font1" style="font-style:italic;">feature selection</span><span class="font1">. Nilai evaluasi terbaik dari metode ini didapatkan ketika menggunakan 1000 feature terbaik yaitu </span><span class="font1" style="font-style:italic;">precision</span><span class="font1"> sebesar 76%, </span><span class="font1" style="font-style:italic;">recall</span><span class="font1"> sebesar 74%, dan </span><span class="font1" style="font-style:italic;">F-Measure</span><span class="font1"> 75%. Sedangkan metode TF.IDF.IBF menempati posisi kedua dengan nilai evaluasi terbaik ketika menggunakan 1000 feature terbaik yaitu </span><span class="font1" style="font-style:italic;">precision</span><span class="font1"> sebesar 68%, </span><span class="font1" style="font-style:italic;">recall</span><span class="font1"> sebesar 62%, dan </span><span class="font1" style="font-style:italic;">F-Measure</span><span class="font1"> 65%. Dari Tabel 1, 2, dan 3 juga dapat dilihat bahwa metode TF.IDF mengalami penurunan performa yang signifikan pada penggunaan jumlah fitur yang sangat sedikit. Hal ini menunjukkan bahwa metode TF.IDF banyak kehilangan fitur-fitur penting ketika hanya sedikit jumlah fitur yang digunakan.</span></p>
<p><span class="font1" style="font-weight:bold;">Tabel 1. Hasil Pengujian Kedua dengan Menggunakan 1000 Fitur</span></p>
<table border="1">
<tr><td rowspan="2" style="vertical-align:middle;">
<p><span class="font1" style="font-weight:bold;">No.</span></p></td><td colspan="2" style="vertical-align:middle;">
<p><span class="font1" style="font-weight:bold;">TF.IDF</span></p></td><td colspan="2" style="vertical-align:middle;">
<p><span class="font1" style="font-weight:bold;">TF.IDF.ICF</span></p></td><td colspan="2" style="vertical-align:middle;">
<p><span class="font1" style="font-weight:bold;">TF.IDF.IBF</span></p></td><td colspan="2" style="vertical-align:middle;">
<p><span class="font1" style="font-weight:bold;">TF.IDF.ICF.IBF</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font1">P</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">R</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">P</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">R</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">P</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">R</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">P</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">R</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font1">Q1</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">1.00</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">1.00</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0.50</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0.50</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">1.00</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">1.00</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">1.00</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">1.00</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font1">Q2</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0.5</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0.25</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0.5</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0.25</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0.5</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0.25</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0.75</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0.75</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font1">Q3</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0.75</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0.75</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0.75</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0.75</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0.75</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0.75</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0.75</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0.75</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font1">Q4</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0.1</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0.33</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0.167</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0.33</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0.167</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0.33</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0.29</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0.67</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font1">Q5</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">1.00</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0.5</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">1.00</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0.5</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">1.00</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0.5</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">1.00</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0.5</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font1">Q6</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0.33</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0.5</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0.33</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0.5</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0.33</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0.5</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0.5</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0.5</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font1">Q7</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">1.00</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">1.00</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">1.00</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">1.00</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">1.00</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">1.00</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">1.00</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">1.00</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font1" style="font-weight:bold;">Rata-rata</span></p></td><td style="vertical-align:middle;">
<p><span class="font1" style="font-weight:bold;">67%</span></p></td><td style="vertical-align:middle;">
<p><span class="font1" style="font-weight:bold;">62%</span></p></td><td style="vertical-align:middle;">
<p><span class="font1" style="font-weight:bold;">61%</span></p></td><td style="vertical-align:middle;">
<p><span class="font1" style="font-weight:bold;">55%</span></p></td><td style="vertical-align:middle;">
<p><span class="font1" style="font-weight:bold;">68%</span></p></td><td style="vertical-align:middle;">
<p><span class="font1" style="font-weight:bold;">62%</span></p></td><td style="vertical-align:middle;">
<p><span class="font1" style="font-weight:bold;">76%</span></p></td><td style="vertical-align:middle;">
<p><span class="font1" style="font-weight:bold;">74%</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font1" style="font-weight:bold;">F1</span></p></td><td colspan="2" style="vertical-align:middle;">
<p><span class="font1" style="font-weight:bold;">64%</span></p></td><td style="vertical-align:middle;">
<p><span class="font1" style="font-weight:bold;">58%</span></p></td><td style="vertical-align:top;"></td><td colspan="2" style="vertical-align:middle;">
<p><span class="font1" style="font-weight:bold;">65%</span></p></td><td style="vertical-align:top;"></td><td style="vertical-align:middle;">
<p><span class="font1" style="font-weight:bold;">75%</span></p></td></tr>
</table>
<p><span class="font1" style="font-weight:bold;text-decoration:underline;">Tabel 2. Hasil Pengujian Kedua dengan Menggunakan 500 Fitur</span></p>
<table border="1">
<tr><td style="vertical-align:top;">
<p><span class="font1" style="font-weight:bold;">Nilai</span></p></td><td style="vertical-align:top;">
<p><span class="font1" style="font-weight:bold;">TF.IDF &nbsp;&nbsp;&nbsp;TF.IDF.ICF &nbsp;&nbsp;TF.IDF.IBF &nbsp;&nbsp;TF.IDF.ICF.IBF</span></p>
<p><span class="font1">P &nbsp;&nbsp;R &nbsp;&nbsp;&nbsp;P &nbsp;&nbsp;&nbsp;R &nbsp;&nbsp;&nbsp;P &nbsp;&nbsp;&nbsp;R &nbsp;&nbsp;&nbsp;&nbsp;P &nbsp;&nbsp;&nbsp;&nbsp;R</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font1">Rata-rata</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">56% 58% &nbsp;59% &nbsp;58% &nbsp;60% &nbsp;58% &nbsp;&nbsp;66% &nbsp;&nbsp;65%</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font1">F1</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">57% &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;58% &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;59% &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;66%</span></p></td></tr>
</table>
<p><span class="font1">Dari semua hasil pengujian, dapat dilihat bahwa metode baru term weighting TF.IDF.ICF.IBF terbukti berhasil diimplementasikan dalam perangkingan dokumen berbahasa arab dengan tingkat akurasi, </span><span class="font1" style="font-style:italic;">precision</span><span class="font1"> dan </span><span class="font1" style="font-style:italic;">recall</span><span class="font1"> yang tinggi. Metode ini juga terbukti memiliki nilai evaluasi</span></p>
<p><span class="font1">yang lebih baik dibandingkan dengan beberapa metode lain. Metode ini mampu mencari dokumen yang relevan terhadap </span><span class="font1" style="font-style:italic;">query</span><span class="font1"> yang dimasukkan dengan memperhatikan bukan hanya indeks dokumen, tetapi juga indeks buku dan kelas. Hal ini memungkinkan metode ini untuk mendapatkan dokumen yang relevan dari buku dan kategori yang tepat sesuai dengan karakteristik </span><span class="font1" style="font-style:italic;">query</span><span class="font1"> yang dimasukkan sehingga hasil pencarianya pun semakin akurat. Nilai terbaik metode ini didapatkan ketika menggunakan 1000 feature terbaik yaitu </span><span class="font1" style="font-style:italic;">precision</span><span class="font1"> sebesar 76%, </span><span class="font1" style="font-style:italic;">recall</span><span class="font1"> sebesar 74%, dan </span><span class="font1" style="font-style:italic;">F-Measure</span><span class="font1"> 75%.</span></p>
<p><span class="font1" style="font-weight:bold;">Tabel 3. Hasil Pengujian Kedua dengan Menggunakan 250 Fitur</span></p>
<table border="1">
<tr><td rowspan="2" style="vertical-align:top;">
<p><span class="font1" style="font-weight:bold;">Nilai</span></p></td><td style="vertical-align:middle;">
<p><span class="font1" style="font-weight:bold;">TF.IDF</span></p></td><td style="vertical-align:middle;">
<p><span class="font1" style="font-weight:bold;">TF.IDF.ICF</span></p></td><td style="vertical-align:middle;">
<p><span class="font1" style="font-weight:bold;">TF.IDF.IBF</span></p></td><td style="vertical-align:middle;">
<p><span class="font1" style="font-weight:bold;">TF.IDF.ICF.IBF</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font1">P &nbsp;&nbsp;R</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">P &nbsp;&nbsp;&nbsp;R</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">P &nbsp;&nbsp;&nbsp;R</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">P &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;R</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font1">Rata-rata</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">51% 51%</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">55% &nbsp;51%</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">57% &nbsp;51%</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">54% &nbsp;&nbsp;63%</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font1">F1</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">51%</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">53%</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">54%</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">58%</span></p></td></tr>
</table>
<p><span class="font1">Berdasarkan hasil ujicoba pada Tabel 1, 2, dan 3 juga dapat dilihat bahwa metode TF.IDF.IBF (tanpa ICF) memiliki </span><span class="font1" style="font-style:italic;">precision</span><span class="font1"> dan </span><span class="font1" style="font-style:italic;">recall</span><span class="font1"> yang lebih tinggi dibandingkan dengan dua metode yang lain. Hal ini menunjukkan bahwa penambahan IBF memberikan dampak yang lebih bagus daripada ICF. Nilai evaluasi terbaik metode ini didapatkan ketika menggunakan 1000 feature terbaik yaitu </span><span class="font1" style="font-style:italic;">precision</span><span class="font1"> sebesar 68%, </span><span class="font1" style="font-style:italic;">recall</span><span class="font1"> sebesar 62%, dan </span><span class="font1" style="font-style:italic;">F-Measure</span><span class="font1"> 65%.</span></p>
<p><span class="font1">Selain itu, dari Tabel 1, 2, dan 3 juga dapat dilihat bahwa pengurangan fitur juga berpengaruh pada performa masing-masing metode. Semakin sedikit fitur yang digunakan, semakin menurun pula performa metode-metode tersebut. TF.IDF memiliki penurunan performa yang sangat signifikan seiring berkurangnya jumlah fitur yang digunakan. Hal ini dikarenakan banyak fitur-fitur penting yang hilang ketika dilakukan pengurangan fitur. Fitur-fitur yang hilang tersebut memiliki nilai TF.IDF yang lebih kecil daripada beberapa fitur lain sehingga harus dihilangkan meski sebenarnya beberapa fitur-fitur tersebut memiliki peranan yang lebih penting. Berbeda dengan TF.IDF.ICF.IBF yang tetap memiliki performa cukup bagus walaupun hanya menggunakan sedikit fitur karena tetap bisa mempertahankan fitur-fitur yang memiliki peranan penting.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark11"></a><span class="font1" style="font-weight:bold;"><a name="bookmark12"></a>5. &nbsp;&nbsp;&nbsp;Kesimpulan</span></h2></li></ul>
<p><span class="font1" style="font-style:italic;">Term Weighting</span><span class="font1"> TF.IDF.ICF.IBF dapat diaplikasikan pada perangkingan dokumen berbahasa Arab yang memiliki hierarki berupa buku-buku yang memiliki banyak halaman. Hasil ujicoba menunjukkan bahwa metode ini memiliki rata - rata nilai </span><span class="font1" style="font-style:italic;">F-Measure</span><span class="font1"> sebesar 75% , rata-rata </span><span class="font1" style="font-style:italic;">precision</span><span class="font1"> 76% dan rata-rata </span><span class="font1" style="font-style:italic;">recall</span><span class="font1"> mencapai 74%. Dibandingkan dengan perangkingan dokumen menggunakan metode </span><span class="font1" style="font-style:italic;">term weighting</span><span class="font1"> yang lain meliputi TF.IDF, TF.IDF.ICF, dan TF.IDF.IBF, metode yang diusulkan memiliki </span><span class="font1" style="font-style:italic;">precision, recall</span><span class="font1">, dan </span><span class="font1" style="font-style:italic;">F-Measure</span><span class="font1"> yang lebih tinggi. Metode </span><span class="font1" style="font-style:italic;">Term Weighting</span><span class="font1"> TF.IDF.ICF.IBF terbukti berhasil digunakan dalam seleksi fitur dan perangkingan dokumen hasil pencarian dengan hierarki berupa buku-buku yang memiliki banyak halaman. Oleh karena itu pada penelitian selanjutnya, metode ini dapat diaplikasikan pada klasifikasi dokumen dengan hierarki yang sama.</span></p>
<h2><a name="bookmark13"></a><span class="font1" style="font-weight:bold;"><a name="bookmark14"></a>Daftar Pustaka</span></h2>
<ul style="list-style:none;"><li>
<p><span class="font1">[1] &nbsp;&nbsp;&nbsp;Esraa E.A., B.L. Nagma, M.F. Tolba, An Efficient Rangking Module for an Arabic Search</span></p></li></ul>
<p><span class="font1">Engine,International Journal of Computer Science and Network Security. 2010; 10(2): 1-3.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1">[2] &nbsp;&nbsp;Suleiman H.M., Character Contiguity in N-gram-based Word Matching: the Case for</span></p></li></ul>
<p><span class="font1">Arabic Text Searching,Information Processing and Management, 2005; 20(4): 2-4.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1">[3] &nbsp;&nbsp;&nbsp;Suleiman H.M., Arabic String Searching in the Context of Character Code Standards and Orthographic Variations,Computer Standards and Interfaces. 1998; 4(1): 3-10.</span></p></li>
<li>
<p><span class="font1">[4] &nbsp;&nbsp;&nbsp;Fuji R., G.S. Mohammad, Class-indexing-based term weighting for automatic text classification,Journal of Informetrics. 2009; 3(1):2-5.</span></p></li>
<li>
<p><span class="font1">[5] &nbsp;&nbsp;&nbsp;Larkey, Leah S., Lisa Ballesteros, Margaret E Connell, Light Stemming for Arabic Information Retrieval,Springer Link: Text, Speech and Language Technology, 2007; 38(1):7-12.</span></p></li>
<li>
<p><span class="font1">[6] &nbsp;&nbsp;&nbsp;Harrag F., A. Hamdi-Cherif, E. El-Qawasmeh. Vector space model for Arabic information retrieval - application to Hadith indexing. Proceedings of the First IEEE Conference on the Applications of Digital Information and Web Technologies. ICADWIT. 2008: 107-112.</span></p></li>
<li>
<p><span class="font1">[7] &nbsp;&nbsp;&nbsp;Manning C.D., R. Prabhakar, S. Hinrich. An Introduction to Information Retrieval. Cambridge, England: Cambridge University Press. 2009.</span></p></li>
<li>
<p><span class="font1">[8] &nbsp;&nbsp;&nbsp;Salton G. Automatic Text Processing: the Transformation, Analysis, and Retrieval of Information by Computer. New York: Addison-Wesly. 1989.</span></p></li>
<li>
<p><span class="font1">[9] &nbsp;&nbsp;&nbsp;Ahmad N., Z.A. Agus, Diana P., Implementasi N-Gram Dalam Pencarian Teks Sebagai Penunjang Aplikasi Perpustakaan Kitab Berbahasa Arab. Under Graduate Thesis. Surabaya: Under Graduate ITS.</span></p></li>
<li>
<p><span class="font1">[10] &nbsp;&nbsp;&nbsp;</span><a href="http://www.miislita.com/term-vector/term-vector-3.html"><span class="font1">http://www.miislita.com/term-vector/term-vector-3.html</span></a><span class="font1">, diakses tanggal 5 Mei 2013.</span></p></li></ul>
<p><span class="font1">442</span></p>