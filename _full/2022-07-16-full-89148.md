---
layout: full_article
title: "Klasifikasi Jurnal menggunakan Metode KNN dengan Mengimplementasikan Perbandingan Seleksi Fitur"
author: "Farin Istighfarizky, Ngurah Agus Sanjaya ER, I Made Widiartha, Luh Gede Astuti, I Gusti Ngurah Anom Cahyadi Putra, I Ketut Gede Suhartana"
categories: jik
canonical_url: https://jurnal.harianregional.com/jik/full-89148 
citation_abstract_html_url: "https://jurnal.harianregional.com/jik/id-89148"
citation_pdf_url: "https://jurnal.harianregional.com/jik/full-89148"  
comments: true
---

<p><span class="font2">p-ISSN: 2301-5373</span></p>
<p><span class="font2">e-ISSN: 2654-5101</span></p>
<p><span class="font2">Jurnal Elektronik Ilmu Komputer Udayana</span></p>
<p><span class="font2">Volume 11, No 1. August 2022</span></p><a name="caption1"></a>
<h1><a name="bookmark0"></a><span class="font5" style="font-weight:bold;"><a name="bookmark1"></a>Klasifikasi Jurnal menggunakan Metode KNN dengan Mengimplementasikan Perbandingan Seleksi Fitur</span></h1>
<p><span class="font2">Farin Istighfarizky<sup>a1</sup></span><span class="font2" style="font-weight:bold;">, </span><span class="font2">Ngurah Agus Sanjaya ER<sup>a2</sup></span><span class="font2" style="font-weight:bold;">, </span><span class="font2">I Made Widiartha<sup>a3</sup></span><span class="font2" style="font-weight:bold;">, </span><span class="font2">Luh Gede Astuti<sup>a4</sup></span><span class="font2" style="font-weight:bold;">, </span><span class="font2">I Gusti Ngurah Anom Cahyadi Putra<sup>a5</sup></span><span class="font2" style="font-weight:bold;">, </span><span class="font2">I Ketut Gede Suhartana<sup>a6</sup></span></p>
<p><span class="font2"><sup>a</sup>Program Studi Informatika, Fakultas Matematika dan Ilmu Pengetahuan Alam, Universitas Udayana Bali, Indonesia</span></p>
<p><a href="mailto:1farin79.istighfarizky@gmail.com"><span class="font2"><sup>1</sup>farin79.istighfarizky@gmail.com</span></a><span class="font2"> <sup>2</sup>a</span><a href="mailto:gus_sanjaya@unud.ac.id"><span class="font2">gus_sanjaya@unud.ac.id</span></a><span class="font2"> </span><a href="mailto:3madewidiartha@unud.ac.id"><span class="font2"><sup>3</sup>madewidiartha@unud.ac.id</span></a><span class="font2"> </span><a href="mailto:4Author2@unud.ac.id"><span class="font2"><sup>4</sup> lg.astuti@unud.ac.id</span></a><span class="font2"> </span><a href="mailto:5Author2@unud.ac.id"><span class="font2"><sup>5</sup> anom.cp@unud.ac.id</span></a><span class="font2"> </span><a href="mailto:6ikg.suhartana@unud.ac.id"><span class="font2"><sup>6</sup>ikg.suhartana@unud.ac.id</span></a></p>
<h3><a name="bookmark2"></a><span class="font2" style="font-weight:bold;font-style:italic;"><a name="bookmark3"></a>Abstract</span></h3>
<p><span class="font2">Classification is a process that automatically places text documents into a text based on the content of the text. Classification can help us classifying many text documents that have been published, with the classification, these text documents can be reached easily and quickly. Feature selection can be used to improve the performance of text classification in terms of learning speed and effectiveness. In the Chi-Square feature selection experiment, a 1% threshold combination with a parameter value of k=6 is the combination chosen to be the best model. In testing the new data, the K-Nearest Neighbor model by selecting the Chi-Square feature produces precision performance, recall, F1-Score, and accuracy respectively, namely 85%, 83.3%, 88.2%, and 92.3%. In the Gini Index feature selection experiment,1% threshold combination with a parameter value of k=4 is the combination chosen to be the best model. This threshold selects about 31 features with the highest Gini Index value. In testi ng the new data, the K-Nearest Neighbor model by selecting the Gini Index feature produces precision performance, recall, F1-Score, and accuracy respectively, namely 81.2%, 80.3%, 81.6%, and 86.6%.</span></p>
<p><span class="font2" style="font-weight:bold;font-style:italic;">Keywords: </span><span class="font2" style="font-style:italic;">Classification, Chi-Square, Gini Index, Features Selection</span><span class="font2">, </span><span class="font2" style="font-style:italic;">K-Nearest Neighbor</span></p>
<ul style="list-style:none;"><li>
<p><span class="font2" style="font-weight:bold;">1. &nbsp;&nbsp;&nbsp;Pendahuluan</span></p></li></ul>
<p><span class="font2">Penemuan dibidang informatika mengalami perkembangan yang sangat pesat. Ratusan penelitian dilakukan di berbagai bidang disetiap tahunnya yang mana dengan harapan hasil penelitian tersebut dapat digunakan untuk penemuan berikutnya. Tidak semua penemuan akan relevan terhadap penelitian yang dilakukan oleh seseorang, oleh karena itu diperlukannya pengelompokan penelitian agar lebih mudah dalam mencari penelitian yang kita inginkan atau butuhkan. Jumlah studi yang dipublikasikan ada ratusan bahkan ribuan penelitian setiap tahunnya, seseorang akan membutuhkan terlalu banyak usaha dan dana yang besar dalam mengelompokkan jurnal-jurnal penelitian. Masalah ini dapat diselesaikan dengan klasifikasioteks.</span></p>
<p><span class="font2">Klasifikasi adalahoproses menempatkanoodokumenoteksosecaraoootomatisokeodalamokategori berdasarkan teks [1]. Klasifikasi membantu mengklasifikasikan jumlah dokumen teks yang diterbitkan. Klasifikasi membuatnya cepat dan mudah untuk mengelompokkan dokumen tekstual. Dasar dari algoritma seleksi fitur adalah untuk menemukan semuaokemungkinanokombinasioatributodalam data. Ini digunakan untuk menemukan subset terbaik untukprediksi. Pemilihan fitur dapat digunakanountuk meningkatkan kinerja klasifikasi teks dalam hal kecepatan dan efektivitas pembelajaran [2].</span></p>
<p><span class="font2">Studi klasifikasi telah dilakukan oleh beberapa peneliti, seperti tentang mengkategorikan soal ujian secara otomatis. Pada penelitian tersebut, penulis menggunakan metode KNN dengan seleksi fitur </span><span class="font2" style="font-style:italic;">Chi-Square</span><span class="font2">. oHasil pada penelitian tersebut menunjukkan bahwa metode seleksi fitur </span><span class="font2" style="font-style:italic;">Chi-Square </span><span class="font2">terbukti mampu meningkatkan performa dari metode KNN [3]. Penelitian selanjutnya adalah</span></p>
<p><span class="font2">Istighfarizky, dkk</span></p>
<p><span class="font2">Klasifikasi Jurnal menggunakan Metode KNN dengan Mengimplementasikan Perbandingan Seleksi Fitur membahas tentang kognitif soalopadaotaksonomi </span><span class="font2" style="font-style:italic;">bloom</span><span class="font2"> denganoKNN. Hasil yang didapatkan dari algoritma KNN dengan seleksi fitur </span><span class="font2" style="font-style:italic;">Gini Index</span><span class="font2"> pada penelitian tersebut adalah akurasi sebesar 68,37% dan kappa tertinggi sebesar 0,607. Berdasarkanohasil tersebut, </span><span class="font2" style="font-style:italic;">Gini</span><span class="font2">o</span><span class="font2" style="font-style:italic;">Index</span><span class="font2"> mampu mengurangi dimensi fitur yang tinggi [4].</span></p>
<p><span class="font2">Seleksi fitur </span><span class="font2" style="font-style:italic;">Chi Square</span><span class="font2"> menggunakan teori statistik untuk menentukan independensi suatu </span><span class="font2" style="font-style:italic;">term</span><span class="font2"> dari kategorinya. Dalam seleksi fitur </span><span class="font2" style="font-style:italic;">Chi Square</span><span class="font2">oberdasarkanoteori statistika, duaoperistiwa dioantaranya adalahokemunculan dari fiturodan kemunculan dari kategori yang kemudian nilai </span><span class="font2" style="font-style:italic;">term</span><span class="font2">odiurutkan dari yangotertinggi. Sedangkanoseleksi fitur </span><span class="font2" style="font-style:italic;">Gini Index</span><span class="font2">omampu mengurangiodimensi fitur yang tinggi pada klasifikasi teks. o</span></p>
<p><span class="font2">Berdasarkan penelitian yang dilakukan sebelumnya, pada penelitian kali ini penulis melakukan klasifikasi jurnal menggunakan metode </span><span class="font2" style="font-style:italic;">K-Nearest Neighbor</span><span class="font2"> dengan menggunakan dua seleksi fitur yaitu </span><span class="font2" style="font-style:italic;">Chi-Square</span><span class="font2"> dan </span><span class="font2" style="font-style:italic;">Gini Index</span><span class="font2">. Penulis berharap bahwa dengan menggunakan kombinasi metode ini dapat menghasilkan performa </span><span class="font2" style="font-style:italic;">precision</span><span class="font2">, </span><span class="font2" style="font-style:italic;">recall</span><span class="font2">, </span><span class="font2" style="font-style:italic;">f1-score</span><span class="font2">, dan akurasi yang lebih baik dibandingkan penelitian sebelumnya.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font2" style="font-weight:bold;">2. &nbsp;&nbsp;&nbsp;Metode Penelitian</span></p>
<ul style="list-style:none;">
<li>
<p><span class="font2" style="font-weight:bold;">2.2. &nbsp;&nbsp;&nbsp;Dataset</span></p></li></ul></li></ul>
<p><span class="font2">Data yang digunakanopadaopenelitianoini adalah jurnal yang dipublikasikan oleh SINTA (</span><span class="font2" style="font-style:italic;">Science and Technology Index</span><span class="font2">) dan </span><span class="font2" style="font-style:italic;">Google Scholar</span><span class="font2">, data dapat diperoleh dari </span><span class="font2" style="font-style:italic;">website</span><span class="font2"> SINTA (</span><span class="font2" style="font-style:italic;">Science and Technology</span><span class="font2">) </span><a href="https://sinta.ristekbrin.go.id/"><span class="font2">(https://sinta.ristekbrin.go.id</span></a><span class="font2">/) dan </span><span class="font2" style="font-style:italic;">Google Scholar</span><span class="font2"> (</span><a href="https://scholar.google.com/"><span class="font2">https://scholar.google.com)</span></a><span class="font2"> Kemudian data yang digunakan untuk proses klasifikasi adalah pada bagian teks abstrak jurnal yang berbahasa Indonesia yang disimpan dalam bentuk (.xlsx) untuk digunakan sebagai data latih dan data uji. Dokumen yang digunakan berjumlah 100 data per kelas disetiap artikel ilmiah yaitu: pendidikan, ekonomi, dan informatika. Data </span><span class="font2" style="font-style:italic;">testing</span><span class="font2"> yang diuji sebanyak 60 data jurnal dan data </span><span class="font2" style="font-style:italic;">training</span><span class="font2"> sebanyak 240 data jurnal. Data pada penelitian ini adalah data sekunder.</span></p>
<ul style="list-style:none;"><li>
<h3><a name="bookmark4"></a><span class="font2" style="font-weight:bold;"><a name="bookmark5"></a>2.2.</span><span class="font6" style="font-weight:bold;font-style:italic;"> &nbsp;&nbsp;&nbsp;Preprocessing</span></h3></li></ul>
<p><span class="font2" style="font-style:italic;">Preprocessing</span><span class="font2"> proses pertama mempersiapkan dataset sebelum pembobotan, tujuannya adalah untuk menyederhanakan pemrosesan data dan juga untuk mendapatkan tingkat performa yang tinggi. Proses </span><span class="font2" style="font-style:italic;">preprocessing</span><span class="font2"> dapat dilihat pada gambar 1.</span></p><img src="https://jurnal.harianregional.com/media/89148-1.jpg" alt="" style="width:113pt;height:326pt;">
<p><span class="font2" style="font-weight:bold;">Gambar 1. </span><span class="font2">Proses </span><span class="font2" style="font-style:italic;">preprocessing</span></p>
<p><span class="font2">Padaotahapoini, terdapat beberapa proses yaitu </span><span class="font2" style="font-style:italic;">case folding, cleansing,</span><span class="font2"> tokenisasi</span><span class="font2" style="font-style:italic;">, stopword, </span><span class="font2">normalisasi, dan </span><span class="font2" style="font-style:italic;">stemming</span><span class="font2">. </span><span class="font2" style="font-style:italic;">Case folding</span><span class="font2"> yaitu proses mengubah semua huruf menjadi huruf kecil</span><span class="font2" style="font-style:italic;">. Cleansing</span><span class="font2"> merupakan proses penghapusan karakter yang tidak relevan dengan klasifikasi jurnal. Tokenisasi yaitu pemisahan kata-kata paragraf atau kalimat menjadi token-token tertentu. </span><span class="font2" style="font-style:italic;">Stopword removal</span><span class="font2"> yaitu penghapusan kata yang tidak mempengaruhi klasifikasi jurnal. Proses normalisasi yaitu mengubah dan mengembalikan bentuk penulisan tidak baku ke bentuk penulisan yang sesuai dengan KBBI. Proses terakhir adalah </span><span class="font2" style="font-style:italic;">stemming,</span><span class="font2"> yaitu mengekstrak kata yang dilampirkan ke dalam kata dasar [5].</span></p>
<ul style="list-style:none;"><li>
<h3><a name="bookmark6"></a><span class="font2" style="font-weight:bold;font-style:italic;"><a name="bookmark7"></a>2.3. &nbsp;&nbsp;&nbsp;Term Frequency Inverse-Document Frequency</span><span class="font2" style="font-weight:bold;"> (TF-IDF) </span><span class="font2">o</span></h3></li></ul>
<p><span class="font2">Metode </span><span class="font2" style="font-style:italic;">Term Frequency</span><span class="font2">o</span><span class="font2" style="font-style:italic;">Invers Document</span><span class="font2">o</span><span class="font2" style="font-style:italic;">Frequency</span><span class="font2"> adalahometodeoopembobotan yang menggabungkan frekuensi istilah dalam satu set dokumen dan kelangkaannya. Metodejini menggabungkanxduajkonsep pembobotan, yaitujfrekuensijkemunculanjkatajdalamjdokumenjtertentu danjfrekuensijkebalikan dari dokumen yang berisi kata tersebut. Berapa kali sebuah kata muncul dalam dokumen tertentu menunjukkanopentingnyajkataotersebut dalam dokumen itu. Frekuensi dokumen yang berisiokata-kata menunjukkan seberapa sering kata-kata itu muncul. Sehingga bobot hubunganjantarajsebuahjkatajdanjsebuahjdokumenjakanjtinggijapabilaofrekuensi kataotersebut tinggi di dalamodokumen dan frekuensiokeseluruhan dokumen yang mengandung kata tersebut yang rendah pada kumpulan dokumen. Proses TF-IDFodapatodilihatopadaogambar 2.</span></p>
<p><span class="font2">Istighfarizky, dkk</span></p>
<p><span class="font2">Klasifikasi Jurnal menggunakan Metode KNN dengan Mengimplementasikan Perbandingan Seleksi Fitur</span></p><img src="https://jurnal.harianregional.com/media/89148-2.jpg" alt="" style="width:121pt;height:224pt;">
<p><span class="font2" style="font-weight:bold;">Gambar 2. </span><span class="font2">TF-IDF</span></p>
<ul style="list-style:none;"><li>
<p><span class="font2">a. &nbsp;&nbsp;&nbsp;Hitung jumlah</span><span class="font1">o</span><span class="font2">kemunculan </span><span class="font2" style="font-style:italic;">term</span><span class="font2"> i dalam dokumen j (tfi,j).</span></p></li>
<li>
<p><span class="font2">b. &nbsp;&nbsp;&nbsp;Hitung jumlah dokumen yang</span><span class="font1">p</span><span class="font2">mengandung </span><span class="font2" style="font-style:italic;">term</span><span class="font2"> i (df)</span></p></li>
<li>
<p><span class="font2">c. &nbsp;&nbsp;&nbsp;Menghitung nilai bobot </span><span class="font2" style="font-style:italic;">inverse document frequency</span><span class="font2"> (idf) dengan menggunakan persamaan:</span></p></li></ul>
<p><span class="font2" style="font-style:italic;">idf<sub>i</sub> = log</span><span class="font2"> g &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1)</span></p>
<p><span class="font2">Keterangan:</span></p>
<p><span class="font2">N = jumlah dokumen secara keseluruhan</span></p>
<ul style="list-style:none;"><li>
<p><span class="font2">d. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Menghitung nilai bobot TF-IDF dengan menggunakan persamaan:</span></p></li></ul>
<p><span class="font2" style="font-style:italic;"><sup>w</sup>i,j = <sup>t</sup>fi.j <sup>x id</sup>fi</span><span class="font2"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(2)</span></p>
<p><span class="font2">Keterangan:</span></p>
<p><span class="font2" style="font-style:italic;"><sup>w</sup>i,j</span><span class="font2"> = bobot </span><span class="font2" style="font-style:italic;">term</span><span class="font2"> i terhadap dokumen jo </span><span class="font2" style="font-style:italic;">t f-</span><span class="font2"> i' </span><span class="font2" style="font-style:italic;">=</span><span class="font2"> frekuensi </span><span class="font2" style="font-style:italic;">term</span><span class="font2"> i pada dokumen jo</span></p>
<p><span class="font2" style="font-style:italic;">Iafi =</span><span class="font2"> nilai bobot IDF pada </span><span class="font2" style="font-style:italic;">term</span><span class="font2"> i</span></p>
<ul style="list-style:none;"><li>
<h3><a name="bookmark8"></a><span class="font2" style="font-weight:bold;"><a name="bookmark9"></a>2.4.</span><span class="font2" style="font-weight:bold;font-style:italic;"> &nbsp;&nbsp;&nbsp;K-Nearest Neighbor</span><span class="font2" style="font-weight:bold;"> (KNN)</span></h3></li></ul>
<p><span class="font2">Algoritmao</span><span class="font2" style="font-style:italic;">K-Nearest Neighbor</span><span class="font2">oadalahometodeountuk mengklasifikasi objekoberdasarkanodata latih yang palingodekatodenganoobjekotersebut. Metode </span><span class="font2" style="font-style:italic;">K-Nearest Neighbor</span><span class="font2"> adalahoalgoritma pembelajaran terawasi, dan hasil dari </span><span class="font2" style="font-style:italic;">query instance</span><span class="font2"> baru dikategorikan berdasarkan sebagaian besar kategori algoritma </span><span class="font2" style="font-style:italic;">K-Nearest Neighbor</span><span class="font2">. Kelasoyangopaling sering ditampilkan adalah kelas yang diperoleh dari hasil klasifikasi. Kedekatan didefinisikan dalam jarak metrik, seperti jarak </span><span class="font2" style="font-style:italic;">Euclidean</span><span class="font2"> [6].</span></p>
<div><img src="https://jurnal.harianregional.com/media/89148-3.jpg" alt="" style="width:104pt;height:26pt;">
</div><br clear="all">
<p><span class="font2">(3)</span></p>
<p><span class="font2">Keterangan: o</span></p>
<p><span class="font2">D = jarak kedekatano</span></p>
<p><span class="font2">x = data trainingl</span></p>
<p><span class="font2">y = data testingo</span></p>
<p><span class="font2">n = jumlah atribut individu antara 1 s.d n</span></p>
<p><span class="font2">i = atribut individu antara 1 s.d no</span></p>
<ul style="list-style:none;"><li>
<h3><a name="bookmark10"></a><span class="font2" style="font-weight:bold;font-style:italic;"><a name="bookmark11"></a>2.5. &nbsp;&nbsp;&nbsp;Chi-Square</span></h3></li></ul>
<p><span class="font2" style="font-style:italic;">Chi-Square</span><span class="font2"> adalah metode untukomenghitung ketergantungan fitur. Pada pemrosesanoteks biasanya menggunakan dua kelasountukomengukur ketergantungan antara dua label dan kata – antara kelas tertentuoc.Tahapan </span><span class="font2" style="font-style:italic;">Chi-Square</span><span class="font2"> dapatodilihat padaogambar 3. o</span></p>
<div><img src="https://jurnal.harianregional.com/media/89148-4.jpg" alt="" style="width:345pt;height:256pt;">
<p><span class="font2" style="font-weight:bold;">Gambar 3. </span><span class="font2" style="font-style:italic;">Chi-Square</span></p>
</div><br clear="all">
<p><span class="font2">Berikut inioadalah rumus yangodigunakan untukomenerapkan metode seleksi fitur </span><span class="font2" style="font-style:italic;">Chi-Square</span><span class="font2"> [7].</span></p>
<div>
<p><span class="font2">⅛c) =</span></p>
</div><br clear="all">
<div>
<p><span class="font2" style="text-decoration:underline;">WlJW-CgJ<sup>z </sup></span><span class="font2">iΛ+C</span><span class="font8">∣</span><span class="font2"> ⅛+θ) (A+3J(C+DJ</span></p>
</div><br clear="all">
<div>
<p><span class="font2">(4)</span></p>
</div><br clear="all">
<p><span class="font2">Keterangan:</span></p>
<p><span class="font2">t = katao</span></p>
<p><span class="font2">c = kelas/kategorio</span></p>
<p><span class="font10" style="font-style:italic;">N</span><span class="font2"> = jumlah data latih</span></p>
<p><span class="font10" style="font-style:italic;">A</span><span class="font2"> = jumlah dokumen pada kelas </span><span class="font10" style="font-style:italic;">c</span><span class="font2"> yang memuat </span><span class="font10" style="font-style:italic;">t</span><span class="font2" style="font-style:italic;">,</span></p>
<p><span class="font10" style="font-style:italic;">B</span><span class="font2"> = jumlah dokumen yang tidak ditemukan pada kelas </span><span class="font10">c </span><span class="font2">tapi memuat </span><span class="font10">t</span><span class="font2">,</span></p>
<p><span class="font10" style="font-style:italic;">C</span><span class="font2"> = jumlah dokumen pada kelas c yang tidak memuat </span><span class="font10">t</span><span class="font2">,</span></p>
<p><span class="font10" style="font-style:italic;">D</span><span class="font2"> = jumlah dokumen yang bukan merupakan dokumen kelas </span><span class="font10">c </span><span class="font2">dan tidak memuat </span><span class="font2" style="font-style:italic;">term </span><span class="font10" style="font-style:italic;">t</span></p>
<ul style="list-style:none;"><li>
<h3><a name="bookmark12"></a><span class="font2" style="font-weight:bold;font-style:italic;"><a name="bookmark13"></a>2.6. &nbsp;&nbsp;&nbsp;Gini Index</span><span class="font2">j</span></h3></li></ul>
<p><span class="font2" style="font-style:italic;">Gini Index</span><span class="font2"> adalah kriteria berbasis ketidakmurnian datajjyangjjmengukur perbedaan antarajjdistribusi probabilitasjjdarijjnilai atribut. </span><span class="font2" style="font-style:italic;">Gini Index</span><span class="font2">jjumumnya dipakai dalamjjAlgoritma </span><span class="font2" style="font-style:italic;">Classification and Regression</span><span class="font2">jj</span><span class="font2" style="font-style:italic;">Trees</span><span class="font2">jjyang merepsentasikanjjukuran seberapa acak pilihan objek darijjdata latih. Ukuran ketidak murnianjjmencapai 0 ketika hanya 1 kelasjjsaja yangjjadajjpada sebuahjjtitik. Namun sebaliknyajjakan mencapaijjmaksimumjjketika ukuran kelas padajjtitik tersebut seimbang. </span><span class="font2" style="font-style:italic;">Gini Index </span><span class="font2">dapat dianggapjjsebagai probabilitas dari duajjdata yangjjdipilih secara acak darijjkelasjjyang berbeda akan digunakan dalam penelitianjjini untuk mengukur divergensijjyang digunakan sebagai dasar bobot setiap. Cocokjjuntuk pemilahan, sistemjjbiner, nilaijjnumerik terus menerus, dan lain-lain. Tahapan </span><span class="font2" style="font-style:italic;">Gini Index</span><span class="font2"> dapat dilihat pada gambar 4.</span></p>
<p><span class="font2">Istighfarizky, dkk</span></p>
<p><span class="font2">Klasifikasi Jurnal menggunakan Metode KNN dengan Mengimplementasikan Perbandingan Seleksi Fitur</span></p><img src="https://jurnal.harianregional.com/media/89148-5.jpg" alt="" style="width:110pt;height:472pt;">
<p><span class="font2" style="font-weight:bold;">Gambar 4. </span><span class="font2" style="font-style:italic;">Gini Index</span></p>
<p><span class="font2">Berikut inioadalah rumus yangodigunakan untukomenerapkan metode seleksi fitur </span><span class="font2" style="font-style:italic;">Gini Index</span><span class="font2"> [8].</span></p>
<p><span class="font10" style="font-style:italic;">Gi(t)</span><span class="font11"> = i - ∑^<sub>1</sub>[<sub>p</sub>Glt)]<sup>2</sup></span></p>
<div>
<p><span class="font2">(5)</span></p>
</div><br clear="all">
<p><span class="font2">Keterangan:</span></p>
<p><span class="font2">C = total kelas</span></p>
<p><span class="font2">t = </span><span class="font2" style="font-style:italic;">termo</span></p>
<p><span class="font2">p(i|t) = peluang kelas i terhadap term t</span></p>
<ul style="list-style:none;"><li>
<p><span class="font2" style="font-weight:bold;">2.7. &nbsp;&nbsp;&nbsp;Evaluasi</span></p></li></ul>
<p><span class="font2" style="font-style:italic;">Confusion</span><span class="font2">o</span><span class="font2" style="font-style:italic;">matrix</span><span class="font2">omerupakansalah satu metodeoyang dapat digunakanuntuk mengukur performansi suatuometodeoklasifikasi. Pada dasarnyao</span><span class="font2" style="font-style:italic;">confusion</span><span class="font2">o</span><span class="font2" style="font-style:italic;">matrix</span><span class="font2"> ini berisi informasi yang membandingkan hasil klasifikasi yang dilakukan oleh sistem dengan hasil klasifikasi sebagaimana mestinya. Saat mengukur kinerja menggunakan </span><span class="font2" style="font-style:italic;">confusion matrix</span><span class="font2">, ada empatjjistilahjjyangjjmenggambarkanjjhasil darijjprosesjjklasifikasi. Keempatjjistilahjjtersebutjjadalahjj</span><span class="font2" style="font-style:italic;">True Positive, True Negative, False Positive</span><span class="font2">,</span></p>
<p><span class="font2">dan </span><span class="font2" style="font-style:italic;">False Negative</span><span class="font2">. Nilaij</span><span class="font2" style="font-style:italic;">True</span><span class="font2">j</span><span class="font2" style="font-style:italic;">Negative</span><span class="font2"> (TN) adalah jumlah data negatif yangjjterdeteksijjdengan benar, jdanjj</span><span class="font2" style="font-style:italic;">False Positive</span><span class="font2"> (FP) adalah data negatif tetapi terdeteksijjsebagaijjdata positif. Sementara itu, </span><span class="font2" style="font-style:italic;">True Positive</span><span class="font2"> (TP) di sisi lain adalah dataopositif yang dikenali denganobenar. </span><span class="font2" style="font-style:italic;">False Negative</span><span class="font2"> (FN) adalah kebalikan dari </span><span class="font2" style="font-style:italic;">True Positive</span><span class="font2">, sehingga datanya positif tetapi dikenali sebagai data negatif. Tabel </span><span class="font2" style="font-style:italic;">Confusion matrix</span><span class="font2"> dapat dilihat pada tabel 1 [9].</span></p>
<ul style="list-style:none;"><li>
<p><span class="font2">Tabel 1. </span><span class="font2" style="font-style:italic;">Confusion Matrixo</span></p>
<table border="1">
<tr><td style="vertical-align:middle;">
<p><span class="font2" style="font-weight:bold;">Kelaso</span></p></td><td style="vertical-align:middle;">
<p><span class="font2" style="font-weight:bold;">oTerklarifikasi Positifo</span></p></td><td style="vertical-align:middle;">
<p><span class="font2" style="font-weight:bold;">oTerklarifikasi Negatifo</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font2" style="font-weight:bold;">Positifo</span></p></td><td style="vertical-align:middle;">
<p><span class="font2" style="font-weight:bold;">o</span><span class="font2">TP (</span><span class="font2" style="font-style:italic;">True Positive</span><span class="font2">) </span><span class="font2" style="font-weight:bold;">o</span></p></td><td style="vertical-align:middle;">
<p><span class="font2" style="font-weight:bold;">o</span><span class="font2">FN (</span><span class="font2" style="font-style:italic;">False Negative</span><span class="font2">) </span><span class="font2" style="font-weight:bold;">o</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font2" style="font-weight:bold;">Negatifo</span></p></td><td style="vertical-align:middle;">
<p><span class="font2" style="font-weight:bold;">o</span><span class="font2">FP (</span><span class="font2" style="font-style:italic;">False Positive</span><span class="font2">) </span><span class="font2" style="font-weight:bold;">o</span></p></td><td style="vertical-align:middle;">
<p><span class="font2" style="font-weight:bold;">o</span><span class="font2">TN (</span><span class="font2" style="font-style:italic;">True Negative</span><span class="font2">) </span><span class="font2" style="font-weight:bold;">o</span></p></td></tr>
</table></li></ul>
<p><span class="font2">Dimana:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font2">•</span><span class="font2" style="font-style:italic;"> &nbsp;&nbsp;&nbsp;True Positive</span><span class="font2">, jumlah</span><span class="font0" style="font-weight:bold;">o</span><span class="font2">data positif yang diklasifikasikan dengan benarooleh sistem.</span></p></li>
<li>
<p><span class="font2">•</span><span class="font2" style="font-style:italic;"> &nbsp;&nbsp;&nbsp;True Negative</span><span class="font2">, jumlah</span><span class="font0" style="font-weight:bold;">o</span><span class="font2">data negatif yang</span><span class="font0" style="font-weight:bold;">o</span><span class="font2">diklasifikasikan dengan benarooleh sistem.</span></p></li>
<li>
<p><span class="font2">•</span><span class="font2" style="font-style:italic;"> &nbsp;&nbsp;&nbsp;False Negative</span><span class="font2">, jumlah</span><span class="font0" style="font-weight:bold;">o</span><span class="font2">data negatif</span><span class="font0" style="font-weight:bold;">o</span><span class="font2">namun diklasifikasikan salah oleh sistem.</span></p></li>
<li>
<p><span class="font2">•</span><span class="font2" style="font-style:italic;"> &nbsp;&nbsp;&nbsp;False Positive</span><span class="font2">, jumlah</span><span class="font0" style="font-weight:bold;">o</span><span class="font2">data positif</span><span class="font0" style="font-weight:bold;">o</span><span class="font2">namun diklasifikasikan salah oleh sistem.</span></p></li></ul>
<p><span class="font2">Berdasarkanjjnilaijj</span><span class="font2" style="font-style:italic;">True Negative</span><span class="font2"> (TN), </span><span class="font2" style="font-style:italic;">False Positive</span><span class="font2"> (FP</span><span class="font2" style="font-style:italic;">), False Negative</span><span class="font2"> (FN), dan </span><span class="font2" style="font-style:italic;">True Positive</span><span class="font2"> (TP) dapatodiperolehnilai akurasi, presisiodan</span><span class="font2" style="font-style:italic;">recall</span><span class="font2">. Nilaioakurasi menggambarkan seberapa akuratjjsistemjjdapatjjmengklasifikasikanjjdatajjsecarajjbenar. Denganjjjkatajjlain, nilaijjjakurasijjjmerupa kan perbandingan antara data yang terklasifikasi benar dengan keseluruhan data. Nilai akurasi dapat diperolehjdenganjjpersamaanjj(6). Nilaijjpresisijjmenggambarkanjjjumlahjdatajjkategorijjjpositif yang diklasifikasikan secara benar dibagi dengan total data yang diklasifikasi positif. Presisi dapat diperolehodenganjpersamaano(7)jsementara itu, </span><span class="font2" style="font-style:italic;">recall</span><span class="font2"> menunjukkanoberapajpersenjdatajkategori positif yang terklasifikasikanjdengan benar oleh sistem. Nilai </span><span class="font2" style="font-style:italic;">recall</span><span class="font2"> diperoleh denganjpersamaan 8.</span></p>
<p><a href="#bookmark14"><span class="font2">Akurasi =(6)</span></a></p>
<p><a href="#bookmark15"><span class="font9" style="font-weight:bold;font-style:italic;">TP+TN+FP+FN &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<sup>v,</sup></span></a></p>
<p><a href="#bookmark16"><span class="font2">Presisi =(7)</span></a></p>
<p><a href="#bookmark17"><span class="font9" style="font-weight:bold;font-style:italic;">FP^7P &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<sup>v,</sup></span></a></p>
<p><a href="#bookmark18"><span class="font2" style="font-style:italic;">Recall</span><span class="font2"> = &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;* 100%(8)</span></a></p>
<p><a href="#bookmark19"><span class="font9" style="font-weight:bold;font-style:italic;">m+TF &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;''</span></a></p>
<p><span class="font2">Setelah mendapat nilai </span><span class="font2" style="font-style:italic;">recal</span><span class="font2">l dan </span><span class="font2" style="font-style:italic;">precision</span><span class="font2">, makaodilakukanoperhitunganomenggunakanoF1-</span><span class="font2" style="font-style:italic;">score</span><span class="font2">. F1-</span><span class="font2" style="font-style:italic;">score</span><span class="font2">odigunakanountukomengukurokombinasiohasil </span><span class="font2" style="font-style:italic;">precision</span><span class="font2"> dan </span><span class="font2" style="font-style:italic;">recall</span><span class="font2">, sehingga menjadi satu nilai pengukuran. F1-</span><span class="font2" style="font-style:italic;">Score</span><span class="font2"> dapat dihitung menggunakan persamaan 9:</span></p>
<p><span class="font2">2</span></p>
<p><span class="font2">F1 = &nbsp;&nbsp;&nbsp;</span><span class="font2" style="text-decoration:underline;">- &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-------</span><span class="font2"> (9)</span></p>
<p><span class="font9" style="font-weight:bold;font-style:italic;">Precission Recall</span></p>
<ul style="list-style:none;"><li>
<p><span class="font2" style="font-weight:bold;">3. &nbsp;&nbsp;&nbsp;Hasil dan Pembahasan</span></p></li></ul>
<p><span class="font2">Pada penelitian yang dilakukan ada 80%ototal data digunakan selama tahap pelatihan dan juga validasi. Perubahan nilai k pada percobaan adalah k = 4, k = 6, k = 7, k = 9, dan k = 11. Uji </span><span class="font2" style="font-style:italic;">threshold </span><span class="font2">dilakukan dengan menggunakan seleksi fitur </span><span class="font2" style="font-style:italic;">Gini Index</span><span class="font2"> dan seleksi fitur </span><span class="font2" style="font-style:italic;">Chi-Square</span><span class="font2">. </span><span class="font2" style="font-style:italic;">Threshold</span><span class="font2">oadalah persentasemjumlah fitur yang dipilih dari semua fitur yang diurutkan. </span><span class="font2" style="font-style:italic;">Threshold </span><span class="font2">yang digunakan adalah 10%, 5%, 2%, 1%, 0.5%, dan 0.2%. Pada setiap iterasi dari 10-</span><span class="font2" style="font-style:italic;">Fold Cross Validation</span><span class="font2">, akan dihitung rata-rata performa F1-</span><span class="font2" style="font-style:italic;">Score</span><span class="font2"> dan akurasi dengan menggunakan persamaan (9) dan (6). Nilai k dengan kinerja F1-</span><span class="font2" style="font-style:italic;">Score</span><span class="font2"> tertinggi akan dipilih sebagai model yang terbaik. Nilai k dengan F1-</span><span class="font2" style="font-style:italic;">Score</span><span class="font2"> tertinggi berarti hasil klasifikasi jurnal lebih akurat. Setelah melakukan proses pelatihan dan validasi pada model </span><span class="font2" style="font-style:italic;">K-Nearest Neighbor</span><span class="font2"> menggunakan uji 10-</span><span class="font2" style="font-style:italic;">Fold Cross Validation</span><span class="font2">,</span></p>
<p><span class="font2">Istighfarizky, dkk</span></p>
<p><span class="font2">Klasifikasi Jurnal menggunakan Metode KNN dengan Mengimplementasikan Perbandingan Seleksi Fitur didapatkan nilai k dengan performansi F1-</span><span class="font2" style="font-style:italic;">Score</span><span class="font2"> terbaik. Uji kombinasi </span><span class="font2" style="font-style:italic;">threshold Chi-Square</span><span class="font2"> dan </span><span class="font2" style="font-style:italic;">Gini Index</span><span class="font2"> dan nilai k yang sudah dilakukan menghasilkan beragam performa yang berbeda. Dari hasil pengujian yang diperoleh, dapat dilihat pengaruh dari </span><span class="font2" style="font-style:italic;">threshold</span><span class="font2"> yang digunakan untuk performansi dari metode </span><span class="font2" style="font-style:italic;">K-Nearest Neighbor</span><span class="font2">, seperti yang ditunjukkan pada tabel 5.</span></p>
<p><span class="font2">Tabel 5. Hasil Evaluasi Pengujian KNN dengan Seleksi Fitur Chi-Square dan Gini Index</span></p>
<table border="1">
<tr><td rowspan="2" style="vertical-align:middle;">
<p><span class="font4" style="font-weight:bold;">Threshold</span></p></td><td colspan="4" style="vertical-align:top;">
<p><span class="font3" style="font-weight:bold;">Ukuran Evaluasi (Rata-Rata Fold)</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font2" style="font-weight:bold;">F-1 Score</span></p>
<p><span class="font2" style="font-weight:bold;">Chi-Square</span></p></td><td style="vertical-align:top;">
<p><span class="font2" style="font-weight:bold;">F1-Sscore</span></p>
<p><span class="font2" style="font-weight:bold;">Gini Index</span></p></td><td style="vertical-align:top;">
<p><span class="font2" style="font-weight:bold;">Akurasi</span></p>
<p><span class="font2" style="font-weight:bold;">Chi-Square</span></p></td><td style="vertical-align:top;">
<p><span class="font2" style="font-weight:bold;">Akurasi</span></p>
<p><span class="font2" style="font-weight:bold;">Gini Index</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font3" style="font-weight:bold;">10%</span></p></td><td style="vertical-align:top;">
<p><span class="font2">82,2%</span></p></td><td style="vertical-align:top;">
<p><span class="font2">75,2%</span></p></td><td style="vertical-align:top;">
<p><span class="font2">82%</span></p></td><td style="vertical-align:top;">
<p><span class="font2">75%</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font3" style="font-weight:bold;">5%</span></p></td><td style="vertical-align:top;">
<p><span class="font2">81,4%</span></p></td><td style="vertical-align:top;">
<p><span class="font2">81,7%</span></p></td><td style="vertical-align:top;">
<p><span class="font2">81,2%</span></p></td><td style="vertical-align:top;">
<p><span class="font2">81,6%</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font3" style="font-weight:bold;">2%</span></p></td><td style="vertical-align:top;">
<p><span class="font2">81,6%</span></p></td><td style="vertical-align:top;">
<p><span class="font2">82,2%</span></p></td><td style="vertical-align:top;">
<p><span class="font2">81,2%</span></p></td><td style="vertical-align:top;">
<p><span class="font2">82%</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font3" style="font-weight:bold;">1%</span></p></td><td style="vertical-align:top;">
<p><span class="font2">81,8%</span></p></td><td style="vertical-align:top;">
<p><span class="font2">81,4%</span></p></td><td style="vertical-align:top;">
<p><span class="font2">81,6%</span></p></td><td style="vertical-align:top;">
<p><span class="font2">80,8%</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font3" style="font-weight:bold;">0.5%</span></p></td><td style="vertical-align:top;">
<p><span class="font2">81,6%</span></p></td><td style="vertical-align:top;">
<p><span class="font2">71,5%</span></p></td><td style="vertical-align:top;">
<p><span class="font2">81,2%</span></p></td><td style="vertical-align:top;">
<p><span class="font2">71,6%</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font3" style="font-weight:bold;">0.2%</span></p></td><td style="vertical-align:top;">
<p><span class="font2">74,1%</span></p></td><td style="vertical-align:top;">
<p><span class="font2">47,9%</span></p></td><td style="vertical-align:top;">
<p><span class="font2">74,1%</span></p></td><td style="vertical-align:top;">
<p><span class="font2">48,3%</span></p></td></tr>
</table>
<p><span class="font2">Pengujian kombinasi </span><span class="font2" style="font-style:italic;">threshold Chi-Square</span><span class="font2"> dan </span><span class="font2" style="font-style:italic;">Gini Index</span><span class="font2"> dan nilai k yang sudah dilakukan menghasilkan beragam performa yang berbeda. Dari hasil pengujian yang diperoleh dapat diketahui pengaruh </span><span class="font2" style="font-style:italic;">threshold</span><span class="font2"> yang digunakan terhadap evaluasi kinerja metode </span><span class="font2" style="font-style:italic;">K-Nearest Neighbor</span><span class="font2">, hal tersebut dapat dilihat pada gambar 5 dan gambar 6.</span></p>
<h2><a name="bookmark20"></a><span class="font7" style="font-weight:bold;"><a name="bookmark21"></a>PENGARUH THRESHOLD TERHADAP Fl</span><br><br><span class="font7" style="font-weight:bold;"><a name="bookmark22"></a>SCORE</span></h2><img src="https://jurnal.harianregional.com/media/89148-6.jpg" alt="" style="width:387pt;height:169pt;">
<p><span class="font2" style="font-weight:bold;">Gambar 5. </span><span class="font2">Pengaruh Threshold terhadap F1-Score</span></p>
<p><span class="font2">Gambar 5 menunjukkan pengaruh </span><span class="font2" style="font-style:italic;">threshold</span><span class="font2"> terhadap performa </span><span class="font2" style="font-style:italic;">F1-Score</span><span class="font2"> metode </span><span class="font2" style="font-style:italic;">K-Nearest Neighbor</span><span class="font2"> dengan seleksi fitur </span><span class="font2" style="font-style:italic;">Chi-Square</span><span class="font2"> dan seleksi fitur </span><span class="font2" style="font-style:italic;">Gini Index</span><span class="font2">. </span><span class="font2" style="font-style:italic;">F1-Score</span><span class="font2"> yang tertera pada Gambar 5 adalah nilai </span><span class="font2" style="font-style:italic;">F1-Score</span><span class="font2"> dari kombinasi nilai k dengan akurasi tertinggi. Nilai </span><span class="font2" style="font-style:italic;">threshold </span><span class="font2">diketahui memiliki pengaruh terhadap </span><span class="font2" style="font-style:italic;">F1-Score</span><span class="font2">.</span></p>
<h2><a name="bookmark23"></a><span class="font7" style="font-weight:bold;"><a name="bookmark24"></a>PENGARUH THRESHOLD TERHADAP AKURASI</span></h2><img src="https://jurnal.harianregional.com/media/89148-7.jpg" alt="" style="width:377pt;height:164pt;">
<p><span class="font2" style="font-weight:bold;">Gambar 6. </span><span class="font2">Pengaruh Threshold terhadap akurasi</span></p>
<p><span class="font2">Akurasi yang tertera pada Gambar 6 adalah akurasi tertinggi dari kombinasi nilai k yang sudah diuji. Nilai threshold diketahui memiliki pengaruh terhadap akurasi. Model dengan threshold yang menghasilkan akurasi di atas nilai rata-rata tersebut dapat dikatakan sebagai model dengan performa yang baik dalam mengklasifikasikan jurnal.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font2" style="font-weight:bold;">4. &nbsp;&nbsp;&nbsp;Kesimpulan</span></p></li></ul>
<p><span class="font2">Berdasarkan penelitian yang telah dilakukan, ditarik kesimpulan bahwa implementasi seleksi fitur dapat meningkatkan performa </span><span class="font2" style="font-style:italic;">precision</span><span class="font2">, </span><span class="font2" style="font-style:italic;">recall, F1-Score,</span><span class="font2"> dan akurasi dari metode </span><span class="font2" style="font-style:italic;">K-Nearest Neighbor</span><span class="font2"> dalam mengklasifikasikan jurnal dan seleksi fitur </span><span class="font2" style="font-style:italic;">Chi-Square</span><span class="font2"> lebih unggul daripada seleksi fitur </span><span class="font2" style="font-style:italic;">Gini Index</span><span class="font2">. Pada eksperimen seleksi fitur </span><span class="font2" style="font-style:italic;">Chi-Square</span><span class="font2">, kombinasi </span><span class="font2" style="font-style:italic;">threshold</span><span class="font2"> 1% denganoparameter nilaiok=6 adalah kombinasi yang dipilih menjadi model terbaik. </span><span class="font2" style="font-style:italic;">Threshold</span><span class="font2"> ini menyeleksi sekitar 31 fitur dengan nilai </span><span class="font2" style="font-style:italic;">Chi-Square</span><span class="font2"> tertinggi. Pada pengujian data baru, model </span><span class="font2" style="font-style:italic;">K-Nearest Neighbor</span><span class="font2"> dengan seleksi fitur </span><span class="font2" style="font-style:italic;">Chi-Square</span><span class="font2"> menghasilkan performa </span><span class="font2" style="font-style:italic;">precision</span><span class="font2">, </span><span class="font2" style="font-style:italic;">recall, F1-Score, </span><span class="font2">dan akurasi secara berturut-turut yaitu 85%, 83.3%, 88.2%, dan 92.3%. Pada eksperimen seleksi fitur </span><span class="font2" style="font-style:italic;">Gini Index</span><span class="font2">, kombinasi </span><span class="font2" style="font-style:italic;">threshold 1</span><span class="font2">% dengan parameter nilai k=4 adalah kombinasi yang dipilih menjadi model terbaik. </span><span class="font2" style="font-style:italic;">Threshold</span><span class="font2"> ini menyeleksi sekitar 31 fitur dengan nilai </span><span class="font2" style="font-style:italic;">Gini Index</span><span class="font2"> tertinggi. Pada pengujian data baru, model </span><span class="font2" style="font-style:italic;">K-Nearest Neighbor</span><span class="font2"> dengan seleksi fitur </span><span class="font2" style="font-style:italic;">Gini Index</span><span class="font2"> menghasilkan performa </span><span class="font2" style="font-style:italic;">precision</span><span class="font2">, </span><span class="font2" style="font-style:italic;">recall, F1-Score,</span><span class="font2"> dan akurasi secara berturut-turut yaitu 81.2%, 80.3%, 81.6%, dan 86.6%</span></p>
<p><span class="font2" style="font-weight:bold;">Daftar Pustaka</span></p>
<ul style="list-style:none;"><li>
<p><span class="font2">[1] &nbsp;&nbsp;&nbsp;Z. XIONG, J. JIANG and Y. ZHANG, &quot;New feature selection approach (CDF) for text categorization&quot;, </span><span class="font2" style="font-style:italic;">Journal of Computer Applications</span><span class="font2">, vol. 29, no. 7, pp. 1755-1757, 2009. Available: 10.3724/sp.j.1087.2009.01755.</span></p></li>
<li>
<p><span class="font2">[2] &nbsp;&nbsp;&nbsp;H. Alshalabi, S. Tiun, N. Omar and M. Albared, &quot;Experiments on the Use of Feature Selection and Machine Learning Methods in Automatic Malay Text Categorization&quot;, </span><span class="font2" style="font-style:italic;">Procedia Technology</span><span class="font2">, vol. 11, pp. 748-754, 2013. Available: 10.1016/j.protcy.2013.12.254.</span></p></li>
<li>
<p><span class="font2">[3] &nbsp;&nbsp;&nbsp;I. Listiowarni and N. Puspa Dewi, &quot;Pemanfaatan Klasifikasi Soal Biologi Cognitive Domain Bloom’s Taxonomy Menggunakan KNN Chi-Square Sebagai Penyusunan Naskah Soal&quot;, </span><span class="font2" style="font-style:italic;">Digital Zone: Jurnal Teknologi Informasi dan Komunikasi</span><span class="font2">, vol. 11, no. 2, pp. 186-197, 2020. Available:</span></p></li></ul>
<p><span class="font2">Istighfarizky, dkk Klasifikasi Jurnal menggunakan Metode KNN dengan Mengimplementasikan</span></p>
<p><span class="font2">Perbandingan Seleksi Fitur 10.31849/digitalzone.v11i2.4798.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font2">[4] &nbsp;&nbsp;&nbsp;T. Setiyorini and R. Asmono, &quot;PENERAPAN METODE K-NEAREST NEIGHBOR DAN GINI INDEX PADA KLASIFIKASI KINERJA SISWA&quot;, </span><span class="font2" style="font-style:italic;">Jurnal Techno Nusa Mandiri</span><span class="font2">, vol. 16, no. 2, pp. 121-126, 2019. Available: 10.33480/techno.v16i2.747.</span></p></li>
<li>
<p><span class="font2">[5] &nbsp;&nbsp;&nbsp;K. Yonatha Wijaya and A. Karyawati, &quot;The Effects of Different Kernels in SVM Sentiment Analysis on Mass Social Distancing&quot;, </span><span class="font2" style="font-style:italic;">JELIKU (Jurnal Elektronik Ilmu Komputer Udayana)</span><span class="font2">, vol. 9, no. 2, p. 161, 2020. Available: 10.24843/jlk.2020.v09.i02.p01.</span></p></li>
<li>
<p><span class="font2">[6] &nbsp;&nbsp;&nbsp;H. Hadi and T. Sukamto, &quot;Klasifikasi Jenis Laporan Masyarakat Dengan K-Nearest Neighbor Algorithm&quot;, </span><span class="font2" style="font-style:italic;">JOINS (Journal of Information System)</span><span class="font2">, vol. 5, no. 1, pp. 77-85, 2020. Available: 10.33633/joins.v5i1.3355.</span></p></li>
<li>
<p><span class="font2">[7] &nbsp;&nbsp;&nbsp;C. Suharno, M. Fauzi and R. Perdana, &quot;Klasifikasi Teks Bahasa Indonesia Pada Dokumen Pengaduan &nbsp;Sambat Online Menggunakan Metode K-Nearest Neighbors Dan Chi</span></p></li></ul>
<p><span class="font2">square&quot;, </span><span class="font2" style="font-style:italic;">Systemic: Information System and Informatics Journal</span><span class="font2">, vol. 3, no. 1, pp. 25-32, 2017. Available: 10.29080/systemic.v3i1.191.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font2">[8] &nbsp;&nbsp;&nbsp;C. Aggarwal, Data Mining: The Textbook. Springer International Publishing Switzerland, 2015. Available: 10.1007/978-3-319-14142-8.</span></p></li>
<li>
<p><span class="font2">[9] &nbsp;&nbsp;&nbsp;M. Imron and B. Prasetyo, &quot;Improving Algorithm Accuracy K-Nearest Neighbor Using Z-Score Normalization and Particle Swarm Optimization to Predict Customer Churn&quot;, </span><span class="font2" style="font-style:italic;">Shmpublisher.com</span><span class="font2">, 2022. [Online]. Available: </span><a href="https://shmpublisher.com/index.php/joscex/article/view/7"><span class="font2">https://shmpublisher.com/index.php/joscex/article/view/7</span></a><span class="font2">.</span></p></li></ul>
<p><span class="font2">176</span></p>