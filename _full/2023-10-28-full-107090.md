---
layout: full_article
title: "Associative Classification with Classification Based Association (CBA) Algorithm on Transaction Data with Rshiny"
author: "Alesia Arum Frederika, I Putu Agung Bayupati, Wira Buana"
categories: lontar
canonical_url: https://jurnal.harianregional.com/lontar/full-107090 
citation_abstract_html_url: "https://jurnal.harianregional.com/lontar/id-107090"
citation_pdf_url: "https://jurnal.harianregional.com/lontar/full-107090"  
comments: true
---

<p><span class="font4" style="font-weight:bold;">LONTAR KOMPUTER VOL. 14, NO. 1 APRIL 2023</span></p>
<p><span class="font4" style="font-weight:bold;">DOI : 10.24843/LKJITI.2023.v14.i01.p03</span></p>
<p><span class="font4" style="font-weight:bold;">Accredited Sinta 2 by RISTEKDIKTI Decree No. 158/E/KPT/2021</span></p>
<p><span class="font4" style="font-weight:bold;">p-ISSN 2088-1541</span></p>
<p><span class="font4" style="font-weight:bold;">e-ISSN 2541-5832</span></p><a name="caption1"></a>
<h1><a name="bookmark0"></a><span class="font5" style="font-weight:bold;"><a name="bookmark1"></a>Associative Classification with Classification Based Association (CBA) Algorithm on Transaction Data with Rshiny</span></h1>
<p><span class="font4">Alesia Arum Frederika<sup>a1</sup></span><span class="font4" style="font-weight:bold;">, </span><span class="font4">I Putu Agung Bayupati<sup>a2</sup></span><span class="font4" style="font-weight:bold;">, </span><span class="font4">Putu Wira Buana<sup>a3</sup></span></p>
<p><span class="font4"><sup>a</sup>Information Technology Department, Udayana University</span></p>
<p><span class="font4">Bali, Indonesia</span></p>
<p><a href="mailto:1alesiaarum@student.unud.ac.id"><span class="font4" style="text-decoration:underline;"><sup>1</sup>alesiaarum@student.unud.ac.id</span><span class="font4"> </span></a><span class="font1" style="font-variant:small-caps;">(c</span><span class="font2">orresponding author)</span></p>
<p><a href="mailto:2bayupati@unud.ac.id"><span class="font4" style="text-decoration:underline;"><sup>2</sup>bayupati@unud.ac.id</span></a><span class="font4" style="text-decoration:underline;"> </span><a href="mailto:wb@unud.ac.id"><span class="font4" style="text-decoration:underline;">wb@unud.ac.id</span></a></p>
<p><span class="font4" style="font-weight:bold;font-style:italic;">Abstract</span></p>
<p><span class="font4" style="font-style:italic;">Data mining can be used for businesses with large amounts of data. One of the data mining techniques is Associative Classification. It is a new strategy in data processing that combines association and classification techniques to build a classification model. This research used an associative classification technique on sales transaction data of Frozen Food Stores, which had sales transaction data on their business activities. It would be used in sales strategies to find items often purchased by class customers, namely, members and general. This research aimed to classify based on association rules using the CBA (Classification based Association) algorithm on sales transaction data. The application used the R programming language that business owners could use. The results of the rules obtained from the trial had the value of support, confidence, coverage, and lift ratio, which were the best value levels of a rule. The results of the rules that had the highest lift ratio value from all the data that have been inputted can be used as a reference to be implemented in sales strategies in knowing consumer needs.</span></p>
<p><span class="font4" style="font-weight:bold;font-style:italic;">Keywords: </span><span class="font4" style="font-style:italic;">Data Mining, Associative Classification, Classification Based Association Algorithm, Rshiny</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark2"></a><span class="font4" style="font-weight:bold;"><a name="bookmark3"></a>1. &nbsp;&nbsp;&nbsp;Introduction</span></h2></li></ul>
<p><span class="font4">Technology has experienced rapid development and advance nowadays. Along with these technological advances, business development in the economy through the free market brings companies to an intense competition level. Therefore, the amount of business competition and the development of increasingly advanced technology can be used in implementing business with information technology. Implementing information technology in business activities can facilitate companies in carrying out business activities. Business activities in companies have great potential to have abundant data. A lot of data in the company can cause a slow process of retrieving information.</span></p>
<p><span class="font4">One way to determine market conditions is by observing transaction sales data. Sales transaction data shows the wants and needs of consumers, which are stored for sales reports and income statements. Sales transaction data has a large amount of data but does not have a significant increase in information. Several studies have been conducted in terms of data mining in sales data, such as data mining in grocery stores using the Apriori algorithm [1], data mining on sales transaction data at the Fasentro Fancy store [2], and the application of Data Mining on Goods Sales Transactions at BE-MART Store [3]. These studies used the Apriori algorithm, which used association rules that were very suitable for mining transaction data. In addition, mining transaction data can also be used to analyze consumer purchasing patterns [4] and predict sales transactions [5].</span></p>
<p><span class="font4">Frozen Food Store is a business in the food sector, with the main product being processed frozen food. Methods of processed frozen food result from food preservation by lowering the temperature to freezing. It aims to slow down the decay process [6]. Frozen Food Store has various types of</span></p>
<p><span class="font4">products that produce thousands of sales transaction data in its business activities that have not been utilized to provide information in developing sales strategies. Problems arise when the business owner has difficulty analyzing sales transaction data due to a large amount of data and limited data processing tools. Problems related to transaction data analysis can cause inappropriate sales strategies to be carried out.</span></p>
<p><span class="font4">One of the helpful technology applications in business applications is data mining. Data Mining is a statistical, mathematical, artificial intelligence, and machine learning technique used to extract and identify useful information from various sales data into valuable information in making decisions on these companies or business activities. Associative Classification is one of the applications carried out on sales transaction data [7].</span></p>
<p><span class="font4">Associative Classification (AC) is a data mining technique that uses association rule discovery methods in classification problems. Several studies prove that AC (Associative Classification) techniques can provide more accurate classification models than traditional classification techniques, such as a decision tree, rule induction, and probabilistic approaches [8]. Classification Rule Mining is a promising approach in data mining to create more interpretable and accurate prediction systems. This approach typically builds on Classification and Association rule data mining techniques, which identify a subset of rules known as Class Association Rules (CAR), whose consequences are limited to the target class label [9]. The rule generation phase is the phase to generate frequent itemsets in the AC (associative Classification) method. This phase extracts rules that aim to generate a set of CAR (Class Association Rules).</span></p>
<p><span class="font4">The second phase in AC (associative Classification) is the classifier-building phase. The classifier-building phase is a phase to predict or classify data that has not been categorized in a particular class or label. Algorithms of associative classification methods are CBA, CMAR, MCAR, L3G, and so on [10].</span></p>
<p><span class="font4">The associative classification algorithm used in Frozen Food Store sales data is the Classification Based Association (CBA) found in the R package. R is a programming language for performing statistical and graphical analysis. The R programming language also uses many packages as needed [11].</span></p>
<p><span class="font4">Innovations are carried out to determine market conditions in frozen food stores using data mining techniques, namely associative Classification. Associative classification analysis can show the wants and needs of consumers in frozen food stores. The package used in implementing associative Classification with the CBA (Classification Based Association) algorithm is the arulesCBA package. Classification Based Association (CBA) integrates classification techniques with association techniques in data mining to find rules. The rules found depend on the minimum support and minimum confidence.</span></p>
<p><span class="font4">Associative classification analysis with the CBA (Classification Based Association) algorithm on Frozen Food Store sales data can be used to provide information from the results of the rules obtained, namely to find the types of goods often purchased by class members and general customers who have support, confidence, and coverage values, as well as lift ratios that can be used as information in decision making for sales strategies at Frozen Food Stores using the RShiny web framework.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark4"></a><span class="font4" style="font-weight:bold;"><a name="bookmark5"></a>2. &nbsp;&nbsp;&nbsp;Research Methods</span></h2></li></ul>
<p><span class="font4">The research phase started with several stages, including the planning stage, the data collection stage, designing the Associative Classification application with the CBA (Classification Based Association) algorithm, and analyzing and evaluating Associative Classification process results with the CBA (Classification Based Association) algorithm).</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark6"></a><span class="font4" style="font-weight:bold;"><a name="bookmark7"></a>2.1. &nbsp;&nbsp;&nbsp;Planning Stages</span></h2></li></ul>
<p><span class="font4">The planning stage included defining the problem, explaining the research objectives, benefits, and problem boundaries as the basis for making the Associative Classification analysis application, and collecting literature reviews.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark8"></a><span class="font4" style="font-weight:bold;"><a name="bookmark9"></a>2.2. &nbsp;&nbsp;&nbsp;Data Collection</span></h2></li></ul>
<p><span class="font4">Data used in the research was secondary data obtained by researchers from existing sources. The data used was sales transaction data from Frozen Food Stores from October 2019 to January 2020. The number of transactions owned at Frozen Food Stores was 6928 in October, 7322 in November, 6480 in December, and 7164 in January.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark10"></a><span class="font4" style="font-weight:bold;"><a name="bookmark11"></a>2.3. &nbsp;&nbsp;&nbsp;Application Design</span></h2></li></ul>
<p><span class="font4">The design of the Associative Classification application with the CBA (Classification based Association) algorithm began with modeling with the R language using the arulesCBA package. Furthermore, the application was designed using R and the Shiny package to create the application interface.</span></p><img src="https://jurnal.harianregional.com/media/107090-1.jpg" alt="" style="width:197pt;height:179pt;">
<p><span class="font4" style="font-weight:bold;">Figure 1. </span><span class="font4">Gambaran Umum Aplikasiover of Lontar Komputer</span></p>
<p><span class="font4">Figure 1 is the application overview. The data load process was done by inputting data in Excel file format. Data pre-processing prepared raw data into the required data format [12].</span></p>
<p><span class="font4">The initial input data was from frozen food store sales transactions with 13 attributes: invoice number, transaction code, transaction date, transaction total, item code, item name, item price, category code, category name, quantity, total, class, and customer name. Data pre-processing was done by selecting and transforming data from the initial data into predetermined transformation data. The attributes used were item code and class label. Table 1 is an example of data pre-processing data results.</span></p>
<p><span class="font4" style="font-weight:bold;">Table 1. </span><span class="font4">Data Pre-processing Results</span></p>
<p><span class="font4">Kode_brg &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Class</span></p>
<table border="1">
<tr><td style="vertical-align:bottom;">
<p><span class="font9">SOSIS37</span></p></td><td style="vertical-align:bottom;">
<p><span class="font9">MEMBER</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font9">BAKSO10</span></p></td><td style="vertical-align:bottom;">
<p><span class="font9">MEMBER</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font9">NAGET50</span></p></td><td style="vertical-align:bottom;">
<p><span class="font9">UMUM</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font9">BUMBU22</span></p></td><td style="vertical-align:bottom;">
<p><span class="font9">UMUM</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font9">SOSIS45</span></p></td><td style="vertical-align:bottom;">
<p><span class="font9">UMUM</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font9">BAKSO10</span></p></td><td style="vertical-align:bottom;">
<p><span class="font9">MEMBER</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font9">SOSIS45</span></p></td><td style="vertical-align:bottom;">
<p><span class="font9">UMUM</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font9">SOSIS37</span></p></td><td style="vertical-align:bottom;">
<p><span class="font9">MEMBER</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font9">BAKSO10</span></p></td><td style="vertical-align:middle;">
<p><span class="font9">MEMBER</span></p></td></tr>
</table>
<p><span class="font4">The user would perform the AC (Associative Classification) process with the CBA algorithm. To perform this process, it would use the arules library and the arulesCBA library available in Rstudio. The AC (Associative Classification) process began with the user entering parameters, including minimum support and confidence. Each ruleitems represented an itemset/condset </span><span class="font9">→ </span><span class="font4">y, where y is the class label. The ruleitems obtained would get a value using the formula.</span></p>
<table border="1">
<tr><td style="vertical-align:middle;">
<p><span class="font9">Support &nbsp;&nbsp;=</span></p></td><td style="vertical-align:top;">
<p><span class="font8" style="font-style:italic;">Rulesup</span></p>
<p><span class="font8">|D|</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">(1)</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font9">Confidence =</span></p></td><td style="vertical-align:middle;">
<p><span class="font8">Rulesup condsup</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">(2)</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font9">Coverage &nbsp;=</span></p></td><td style="vertical-align:middle;">
<p><span class="font8" style="font-style:italic;">Count, left</span></p>
<p><span class="font8">|D|</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">(3)</span></p></td></tr>
<tr><td rowspan="2" style="vertical-align:bottom;">
<p><span class="font9">Lift ratio &nbsp;&nbsp;=</span></p></td><td style="vertical-align:bottom;">
<p><span class="font8" style="font-style:italic;">confidence</span></p></td><td rowspan="3" style="vertical-align:bottom;">
<p><span class="font4">(4)</span></p></td></tr>
<tr><td rowspan="2" style="vertical-align:bottom;">
<p><span class="font8" style="font-style:italic;">benchmark conf</span></p></td></tr>
<tr><td style="vertical-align:top;"></td></tr>
</table>
<div>
<p><span class="font4">Where:</span></p>
<p><span class="font4">Rulesup</span></p>
<p><span class="font4">Condsup</span></p>
<p><span class="font4">|D|</span></p>
<p><span class="font4">Count left</span></p>
<p><span class="font4">Benchmark conf</span></p>
</div><br clear="all">
<p><span class="font4">= number of items and class y in dataset D</span></p>
<p><span class="font4">= number of items in dataset D</span></p>
<p><span class="font4">= number/size of datasets</span></p>
<p><span class="font4">= items on the left</span></p>
<p><span class="font4">= number of count right divided by |D|</span></p>
<p><span class="font4">The ruleitem rules obtained had a support value, which is a supporting value to determine item dominance level from the entire transaction, a confidence value, which is a certainty value to show the relationship of item combination in a rule, and a coverage value, which is a coverage value of how often the left-hand item (lhs) occurs in all transactions, and a lift ratio value which is the accuracy of item combination in the rules that have been obtained. The results of AC (Associative Classification) rules that had been generated after the AC (Associative Classification) process with the CBA (Classification based Association) algorithm were presented in the form of table data and visualization using the arulesViz library available in Rstudio.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark12"></a><span class="font4" style="font-weight:bold;"><a name="bookmark13"></a>2.3.1. &nbsp;&nbsp;&nbsp;Associative Classification</span></h2></li></ul>
<p><span class="font4">Associative Classification is a combination of association rules with Classification. Associative Classification is a special method based on association rule mining, with attributes or class labels on the rule's right side. For example, X =&gt; Y, Y must be a class attribute [13]. Associative Classification is a data mining technique that performs Classification with association rules. Associative classification algorithms have been proposed, such as Classification based Association (CBA), Classification based on Multiple Association Rules (CMAR), Class based Associative Classification (CACA), and Classification based on Predicted Association Rule (CPAR) [14].</span></p>
<p><span class="font4">Associative Classification (AC) is a suitable classification approach that facilitates managers' prediction and decision-making in a highly accurate and easy-to-interpret manner. Most existing AC algorithms mainly focus on two static metrics of association rules: support and confidence [15]. Associative Classification uses the parameters of minimum support and minimum confidence. Data in associative Classification can be represented in horizontal, vertical, and set theory data representation [16]. Horizontal theory is adopted from association rule mining. This type of theory is found in the CBA algorithm. The vertical approach converts training data into a table that identifies transactions. This type of theory is found in Multi-Class Multi-Label Associative Classification (MMAC) and MultiClass Classification Association Rules (MCAR). The set approach is based on removing redundant attributes from the training dataset.</span></p>
<p><span class="font4">Furthermore, AC (Associative Classification) applied rule ranking and pruning to minimize the number of rules in the classifier. The reduction made the classifier smaller, improving classification efficiency [17]. The first algorithm proposed in the AC (Associative Classification) field was the CBA (Classification-based Association) algorithm. It worked in two phases, and the first one generated association rules through an exhaustive search algorithm. Then, it ranked the discovered rules to form the final classifier in the second phase [18]. On the other hand, Associative Classification fitted categorical domains very well, and they had the potential to outperform other advanced algorithms. Associative Classification on a distributed computing framework performed on a job, proving the feasibility of such a system [19].</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark14"></a><span class="font4" style="font-weight:bold;"><a name="bookmark15"></a>2.3.2. &nbsp;&nbsp;&nbsp;CBA Algorithm</span></h2></li></ul>
<p><span class="font4">The CBA (Classification-based Association) algorithm is an algorithm that performs classifiers based on an association approach that has a slightly more accurate and effective level. The CBA (Classification-based Association) algorithm is a utilization derived from the Apriori algorithm. CBA discovers and generates rules by applying Aprori rules that generate candidate characteristics. The main difference between an itemset and a ruleitem is that an itemset only appears as an attribute value through itself, where as a ruleitem consists of a classification value attached to an attribute value. The concept of modeling the CBA algorithm is divided into two stages: CBA-RG and CBA-CB [20].</span></p>
<p><span class="font4">CBA-RG or CBA rule generator is based on the Apriori method in finding the results of association rules in the process. This stage was carried out to find ruleitems that have or meet the parameters of the minimum support. The first step of generating all frequent rule items was to calculate the support of the individual rule items and determine their status. Subsequence with a support value higher than the minimum support was a frequent ruleitem in the previous stage. The process of creating a possible set of new frequent ruleitems was called the candidate ruleitem. The candidate ruleitems were then calculated for their support value to determine candidate ruleitems with a support value more significant than the minimum support to determine frequent candidate ruleitems. After that, the rules (CARs) were produced.</span></p>
<p><span class="font4">CBA-CB is a classifier builder using CARs or prCARs that have been obtained previously in the CBA-RG stage. Producing a classifier was done by performing an evaluation stage on all possible subsets in the training data and selecting the subset with the rule sequence with the least error by looking at the rules with a more excellent confidence value. For example, if given two rules r</span><span class="font1">i </span><span class="font4">and r</span><span class="font1">j</span><span class="font4">. If the confidence value of r</span><span class="font1">i</span><span class="font4">is greater than r</span><span class="font1">j</span><span class="font4">, then r</span><span class="font1">i </span><span class="font4">is among the rules with a higher priority. If the confidence r</span><span class="font1">i </span><span class="font4">and r</span><span class="font1">j </span><span class="font4">have the same value, but the support value of r</span><span class="font1">i </span><span class="font4">is greater than r</span><span class="font1">j</span><span class="font4">, then ri is included in the higher priority rules. If both rules' confidence and support values are the same, but r</span><span class="font1">i </span><span class="font4">is generated earlier than r</span><span class="font1">j, </span><span class="font4">then the first rule order chosen is r</span><span class="font1">i</span><span class="font4">. The stage of building a classifier builder is sorting the generated &quot;r&quot; rules according to the precedence relationship (preceding or having a higher priority). The process was done by selecting the rules with the highest rights in performing the classifier.</span></p>
<p><span class="font4">The second step was to select the rules in a pre-sorted order for the classifier of R. Rules that were correctly classified would be marked. For example, marked R would become a potential rule in the classifier. The cases were covered and removed from the dataset as candidate rules. The default class selection was based on the remaining data's majority class. For example, if classifier C stops selecting rules, the class becomes the default class C. The next step was to calculate the number of errors made by C and the default class and record them. When no more candidate rules exist, the rules selection process is complete.</span></p><img src="https://jurnal.harianregional.com/media/107090-2.jpg" alt="" style="width:262pt;height:275pt;">
<p><span class="font4" style="font-weight:bold;">Figure 2. </span><span class="font4">Application Activity Diagram</span></p>
<p><span class="font4">Creating an Associative Classification application model using the CBA (Classification based Association) algorithm with the arulesCBA package in the R programming language using the shiny web framework for its appearance. The design of the activity diagram in the Associative Classification application using the CBA (Classification based Association) algorithm can be seen in Figure 2.</span></p>
<p><span class="font4">Figure 2 shows the activity diagram of the associative classification application. The home menu would be displayed when running the application for the first time. The user must input data used in the associative classification process in the form of Excel files. Server R would process and transform the data into the appropriate data format. Thus, the associative classification process could be carried out with a predetermined format. After the process was done, the application displayed the pre-processing data results. After pre-processing the data, the user could perform the associative Classification with the CBA (Classification based Association) algorithm. The user must input minsupp (minimum support) and minconf (minimum confidence).</span></p>
<p><span class="font4">Furthermore, it would process with the CBA (Classification based Association) algorithm from the data that had been inputted previously by the R server. With the support of the minsupp (minimum support) and minconf (minimum confidence) parameters that the user had input, it would display a summary of the associative classification process, which was the number of rules obtained from the process, the results of the associative classification rules which are details of the results of the rules obtained, and their visualization by the system. The user could save the associative classification results in Excel file format.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark16"></a><span class="font4" style="font-weight:bold;"><a name="bookmark17"></a>2.4. &nbsp;&nbsp;&nbsp;Analysis and Result Evaluation</span></h2></li></ul>
<p><span class="font4">Analysis and result evaluation was a stage to analyze and evaluate the results of the Associative Classification process, namely the accuracy value of the Associative Classification rules obtained with the CBA (Classification-based Association) algorithm.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark18"></a><span class="font4" style="font-weight:bold;"><a name="bookmark19"></a>3. &nbsp;&nbsp;&nbsp;Results and Discussion</span></h2></li></ul>
<p><span class="font4">Results and discussion contained a discussion of the application usage in the Associative Classification process with the CBA (Classification based Association) algorithm, evaluating and analyzing the results.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark20"></a><span class="font4" style="font-weight:bold;"><a name="bookmark21"></a>3.1. &nbsp;&nbsp;&nbsp;Application Usage</span></h2></li></ul>
<p><span class="font4">Application usage discusses the application the user used when using the Associative Classification application. When the user used the Associative Classification application, the user would see the home display in the Associative Classification application. The application home menu included the first display visited by the user when using the Associative Classification application. Furthermore, the user entered transaction data that would be used to perform the Associative Classification process. The initial data inputted would be displayed on the load data menu of the Associative Classification application. The data would be converted into transformed data with predefined attributes. The transformed data results on the load data menu, as shown in Figure 3.</span></p><img src="https://jurnal.harianregional.com/media/107090-3.jpg" alt="" style="width:212pt;height:138pt;">
<p><span class="font4" style="font-weight:bold;">Figure 3. </span><span class="font4">Application Data Load Menu</span></p>
<p><span class="font4">Figure 3 shows the load data menu displaying transformed data from the initial data entered by the user in the Associative Classification application. Data transform had two attributes, namely item code, and class. Class is customer information that has made transactions at frozen food stores. These two attributes would be converted into data frames.</span></p>
<p><span class="font4">To be used in performing the Associative Classification process with the CBA (Classification based Association) algorithm, the process is found in the CBA menu, where the user must input the CBA parameters, as shown in Figure 4.</span></p>
<p><span class="font10" style="font-weight:bold;">Parameter CBA</span></p>
<p><a href="#bookmark22"><span class="font2" style="font-weight:bold;">Select min support: </span><span class="font7" style="font-weight:bold;text-decoration:underline;">∣</span><span class="font2" style="font-weight:bold;text-decoration:underline;">T∏</span><span class="font2" style="font-weight:bold;">i</span></a></p>
<p><span class="font2" style="font-weight:bold;">∩_______</span></p>
<p><a href="#bookmark23"><span class="font1" style="font-variant:small-caps;">. Iiiiiiiiii </span><span class="font0" style="font-weight:bold;">0.01 &nbsp;&nbsp;0.21 &nbsp;&nbsp;&nbsp;0.41 &nbsp;&nbsp;&nbsp;0.61 &nbsp;&nbsp;0.811</span></a></p>
<p><a href="#bookmark24"><span class="font2" style="font-weight:bold;">Select min confidence: </span><span class="font0" style="font-weight:bold;">o.ιi</span></a></p>
<p><a href="#bookmark25"><span class="font2" style="font-weight:bold;">llllιιlllll </span><span class="font0" style="font-weight:bold;">0.1 &nbsp;&nbsp;&nbsp;0.28 &nbsp;&nbsp;0.46 &nbsp;&nbsp;0.64 &nbsp;&nbsp;0.821</span></a></p>
<ul style="list-style:none;"><li>
<p><span class="font4" style="font-weight:bold;">Figure 4.</span><span class="font4"> &nbsp;&nbsp;&nbsp;CBA Parameters</span></p></li></ul>
<p><span class="font4">Figure 4 shows the CBA parameters display that must be inputted by the user to get the rules result in the Associative Classification process with the CBA (Classification based Association) algorithm. The CBA parameter had input from minimum support with a value from 0.01 to 1 and minimum confidence from 0.1 to 1. The user would input the sales transaction data's minimum support and confidence values. The user would obtain the rules result after inputting the CBA parameters, as shown in Figure 5.</span></p>
<p><span class="font0" style="font-weight:bold;">Summary Ilayl Rule* AC Ikst Rules</span></p>
<p><span class="font0" style="font-weight:bold;">± Download </span><span class="font0" style="font-weight:bold;font-variant:small-caps;">RuIcsCBA</span></p>
<table border="1">
<tr><td colspan="2" style="vertical-align:bottom;">
<p><span class="font0" style="font-weight:bold;">Show 110 <sup>v</sup> entries</span></p></td><td rowspan="2" style="vertical-align:bottom;">
<p><span class="font0" style="font-weight:bold;">V≡r.3</span></p></td><td rowspan="2" style="vertical-align:bottom;">
<p><span class="font0" style="font-weight:bold;">rhs</span></p></td></tr>
<tr><td style="vertical-align:top;"></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">Ihs</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font3">W</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">(kαde brg=BAKSO26</span><span class="font6" style="font-weight:bold;">∣</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">=*</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">IclJss-MtMBtR)</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font3">PJ</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">(kθde Lrg-NAGt I ⅛)</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">=»</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">(Class=MtMtilK)</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font3">PJ</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">(kode bqrSOSlS57)</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">≡&gt;</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">{class-MΓMBIR)</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font3">HI</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">IkodeJwg=SAOSMl</span></p></td><td style="vertical-align:middle;">
<p><span class="font6" style="font-weight:bold;">⊂</span><span class="font0" style="font-weight:bold;">&gt;</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">Iclass=MEMKR)</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font3">Pl</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">{k □deJwg=Kf NTΛNG27)</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">≡⅛</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">IcIass=MFMIVR)</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font3">W</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">(kode.br g≈SCAHOPOβ</span><span class="font6" style="font-weight:bold;">∣</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">=&gt;</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">IcIass=MEMBER)</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font3">in</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">Ikodc-Iwg=NAGETOAl</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">≈&gt;</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">IcIass-MEMBER)</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font3">(«1</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">(kode brg=NAGET58</span><span class="font6" style="font-weight:bold;">∣</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">=»</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">(Class-MtMBtR)</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font3">PJ</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">3kodC-br</span><span class="font6" style="font-weight:bold;">∣</span><span class="font0" style="font-weight:bold;">ζ&lt;ORNΠ02J</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">¾</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">(Class=MEMBtR)</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font3">IWl</span></p></td><td style="vertical-align:middle;">
<p><span class="font6" style="font-weight:bold;">∣</span><span class="font0" style="font-weight:bold;">kodc-bτg-KENTANG23</span><span class="font6" style="font-weight:bold;">∣</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">∙=&gt;</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">Iclass=MEMBER)</span></p></td></tr>
</table>
<ul style="list-style:none;"><li>
<p><span class="font4" style="font-weight:bold;">Figure 5.</span><span class="font4"> &nbsp;&nbsp;&nbsp;CBA A Menu</span></p></li></ul>
<p><span class="font4">Figure 5 shows the CBA menu display that displays the rules result obtained in the Associative Classification process with the CBA (Classification based Association) algorithm from the data that had been inputted. Rules result in the image above have a value shown in Figure 6.</span></p>
<table border="1">
<tr><td style="vertical-align:top;">
<p><span class="font0" style="font-weight:bold;">support</span></p></td><td style="vertical-align:top;">
<p><span class="font0" style="font-weight:bold;">confidence</span></p></td><td style="vertical-align:top;">
<p><span class="font0" style="font-weight:bold;">coverage</span></p></td><td style="vertical-align:top;">
<p><span class="font0" style="font-weight:bold;">lift</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">0.0104704732653916</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">0.974025974025974</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">0.010749685885802</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">1.24543878114032</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">0.0226162222532458</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">0.9/00598802 19⅛21</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">0.0233142538042/2</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">1.24036/533408 73</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">0.0100516543347759</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">0.96</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">0.0104704732653916</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">1.2275044626919</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">0.0221974033226302</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">0.957831325301205</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">0.0231746474940667</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">1.22473148574304</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">0.0203825212899623</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">0.948051948051948</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">0.0714993717716041</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">1.21222708030991</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">0.0209409465307832</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">0 943396226415094</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">0.0221974033226302</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">1.20627403959502</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">0.0114477174368281</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">0.942528735632184</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">0.012145 74898 78543</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">1.20516482208 735</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">0.0269440178696077</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">0 936893203883495</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">0.0287588999022756</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">1.19795894670073</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">0.0164735446042161</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">0.936507936507937</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">0.01759039S0858579</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">1.19746632438528</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">0.0198240960491414</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">0 928104575163399</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">0.0213597654613989</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">1.18672136235191</span></p></td></tr>
</table>
<ul style="list-style:none;"><li>
<p><span class="font4" style="font-weight:bold;">Figure 6.</span><span class="font4"> &nbsp;&nbsp;&nbsp;CBA B Menu</span></p></li></ul>
<p><span class="font4">The CBA rules result included the value of support, confidence, coverage, and lift ratio. These values could be used as a reference for the accuracy level of a rule. From frozen food sales transaction data, the Associative Classification process with the CBA algorithm, with specific support, Confidence, Coverage, and Lift parameter values, will produce rules used for Classification. Rules resulting from the Associative Classification process with the CBA (Classification based Association) algorithm could be downloaded in .xls file format.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark26"></a><span class="font4" style="font-weight:bold;"><a name="bookmark27"></a>3.2. &nbsp;&nbsp;&nbsp;Results Evaluation</span></h2></li></ul>
<p><span class="font4">Results evaluation was done to determine the accuracy of the CBA (Classification based Association) algorithm in the testing that had been carried out. Accuracy was achieved by calculating the level of support, confidence, coverage, and lift ratio values generated by the CBA</span></p>
<p><span class="font4">(Classification-based Association) algorithm. Data testing was conducted on data from October to January, where the number of rules obtained differed based on the minimum support and minimum confidence inputted by the user. Testing conducted with a minimum support of 1% and a minimum confidence of 10% obtained 28 rules. This number differed from the minimum support of 2% with a minimum confidence of 10%, which acquired two rules. It indicated that the smaller the minimum support and confidence, the greater the number of rules obtained. After conducting several experiments, the minimum value for support is 1%, and confidence is 10%. The maximum value will be reached in the Overfitting condition.</span></p>
<p><span class="font4">This evaluation used 90% training data in October with 6234 transactions that obtained 28 rules with a minimum support of 1% and a minimum confidence of 10%. The following ten rules from the results of the rules obtained in October can be seen in Table 2.</span></p>
<p><span class="font4" style="font-weight:bold;">Table 2. </span><span class="font4">Evaluation of CBA Algorithm of 90% Training Data</span></p>
<table border="1">
<tr><td style="vertical-align:bottom;">
<p><span class="font4" style="font-weight:bold;">No</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4" style="font-weight:bold;">Support</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4" style="font-weight:bold;">Confidence</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4" style="font-weight:bold;">Coverage</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4" style="font-weight:bold;">Lift</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font4">1</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0.013</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0.977</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0.013</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">1.28</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font4">2</span></p></td><td style="vertical-align:top;">
<p><span class="font4">0.024</span></p></td><td style="vertical-align:top;">
<p><span class="font4">0.961</span></p></td><td style="vertical-align:top;">
<p><span class="font4">0.025</span></p></td><td style="vertical-align:top;">
<p><span class="font4">1.26</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font4">3</span></p></td><td style="vertical-align:top;">
<p><span class="font4">0.011</span></p></td><td style="vertical-align:top;">
<p><span class="font4">0.945</span></p></td><td style="vertical-align:top;">
<p><span class="font4">0.011</span></p></td><td style="vertical-align:top;">
<p><span class="font4">1.24</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font4">4</span></p></td><td style="vertical-align:top;">
<p><span class="font4">0.026</span></p></td><td style="vertical-align:top;">
<p><span class="font4">0.931</span></p></td><td style="vertical-align:top;">
<p><span class="font4">0.028</span></p></td><td style="vertical-align:top;">
<p><span class="font4">1.22</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font4">5</span></p></td><td style="vertical-align:top;">
<p><span class="font4">0.010</span></p></td><td style="vertical-align:top;">
<p><span class="font4">0.916</span></p></td><td style="vertical-align:top;">
<p><span class="font4">0.011</span></p></td><td style="vertical-align:top;">
<p><span class="font4">1.20</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font4">6</span></p></td><td style="vertical-align:top;">
<p><span class="font4">0.010</span></p></td><td style="vertical-align:top;">
<p><span class="font4">0.916</span></p></td><td style="vertical-align:top;">
<p><span class="font4">0.011</span></p></td><td style="vertical-align:top;">
<p><span class="font4">1.20</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font4">7</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0.018</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0.912</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0.020</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">1.19</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font4">8</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0.011</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0.911</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0.012</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">1.197</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font4">9</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0.022</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0.909</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0.024</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">1.194</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font4">10</span></p></td><td style="vertical-align:top;">
<p><span class="font4">0.021</span></p></td><td style="vertical-align:top;">
<p><span class="font4">0.905</span></p></td><td style="vertical-align:top;">
<p><span class="font4">0.023</span></p></td><td style="vertical-align:top;">
<p><span class="font4">1.18</span></p></td></tr>
<tr><td style="vertical-align:top;"></td><td style="vertical-align:top;"></td><td style="vertical-align:bottom;">
<p><span class="font4">Overall Rules Accuracy</span></p></td><td style="vertical-align:top;"></td><td style="vertical-align:bottom;">
<p><span class="font4" style="font-weight:bold;">0.75</span></p></td></tr>
</table>
<p><span class="font4">Table 2 shows 10 rule results obtained from 28 rules in the testing with October transaction data on 90% training data. Rule number 1 included the rule KNAGA01 =&gt; class=MEMBER with the highest lift ratio value of 1.28 and a confidence value of 0.97. It was concluded that item KNAGA01 was often purchased item by class member customers with a confidence level of 97%, which was the certainty value obtained from the combination of items in a rule. The lift ratio value was used to measure how accurate the resulting rule was. The higher the lift ratio value, the greater the rule accuracy strength. The accuracy obtained from all 28 rules had an accuracy rate of 0.75. The results of the rules were obtained using 80% training data in October, which had a different number of rules, namely, 26 rules with a minimum support of 1% and a minimum confidence of 10%. The following ten rules from the results of the rules obtained in October can be seen in Table 3.</span></p>
<table border="1">
<tr><td colspan="5" style="vertical-align:bottom;">
<p><span class="font4" style="font-weight:bold;">Table 3. </span><span class="font4">Evaluation of CBA Algorithm of 80% Training Data</span></p>
<p><span class="font4" style="font-weight:bold;">No Support &nbsp;Confidence &nbsp;Coverage &nbsp;Lift</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font4">1</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0.013</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0.98</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0.01</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">1.29</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font4">2</span></p></td><td style="vertical-align:top;">
<p><span class="font4">0.024</span></p></td><td style="vertical-align:top;">
<p><span class="font4">0.96</span></p></td><td style="vertical-align:top;">
<p><span class="font4">0.02</span></p></td><td style="vertical-align:top;">
<p><span class="font4">1.26</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font4">3</span></p></td><td style="vertical-align:top;">
<p><span class="font4">0.027</span></p></td><td style="vertical-align:top;">
<p><span class="font4">0.95</span></p></td><td style="vertical-align:top;">
<p><span class="font4">0.02</span></p></td><td style="vertical-align:top;">
<p><span class="font4">1.24</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font4">4</span></p></td><td style="vertical-align:top;">
<p><span class="font4">0.010</span></p></td><td style="vertical-align:top;">
<p><span class="font4">0.93</span></p></td><td style="vertical-align:top;">
<p><span class="font4">0.01</span></p></td><td style="vertical-align:top;">
<p><span class="font4">1.23</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font4">5</span></p></td><td style="vertical-align:top;">
<p><span class="font4">0.022</span></p></td><td style="vertical-align:top;">
<p><span class="font4">0.92</span></p></td><td style="vertical-align:top;">
<p><span class="font4">0.02</span></p></td><td style="vertical-align:top;">
<p><span class="font4">1.21</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font4">6</span></p></td><td style="vertical-align:top;">
<p><span class="font4">0.023</span></p></td><td style="vertical-align:top;">
<p><span class="font4">0.92</span></p></td><td style="vertical-align:top;">
<p><span class="font4">0.02</span></p></td><td style="vertical-align:top;">
<p><span class="font4">1.21</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font4">7</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0.013</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0.90</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0.01</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">1.19</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font4">8</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0.011</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0.90</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0.01</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">1.18</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font4">9</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0.016</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0.90</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0.01</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">1.18</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font4">10</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0.013</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0.90</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0.01</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">1.18</span></p></td></tr>
<tr><td style="vertical-align:top;"></td><td colspan="3" style="vertical-align:middle;">
<p><span class="font4">Overall Rules Accuracy</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4" style="font-weight:bold;">0.74</span></p></td></tr>
</table>
<p><span class="font4">Table 3 shows the 10 rule results obtained from 26 rules in the testing with October transaction data that had been carried out. Rule number 1 included the rule code_brg=KNAGA01 =&gt; class=MEMBER with the highest lift ratio value of 1.29 and a confidence value of 0.98. It was concluded that item KNAGA01 was often purchased item by class member customers with a confidence level of 98%, which was the certainty value obtained from the combination of items in</span></p>
<p><span class="font4">a rule. The accuracy obtained from all 26 rules had an accuracy rate of 0.74. The accuracy rate of all rules with 80% and 90% training data differed. It indicated that the greater the number of rules obtained, the greater the accuracy rate. The rule results obtained on 90% of training data in October differed from those in November, which were 26 rules. The following ten rules from the results obtained in November with 90% training data can be seen in Table 4.</span></p>
<p><span class="font4" style="font-weight:bold;">Table 4. </span><span class="font4">Evaluation of CBA Algorithm Results of 90% Nov Data</span></p>
<table border="1">
<tr><td style="vertical-align:bottom;">
<p><span class="font4" style="font-weight:bold;">No</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4" style="font-weight:bold;">Support</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4" style="font-weight:bold;">Confidence</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4" style="font-weight:bold;">Coverage</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4" style="font-weight:bold;">Lift</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font4">1</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0.010</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0.971</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0.010</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">1.27</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font4">2</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0.025</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0.959</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0.026</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">1.25</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font4">3</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0.024</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0.959</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0.025</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">1.25</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font4">4</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0.011</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0.950</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0.012</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">1.24</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font4">5</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0.011</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0.939</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0.012</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">1.22</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font4">6</span></p></td><td style="vertical-align:top;">
<p><span class="font4">0.020</span></p></td><td style="vertical-align:top;">
<p><span class="font4">0.925</span></p></td><td style="vertical-align:top;">
<p><span class="font4">0.022</span></p></td><td style="vertical-align:top;">
<p><span class="font4">1.20</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font4">7</span></p></td><td style="vertical-align:top;">
<p><span class="font4">0.022</span></p></td><td style="vertical-align:top;">
<p><span class="font4">0.923</span></p></td><td style="vertical-align:top;">
<p><span class="font4">0.023</span></p></td><td style="vertical-align:top;">
<p><span class="font4">1.20</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font4">8</span></p></td><td style="vertical-align:top;">
<p><span class="font4">0.018</span></p></td><td style="vertical-align:top;">
<p><span class="font4">0.911</span></p></td><td style="vertical-align:top;">
<p><span class="font4">0.020</span></p></td><td style="vertical-align:top;">
<p><span class="font4">1.19</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font4">9</span></p></td><td style="vertical-align:top;">
<p><span class="font4">0.026</span></p></td><td style="vertical-align:top;">
<p><span class="font4">0.907</span></p></td><td style="vertical-align:top;">
<p><span class="font4">0.029</span></p></td><td style="vertical-align:top;">
<p><span class="font4">1.18</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font4">10</span></p></td><td style="vertical-align:top;">
<p><span class="font4">0.013</span></p></td><td style="vertical-align:top;">
<p><span class="font4">0.907</span></p></td><td style="vertical-align:top;">
<p><span class="font4">0.014</span></p></td><td style="vertical-align:top;">
<p><span class="font4">1.18</span></p></td></tr>
<tr><td style="vertical-align:top;"></td><td style="vertical-align:top;"></td><td style="vertical-align:bottom;">
<p><span class="font4">Overall Rules Accuracy</span></p></td><td style="vertical-align:top;"></td><td style="vertical-align:bottom;">
<p><span class="font4" style="font-weight:bold;">0.76</span></p></td></tr>
</table>
<p><span class="font4">Table 4 shows the 10 rule results obtained with 90% training data in November, with a minimum support of 1% and a minimum confidence of 10%. Rule 1 included FLAT28 =&gt; class=MEMBER with the highest lift ratio value of 1.27. It indicated that KENTANG28 was often purchased item by member customers in November, with a value of 97% confidence. The accuracy obtained from all 26 rules had an accuracy rate of 0.76. The results of the rules obtained using 80% training data in November, which had a different number of rules, namely 27 rules with a minimum support of 1% and a minimum confidence of 10%, are shown in Table 5.</span></p>
<p><span class="font4" style="font-weight:bold;">Table 5. </span><span class="font4">Evaluation of CB</span><span class="font4" style="text-decoration:underline;">A Algorithm Results of 90</span><span class="font4">% Nov Data</span></p>
<table border="1">
<tr><td style="vertical-align:bottom;">
<p><span class="font4" style="font-weight:bold;">No</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4" style="font-weight:bold;">Support</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4" style="font-weight:bold;">Confidence</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4" style="font-weight:bold;">Coverage</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4" style="font-weight:bold;">Lift</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font4">1</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0.010</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0.96</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0.010</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">1.26</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font4">2</span></p></td><td style="vertical-align:top;">
<p><span class="font4">0.023</span></p></td><td style="vertical-align:top;">
<p><span class="font4">0.95</span></p></td><td style="vertical-align:top;">
<p><span class="font4">0.025</span></p></td><td style="vertical-align:top;">
<p><span class="font4">1.24</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font4">3</span></p></td><td style="vertical-align:top;">
<p><span class="font4">0.012</span></p></td><td style="vertical-align:top;">
<p><span class="font4">0.94</span></p></td><td style="vertical-align:top;">
<p><span class="font4">0.012</span></p></td><td style="vertical-align:top;">
<p><span class="font4">1.23</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font4">4</span></p></td><td style="vertical-align:top;">
<p><span class="font4">0.020</span></p></td><td style="vertical-align:top;">
<p><span class="font4">0.94</span></p></td><td style="vertical-align:top;">
<p><span class="font4">0.021</span></p></td><td style="vertical-align:top;">
<p><span class="font4">1.23</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font4">5</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0.012</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0.93</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0.013</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">1.22</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font4">6</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0.023</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0.93</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0.025</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">1.21</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font4">7</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0.011</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0.93</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0.012</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">1.21</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font4">8</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0.019</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0.91</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0.021</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">1.20</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font4">9</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0.013</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0.90</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0.014</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">1.18</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font4">10</span></p></td><td style="vertical-align:top;">
<p><span class="font4">0.012</span></p></td><td style="vertical-align:top;">
<p><span class="font4">0.9</span></p></td><td style="vertical-align:top;">
<p><span class="font4">0.013</span></p></td><td style="vertical-align:top;">
<p><span class="font4">1.17</span></p></td></tr>
<tr><td style="vertical-align:top;"></td><td colspan="2" style="vertical-align:bottom;">
<p><span class="font4">Overall Rules Accuracy</span></p></td><td style="vertical-align:top;"></td><td style="vertical-align:bottom;">
<p><span class="font4" style="font-weight:bold;">0.77</span></p></td></tr>
</table>
<p><span class="font4">Table 5 shows 10 rule results from 80% training data with a minimum support of 1% and a minimum confidence of 10%. The rule with the highest lift ratio value on 80% of training data differed from 90% of training data, which was 1.26, with a confidence value of 96%. The overall rules accuracy obtained differed from the overall rules accuracy on the 90% training data with a value level of 0.77. It indicated that the greater the number of rules obtained, the greater the overall rules accuracy.</span></p>
<p><span class="font4">Likewise, the results of the rules were obtained using other months of transaction data using the CBA (Classification based Association) algorithm, which had a different number of rules.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark28"></a><span class="font4" style="font-weight:bold;"><a name="bookmark29"></a>3.3. &nbsp;&nbsp;&nbsp;Results Analysis</span></h2></li></ul>
<p><span class="font4">The results of processing sales transaction data from October to January using the CBA (Classification based Association) algorithm to see the pattern of associative classification rules formed with parameters, namely the support value, confidence value, coverage value, and lift ratio value. Associative classification rules with the CBA (Classification based Association) algorithm were selected based on the highest lift ratio value, which was different every month with</span></p>
<p><span class="font4">two classes, namely general and member classes. A comparison of the rule results used was using 90% training data with a minimum support parameter of 1% and a minimum confidence of 10%. It can be seen in Table 6.</span></p>
<p><span class="font4" style="font-weight:bold;">Table 6. </span><span class="font4">Analysis of CBA Algorithm Results</span></p>
<table border="1">
<tr><td style="vertical-align:bottom;">
<p><span class="font4" style="font-weight:bold;">bln</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4" style="font-weight:bold;">Rules</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4" style="font-weight:bold;">Supp</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4" style="font-weight:bold;">Conf</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4" style="font-weight:bold;">Cov</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4" style="font-weight:bold;">Lift</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font4">1</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">KNAGA01 &nbsp;&nbsp;&nbsp;=&gt;</span></p>
<p><span class="font4">class=MEMBER</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">0.0136</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">0.97</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">0.01</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">1.28</span></p></td></tr>
<tr><td style="vertical-align:top;"></td><td style="vertical-align:bottom;">
<p><span class="font4">KENTANG13} =&gt; class=UMUM</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">0.013</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">0.67</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">0.01</span></p></td><td style="vertical-align:middle;">
<p><span class="font4">2.8</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font4">2</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">KENTANG28 &nbsp;=&gt;</span></p>
<p><span class="font4">class=MEMBER</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0.010</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0.97</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0.01</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">1.27</span></p></td></tr>
<tr><td style="vertical-align:top;"></td><td style="vertical-align:bottom;">
<p><span class="font4">KENTANG13 &nbsp;=&gt;</span></p>
<p><span class="font4">class=UMUM</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0.018</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0.62</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0.03</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">2.6</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font4">3</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">SAOS58 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=&gt;</span></p>
<p><span class="font4">class=MEMBER</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0.010</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0.98</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0.01</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">1.27</span></p></td></tr>
<tr><td style="vertical-align:top;"></td><td style="vertical-align:bottom;">
<p><span class="font4">KENTANG13 &nbsp;=&gt;</span></p>
<p><span class="font4">class=UMUM</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0.019</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0.6</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0.03</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">2.6</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font4">4</span></p></td><td style="vertical-align:top;">
<p><span class="font4">BAKSO26 &nbsp;&nbsp;&nbsp;=&gt;</span></p>
<p><span class="font4">class=MEMBER</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0.010</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0.98</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0.01</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">1.26</span></p></td></tr>
<tr><td style="vertical-align:top;"></td><td style="vertical-align:top;">
<p><span class="font4">KENTANG13 =&gt;</span></p>
<p><span class="font4">class=UMUM</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0.016</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0.63</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0.02</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">2.9</span></p></td></tr>
</table>
<p><span class="font4">Table 6 shows the analysis of four months of sales transaction data. Each month, the rules results on the member and general classes obtained different results based on the highest lift ratio value. The rule with the highest lift ratio value with four months of transaction data on the member class fell on month 1 data with the rule {code_brg=KNAGA01} =&gt; {class=MEMBER}. It indicated that member customers often purchased the item code KNAGA01 with the highest level of accuracy compared to the rules obtained from each other month's data. In contrast to the rule results obtained in the general class, which showed the consistency of the same rule results in the data every month with the highest accuracy based on the lift ratio value which produced the rule {code_brg=KENTANG13} =&gt; {class=General} in month 4. This rule showed that general customers often purchased item code KENTANG13 with the same consistency level every month. The comparison of the rules obtained could be used as a decision in the sales strategy by providing discounts or rewards shown to customers.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark30"></a><span class="font4" style="font-weight:bold;"><a name="bookmark31"></a>4. &nbsp;&nbsp;&nbsp;Conclusions</span></h2></li></ul>
<p><span class="font4">The application of Associative Classification with the CBA (Classification based Association) algorithm using R and the Shiny framework was able to apply classification cases based on associations in determining often purchased items by general customers and members by processing attribute data according to the criteria to form rules using minimum support and minimum confidence parameters. The rules results obtained in the application of Associative Classification used a minimum support parameter of 1% and a minimum confidence of 10% in the application of Associative Classification. The greater the number of rules obtained, the greater the overall accuracy value level. The ruleitems obtained had the best accuracy based on the lift ratio. It could be used to give discounts or rewards to loyal customers.</span></p>
<h2><a name="bookmark32"></a><span class="font4" style="font-weight:bold;"><a name="bookmark33"></a>References</span></h2>
<ul style="list-style:none;"><li>
<p><span class="font4">[1] &nbsp;&nbsp;&nbsp;K. Nisa, “Penerapan Data Mining Terhadap Data Transaksi Sebagai Pendukung Informasi Strategi Penjualan Menggunakan Algoritma Apriori,” </span><span class="font4" style="font-style:italic;">Jurnal Teknik Informatika Unika Santo Thomas</span><span class="font4">, vol. 6, no. 2, pp. 306–315, 2021.</span></p></li>
<li>
<p><span class="font4">[2] &nbsp;&nbsp;&nbsp;A. Erfina, M. Melawati, and N. Destria Arianti, “Penerapan Metode Data Mining Terhadap Data Transaksi Penjualan Menggunakan Algoritma Apriori (Studi Kasus: Toko Fasentro Fancy),” </span><span class="font4" style="font-style:italic;">Jurnal Ilmiah Sains dan Teknologi(SANTIKA)</span><span class="font4">, vol. 10, no. 1, pp. 11–17, 2020.</span></p></li>
<li>
<p><span class="font4">[3] &nbsp;&nbsp;&nbsp;F. R. Pare, O. Wati, L. P. Taran, and L. M. Arsai, “Penerapan Data Mining Pada Transaksi</span></p></li></ul>
<p><span class="font4">Penjualan Barang Menggunakan Metode Apriori (Studi Kasus:Toko BE-MART),” </span><span class="font4" style="font-style:italic;">Jurnal Teknologi Terapan G-Tech</span><span class="font4">, vol. 7, no. 1, pp. 255–261, 2023.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font4">[4] &nbsp;&nbsp;&nbsp;A. Maulana and A. A. Fajrin, “Penerapan Data Mining Untuk Analisis Pola Pembelian Konsumen Dengan Algoritma Fp-Growth Pada Data Transaksi Penjualan Spare Part Motor,” </span><span class="font4" style="font-style:italic;">Klik - Kumpulan Jurnal Ilmu Komputer</span><span class="font4">, vol. 5, no. 1, p. 27, 2018.</span></p></li>
<li>
<p><span class="font4">[5] &nbsp;&nbsp;&nbsp;P. N. Harahap and S. Sulindawaty, “Implementasi Data Mining Dalam Memprediksi Transaksi Penjualan Menggunakan Algoritma Apriori (Studi Kasus PT.Arma Anugerah Abadi Cabang Sei Rampah),” </span><span class="font4" style="font-style:italic;">Matics</span><span class="font4">, vol. 11, no. 2, p. 46, 2020.</span></p></li>
<li>
<p><span class="font4">[6] &nbsp;&nbsp;&nbsp;Siregar Simon Sadok and Friska Abadi, “Penerapan Frozen Food Technology Di Ukm Mimingfish Untuk Meningkatkan Diversifikasi Produksi Dan Ekonomi,” </span><span class="font4" style="font-style:italic;">Pro Sejahtera</span><span class="font4">, pp. 2656–5021, 2021.</span></p></li>
<li>
<p><span class="font4">[7] &nbsp;K. D. Rajab, &quot;New Associative Classification Method Based on Rule Pruning for</span></p></li></ul>
<p><span class="font4">Classification of Datasets,&quot; </span><span class="font4" style="font-style:italic;">IEEE Access</span><span class="font4">, vol. 7, pp. 157783–157795, 2019.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font4">[8] &nbsp;A. F. Andikos and H. Andri, “Pengujian Association Clasification Dalam Meningkatkan</span></p></li></ul>
<p><span class="font4">Kualitas Minyak Sawit Sebagai Bahan Dasar Biodisel,” </span><span class="font4" style="font-style:italic;">Jurnal Media Informatika Budidarma</span><span class="font4">, vol. 3, no. 4, p. 340, 2019.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font4">[9] &nbsp;&nbsp;&nbsp;H. F. Ong, C. Y. M. Neoh, V. K. Vijayaraj, and Y. X. Low, &quot;Information-Based Rule Ranking for Associative Classification,&quot; </span><span class="font4" style="font-style:italic;">2022 International Symposium on Intelligent Signal Processing and Communication Systems (ISPACS)</span><span class="font4">, 2022.</span></p></li>
<li>
<p><span class="font4">[10] &nbsp;&nbsp;&nbsp;C. Thanajiranthorn and P. Songram, &quot;Efficient rule generation for associative classification,&quot; </span><span class="font4" style="font-style:italic;">Algorithms</span><span class="font4">, vol. 13, no. 11, 2020.</span></p></li>
<li>
<p><span class="font4">[11] &nbsp;&nbsp;&nbsp;P. U. Gio and A. R. Effendie, </span><span class="font4" style="font-style:italic;">Belajar Bahasa Pemrograman R</span><span class="font4">, vol. 1, no. 1. 2017.</span></p></li>
<li>
<p><span class="font4">[12] &nbsp;&nbsp;&nbsp;I. P. A. P. Wibawa, I. K. A. Purnawan, D. P. S. Putri, and N. K. D. Rusjayanthi, “Prediksi Partisipasi Pemilih dalam Pemilu Presiden 2014 dengan Metode Support Vector Machine,” </span><span class="font4" style="font-style:italic;">Jurnal Ilmiah Merpati (Menara Penelitian Akademika Teknologi Informasi)</span><span class="font4">, p. 182, 2019.</span></p></li>
<li>
<p><span class="font4">[13] &nbsp;&nbsp;&nbsp;M. Hahsler, I. Johnson, T. Kliegr, and J. Kuchar, &quot;Associative classification in R: Arc, arulesCBA, and rCBA,&quot; </span><span class="font4" style="font-style:italic;">The R Journal</span><span class="font4">, vol. 11, no. 2, pp. 254–267, 2019.</span></p></li>
<li>
<p><span class="font4">[14] &nbsp;&nbsp;&nbsp;N. Abdelhamid and F. Thabtah, &quot;Associative Classification Approaches: Review and Comparison,&quot; </span><span class="font4" style="font-style:italic;">Journal of Information &amp;&nbsp;Knowledge Management</span><span class="font4">, vol. 13, no. 3, 2014.</span></p></li>
<li>
<p><span class="font4">[15] &nbsp;&nbsp;&nbsp;W. Cao, Q. Zhong, H. Li, and S. Liang, &quot;A Novel Approach for Associative Classification Based on Information Entropy of Frequent Attribute Set,&quot; </span><span class="font4" style="font-style:italic;">IEEE Access</span><span class="font4">, vol. 8, pp. 140181– 140193, 2020.</span></p></li>
<li>
<p><span class="font4">[16] &nbsp;&nbsp;&nbsp;D. Sasirekha and A. Punitha, &quot;A comprehensive analysis on associative classification in medical datasets,&quot; </span><span class="font4" style="font-style:italic;">Indian Journal of Science and Technology</span><span class="font4">, vol. 8, no. 33, 2015.</span></p></li>
<li>
<p><span class="font4">[17] &nbsp;&nbsp;&nbsp;M. Abrar, A. T. H. Sim, and S. Abbas, &quot;Associative classification using automata with structure based merging,&quot; </span><span class="font4" style="font-style:italic;">International Journal of Advanced Computer Science and Applications(IJACSA)</span><span class="font4">, vol. 10, no. 7, pp. 672–685, 2019.</span></p></li>
<li>
<p><span class="font4">[18] &nbsp;&nbsp;&nbsp;F. Padillo, J. M. Luna, and S. Ventura, &quot;Evaluating associative classification algorithms for Big Data,&quot; </span><span class="font4" style="font-style:italic;">Big Data Analytics</span><span class="font4">, vol. 4, no. 1, 2019.</span></p></li>
<li>
<p><span class="font4">[19] &nbsp;&nbsp;&nbsp;L. Venturini, E. Baralis, and P. Garza, &quot;Scaling associative classification for very large datasets,&quot; </span><span class="font4" style="font-style:italic;">Journal of Big Data</span><span class="font4">, vol. 4, no. 1, 2017.</span></p></li>
<li>
<p><span class="font4">[20] &nbsp;&nbsp;&nbsp;F. Jiří and T. Kliegr, &quot;Classification based on associations (CBA) - A performance analysis,&quot; </span><span class="font4" style="font-style:italic;">CEUR Workshop Proceedings</span><span class="font4">, vol. 2204, 2018.</span></p></li></ul>
<p><span class="font4">35</span></p>