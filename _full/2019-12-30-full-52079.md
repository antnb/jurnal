---
layout: full_article
title: "Buildings Cracks Classification Using Zoning and Invariant Moment Features and Quadratic Discriminant Analysis Classifier"
author: "I Gede Pasek Suta Wijaya, Ida Bagus Ketut Widiartha, Fitri Bimantoro, Aldian Wahyu Septiadi"
categories: lontar
canonical_url: https://jurnal.harianregional.com/lontar/full-52079 
citation_abstract_html_url: "https://jurnal.harianregional.com/lontar/id-52079"
citation_pdf_url: "https://jurnal.harianregional.com/lontar/full-52079"  
comments: true
---

<p><span class="font3" style="font-weight:bold;">LONTAR KOMPUTER VOL. 10, NO. 3 DECEMBER 2019</span></p>
<p><span class="font3" style="font-weight:bold;">DOI : 10.24843/LKJITI.2019.v10.i03.p04</span></p>
<p><span class="font3" style="font-weight:bold;">Accredited B by RISTEKDIKTI Decree No. 51/E/KPT/2017</span></p>
<p><span class="font3" style="font-weight:bold;">p-ISSN 2088-1541</span></p>
<p><span class="font3" style="font-weight:bold;">e-ISSN 2541-5832</span></p><a name="caption1"></a>
<h1><a name="bookmark0"></a><span class="font4" style="font-weight:bold;"><a name="bookmark1"></a>Buildings Cracks Classification Using Zoning and Invariant Moment Features and Quadratic Discriminant Analysis Classifier</span></h1>
<p><span class="font3">I Gede Pasek Suta Wijaya<sup>a1</sup>, Ida Bagus Ketut Widiartha<sup>a2</sup>, Fitri Bimantoro<sup>a3</sup>, Aldian Wahyu Septiadi<sup>a4</sup></span></p>
<p><span class="font3"><sup>a</sup>Informatics Engineering Dept., Faculty of Engineering, University of Mataram</span></p>
<p><span class="font3">Jl. Majapahit 62, Mataram, Lombok NTB, Indonesia</span></p>
<p><span class="font1"><sup>1</sup></span><span class="font3">gpsutawijaya@unram.ac.id</span><span class="font2">(corresponding author)</span></p>
<p><a href="mailto:2widi@unram.ac.id"><span class="font1"><sup>2</sup></span><span class="font3">widi@unram.ac.id</span></a><span class="font3">, </span><a href="mailto:3bimo@unram.ac.id"><span class="font1"><sup>3</sup></span><span class="font3">bimo@unram.ac.id</span></a><span class="font3">, </span><a href="mailto:4aldianwahyu78@gmail.com"><span class="font1"><sup>4</sup></span><span class="font3">aldianwahyu78@gmail.com</span></a></p>
<p><span class="font3" style="font-weight:bold;font-style:italic;">Abstract</span></p>
<p><span class="font3" style="font-style:italic;">Natural disasters such as earthquake often cause cracks in buildings and even demolish them. The cracked building must be assessed by an expert to determine whether the building is still suitable for use or not. The feasibility of a building is assessed based on the width, depth, and length of cracks in walls, beams, columns, and even the floor of the building. Only experienced experts can do such kind of task so that building assessment requires many structural engineering experts when an earthquake has happened. However, structural engineering experts are limited which able to do buildings assessment in the area affected. Therefore, the research based on a pattern recognition approach is conducted to classify cracks in buildings to be mild, moderate, or severe. It will be part of automatic building assessment based on the crack analysis. An alternative pattern recognition approach for classifying buildings cracks is a scheme based on zoning and shape features and Quadratic discriminant analysis (QDA) classifier. Based on the experimental results the proposed scheme gives reasonable achievement more than 80% of accuracy.</span></p>
<p><span class="font3" style="font-weight:bold;font-style:italic;">Keywords: </span><span class="font3" style="font-style:italic;">Expert System, Image Classification, Moment, Zoning, QDA</span></p>
<ul style="list-style:none;"><li>
<h3><a name="bookmark2"></a><span class="font3" style="font-weight:bold;"><a name="bookmark3"></a>1. &nbsp;&nbsp;&nbsp;Introduction</span></h3></li></ul>
<p><span class="font3">Earthquake is vibrations that occur on the surface of the earth due to the sudden release of energy, which creates seismic waves. Tectonic movements and volcanic eruptions usually cause earthquakes. Earthquake magnitude is measured by using the Richter Scale (RS). An earthquake measuring more than 5 RS has potentially caused cracks and even demolish buildings. Certain cracks in buildings (mild, moderate, or severe) are indicative of the failure rate of the structure of the building. Theoretically, crack is a symptom due to the many combinations of forces acting on the building that exceed the capacity of the building or its material components [1]. The level of damage to buildings can be seen from the shape of the cracks that can be assessed by experts during assessment activities. The building assessment activities can be carried out through two stages, namely the initial inspection and detail inspection through a series of tests before concluding in the reliability assessment. Until the testing phase, several standards and manuals must be available, which must be used as references.</span></p>
<p><span class="font3">Up today, the building’s assessment after the earthquake has been carried out manually by structural engineering experts. The expert checks the building cracks, measuring the level of damage, and adjusting to standards that will be used as a reference to determine whether the building still feasible to be used or not. Commonly, the damage level is classified based on crack’s</span></p>
<p><span class="font3">length, width, and area (quantitative metrics), which is categorized as minor, moderate, and severe cracks[2]. However, the assessment process requires a long time and is expensive due to limited experts and the large affected area.</span></p>
<p><span class="font3">On the other hand, digital image processing and pattern recognition have been widely used to analyze various things, including classification. In essence, the principle of pattern recognition follows the working principle of the human brain in recognizing and concluding about different objects captured by the human senses, especially the eyes for images and ears for sound. This concept is a challenge to utilize pattern recognition and digital image processing in carrying out assessment activities for post-earthquake buildings.</span></p>
<p><span class="font3">Various types of research related to pattern recognition and digital image processing have been carried out to determine conclusions. The pattern recognition process and digital image processing have several steps are taken, namely, feature extraction stages and classification. Several studies on the concept of pattern recognition and digital image processing have been conducted to classify building cracks, including image centroid approach, statistical approach, GLCM texture analysis, wavelet transformation, and so on. The results of the accuracy obtained using the methods mentioned are 70% to 95%[3]. The results showed that applying the concept of pattern recognition and digital image processing in the case of crack identification and classification could determine damage (damaged or undamaged) to a percentage of 75-95%.</span></p>
<p><span class="font3">The most related work of the implementation of the zoning feature was for character recognition recognition[4], which obtained reasonable accuracy. Additionally, the other character recognition using local and global features and Learning Vector Quantization (LVQ) [5] was proposed in 2007, which provided reasonable achievement. Another approach using Quadratic Discriminant Analysis (QDA classifier produced the best accuracy with 20 features or less for Arabic character recognition, while Linear Discriminant Analysis (LDA) classifier provided the best accuracy with more features[6]. It means that Zoning features and QDA classifier is potential to be employed for crack classification because the crack patterns are similar to those of characters because some parts of the crack images are similar to the Arabic character’s handwriting style in terms of bows and arches.</span></p>
<p><span class="font3">Crack detection and classification techniques with quantitative analysis on an infrastructure (the road, bridge, pavement, building, railway track, tunnel, ship, vehicle, and aircraft) is an essential process in finding crack level using various approaches[2, 7, 8, 9]. A great review and analysis of crack detection had been successfully examined on 20 image processing algorithms[3]. From this review, it was found that the GLCM with ANN (Artificial Neural Network) methods were also included in the work for handling the crack detection for thermography, visual color and grayscale images of concrete blocks. However, its performance lack of accuracy (ranging from 71 to 75.2%)[10, 11]. Additionally, a deep-learning-based approach for road crack detection provided remarkable achievement compared with features obtained with existing hand-craft techniques[12].</span></p>
<p><span class="font3">Based on the previous research, the paper proposes zoning and shape features and QDA classifier for the crack level classification of Lombok earthquake-damaged building. The main propose of this work is to find out the compact and powerful scheme for crack level classification of damage building due to the earthquake. The compact scheme must require less computational complexity, which is potentially developed for the smartphone application.</span></p>
<ul style="list-style:none;"><li>
<h3><a name="bookmark4"></a><span class="font3" style="font-weight:bold;"><a name="bookmark5"></a>2. &nbsp;&nbsp;&nbsp;Research Methods</span></h3></li></ul>
<p><span class="font3">Briefly, Figure 1 presents building crack classification using zoning and shape features and QDA classifiers. This system consists of several main processes, namely: pre-processing, feature extraction, and classification.</span></p>
<ul style="list-style:none;"><li>
<h3><a name="bookmark6"></a><span class="font3" style="font-weight:bold;"><a name="bookmark7"></a>2.1. &nbsp;&nbsp;&nbsp;Pre-processing</span></h3></li></ul>
<p><span class="font3">Each training image and test image are converted into grayscale to get an image value of 0 to 255 (0 for black and 255 for white). The grayscale matrix generated from the preprocessing will be</span></p>
<div><img src="https://jurnal.harianregional.com/media/52079-1.jpg" alt="" style="width:361pt;height:230pt;">
<p><span class="font3" style="font-weight:bold;">Figure 1. </span><span class="font3">Crack classification block diagram.</span></p>
</div><br clear="all">
<p><span class="font3">used to calculate seven invariant moments, which represents the shape information of the image. In this case, the a weighted sum of the R, G, and B components (0.2989 * R + 0.5870 * G + 0.1140 * B)[13] are employed for as grayscale transformation. Additionally, a binarization, which converts each pixel of the crack image into binary value (0 or 1) will be used to perform zoning features in this study. The binary image is obtained by replacing all pixels in the input image with luminance higher than level with the value 1 (white) and replacing all other pixels with the value 0 (black). The pre-processing sequence of the crack image is shown in Figure 2.</span></p>
<div><img src="https://jurnal.harianregional.com/media/52079-2.jpg" alt="" style="width:276pt;height:83pt;">
<p><span class="font3" style="font-weight:bold;">Figure 2. </span><span class="font3">Pre-Processing sequence of crack image.</span></p>
</div><br clear="all">
<ul style="list-style:none;"><li>
<h3><a name="bookmark8"></a><span class="font3" style="font-weight:bold;"><a name="bookmark9"></a>2.2. &nbsp;&nbsp;&nbsp;Feature Extraction</span></h3></li></ul>
<p><span class="font3">Feature extraction is used to extract unique values from an object that distinguishes from other objects. This study uses statistical feature methods, namely zoning and invariant moments. The zoning method has several algorithm variations. In this study, two ways, namely Image Centroid and Zone (ICZ) and Zone Centroid and Zone (ZCZ)[14] were employed for features extraction of the cracks. Four steps to determine the zoning feature using the ICZ method as follows:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font3">1. &nbsp;&nbsp;&nbsp;Calculate the centroid of the input image, the centroid of the image is expressed as a coordinate value (</span><span class="font13">x</span><span class="font11">c</span><span class="font3">,</span><span class="font13">y</span><span class="font11">c</span><span class="font3">), using Equation (1) and (2).</span></p>
<div>
<p><span class="font13">x</span><span class="font11">c</span></p>
</div><br clear="all">
<div>
<p><span class="font2">P</span><span class="font11">n</span></p>
<p><span class="font11">i=ι </span><span class="font14" style="font-style:italic;"><sup>χ</sup></span><span class="font12" style="font-style:italic;">i</span><span class="font14" style="font-style:italic;">P</span><span class="font12" style="font-style:italic;">i</span></p>
<p><span class="font2">P</span><span class="font11">n</span></p>
<p><span class="font11">i=ι </span><span class="font13">P</span><span class="font11">i</span></p>
</div><br clear="all">
<div>
<p><span class="font13">y</span><span class="font11">c </span><span class="font14">=</span></p>
</div><br clear="all">
<div>
<p><span class="font2">P</span><span class="font11">n</span></p>
<p><span class="font11">i=ι </span><span class="font14" style="font-style:italic;">y</span><span class="font12" style="font-style:italic;">i</span><span class="font14" style="font-style:italic;">P</span><span class="font12" style="font-style:italic;">i</span></p>
<p><span class="font2">P</span><span class="font11">n</span></p>
<p><span class="font11">i=ι </span><span class="font13">P</span><span class="font11">i</span></p>
</div><br clear="all">
<div>
<p><span class="font3">(1)</span></p>
<p><span class="font3">(2)</span></p>
</div><br clear="all"></li></ul>
<p><span class="font3">where </span><span class="font13">x</span><span class="font11">c </span><span class="font3">is the centroid of the </span><span class="font3" style="font-style:italic;">x</span><span class="font3"> coordinate; </span><span class="font13">y</span><span class="font11">c </span><span class="font3">is the centroid of the </span><span class="font3" style="font-style:italic;">y</span><span class="font3"> coordinate; </span><span class="font13">x</span><span class="font11">i </span><span class="font3">is the </span><span class="font3" style="font-style:italic;">x</span><span class="font3"> coordinate of the </span><span class="font3" style="font-style:italic;">i</span><span class="font3">-th pixel; </span><span class="font13">y</span><span class="font11">i </span><span class="font3">is the </span><span class="font3" style="font-style:italic;">y</span><span class="font3"> coordinate of the </span><span class="font3" style="font-style:italic;">i</span><span class="font3">-th pixel, and </span><span class="font13">p</span><span class="font11">i </span><span class="font3">is the </span><span class="font3" style="font-style:italic;">i</span><span class="font3">-th pixel value.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font3">2. &nbsp;&nbsp;&nbsp;Divide image input to be </span><span class="font3" style="font-style:italic;">n</span><span class="font3"> same zone then calculate the distance between the centroid of the image with the coordinates of each pixel that has a value of one found in a particular zone, using Eq. (3).</span></p></li></ul>
<p><span class="font14" style="font-style:italic;">d</span><span class="font2" style="font-style:italic;">(</span><span class="font14" style="font-style:italic;">p<sup>,</sup></span><span class="font13"> c</span><span class="font14">) = </span><span class="font7" style="font-style:italic;">∖</span><span class="font14" style="font-style:italic;">J</span><span class="font2" style="font-style:italic;">(</span><span class="font14" style="font-style:italic;">x</span><span class="font12" style="font-style:italic;">c</span><span class="font2"><sup>-</sup> </span><span class="font13">x</span><span class="font11">p</span><span class="font14">)</span><span class="font11">2</span><span class="font2"><sup>+</sup> </span><span class="font2" style="font-style:italic;">(</span><span class="font14" style="font-style:italic;">y</span><span class="font12" style="font-style:italic;">c</span><span class="font2"><sup>-</sup> </span><span class="font13">y</span><span class="font11">p</span><span class="font14">)</span><span class="font11">2 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="font3">(3)</span></p>
<p><span class="font3">where </span><span class="font3" style="font-style:italic;">d</span><span class="font3"> is the distance between two points, p is the coordinates of the center of gravity, </span><span class="font3" style="font-style:italic;">c</span><span class="font3"> is the pixel coordinate, </span><span class="font13">x</span><span class="font11">p </span><span class="font3">is the </span><span class="font3" style="font-style:italic;">x</span><span class="font3"> coordinate of gravity, </span><span class="font13">y</span><span class="font11">p </span><span class="font3">is the </span><span class="font3" style="font-style:italic;">y</span><span class="font3"> coordinate of gravity.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font3">3. &nbsp;&nbsp;&nbsp;Repeat step 3 for all pixels in the particular zone.</span></p></li>
<li>
<p><span class="font3">4. &nbsp;&nbsp;&nbsp;Calculate the average distance between these points.</span></p>
<div>
<p><span class="font3">Figure 3 present the illustration of features extraction of crack images using the ICZ zoning algorithm.</span></p><img src="https://jurnal.harianregional.com/media/52079-3.png" alt="" style="width:179pt;height:75pt;">
</div><br clear="all">
<div><img src="https://jurnal.harianregional.com/media/52079-4.jpg" alt="" style="width:102pt;height:66pt;">
<p><span class="font1" style="font-weight:bold;">Feature extractions result—</span></p>
</div><br clear="all"></li></ul>
<h2><a name="bookmark10"></a><span class="font9" style="font-weight:bold;"><a name="bookmark11"></a>[1.0000 0.9642 0.9159]</span></h2>
<p><span class="font3" style="font-weight:bold;">Figure 3. </span><span class="font3">Example of zoning feature extraction with centroid and zone (ICZ) image</span></p>
<p><span class="font3">While steps to determine the zoning feature using the ZCZ method as follows:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font3">1. &nbsp;&nbsp;&nbsp;Divide the input image into N same zone.</span></p></li>
<li>
<p><span class="font3">2. &nbsp;&nbsp;&nbsp;Calculate the centroid of each zone with equations (1) and (2).</span></p></li>
<li>
<p><span class="font3">3. &nbsp;&nbsp;&nbsp;Calculate the distance between the centroid of the zone and each pixel in the zone with Eq. (3).</span></p></li>
<li>
<p><span class="font3">4. &nbsp;&nbsp;&nbsp;Repeat step c for all pixels in the zone.</span></p></li>
<li>
<p><span class="font3">5. &nbsp;&nbsp;&nbsp;Calculate the average distance between these points.</span></p></li>
<li>
<p><span class="font3">6. &nbsp;&nbsp;&nbsp;Repeat c-e steps for all zones in sequence.</span></p></li>
<li>
<p><span class="font3">7. &nbsp;&nbsp;&nbsp;N characteristics will be obtained for classification and recognition.</span></p></li></ul>
<p><span class="font3">Figure 4 shows an illustration of taking features from a crack image using the ZCZ zoning calculation.</span></p>
<p><span class="font3">All features obtained from zoning ICZ and ZCZ algorithms combined as a vector. Another information that is included as features is shape information extracted using invariant moments. In this case, there are three processes performed to obtain the shape information of the crack image:</span></p>
<div><img src="https://jurnal.harianregional.com/media/52079-5.jpg" alt="" style="width:66pt;height:31pt;">
<p><span class="font1" style="font-weight:bold;">Pre-processing</span></p>
</div><br clear="all">
<div><img src="https://jurnal.harianregional.com/media/52079-6.jpg" alt="" style="width:76pt;height:77pt;">
</div><br clear="all">
<div><img src="https://jurnal.harianregional.com/media/52079-7.jpg" alt="" style="width:64pt;height:104pt;">
<p><span class="font8">Extraction feature result</span></p>
</div><br clear="all">
<div>
<h2><a name="bookmark12"></a><span class="font9" style="font-weight:bold;"><a name="bookmark13"></a>[0.7082 0.8328 1.0000]</span></h2>
</div><br clear="all">
<div>
<p><span class="font3" style="font-weight:bold;">Figure 4. </span><span class="font3">Example of zoning feature extraction with centroid and zone (ICZ) image</span></p>
</div><br clear="all">
<div>
<p><span class="font3">firstly determining moments from each order of the image, secondly calculating the central moment, and finally normalizing the central moment. The each order moments (</span><span class="font13">m</span><span class="font11">11</span><span class="font3">, </span><span class="font13">m</span><span class="font11">20</span><span class="font3">, </span><span class="font13">m</span><span class="font11">02</span><span class="font3">, </span><span class="font13">m</span><span class="font11">21</span><span class="font3">, </span><span class="font13">m</span><span class="font11">12</span><span class="font3">, </span><span class="font13">m</span><span class="font11">03</span><span class="font3">, </span><span class="font13">m</span><span class="font11">30</span><span class="font3">) in the discrete system are determined by using the Eq.(4)[13].</span></p>
</div><br clear="all">
<div>
<p><span class="font11">w</span><span class="font1" style="font-weight:bold;">-</span><span class="font11">1 h</span><span class="font1" style="font-weight:bold;">-</span><span class="font11">1</span></p>
<p><span class="font14" style="font-style:italic;">m</span><span class="font12" style="font-style:italic;">p,q</span><span class="font14"> = </span><span class="font14" style="font-weight:bold;">X X </span><span class="font14" style="font-style:italic;">x</span><span class="font1" style="font-style:italic;"><sup>p</sup> </span><span class="font14" style="font-style:italic;">y</span><span class="font1" style="font-style:italic;"><sup>q</sup></span><span class="font14" style="font-style:italic;"><sup>f</sup> </span><span class="font2" style="font-style:italic;">(</span><span class="font14" style="font-style:italic;"><sup>x,</sup>y</span><span class="font2" style="font-style:italic;">)</span></p>
<p><span class="font11">x=0 y=0</span></p>
</div><br clear="all">
<div>
<p><span class="font3">(4)</span></p>
</div><br clear="all">
<div>
<p><span class="font3">where h and w are the height and width of the image respectively, and p = 0,1,2 ... and q = 0,1,2 ... are integers. So using the Eq. (4) can be rewritten as Eq. (5).</span></p>
</div><br clear="all">
<div>
<p><span class="font11">w</span><span class="font1" style="font-weight:bold;">-</span><span class="font11">1 h</span><span class="font1" style="font-weight:bold;">-</span><span class="font11">1</span></p>
<p><span class="font14" style="font-style:italic;">m</span><span class="font12" style="font-style:italic;">p,q</span><span class="font14"> = </span><span class="font14" style="font-weight:bold;">X X</span><span class="font14">(<sup>x </sup></span><span class="font2"><sup>- </sup></span><span class="font14"><sup>x </sup></span><span class="font2"><sup>)</sup></span><span class="font1"><sup>p</sup></span><span class="font14">(</span><span class="font13">y</span><span class="font2"><sup>-</sup> </span><span class="font14" style="font-style:italic;">y </span><span class="font2" style="font-style:italic;">)</span><span class="font1" style="font-style:italic;"><sup>q</sup></span><span class="font14" style="font-style:italic;"><sup>f</sup></span><span class="font14"> (<sup>x,</sup> </span><span class="font14" style="font-style:italic;">y</span><span class="font2" style="font-style:italic;">) </span><span class="font11">x=0 y=0</span></p>
</div><br clear="all">
<div>
<p><span class="font3">(5)</span></p>
</div><br clear="all">
<div>
<p><span class="font3">where </span><span class="font13">x</span><span class="font0">0 </span><span class="font14">= </span><span class="font13">m</span><span class="font1"><sub>10</sub></span><span class="font13">∕m</span><span class="font1"><sub>00</sub> </span><span class="font3">and </span><span class="font14" style="font-style:italic;">y </span><span class="font2" style="font-style:italic;">= </span><span class="font14" style="font-style:italic;">m<sub>w</sub>∕m</span><span class="font1" style="font-style:italic;"><sub>00</sub></span><span class="font3" style="font-style:italic;">.</span><span class="font3"> After getting the central moment, then the normalized central moment was determined by Eq. (6).</span></p>
</div><br clear="all">
<div>
<p><span class="font13">µ</span><span class="font11">p,q</span></p>
<p><span class="font1" style="font-style:italic;"><sup>q</sup></span></p>
</div><br clear="all">
<div>
<p><span class="font3">(6)</span></p>
</div><br clear="all">
<div>
<p><span class="font3">where </span><span class="font13">γ </span><span class="font14">= ((</span><span class="font13">p </span><span class="font14">+ </span><span class="font13">q</span><span class="font14">)</span><span class="font13">/</span><span class="font14">2) + 1 </span><span class="font3">and </span><span class="font13">μ</span><span class="font11">oo </span><span class="font14">= </span><span class="font13">m</span><span class="font11">oo</span><span class="font3">.</span></p>
</div><br clear="all">
<div><img src="https://jurnal.harianregional.com/media/52079-8.jpg" alt="" style="width:298pt;height:125pt;">
<p><span class="font3" style="font-weight:bold;">Figure 5. </span><span class="font3">The illustration of moment feature extraction of input image.</span></p>
</div><br clear="all">
<ul style="list-style:none;"><li>
<h3><a name="bookmark14"></a><span class="font3" style="font-weight:bold;"><a name="bookmark15"></a>2.3. &nbsp;&nbsp;&nbsp;QDA Classifier</span></h3></li></ul>
<p><span class="font3">Suppose there is a set of </span><span class="font13">n </span><span class="font3">observations </span><span class="font13">X </span><span class="font14">= </span><span class="font13">X</span><span class="font1"><sub>1</sub></span><span class="font13">, X</span><span class="font1"><sub>2</sub></span><span class="font14" style="font-style:italic;">,. ..,X</span><span class="font12" style="font-style:italic;">n</span><span class="font3"> in </span><span class="font3" style="font-style:italic;">p</span><span class="font3"> dimensional space derived from the random population. Quadratic discriminant analysis (QDA) is an alternative classifier which assumes that each class of sample data has its own covariance </span><span class="font14">Σ</span><span class="font1"><sub>k</sub></span><span class="font3">. While the LDA classifier assumes that the sample data has a global covariance matrix (</span><span class="font14">Σ</span><span class="font3">) for all k classes and the </span><span class="font13">X </span><span class="font3">is a multivariate Gaussian distribution. The LDA function or linear score function is defined as Eq. (7)[15, 16, 17].</span></p>
<p><span class="font14" style="font-style:italic;">δ</span><span class="font12" style="font-style:italic;">k</span><span class="font14">(</span><span class="font13">x</span><span class="font14">) = log</span><span class="font13">∏</span><span class="font11">k </span><span class="font6">- </span><span class="font14">2</span><span class="font14" style="font-style:italic;">μ</span><span class="font1" style="font-style:italic;"><sup>τ</sup></span><span class="font14">∑</span><span class="font1"><sup>-1</sup> </span><span class="font14">+ </span><span class="font14" style="font-style:italic;">χ<sup>τ</sup></span><span class="font14">∑</span><span class="font1"><sup>-1</sup> </span><span class="font14" style="font-style:italic;">μ</span><span class="font12" style="font-style:italic;">k</span><span class="font3"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(7)</span></p>
<p><span class="font3">where </span><span class="font13">π</span><span class="font11">k </span><span class="font3">and </span><span class="font13">µ</span><span class="font11">k </span><span class="font3">are prior probability and mean of k-th class. In LDA and QDA, the </span><span class="font13">π</span><span class="font11">k </span><span class="font3">is defined as the class membership probabilities. It means that that given an input </span><span class="font3" style="font-style:italic;">x</span><span class="font3"> is predicted to the class with the highest value of </span><span class="font14" style="font-style:italic;">δ</span><span class="font1" style="font-style:italic;"><sub>k</sub></span><span class="font14">(</span><span class="font13">x</span><span class="font14">)</span><span class="font3">.</span></p>
<p><span class="font3">While the QDA classifier assigns an observation </span><span class="font13">X </span><span class="font14">= </span><span class="font13">x </span><span class="font3">to the class for which the quadratic score function is the largest using the Eq. (8)</span></p>
<div>
<p><span class="font3">(8)</span></p>
</div><br clear="all">
<p><span class="font14" style="font-style:italic;">δ</span><span class="font12" style="font-style:italic;">k</span><span class="font14">(</span><span class="font13">x</span><span class="font14">) = log </span><span class="font14" style="font-style:italic;">∏</span><span class="font12" style="font-style:italic;">k </span><span class="font14" style="font-style:italic;">-</span><span class="font14"> 2 log </span><span class="font6">∣</span><span class="font14">∑</span><span class="font11">k</span><span class="font6">| - </span><span class="font2" style="font-style:italic;">^(</span><span class="font14" style="font-style:italic;">x</span><span class="font6"> - </span><span class="font14" style="font-style:italic;">μ</span><span class="font12" style="font-style:italic;">k</span><span class="font2" style="font-style:italic;">)</span><span class="font12" style="font-style:italic;">T</span><span class="font14">Σ</span><span class="font11">k </span><span class="font1"><sup>1</sup> </span><span class="font14">(</span><span class="font13">x </span><span class="font6">- </span><span class="font14" style="font-style:italic;">μ</span><span class="font12" style="font-style:italic;">k</span><span class="font14">)</span></p>
<ul style="list-style:none;"><li>
<h3><a name="bookmark16"></a><span class="font3" style="font-weight:bold;"><a name="bookmark17"></a>3. &nbsp;&nbsp;&nbsp;Result and Discussion</span></h3></li></ul>
<p><span class="font3">Several experiments were carried out to find out the best variation of features of zoning and shape features for QDA classifier. We prepared the data for evaluation from two datasets: METU[18]and CDLE. The METU dataset consists of 40.000 standard images which were captured from structural laboratory testing under almost uniform lighting condition. The ratio between crack and noncrack images of METU dataset is 50%:50%. Fig. 6 is images samples from METU dataset. CDLE dataset is a crack image collection recorded from damage building due to Lombok earthquake in 2018. The images were captured by using a cellphone camera without capturing standardization in terms of distance of the camera to object, lighting, and camera resolution. The CDLE has 334 images which were annotated into three types of cracks: minor, moderate, and severe cracks by an expert (Pathurahman, S.T., M.T) from Civil Engineering Dept., University of Mataram. Fig. 7 presents the images samples from CDLE dataset.</span></p>
<div><img src="https://jurnal.harianregional.com/media/52079-9.jpg" alt="" style="width:311pt;height:59pt;">
<p><span class="font3" style="font-weight:bold;">Figure 6. </span><span class="font3">Images samples from METU dataset</span></p>
</div><br clear="all">
<div><img src="https://jurnal.harianregional.com/media/52079-10.jpg" alt="" style="width:279pt;height:61pt;">
<p><span class="font3" style="font-weight:bold;">Figure 7. </span><span class="font3">Images samples from CDLE dataset</span></p>
</div><br clear="all">
<div>
<p><span class="font3">The testing using METU dataset aims to evaluate our proposed scheme (zoning and shape features and QDA classifier) work properly for classifying the crack image. While the testing using CDLE dataset aims to validate whether the crack classification scheme can works correctly on non-standard building crack image due to the earthquake. Accuracy, Recall, and Precision metrics are performance evaluation parameter of the proposed methods, which are determined based on confusion matrix as given by Eq. (9, 10, and 11).</span></p>
</div><br clear="all">
<div>
<p><span class="font14" style="font-style:italic;">„ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;TP </span><span class="font2" style="font-style:italic;">+ </span><span class="font14" style="font-style:italic;">TN</span></p>
<p><span class="font14" style="font-style:italic;">Accuracy</span><span class="font14"> = </span><span class="font10" style="font-style:italic;text-decoration:line-through;">TP</span><span class="font5" style="text-decoration:line-through;"> <sub>+</sub> </span><span class="font10" style="font-style:italic;text-decoration:line-through;">TN</span><span class="font5" style="text-decoration:line-through;"> <sub>+</sub> </span><span class="font10" style="font-style:italic;text-decoration:line-through;">FP</span><span class="font5" style="text-decoration:line-through;"> <sub>+</sub> </span><span class="font10" style="font-style:italic;text-decoration:line-through;">FN</span></p>
</div><br clear="all">
<div>
<p><span class="font14" style="font-style:italic;">Recall </span><span class="font2" style="font-style:italic;">=</span></p>
</div><br clear="all">
<div>
<p><span class="font14" style="font-style:italic;">TP</span></p>
<p><span class="font14" style="font-style:italic;">TP</span><span class="font14"> + </span><span class="font14" style="font-style:italic;">FN</span></p>
</div><br clear="all">
<div>
<p><span class="font14" style="font-style:italic;">TP</span></p>
<p><span class="font14" style="font-style:italic;">Precision = ——--——</span></p>
<p><span class="font14" style="font-style:italic;">TP</span><span class="font14"> + </span><span class="font14" style="font-style:italic;">FP</span></p>
</div><br clear="all">
<div>
<p><span class="font3">(9)</span></p>
<p><span class="font3">(10)</span></p>
<p><span class="font3">(11)</span></p>
</div><br clear="all">
<div>
<p><span class="font3">where:</span></p>
</div><br clear="all">
<div>
<p><span class="font6">• </span><span class="font3">TP (True Positive) means the crack samples are correctly classified as crack</span></p>
</div><br clear="all">
<ul style="list-style:none;"><li>
<p><span class="font6">•</span><span class="font3"> &nbsp;&nbsp;&nbsp;TN (True Negative) means the non-crack samples are correctly classified as non-crack</span></p></li>
<li>
<p><span class="font6">•</span><span class="font3"> &nbsp;&nbsp;&nbsp;FP (True Positive) means the non-crack samples are falsely classified as crack</span></p></li>
<li>
<p><span class="font6">•</span><span class="font3"> &nbsp;&nbsp;&nbsp;TN (True Positive) means the crack samples are falsely classified classified as non-crack</span></p></li></ul>
<ul style="list-style:none;"><li>
<h3><a name="bookmark18"></a><span class="font3" style="font-weight:bold;"><a name="bookmark19"></a>3.1. &nbsp;&nbsp;&nbsp;Testing on small size dataset</span></h3></li></ul>
<p><span class="font3">Firstly, the proposed scheme was evaluated by using 10-fold cross-validation on the 1200 images set, which were sampled randomly from METU dataset. The images set has a balanced amount of data for crack and non-crack categories. This test was conducted to find the best combination moment invariant and zoning variation for classification crack types. Table 1 presented the experimental results, which 4-moment invariant features and 8 zoning features provided the best performances with a percentage of accuracy, precision, and recall of 89.42%; 90.16%; and 89.42%, respectively. In detail, the number of crack images was incorrectly predicted about 29 images from 180 testing images (83.5%), while the number of non-cracked data that was wrongly predicted by this scheme about 6 images out of 180 testing images (95,342%). This result could be obtained because the shape information representing by four-invariant moments (See Fig 8) have large differences between the shape information of crack and non-crack images. Therefore, explicitly four of seven moments are suitable for features of crack and non-crack. Additionally, Fig. 9 also presented that the 8 zoning features show significant differences between those of crack and non-crack. It means the combination between the shape and zoning information is good enough for features of the crack images.</span></p>
<p><span class="font3" style="font-weight:bold;">Table 1. </span><span class="font3">The performances of the proposed scheme on small size dataset</span></p>
<table border="1">
<tr><td rowspan="2" style="vertical-align:middle;">
<p><span class="font13" style="font-weight:bold;">Model</span></p></td><td colspan="2" style="vertical-align:top;">
<p><span class="font13" style="font-weight:bold;">Amount of Feature</span></p></td><td rowspan="2" style="vertical-align:middle;">
<p><span class="font13" style="font-weight:bold;font-style:italic;">Accuracy ' (%)</span></p></td><td rowspan="2" style="vertical-align:middle;">
<p><span class="font13" style="font-weight:bold;font-style:italic;">Precision (%)</span></p></td><td rowspan="2" style="vertical-align:middle;">
<p><span class="font13" style="font-weight:bold;font-style:italic;">Recall</span></p>
<p><span class="font13" style="font-weight:bold;font-style:italic;">(%)</span></p></td><td rowspan="2" style="vertical-align:middle;">
<p><span class="font13" style="font-weight:bold;">Compilation Times</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font13" style="font-weight:bold;">Shape</span></p></td><td style="vertical-align:bottom;">
<p><span class="font13" style="font-weight:bold;">Zoning</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font13">1</span></p></td><td style="vertical-align:bottom;">
<p><span class="font13">4</span></p></td><td style="vertical-align:bottom;">
<p><span class="font13">4</span></p></td><td style="vertical-align:bottom;">
<p><span class="font13">86,25</span></p></td><td style="vertical-align:bottom;">
<p><span class="font13">87,63</span></p></td><td style="vertical-align:bottom;">
<p><span class="font13">86,25</span></p></td><td style="vertical-align:bottom;">
<p><span class="font13">0,6902</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font13" style="font-weight:bold;">2</span></p></td><td style="vertical-align:bottom;">
<p><span class="font13" style="font-weight:bold;">4</span></p></td><td style="vertical-align:bottom;">
<p><span class="font13" style="font-weight:bold;">8</span></p></td><td style="vertical-align:bottom;">
<p><span class="font13" style="font-weight:bold;">89,42</span></p></td><td style="vertical-align:bottom;">
<p><span class="font13" style="font-weight:bold;">90,16</span></p></td><td style="vertical-align:bottom;">
<p><span class="font13" style="font-weight:bold;">89,42</span></p></td><td style="vertical-align:bottom;">
<p><span class="font13" style="font-weight:bold;">1,1223</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font13">3</span></p></td><td style="vertical-align:bottom;">
<p><span class="font13">7</span></p></td><td style="vertical-align:bottom;">
<p><span class="font13">4</span></p></td><td style="vertical-align:bottom;">
<p><span class="font13">83,75</span></p></td><td style="vertical-align:bottom;">
<p><span class="font13">86,21</span></p></td><td style="vertical-align:bottom;">
<p><span class="font13">83,75</span></p></td><td style="vertical-align:bottom;">
<p><span class="font13">0,6900</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font13">4</span></p></td><td style="vertical-align:bottom;">
<p><span class="font13">7</span></p></td><td style="vertical-align:bottom;">
<p><span class="font13">8</span></p></td><td style="vertical-align:bottom;">
<p><span class="font13">85,17</span></p></td><td style="vertical-align:bottom;">
<p><span class="font13">87,04</span></p></td><td style="vertical-align:bottom;">
<p><span class="font13">85,17</span></p></td><td style="vertical-align:bottom;">
<p><span class="font13">1,1498</span></p></td></tr>
<tr><td style="vertical-align:top;"></td><td style="vertical-align:bottom;">
<p><span class="font13" style="font-weight:bold;">Mean</span></p></td><td style="vertical-align:top;"></td><td style="vertical-align:bottom;">
<p><span class="font13" style="font-weight:bold;">86,15</span></p></td><td style="vertical-align:bottom;">
<p><span class="font13" style="font-weight:bold;">87,76</span></p></td><td style="vertical-align:bottom;">
<p><span class="font13" style="font-weight:bold;">86,15</span></p></td><td style="vertical-align:bottom;">
<p><span class="font13" style="font-weight:bold;">0,9131</span></p></td></tr>
</table><img src="https://jurnal.harianregional.com/media/52079-11.jpg" alt="" style="width:298pt;height:229pt;">
<p><span class="font3" style="font-weight:bold;">Figure 8. </span><span class="font3">Comparison of crack and non-crack moment invariant features</span></p>
<p><span class="font3">Regarding computational time, it could be seen that there is no significant increment of computational time for each addition of features in the zoning method. It can be achieved by representing each image using small data (12 discrete values) instead of whole data pixels. In this case, the computational time was determined from the input image is given until the results of the classification results are released.</span></p><img src="https://jurnal.harianregional.com/media/52079-12.jpg" alt="" style="width:241pt;height:149pt;">
<p><span class="font3" style="font-weight:bold;">Figure 9. </span><span class="font3">Comparison of crack and non-crack zoning features</span></p><img src="https://jurnal.harianregional.com/media/52079-13.jpg" alt="" style="width:227pt;height:135pt;">
<p><span class="font3" style="font-weight:bold;">Figure 10. </span><span class="font3">The performance of the proposed scheme on large size dataset (40000 images) compared to LDA</span></p>
<ul style="list-style:none;"><li>
<h3><a name="bookmark20"></a><span class="font3" style="font-weight:bold;"><a name="bookmark21"></a>3.2. &nbsp;&nbsp;&nbsp;Testing on large size dataset</span></h3></li></ul>
<p><span class="font3">Based on the best features variation obtained in the first experiment, the second experiment was carried out to know the robustness of the proposed scheme on large size dataset (METU has 40.000 images)) and different classifiers. In the second experiments, the QDA classifier was also compared to the statistical classifiers (Linear Discriminant Analysis (LDA)[16]). Additionally, the ratio between training and testing data of METU dataset was set up 70:30% which was selected randomly. The experimental results (see Fig. 10) showed that the proposed method could work properly for large size dataset, which was in-line to the achievement of the first experiments. In detail, the proposed scheme provided more than 85% Accuracy, Precision, and Recall and it also gave a higher performance than LDA on the METU dataset. It means the experimental results reconfirmed that the proposed scheme (a combination of moment invariant and zoning features, as well as QDA classifier) could work properly on crack classification especially a large variety of crack and non-crack images.</span></p>
<ul style="list-style:none;"><li>
<h3><a name="bookmark22"></a><span class="font3" style="font-weight:bold;"><a name="bookmark23"></a>3.3. &nbsp;&nbsp;&nbsp;Testing on CDLE dataset</span></h3></li></ul>
<p><span class="font3">The last experiment was conducted on CDLE dataset to classify real crack image due to Lombok Earthquake into three classes, namely minor, moderate, and severe. The best feature variation (4</span></p>
<p><span class="font3">moment invariant and 8 zoning), which were found in the first and second tests were implemented to determine the damage level of the crack image due to Lombok Earthquake. The data used in this test is 334 damaged images by the earthquake in Lombok, West Nusa Tenggara, which the ratio between training and testing images were set at 90%:10%, that was commonly used for small size data. The experimental results showed that the combination of our proposed features and QDA classifier did not give high enough accuracy by about 39.39%. It can be caused by large variability of CDLE dataset which was taken by different cameras, lighting condition, capturing distance, direction, and backgrounds. The same examples images which failed to classify are given in Figure 11(b). Even the human-vision is hard to the type of crack from the images in the Figure 11(b).</span></p><img src="https://jurnal.harianregional.com/media/52079-14.jpg" alt="" style="width:241pt;height:174pt;">
<p><span class="font3" style="font-weight:bold;">Figure 11. </span><span class="font3">crack images (a)correctly and (b)falsely classified by our scheme</span></p>
<p><span class="font3">Based on this problem, only 82 standard images of 334 images were manually selected based on image sharpness, and the annotation results from an expert for the next experiments. Similar to the previous experiment, the ratio between training and testing images were set up 90%:10%. By using the same variety of features (4-moment invariant features and 8 zoning features) and QDA classifier, the accuracy increases significantly almost 49.5% (form 39.39% to be 88.89%). Therefore, the standardization of data input is the most essential part of crack image classification which must be considered for next works.</span></p>
<ul style="list-style:none;"><li>
<h3><a name="bookmark24"></a><span class="font3" style="font-weight:bold;"><a name="bookmark25"></a>4. Conclusion</span></h3></li></ul>
<p><span class="font3">Based on the experimental results and discussion, it can be concluded as follows: firstly, the zoning and moment invariant method is a appropriate combination of feature extraction methods for determining the level of damage to buildings; secondly, the best combination of moment invariant and zoning features which obtain a high enough of accuracy (89.42%) is a combination of 4 features for moment invariant and 8 features for zoning; thirdly, the QDA classifier is better than LDA classifier for crack image classification; and the rest standardization of data is very influential in the process of training and classification, which is able to increase about 49.5% of accuracy when Standardization of data was given.</span></p>
<p><span class="font3">The achievements of the proposed scheme must be improved and developed in further research, including: training data must be updated/added for getting robust performances, data must be standardized by image pre-processing techniques, employing another classifier for increasing the accuracy.</span></p>
<h3><a name="bookmark26"></a><span class="font3" style="font-weight:bold;"><a name="bookmark27"></a>Acknowledgements</span></h3>
<p><span class="font3">The paper is part of a funded by the Ministry of Research, Technology and Higher Education of the Republic of Indonesia under the scheme basic research and contract no:182/SP2H/LT/DRPM/2019.</span></p>
<p><span class="font3">We also thank the expert system laboratory staff for hardware supporting and useful discussion.</span></p>
<h3><a name="bookmark28"></a><span class="font3" style="font-weight:bold;"><a name="bookmark29"></a>References</span></h3>
<ul style="list-style:none;"><li>
<p><span class="font3">[1] &nbsp;&nbsp;&nbsp;W. Nuswantoro, “Analisis jenis kerusakan pada bangunan perumahan (studi kasus pada perumahan pondok pasir mas palangka raya),” </span><span class="font3" style="font-style:italic;">Jurnal Rekayasa Bangunan</span><span class="font3">, vol. 11, no. 1, pp. 1–14, 2010.</span></p></li>
<li>
<p><span class="font3">[2] &nbsp;&nbsp;&nbsp;S. N. Sheerin, S. Kavitha, and G. Raghuraman, “Review and analysis of crack detection and classification techniques based on crack types,” </span><span class="font3" style="font-style:italic;">International Journal of Applied Engineering Research</span><span class="font3">, vol. 13, no. 8, pp. 6056–6062, 2018.</span></p></li>
<li>
<p><span class="font3">[3] &nbsp;&nbsp;&nbsp;A. Mohan and S. Poobal, “Crack detection using image processing: A critical review and analysis,” </span><span class="font3" style="font-style:italic;">Alexandria Engineering Journal</span><span class="font3">, vol. 57, no. 2, pp. 787–798, 2018.</span></p></li>
<li>
<p><span class="font3">[4] &nbsp;&nbsp;&nbsp;E. Hussain, A. Hannan, and K. Kashyap, “A zoning based feature extraction method for recognition of handwritten assamese characters,” </span><span class="font3" style="font-style:italic;">International Journal of Computer Science and Technology</span><span class="font3">, vol. 6, 01 2015.</span></p></li>
<li>
<p><span class="font3">[5] &nbsp;&nbsp;&nbsp;F. Camastra, “Handwritten greek character recognition with learning vector quantization,” in </span><span class="font3" style="font-style:italic;">International Conference on Knowledge-Based and Intelligent Information and Engineering Systems</span><span class="font3">. Springer, 2007, pp. 267–274.</span></p></li>
<li>
<p><span class="font3">[6] &nbsp;&nbsp;&nbsp;G. A. Abandah, K. S. Younis, and M. Z. Khedher, “Handwritten arabic character recognition using multiple classifiers based on letter form,” in </span><span class="font3" style="font-style:italic;">Proceedings of the Fifth IASTED International Conference on Signal Processing, Pattern Recognition and Applications</span><span class="font3">, ser. SPPRA ’08. Anaheim, CA, USA: ACTA Press, 2008, pp. 128–133. [Online]. Available: </span><a href="http://dl.acm.org/citation.cfm?id=1722683.1722710"><span class="font3">http://dl.acm.org/citation.cfm?id=1722683.1722710</span></a></p></li>
<li>
<p><span class="font3">[7] &nbsp;&nbsp;&nbsp;P. Prasanna, K. J. Dana, N. Gucunski, B. B. Basily, H. M. La, R. S. Lim, and H. Parvardeh, “Automated crack detection on concrete bridges,” </span><span class="font3" style="font-style:italic;">IEEE Transactions on Automation Science and Engineering</span><span class="font3">, vol. 13, no. 2, pp. 591–599, April 2016.</span></p></li>
<li>
<p><span class="font3">[8] &nbsp;&nbsp;&nbsp;Y. Shi, L. Cui, Z. Qi, F. Meng, and Z. Chen, “Automatic road crack detection using random structured forests,” </span><span class="font3" style="font-style:italic;">IEEE Transactions on Intelligent Transportation Systems</span><span class="font3">, vol. 17, no. 12, pp. 3434–3445, Dec 2016.</span></p></li>
<li>
<p><span class="font3">[9] &nbsp;&nbsp;&nbsp;A. R. Rizvi, P. R. Khan, and S. Ahmad, “Crack detection in railway track using image processing,” </span><span class="font3" style="font-style:italic;">International Journal of Advance Research, Ideas and Innovations in Technology</span><span class="font3">, vol. 3, no. 4, pp. 489–496, 2017.</span></p></li>
<li>
<p><span class="font3">[10] &nbsp;&nbsp;&nbsp;S. Kabir, “Imaging-based detection of aar induced map-crack damage in concrete structure,” </span><span class="font3" style="font-style:italic;">NDT &amp;&nbsp;E International</span><span class="font3">, vol. 43, no. 6, pp. 461–469, 2010.</span></p></li>
<li>
<p><span class="font3">[11] &nbsp;&nbsp;&nbsp;S. Kabir, P. Rivard, G. Ballivy, and D.-C. He, “Textural analysis for crack-detection using infrared thermography, visual colour, and greyscale concrete imagery,” in </span><span class="font3" style="font-style:italic;">Joint International Conference on Computing and Decision Making in Civil and Building Engineering</span><span class="font3">, 06 2006, pp. 14–16.</span></p></li>
<li>
<p><span class="font3">[12] &nbsp;&nbsp;&nbsp;L. Zhang, F. Yang, Y. D. Zhang, and Y. J. Zhu, “Road crack detection using deep convolutional neural network,” in </span><span class="font3" style="font-style:italic;">2016 IEEE international conference on image processing (ICIP)</span><span class="font3">. IEEE, 2016, pp. 3708–3712.</span></p></li>
<li>
<p><span class="font3">[13] &nbsp;&nbsp;&nbsp;R. C. Gonzalez and R. E. Woods, </span><span class="font3" style="font-style:italic;">Digital Image Processing (3Rd Edition)</span><span class="font3">. Prentice Hall, August, 2007.</span></p></li>
<li>
<p><span class="font3">[14] &nbsp;&nbsp;&nbsp;T. Zuraiyah, A. Qur’ania, and C. R Pitoyo, “Optimization of feature extraction using combined image centroid zone and zone centroid zone method,” in </span><span class="font3" style="font-style:italic;">IORA International Conference on Operation Research</span><span class="font3">, 09 2016.</span></p></li>
<li>
<p><span class="font3">[15] &nbsp;&nbsp;&nbsp;R. O. Duda, P. E. Hart, and D. G. Stork, </span><span class="font3" style="font-style:italic;">Pattern Classification (2Nd Edition)</span><span class="font3">. New York, NY, USA: Wiley-Interscience, 2001.</span></p></li>
<li>
<p><span class="font3">[16] &nbsp;&nbsp;&nbsp;A. Tharwat, “Linear vs. quadratic discriminant analysis classifier: a tutorial,” </span><span class="font3" style="font-style:italic;">International Journal of Applied Pattern Recognition</span><span class="font3">, vol. 3, no. 2, pp. 145–180, 2016.</span></p></li>
<li>
<p><span class="font3">[17] &nbsp;&nbsp;&nbsp;X. Sicotte, “Linear and quadratic discriminant analysis,” 2018. [Online]. Available: </span><a href="https://xavierbourretsicotte.github.io/LDA_QDA.html"><span class="font3">https://xavierbourretsicotte.github.io/LDA_QDA.html</span></a></p></li>
<li>
<p><span class="font3">[18] &nbsp;&nbsp;&nbsp;Çag˘ lar Fırat Özgenel, “Concrete Crack Images for Classification,” 2018. [Online]. Available: </span><a href="http://dx.doi.org/10.17632/5y9wdsg2zt.1"><span class="font3">http://dx.doi.org/10.17632/5y9wdsg2zt.1</span></a></p></li></ul>
<p><span class="font13">168</span></p>