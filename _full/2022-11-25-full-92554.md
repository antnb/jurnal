---
layout: full_article
title: "Implementasi Algoritma Random Forest Dalam Menentukan Kualitas Susu Sapi"
author: "I Putu Ryan Paramaditya, Cokorda Rai Adi Paramartha"
categories: jnatia
canonical_url: https://jurnal.harianregional.com/jnatia/full-92554 
citation_abstract_html_url: "https://jurnal.harianregional.com/jnatia/id-92554"
citation_pdf_url: "https://jurnal.harianregional.com/jnatia/full-92554"  
comments: true
---

<p><span class="font2">JNATIA Volume 1, Nomor 1, November 2022</span></p>
<p><span class="font2">Jurnal Nasional Teknologi Informasi dan Aplikasinya</span></p><a name="caption1"></a>
<h1><a name="bookmark0"></a><span class="font4" style="font-weight:bold;"><a name="bookmark1"></a>Implementasi Algoritma </span><span class="font4" style="font-weight:bold;font-style:italic;">Random Forest </span><span class="font4" style="font-weight:bold;">Dalam Menentukan Kualitas Susu Sapi</span></h1>
<p><span class="font2">I Putu Ryan Paramaditya<sup>a1</sup></span><span class="font2" style="font-weight:bold;">, </span><span class="font2">Cokorda Pramartha<sup>b2</sup></span></p>
<p><span class="font2"><sup>a</sup>Informatics Department, Udayana University <sup>b</sup>Net-Centric Computing Laboratory, Udayana University </span><a href="mailto:1ryanparamaditya@gmail.com"><span class="font2"><sup>1</sup>ryanparamaditya@gmail.com</span></a></p>
<p><a href="mailto:2cokorda@unud.ac.id"><span class="font2"><sup>2</sup>cokorda@unud.ac.id</span></a></p>
<p><span class="font2" style="font-weight:bold;font-style:italic;">Abstract</span></p>
<p><span class="font2" style="font-style:italic;">Milk is one of the food ingredients as a source of animal protein that can meet the needs and improve the nutrition of the people of Indonesia, especially protein, carbohydrates, fats and minerals of high nutritional value, namely calcium and phosphorus which can help the healing process of various diseases. Use the classification method performed with the Random Forest algorithm on the data content of cow's milk content where the results of the experiments that have been carried out, the accuracy rate of classification with the Random Forest algorithm is 98%. In addition, in testing precision, recall, and f1-score generated from each variable has the same value of 98%. then the highest level of accuracy of the response variable is in the &quot;medium&quot; category.</span></p>
<p><span class="font2" style="font-weight:bold;font-style:italic;">Keywords: </span><span class="font2" style="font-style:italic;">Classification, Random Forest, Accuracy, Confusion Matrix, ROC Curve</span></p>
<ul style="list-style:none;"><li>
<h3><a name="bookmark2"></a><span class="font2" style="font-weight:bold;"><a name="bookmark3"></a>1. &nbsp;&nbsp;&nbsp;Pendahuluan</span></h3></li></ul>
<p><span class="font2">Susu merupakan salah satu bahan pangan sebagai sumber protein hewani yang dapat memenuhi kebutuhan dan meningkatkan gizi masyarakat Indonesia, termasuk protein, karbohidrat, dan mineral, khususnya kalsium dan fosfor, yang dapat membantu proses pemulihan dari berbagai penyakit.[1] Sapi, kerbau, kuda, dan kambing hanyalah beberapa contoh hewan yang diperah untuk menghasilkan susu, elemen makanan dengan nilai gizi yang tinggi. Dalam mengetahui dan menentukan kualitas dari susu tersebut diperlukan pengujian pada kadar yang dikandung pada susu dari kadar lemak, protein, nilai </span><span class="font2" style="font-style:italic;">pH</span><span class="font2"> hingga suhu yang mempengaruhinya.</span></p>
<p><span class="font2">Istilah </span><span class="font2" style="font-style:italic;">data mining</span><span class="font2"> sering diartikan sebagai proses untuk menemukan pola-pola yang berwawasan, menarik, dan baru, serta model deskriptif, mudah dipahami dan prediktif dari data skala besar. </span><span class="font2" style="font-style:italic;">Data mining</span><span class="font2"> adalah proses yang mencari tautan dan pola tersembunyi dalam data menggunakan berbagai metodologi dan alat untuk analisis data. Pendekatan dasarnya ialah untuk meringkas data dan ekstrasi informasi berguna yang sebelumnya tidak diketahui. Klasifikasi dan regresi merupakan contoh tugas prediktif, sedangkan </span><span class="font2" style="font-style:italic;">clustering</span><span class="font2"> dan asosiasi adalah contoh tugas deskriptif.[2] Maka dari itu dalam mengetahui proses pola dalam menentukan kualitas susu sapi berdasarkan pada kadar setiap kandungan susu, dilakukan data mining dengan metode klasifikasi.</span></p>
<p><span class="font2">Menggunakan metode klasifikasi dilakukan, karena pada data tersebut memiliki </span><span class="font2" style="font-style:italic;">class</span><span class="font2"> yang dapat digunakan dalam menentukan pola dan prediksi yang sesuai dengan kategori (</span><span class="font2" style="font-style:italic;">class</span><span class="font2">) pada data tersebut.[3] Penggunaan algoritma dalam melakukan klasifikasi salah satunya adalah </span><span class="font2" style="font-style:italic;">random forest. Random Forest</span><span class="font2"> merupakan perpanjangan dari pendekatan Pohon Klasifikasi dan Regresi (</span><span class="font2" style="font-style:italic;">CART</span><span class="font2">) yang menggabungkan agregasi </span><span class="font2" style="font-style:italic;">bootstrap</span><span class="font2"> dan pemilihan fitur acak. Manfaat dari pendekatan ini termasuk peningkatan akurasi, kemampuan untuk menangani sejumlah besar data secara efisien, dan tidak ada pemangkasan variabel seperti pada algoritma pohon klasifikasi tunggal. </span><span class="font2" style="font-style:italic;">Random Forest</span><span class="font2"> menciptakan nilai signifikansi dari faktor prediktor dalam mengkategorikan variabel respons selain memberikan hasil prediksi yang sangat akurat.[4]</span></p>
<p><span class="font2">Dalam penelitiannya, Widya Apriliah dkk. membandingkan kinerja klasifikasi dengan algoritma </span><span class="font2" style="font-style:italic;">support vector machine, random forest,</span><span class="font2"> dan </span><span class="font2" style="font-style:italic;">naive bayes</span><span class="font2">. Temuan yang dikumpulkan menunjukkan bahwa </span><span class="font2" style="font-style:italic;">Random Forest</span><span class="font2"> melampaui algoritma lainnya dalam memprediksi kemungkinan diabetes pada tahap awal, dengan skor akurasi terbesar 97,88%.[5] Penggunaan algoritma </span><span class="font2" style="font-style:italic;">random forest</span><span class="font2"> dalam memprediksi harga ponsel yang dilakukan oleh Vanissa Wanika</span></p>
<p><span class="font2">Siburian, dkk. Dimana tingkat akurasi prediksi yang menggunakan pendekatan </span><span class="font2" style="font-style:italic;">Random Forest </span><span class="font2">adalah 81% ketika klasifikasi dalam penelitian ini mencakup tujuh variabel prediksi dan satu variabel respon.[6] Maka pada paper ini digunakan algoritma </span><span class="font2" style="font-style:italic;">Random Forest</span><span class="font2"> dalam melakukan metode klasifikasi pada data kualitas kadar pada kandungan susu sapi. Hasil yang diharapkan dengan akurasi yang tinggi dari penelitian yang sudah dilakukan sebelumnya.</span></p>
<ul style="list-style:none;"><li>
<h3><a name="bookmark4"></a><span class="font2" style="font-weight:bold;"><a name="bookmark5"></a>2. &nbsp;&nbsp;&nbsp;Metode Penelitian</span><br><br><span class="font2" style="font-weight:bold;"><a name="bookmark6"></a>2.1. &nbsp;&nbsp;&nbsp;Dataset dan Analisis</span></h3></li></ul>
<p><span class="font2">Metode penelitian yang diterapkan dengan pendekatan kuantitatif. Dimana pada penelitian ini melakukan klasifikasi menggunakan algoritma </span><span class="font2" style="font-style:italic;">Random Forest</span><span class="font2"> dengan data yang memiliki tiga kategori. Pada penelitian tersebut menggunakan data sekunder yang meklasifikasikan kadar pada kandungan susu sapi berdasarkan pada kualitasnya. Data yang didapatkan pada situs kaggle</span><a href="https://www.kaggle.com/datasets/yrohit199/milk-quality"><span class="font2"> https://www.kaggle.com/datasets/yrohit199/milk-quality </span></a><span class="font2">dengan data yang digunakan sebanyak 1059 data.</span></p>
<table border="1">
<tr><td style="vertical-align:top;"></td><td style="vertical-align:top;">
<p><span class="font2">PH</span></p></td><td style="vertical-align:top;">
<p><span class="font5">Temprature</span></p></td><td style="vertical-align:top;">
<p><span class="font5">Taste</span></p></td><td style="vertical-align:top;">
<p><span class="font5">Odor</span></p></td><td style="vertical-align:top;">
<p><span class="font5">Fat</span></p></td><td style="vertical-align:top;">
<p><span class="font5">Turbidity</span></p></td><td style="vertical-align:top;">
<p><span class="font5">Colour</span></p></td><td style="vertical-align:top;">
<p><span class="font5">Grade</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font1">O</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">6.6</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">35</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">1</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">1</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">254</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">high</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font1" style="font-weight:bold;">1</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">6.6</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">36</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">1</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">1</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">253</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">high</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font1" style="font-weight:bold;">2</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">8.5</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">70</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">1</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">1</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">1</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">1</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">246</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">low</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font1" style="font-weight:bold;">3</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">9.5</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">34</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">1</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">1</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">1</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">255</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">low</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font1" style="font-weight:bold;">4</span></p></td><td style="vertical-align:top;">
<p><span class="font1">6.6</span></p></td><td style="vertical-align:top;">
<p><span class="font1">37</span></p></td><td style="vertical-align:top;">
<p><span class="font1">0</span></p></td><td style="vertical-align:top;">
<p><span class="font1">0</span></p></td><td style="vertical-align:top;">
<p><span class="font1">0</span></p></td><td style="vertical-align:top;">
<p><span class="font1">0</span></p></td><td style="vertical-align:top;">
<p><span class="font1">255</span></p></td><td style="vertical-align:top;">
<p><span class="font1">medium</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font1" style="font-weight:bold;">1054</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">6.7</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">45</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">1</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">1</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">0</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">0</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">247</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">medium</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font1" style="font-weight:bold;">1055</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">6.7</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">38</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">1</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">1</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">255</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">high</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font1" style="font-weight:bold;">1056</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">3.0</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">40</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">1</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">1</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">1</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">1</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">255</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">low</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font1" style="font-weight:bold;">1057</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">6.8</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">43</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">1</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">1</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">250</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">high</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font1" style="font-weight:bold;">1058</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">8.6</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">55</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">1</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">1</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">1</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">255</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">low</span></p></td></tr>
<tr><td colspan="3" style="vertical-align:bottom;">
<p><span class="font1">1059 rows × 8 columns</span></p></td><td style="vertical-align:top;"></td><td style="vertical-align:top;"></td><td style="vertical-align:top;"></td><td style="vertical-align:top;"></td><td style="vertical-align:top;"></td><td style="vertical-align:top;"></td></tr>
</table>
<p><span class="font2" style="font-weight:bold;">Gambar 1. </span><span class="font2">Milk Quality Database</span></p>
<p><span class="font2">Terdapat tujuh variabel prediksi pada data tersebut ialah </span><span class="font2" style="font-style:italic;">&quot;pH&quot; &quot;Temprature&quot;, &quot;Taste&quot;, &quot;Odor&quot;, &quot;Fat &quot;, &quot;Turbidity&quot;,</span><span class="font2"> dan </span><span class="font2" style="font-style:italic;">&quot;Color&quot;</span><span class="font2">. Semua variabel tersebut memiliki perbedaan nilai. Terdapat nilai </span><span class="font2" style="font-style:italic;">count </span><span class="font2">(jumlah keseluruhan data dari variabel), </span><span class="font2" style="font-style:italic;">mean</span><span class="font2"> (nilai rata-rata keseluruhan per variabel), </span><span class="font2" style="font-style:italic;">std </span><span class="font2">(persebaran keseluruhan data dari variabel), </span><span class="font2" style="font-style:italic;">min</span><span class="font2"> (nilai terkecil dari variabel), 25% dari nilai dari per variabel, 50% dari nilai dari per variabel, 75% dari nilai dari per variabel, </span><span class="font2" style="font-style:italic;">max</span><span class="font2"> (nilai terbesar dari variabel. Berikut nilai variabel prediksi pada gambar 2.</span></p>
<table border="1">
<tr><td style="vertical-align:top;"></td><td style="vertical-align:top;">
<p><span class="font2">PH</span></p></td><td style="vertical-align:top;">
<p><span class="font5">Temprature</span></p></td><td style="vertical-align:top;">
<p><span class="font5">Taste</span></p></td><td style="vertical-align:top;">
<p><span class="font5">Odor</span></p></td><td style="vertical-align:top;">
<p><span class="font5">Fat</span></p></td><td style="vertical-align:top;">
<p><span class="font5">Turbidity</span></p></td><td style="vertical-align:top;">
<p><span class="font5">Colour</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">count</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">1059.000000</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">1059.000000</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">1059.000000</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">1059.000000</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">1059.000000</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">1059.000000</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">1059.000000</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">mean</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">6.630123</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">44.226629</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0.546742</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0.432483</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0.671388</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0.491029</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">251.840415</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">std</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">1.399679</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">10.098364</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0.498046</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0.495655</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0.469930</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0.500156</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">4.307424</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">min</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">3.000000</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">34.000000</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0.000000</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0.000000</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0.000000</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0.000000</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">240.000000</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font1">25%</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">6.500000</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">38.000000</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0.000000</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0.000000</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0.000000</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0.000000</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">250.000000</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">50%</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">6.700000</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">41.000000</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">1.000000</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0.000000</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">1.000000</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0.000000</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">255.000000</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">75%</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">6.800000</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">45.000000</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">1.000000</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">1.000000</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">1.000000</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">1.000000</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">255.000000</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0" style="font-weight:bold;">max</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">9.500000</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">90.000000</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">1.000000</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">1.000000</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">1.000000</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">1.000000</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">255.000000</span></p></td></tr>
</table>
<p><span class="font2" style="font-weight:bold;">Gambar 2. </span><span class="font2">Perbedaan Nilai Variabel Prediksi</span></p>
<p><span class="font2">Pada variabel </span><span class="font2" style="font-style:italic;">“Grade”</span><span class="font2"> sebagai variabel respon yang memiliki tiga kategori, yakni </span><span class="font2" style="font-style:italic;">“high”, “low”, “medium”</span><span class="font2">. Kemudian ditransformasi menjadi variabel numerik. Seperti pada tabel 1 di bawah ini.</span></p>
<p><span class="font2" style="font-weight:bold;">Tabel 1. </span><span class="font2">Perbedaan Nilai Variabel Prediksi</span></p>
<table border="1">
<tr><td style="vertical-align:bottom;">
<p><span class="font2">Kategori</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">Variabel</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2">high</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">0</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2">low</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">1</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font2">medium</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">2</span></p></td></tr>
</table>
<p><span class="font2">Dalam melakukan analisis klasifikasi data tersebut menggunakan </span><span class="font2" style="font-style:italic;">Google Collab</span><span class="font2"> dengan bahasa pemrograman </span><span class="font2" style="font-style:italic;">Python 3.x</span><span class="font2"> dengan format </span><span class="font2" style="font-style:italic;">ipynb</span><span class="font2">. Tahapan analisis yang dilakukan yakni:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font2">1. &nbsp;&nbsp;&nbsp;Melakukan eksplorasi data untuk mendapatkan gambaran umum pada data tersebut.</span></p></li>
<li>
<p><span class="font2">2. &nbsp;&nbsp;&nbsp;Membagi data tersebut menjadi data latih dan data uji.</span></p></li>
<li>
<p><span class="font2">3. &nbsp;&nbsp;&nbsp;Melakukan transformasi data yang menggunakan data tipe nominal menjadi tipe numerik</span></p></li>
<li>
<p><span class="font2">4. &nbsp;&nbsp;&nbsp;Melakukan klasifikasi </span><span class="font2" style="font-style:italic;">random forest</span><span class="font2"> pada data latih.</span></p></li>
<li>
<p><span class="font2">5. &nbsp;&nbsp;&nbsp;Melakukan prediksi kelas berdasarkan kategori variabel respon dengan data uji.</span></p></li>
<li>
<p><span class="font2">6. &nbsp;&nbsp;&nbsp;Mengevaluasi model klasifikasi dengan menghitung nilai akurasi.</span></p></li></ul>
<ul style="list-style:none;"><li>
<p><span class="font2" style="font-weight:bold;">2.2.</span><span class="font2" style="font-weight:bold;font-style:italic;"> &nbsp;&nbsp;&nbsp;Random Forest</span></p></li></ul>
<p><span class="font2">Metode </span><span class="font2" style="font-style:italic;">Random Forest</span><span class="font2"> menggunakan banyak pohon keputusan sebagai bagian dari teknik pembelajaran mesin. Salah satu algoritma pembelajaran mesin terbesar yang digunakan dalam beberapa disiplin ilmu, teknik ini baru-baru ini menunjukkan kemanjurannya dalam masalah regresi dan klasifikasi.[5] Pendekatan ini membagi jaringan menjadi </span><span class="font2" style="font-style:italic;">root node. internal node</span><span class="font2">, dan </span><span class="font2" style="font-style:italic;">leaf node</span><span class="font2"> dengan memilih kualitas dan data secara acak sesuai dengan hukum yang relevan. Simpul atas pohon keputusan, juga dikenal sebagai akar pohon keputusan, dikenal sebagai simpul akar. </span><span class="font2" style="font-style:italic;">Internal node</span><span class="font2"> adalah node percabangan yang hanya memiliki satu input dan satu atau lebih output. Simpul terakhir, yang dikenal sebagai simpul daun atau simpul terminal, hanya memiliki satu masukan dan tidak ada keluaran. Nilai </span><span class="font2" style="font-style:italic;">entropy</span><span class="font2"> pertama-tama dihitung oleh pohon keputusan untuk menentukan tingkat ketidakmurnian atribut dan pentingnya perolehan informasi. Rumus persamaan 1 digunakan untuk menghitung </span><span class="font2" style="font-style:italic;">entropy</span><span class="font2">, sedangkan rumus persamaan 2 digunakan untuk menghitung perolehan informasi.[6][7]</span></p>
<p><span class="font9" style="font-style:italic;">EntTOjjy </span><span class="font8" style="font-style:italic;">(</span><span class="font9" style="font-style:italic;">Y</span><span class="font8" style="font-style:italic;">) =</span><span class="font8"> - ∑ p (c|Y) i log2 p (c|Y)</span></p>
<div>
<p><span class="font8">(1)</span></p>
</div><br clear="all">
<p><span class="font2">Dimana Y merepresentasikan himpunan kasus dan p(c|Y) merepresentasikan proporsi nilai Y yang termasuk dalam kelas c.</span></p>
<div>
<h2><a name="bookmark7"></a><span class="font9" style="font-style:italic;"><a name="bookmark8"></a>I-nformatio-n Gain </span><span class="font8" style="font-style:italic;">(</span><span class="font9" style="font-style:italic;">Y</span><span class="font8" style="font-style:italic;">, </span><span class="font9" style="font-style:italic;">a) </span><span class="font8" style="font-style:italic;">= </span><span class="font9" style="font-style:italic;">Entropy </span><span class="font8" style="font-style:italic;">(</span><span class="font9" style="font-style:italic;">Y</span><span class="font8" style="font-style:italic;">) - ∑</span><span class="font9" style="font-style:italic;">veValues</span></h2>
</div><br clear="all">
<div>
<p><span class="font8" style="font-style:italic;text-decoration:underline;">IYvI</span></p>
<p><span class="font8" style="font-style:italic;">IYaI</span></p>
</div><br clear="all">
<div>
<h2><a name="bookmark9"></a><span class="font9" style="font-style:italic;"><a name="bookmark10"></a>Entropy </span><span class="font8" style="font-style:italic;">(</span><span class="font9" style="font-style:italic;">Yv</span><span class="font8" style="font-style:italic;">)</span></h2>
</div><br clear="all">
<div>
<p><span class="font8">(2)</span></p>
</div><br clear="all">
<p><span class="font2">Dimana Nilai (a) mewakili semua nilai yang mungkin dalam himpunan kasus a. Yv adalah </span><span class="font2" style="font-style:italic;">subclass</span><span class="font2"> dari Y, dengan kelas v setara dengan kelas a. Y,a semua nilai yang sesuai dengan a.</span></p>
<ul style="list-style:none;"><li>
<h3><a name="bookmark11"></a><span class="font2" style="font-weight:bold;"><a name="bookmark12"></a>2.3. &nbsp;&nbsp;&nbsp;Penerapan </span><span class="font2" style="font-weight:bold;font-style:italic;">Gain Ratio</span></h3></li></ul>
<p><span class="font2">Nilai </span><span class="font2" style="font-style:italic;">information gain</span><span class="font2"> terbesar dari atribut saat ini digunakan untuk memilih atribut sebagai </span><span class="font2" style="font-style:italic;">node</span><span class="font2">, baik akar (</span><span class="font2" style="font-style:italic;">root</span><span class="font2">) maupun </span><span class="font2" style="font-style:italic;">internal node</span><span class="font2">. Nilai gain ratio dihitung dengan membagi information gain dengan </span><span class="font2" style="font-style:italic;">split information</span><span class="font2">. Dimana </span><span class="font2" style="font-style:italic;">split information</span><span class="font2"> (S, A) adalah estimasi nilai entropi dari variabel input S dengan kelas c dan |Si|/|S| adalah probabilitas kelas i dari atribut tersebut.[6][8] Nilai </span><span class="font2" style="font-style:italic;">split information</span><span class="font2"> dan </span><span class="font2" style="font-style:italic;">gain ratio</span><span class="font2"> dapat dilihat pada persamaan 3 dan 4 sebagai berikut.</span></p>
<p><span class="font8">v </span><span class="font9">c</span><span class="font6">∣</span><span class="font8">Si</span><span class="font6">∣</span><span class="font8"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ISiI</span></p>
<h2><a name="bookmark13"></a><span class="font9" style="font-style:italic;"><a name="bookmark14"></a>S-plit Information </span><span class="font8" style="font-style:italic;">(</span><span class="font9" style="font-style:italic;">S</span><span class="font8" style="font-style:italic;">, </span><span class="font9" style="font-style:italic;">A</span><span class="font8" style="font-style:italic;">)</span><span class="font8"> = </span><span class="font10">∑ </span><span class="font9">j </span><span class="font8">— log2 —</span></h2>
<div>
<p><span class="font2">(3)</span></p>
</div><br clear="all">
<div>
<p><span class="font2">(4)</span></p>
</div><br clear="all">
<p><span class="font8">Information Gain </span><span class="font8" style="font-style:italic;">(S,A)</span></p>
<p><span class="font9" style="font-style:italic;">Gain Ratio </span><span class="font8" style="font-style:italic;">(</span><span class="font9" style="font-style:italic;">S</span><span class="font8" style="font-style:italic;">,</span><span class="font8"> A) = — -------------—-</span><span class="font8" style="font-style:italic;">Split Information (S,A)</span></p>
<ul style="list-style:none;"><li>
<h3><a name="bookmark15"></a><span class="font2" style="font-weight:bold;"><a name="bookmark16"></a>2.4. &nbsp;&nbsp;&nbsp;Confusion Matrix</span></h3></li></ul>
<p><span class="font2">Kinerja model klasifikasi pada kumpulan data testing dengan nilai sebenarnya yang diketahui sering digambarkan menggunakan </span><span class="font2" style="font-style:italic;">Confusion Multiclass Matrix.</span><span class="font2"> Tabel 2 di bawah ini menunjukkan persamaan </span><span class="font2" style="font-style:italic;">Confusion Multiclass Matrix.</span></p>
<p><span class="font2" style="font-weight:bold;">Tabel 2. </span><span class="font2" style="font-style:italic;">Confusion Multiclass Matrix</span></p>
<table border="1">
<tr><td rowspan="5" style="vertical-align:middle;">
<p><span class="font2">Actual</span></p></td><td colspan="4" style="vertical-align:bottom;">
<p><span class="font2">Predicted</span></p></td></tr>
<tr><td style="vertical-align:top;"></td><td style="vertical-align:bottom;">
<p><span class="font2">A</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">B</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">C</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2">A</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">TP</span><span class="font5">A</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2" style="font-variant:small-caps;">Eab</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2" style="font-variant:small-caps;">Eac</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2">B</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2" style="font-variant:small-caps;">Eba</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">TP</span><span class="font5">B</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2" style="font-variant:small-caps;">Ebc</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2">C</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2" style="font-variant:small-caps;">Eca</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2" style="font-variant:small-caps;">Ecb</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">TP</span><span class="font5">C</span></p></td></tr>
</table>
<p><span class="font2">Asumsikan pada tabel di atas bahwa terdapat kelas prediksi terdiri dari variabel A, B, dan C. </span><span class="font2" style="font-style:italic;">True Positive</span><span class="font2"> (TP): Ketika kita mengantisipasi ya dan nilai sebenarnya adalah benar. Confusion Multiclass Matrix berkembang dari </span><span class="font2" style="font-style:italic;">Confusion Biner Matrix</span><span class="font2">, yang sebelumnya menyertakan nilai </span><span class="font2" style="font-style:italic;">False Negative</span><span class="font2"> (FN), </span><span class="font2" style="font-style:italic;">False Positive</span><span class="font2"> (FP), dan </span><span class="font2" style="font-style:italic;">True Negative</span><span class="font2"> (TN). Pada </span><span class="font2" style="font-style:italic;">Confusion Multiclass Matrix,</span><span class="font2"> hanya TP yang disebutkan karna FN ditentukan oleh jumlah baris per variabel, sedangkan FP ditentukan oleh jumlah kolom per variabel, dan TN merupakan situasi ketika tak dapat ditafsir dan nilai aktual yang salah.[6]</span></p>
<ul style="list-style:none;"><li>
<h3><a name="bookmark17"></a><span class="font2" style="font-weight:bold;"><a name="bookmark18"></a>2.5. &nbsp;&nbsp;&nbsp;Perhitungan Akurasi dan Presisi</span></h3></li></ul>
<p><span class="font2">Melakukan perhitungan akurasi sesudah proses klasifikasi telah selesai yang bertujuan untuk menunjukan keakuratan dalam melakukan klasifikasi data terhadap data sebenarnya[6] dengan rumus pada persamaan 5 berikut ini.</span></p>
<div>
<h2><a name="bookmark19"></a><span class="font9" style="font-style:italic;"><a name="bookmark20"></a>Akurasi </span><span class="font8" style="font-style:italic;">=</span></h2>
</div><br clear="all">
<div>
<p><span class="font8">∑ data uji benar klasifikasi ∑ jumlah total data uji</span></p>
</div><br clear="all">
<div>
<h3><a name="bookmark21"></a><span class="font8" style="font-weight:bold;"><a name="bookmark22"></a>X 100</span></h3>
</div><br clear="all">
<div>
<p><span class="font2">(5)</span></p>
</div><br clear="all">
<p><span class="font2">Setelah menentukan tingkat akurasi, kemudian dilakukan perhitungan nilai presisi. Dimana dalam menentukan nilai presisi, terdapat tp adalah nilai </span><span class="font2" style="font-style:italic;">true positive</span><span class="font2"> dan fp adalah nilai </span><span class="font2" style="font-style:italic;">false negative</span><span class="font2">. Nilai tp sama untuk data latih (</span><span class="font2" style="font-style:italic;">predictive</span><span class="font2">) dan data uji (</span><span class="font2" style="font-style:italic;">reference</span><span class="font2">). Nilai tp + fp merupakan jumlah keseluruhan data uji.[6] Rumus untuk menghitung nilai presisi sebagai berikut pada persamaan 6.</span></p>
<p><span class="font8">tp </span><span class="font9" style="font-style:italic;">precision</span><span class="font8"> =---— X 100%</span></p>
<div>
<p><span class="font2">(6)</span></p>
</div><br clear="all">
<p><span class="font8">tp+fp</span></p>
<ul style="list-style:none;"><li>
<p><span class="font2" style="font-weight:bold;">2.6. &nbsp;&nbsp;&nbsp;ROC (</span><span class="font2" style="font-weight:bold;font-style:italic;">Receiver Operating Characteristic</span><span class="font2" style="font-weight:bold;">)</span></p></li></ul>
<p><span class="font2">ROC melakukan perbandingan klasifikasi serta menampilkan akurasi secara grafis dengan garis kurva, yang mengekspresikan </span><span class="font2" style="font-style:italic;">Confusion matrix</span><span class="font2">. ROC merupakan grafik dua dimensi dengan garis horizontal mewakili </span><span class="font2" style="font-style:italic;">false positives</span><span class="font2"> dan </span><span class="font2" style="font-style:italic;">true positive</span><span class="font2"> mewakili garis vertikal.[6][9][10] Angka-angka yang ditunjukkan pada kurva adalah nilai </span><span class="font2" style="font-style:italic;">True Positive Rate</span><span class="font2"> (TPR) dan </span><span class="font2" style="font-style:italic;">False Positive Rate </span><span class="font2">(FPR), yang dapat dihitung sebagai berikut menggunakan persamaan 7 dan 8 sebagai berikut.</span></p>
<p><span class="font8">tp TPR = —— tp+fp</span></p>
<div>
<p><span class="font3">(7)</span></p>
<p><span class="font3">(8)</span></p>
</div><br clear="all">
<div>
<p><span class="font8">FPR </span><span class="font7">=</span></p>
</div><br clear="all">
<div>
<p><span class="font8" style="text-decoration:underline;">fp </span><span class="font8">tp+fp</span></p>
</div><br clear="all">
<ul style="list-style:none;"><li>
<h3><a name="bookmark23"></a><span class="font2" style="font-weight:bold;"><a name="bookmark24"></a>3. &nbsp;&nbsp;&nbsp;Hasil dan Diskusi</span></h3></li></ul>
<p><span class="font2">Pada pembahasan mengenai hasil dari penelitian tersebut berdasarkan data yang didapatkan sebanyak 1059 data telah diidentifikasi, mendapatkan bahwa variabel respon (</span><span class="font2" style="font-style:italic;">label</span><span class="font2">) pada kategori </span><span class="font2" style="font-style:italic;">“Grade”</span><span class="font2"> yaitu high berjumlah 256 data, low berjumlah 429 data, dan medium berjumlah 374 data. Berikut hasilnya pada gambar 3.</span></p><img src="https://jurnal.harianregional.com/media/92554-1.jpg" alt="" style="width:242pt;height:164pt;">
<p><span class="font2" style="font-weight:bold;">Gambar 3. </span><span class="font2">Perhitungan jumlah data tiap Grade</span></p>
<p><span class="font2">Pada nilai korelasi matriks antara </span><span class="font2" style="font-style:italic;">Grade</span><span class="font2"> dengan nilai pengukuran pada kadar susu sapi menunjukan bahwa korelasi pada masing-masing variabel ada yang memiliki nilai tertinggi dan terendah. Pada nilai tertinggi yaitu korelasi antara “</span><span class="font2" style="font-style:italic;">Odor</span><span class="font2">” dengan “</span><span class="font2" style="font-style:italic;">Turbidity</span><span class="font2">” sebesar 0.46. sedangkan pada nilai terendah yaitu korelasi antara “</span><span class="font2" style="font-style:italic;">pH</span><span class="font2">” dengan “</span><span class="font2" style="font-style:italic;">Colour</span><span class="font2">” sebesar -0.16. Berikut hasil keseluruhan korelasi matriks pada gambar 4.</span></p><img src="https://jurnal.harianregional.com/media/92554-2.jpg" alt="" style="width:268pt;height:201pt;">
<ul style="list-style:none;"><li>
<p><span class="font2" style="font-weight:bold;">Gambar 4. </span><span class="font2">Matriks Korelasi Grade dengan Nilai Kadar pada Kandungan Susu</span></p></li></ul>
<p><span class="font2">Kemudian pembagian data yang dilakukan dengan perbandingan 70% data latih (</span><span class="font2" style="font-style:italic;">training</span><span class="font2">) dan juga 30% data uji (</span><span class="font2" style="font-style:italic;">testing</span><span class="font2">). Selanjutnya dilakukan klasifikasi dengan Algoritma </span><span class="font2" style="font-style:italic;">Random Forest </span><span class="font2">dengan data yang telah dibagi, maka nilai yang dihasilkan berupa </span><span class="font2" style="font-style:italic;">precision, recall,</span><span class="font2"> dan </span><span class="font2" style="font-style:italic;">f1-score </span><span class="font2">dari setiap variabel bernilai sama sebesar 98% dengan nilai akurasi juga mencapai 98%. Berikut data nilai yang dihasilkan pada tabel 3.</span></p>
<p><span class="font2" style="font-weight:bold;">Tabel 3. </span><span class="font2">Hasil </span><span class="font2" style="font-style:italic;">Accuracy, Precision, Recall, F1-score</span></p>
<table border="1">
<tr><td style="vertical-align:top;"></td><td style="vertical-align:middle;">
<p><span class="font2" style="font-weight:bold;font-style:italic;">Precision</span></p></td><td style="vertical-align:middle;">
<p><span class="font2" style="font-weight:bold;font-style:italic;">Recall</span></p></td><td style="vertical-align:middle;">
<p><span class="font2" style="font-weight:bold;font-style:italic;">F1-Score</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font2">0</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">0.97</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">0.98</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">0.98</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font2">1</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">1.00</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">0.97</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">0.98</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font2">2</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">0.98</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">1.00</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">0.99</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2">Avg</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">0.98</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">0.98</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">0.98</span></p></td></tr>
<tr><td colspan="3" style="vertical-align:bottom;">
<p><span class="font2" style="font-weight:bold;font-style:italic;">Accuracy</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">0.98</span></p></td></tr>
</table>
<p><span class="font2">Pada perhitungan akurasi yang lain menggunakan </span><span class="font2" style="font-style:italic;">Confusion Matrix</span><span class="font2"> pada tiga kelas prediksi yaitu variabel 0 (</span><span class="font2" style="font-style:italic;">high</span><span class="font2">), 1 (</span><span class="font2" style="font-style:italic;">low</span><span class="font2">) dan 2 (</span><span class="font2" style="font-style:italic;">medium</span><span class="font2">) dengan membandingkan dari segi </span><span class="font2" style="font-style:italic;">Predicted</span><span class="font2"> dan </span><span class="font2" style="font-style:italic;">Actual</span><span class="font2">.</span></p>
<p><span class="font2">Pada variabel 0 sebesar 85, variabel 1 sebesar 113, dan variabel 2 sebesar 116. Berikut hasilnya ditampilkan pada Tabel 4 .</span></p>
<p><span class="font2" style="font-weight:bold;">Tabel 4. </span><span class="font2" style="font-style:italic;">Confusion Matrix</span><span class="font2"> data</span></p>
<table border="1">
<tr><td rowspan="5" style="vertical-align:middle;">
<p><span class="font2" style="font-weight:bold;font-style:italic;">Actual</span></p></td><td colspan="4" style="vertical-align:bottom;">
<p><span class="font2" style="font-weight:bold;font-style:italic;">Predicted</span></p></td></tr>
<tr><td style="vertical-align:top;"></td><td style="vertical-align:bottom;">
<p><span class="font2">0</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">1</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">2</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2">0</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">85</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">0</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">1</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2">1</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">2</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">113</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">1</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2">2</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">0</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">0</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">116</span></p></td></tr>
</table>
<p><span class="font2">Adapun pengujian yang menggunakan ROC </span><span class="font2" style="font-style:italic;">Curve</span><span class="font2"> untuk menampilkan akurasi secara visual pada setiap kelas kategori dari model yang dihasilkan sangat memuaskan. Pada gambar terdapat sebuah garis putus-putus sebagai acuan (</span><span class="font2" style="font-style:italic;">baseline</span><span class="font2">) jika semakin besar jarak antara garis-garis tersebut tehadap acuannya maka semakin baik tingkat prediksi. Tiga garis kurva berwarna digunakan untuk mewakili setiap kategori (</span><span class="font2" style="font-style:italic;">class</span><span class="font2">) sebagai variabel respon. Dimana garis biru menunjukkan kurva ROC </span><span class="font2" style="font-style:italic;">“high”</span><span class="font2"> dengan tingkat prediksi AUC sebesar 0.9999, garis orange menunjukkan kurva ROC </span><span class="font2" style="font-style:italic;">“low”</span><span class="font2"> dengan tingkat prediksi AUC sebesar 0.999701, dan garis hijau menunjukkan kurva ROC </span><span class="font2" style="font-style:italic;">“medium”</span><span class="font2"> dengan tingkat prediksi AUC sebesar 1.00 berarti memiliki tingkat prediksi yang teritinggi. Meskipun dibandingkan dengan </span><span class="font2" style="font-style:italic;">class</span><span class="font2"> lainnya tidak memiliki perbedaan yang signifikan. Berikut hasil ROC pada gambar 5.</span></p><img src="https://jurnal.harianregional.com/media/92554-3.jpg" alt="" style="width:319pt;height:159pt;">
<p><span class="font1">LO</span></p>
<p><span class="font0" style="font-weight:bold;">0.6</span></p>
<p><span class="font0" style="font-weight:bold;">0.8</span></p>
<p><span class="font0" style="font-weight:bold;">False Positive Rate</span></p>
<p><span class="font0" style="font-weight:bold;">14</span></p>
<p><span class="font0" style="font-weight:bold;">ROC Curve of high (AUC=O 999900)</span></p>
<p><span class="font0" style="font-weight:bold;">ROC Curve of low (AUC=0.999701)</span></p>
<p><span class="font0" style="font-weight:bold;">ROC Curve of medium (AUC=1.000000)</span></p>
<p><span class="font2" style="font-weight:bold;">Gambar 5. </span><span class="font2">Kurva ROC dari dataset</span></p>
<ul style="list-style:none;"><li>
<h3><a name="bookmark25"></a><span class="font2" style="font-weight:bold;"><a name="bookmark26"></a>4. Kesimpulan</span></h3></li></ul>
<p><span class="font2">Berdasarkan hasil percobaan yang telah dilakukan, maka diperoleh tingkat akurasi pada klasifikasi dengan algoritma </span><span class="font2" style="font-style:italic;">Random Forest</span><span class="font2"> sebesar 98%. Pada pengujian </span><span class="font2" style="font-style:italic;">precision, recall,</span><span class="font2"> dan </span><span class="font2" style="font-style:italic;">f1-score</span><span class="font2"> yang dihasilkan dari setiap variabel bernilai sama sebesar 98%. kemudian tingkat akurasi variabel respon yang tertinggi terdapat pada kategori “medium” dengan AUC sebesar 1.00, meskipun perbedaan hasil akurasi dengan kategori yang lainnya tidak berbeda cukup jauh. Maka dari itu algoritma </span><span class="font2" style="font-style:italic;">Random Forest</span><span class="font2"> sangat cocok untuk digunakan dalam melakukan klasifikasi pada data kualitas susu sapi.</span></p>
<h3><a name="bookmark27"></a><span class="font2" style="font-weight:bold;"><a name="bookmark28"></a>Referensi</span></h3>
<ul style="list-style:none;"><li>
<p><span class="font2">[1] &nbsp;&nbsp;&nbsp;E. Situmorang, “Studi Perbandingan Kandungan Kalsium dan Fosfor dalam Susu Kambing Etawa Murni dan Susu Kambing Etawa Kemasan,” Thesis, Universitas Sumatera Utara, 2019. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Accessed: &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Oct. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;19, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2022. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[Online]. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Available:</span></p></li></ul>
<p><a href="https://repositori.usu.ac.id/handle/123456789/24643"><span class="font2">https://repositori.usu.ac.id/handle/123456789/24643</span></a></p>
<ul style="list-style:none;"><li>
<p><span class="font2">[2] &nbsp;&nbsp;&nbsp;A. Wanto </span><span class="font2" style="font-style:italic;">et al.</span><span class="font2">, </span><span class="font2" style="font-style:italic;">Data Mining: Algoritma dan Implementasi</span><span class="font2">. Yayasan Kita Menulis, 2020.</span></p></li>
<li>
<p><span class="font2">[3] &nbsp;&nbsp;&nbsp;A. Damuri, U. Riyanto, H. Rusdianto, and M. Aminudin, “Implementasi Data Mining dengan Algoritma Naïve Bayes Untuk Klasifikasi Kelayakan Penerima Bantuan Sembako,” </span><span class="font2" style="font-style:italic;">JURIKOM J. Ris. Komput.</span><span class="font2">, vol. 8, no. 6, Art. no. 6, Dec. 2021, doi: 10.30865/jurikom.v8i6.3655.</span></p></li>
<li>
<p><span class="font2">[4] &nbsp;&nbsp;&nbsp;A. Ramadhan, B. Susetyo, and Indahwati, “PENERAPAN METODE KLASIFIKASI </span><span class="font2" style="font-style:italic;">RANDOM FOREST</span><span class="font2"> DALAM MENGIDENTIFIKASI FAKTOR PENTING PENILAIAN MUTU PENDIDIKAN,” </span><span class="font2" style="font-style:italic;">J. Pendidik. Dan Kebud.</span><span class="font2">, vol. 4, no. 2, pp. 169–182, Dec. 2019, doi: 10.24832/jpnk.v4i2.1327.</span></p></li>
<li>
<p><span class="font2">[5] &nbsp;&nbsp;&nbsp;W. Apriliah, I. Kurniawan, M. Baydhowi, and T. Haryati, “Prediksi Kemungkinan Diabetes pada Tahap Awal Menggunakan Algoritma Klasifikasi </span><span class="font2" style="font-style:italic;">Random Forest</span><span class="font2">,” </span><span class="font2" style="font-style:italic;">SISTEMASI</span><span class="font2">, vol. 10, no. 1, p. 163, Jan. 2021, doi: 10.32520/stmsi.v10i1.1129.</span></p></li>
<li>
<p><span class="font2">[6] &nbsp;&nbsp;&nbsp;V. W. Siburian and I. E. Mulyana, “Prediksi Harga Ponsel Menggunakan Metode </span><span class="font2" style="font-style:italic;">Random Forest</span><span class="font2">,” p. 4, 2018.</span></p></li>
<li>
<p><span class="font2">[7] &nbsp;&nbsp;&nbsp;N. L. W. S. R. Ginantra </span><span class="font2" style="font-style:italic;">et al.</span><span class="font2">, </span><span class="font2" style="font-style:italic;">Data Mining dan Penerapan Algoritma</span><span class="font2">. Yayasan Kita Menulis, 2021.</span></p></li>
<li>
<p><span class="font2">[8] &nbsp;&nbsp;&nbsp;R. C. Barros, A. C. P. L. F. de Carvalho, and A. A. Freitas, </span><span class="font2" style="font-style:italic;">Automatic Design of DecisionTree Induction Algorithms</span><span class="font2">. Springer, 2015.</span></p></li>
<li>
<p><span class="font2">[9] &nbsp;&nbsp;&nbsp;C. Vercellis, </span><span class="font2" style="font-style:italic;">Business Intelligence: Data Mining and Optimization for Decision Making</span><span class="font2">. John Wiley &amp;&nbsp;Sons, 2011.</span></p></li>
<li>
<p><span class="font2">[10] &nbsp;&nbsp;&nbsp;A. Amrin, “Perbandingan Metode Neural Network Model Radial Basis Function Dan Multilayer Perceptron Untuk Analisa Risiko Kredit Mobil,” </span><span class="font2" style="font-style:italic;">Paradigma</span><span class="font2">, vol. 20, no. 1, Art. no. 1, Apr. 2018, doi: 10.31294/p.v20i1.2783.</span></p></li></ul>
<p><span class="font9">halaman ini sengaja dibiarkan kosong</span></p>
<p><span class="font7">8</span></p>