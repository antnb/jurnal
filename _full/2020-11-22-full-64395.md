---
layout: full_article
title: "The Effects of Different Kernels in SVM Sentiment Analysis on Mass Social Distancing"
author: "Komang Dhiyo Yonatha Wijaya, Anak Agung Istri Ngurah Eka Karyawati"
categories: jik
canonical_url: https://jurnal.harianregional.com/jik/full-64395 
citation_abstract_html_url: "https://jurnal.harianregional.com/jik/id-64395"
citation_pdf_url: "https://jurnal.harianregional.com/jik/full-64395"  
comments: true
---

<p><span class="font1">p-ISSN: 2301-5373</span></p>
<p><span class="font1">e-ISSN: 2654-5101</span></p>
<p><span class="font1">Jurnal Elektronik Ilmu Komputer Udayana</span></p>
<p><span class="font1">Volume 9 No. 2, November 2020</span></p><a name="caption1"></a>
<h1><a name="bookmark0"></a><span class="font2" style="font-weight:bold;"><a name="bookmark1"></a>The Effects of Different Kernels in SVM Sentiment Analysis on Mass Social Distancing</span></h1>
<p><span class="font1">Komang Dhiyo Yonatha Wijaya<sup>a1</sup></span><span class="font1" style="font-weight:bold;">, </span><span class="font1">AAIN Eka Karyawati<sup>a2</sup></span></p>
<p><span class="font1"><sup>a</sup>Informatics Department, Faculty of Math and Science, Udayana University Bali, Indonesia </span><a href="mailto:1komangdhiyo66@gmail.com"><span class="font1"><sup>1</sup>komangdhiyo66@gmail.com</span></a><span class="font1"> </span><a href="mailto:2eka.karyawati@unud.ac.id"><span class="font1"><sup>2</sup>eka.karyawati@unud.ac.id</span></a></p>
<p><span class="font1" style="font-weight:bold;font-style:italic;">Abstract</span></p>
<p><span class="font1" style="font-style:italic;">During this pandemic, social media has become a major need as a means of communication. One of the social medias used is Twitter by using messages referred to as tweets. Indonesia currently undergoing mass social distancing. During this time most people use social media in order to spend their idle time However, sometimes, this result in negative sentiment that used to insult and aimed at an individual or group. To filter that kind of tweets, a sentiment analysis was performed with SVM and 3 different kernel method. Tweets are labelled into 3 classes of positive, neutral, and negative. The experiments are conducted to determine which kernel is better. From the sentiment analysis that has been performed, SVM linear kernel yield the best score Some experiments show that the precision of linear kernel is 57%, recall is 50%, and f-measure is 44%.</span></p>
<p><span class="font1" style="font-weight:bold;font-style:italic;">Keywords: </span><span class="font1" style="font-style:italic;">Sentiment Analysis, Tweet, SVM, Indonesia, Kernel</span></p>
<ul style="list-style:none;"><li>
<h4><a name="bookmark2"></a><span class="font1" style="font-weight:bold;"><a name="bookmark3"></a>1. &nbsp;&nbsp;&nbsp;Introduction</span></h4></li></ul>
<p><span class="font1">The need for social media has become part of Indonesian society. Moreover, in present that the current Covid-19 pandemic happen where social media are used as the main means to communicate due to social restrictions to prevent the spread of viruses. One of the social medias that used is the Twitter where users communicate using tweet as a message. This message can be used to see people thoughts about mass social distancing to further improve the quality of mass social distancing.</span></p>
<p><span class="font1">To find out the sentiment of the tweet whether it is positive, neutral, or negative can be done by applying sentiment analysis to the tweet. Sentiment analysis is a field of science that analyzes opinions, attitudes, evaluations, and assessments of an event, topic, organization, or individual [4]. In sentiment analysis we can use machine learning such as suport vector machine (SVM). Using the SVM method, researcher analyzed the sentiment to determine the sentiment of the tweet which can be positive, neutral, or negative sentiment. To find out how the performance of the sentiment analysis is performed, the scores of precision, recall, and f-measure are used as the performance values of the analysis.</span></p>
<p><span class="font1">The example of machine-learning-based sentiment analysis is a research carried out by [7]. The research conduct a study about classification using Naïve Bayes method of snack review and the performance in their research is 80.5% for the average accuracy score. Research of SVM have been carried out by[3]. The research conducted a study about text classification using SVM with multiple different kernel such as sigmoid, polynomial, rbf and linear. In their research Linear Kernel SVM have the best accuracy with 92.4381% score. The other research conducted a study carried by[6]. The research conducted a study about comparing RBF and linear kernel SVM in spam classification. In their research have the best accuracy with 96.6% score</span></p>
<p><span class="font1">Based on existing problems and related studies this research is conducted to compare the evaluation results (Precision, Recall and F-Measure) of three different kernel function of</span></p>
<div>
<p><span class="font1">SVM method. The three-kernel and RBF kernel function.</span></p>
</div><br clear="all">
<p><span class="font1">function are polynomial kernel function, linear kernel function,</span></p>
<ul style="list-style:none;"><li>
<h4><a name="bookmark4"></a><span class="font1" style="font-weight:bold;"><a name="bookmark5"></a>2. &nbsp;&nbsp;&nbsp;Research Method</span><br><br><span class="font1" style="font-weight:bold;"><a name="bookmark6"></a>2.1 &nbsp;&nbsp;&nbsp;Research Stage</span></h4></li></ul>
<p><span class="font1">The research is divided into several stages. These stages are the data gathering stage, the preprocessing stage, the sentiment analysis stage with SVM method, and the results evaluation phase. Here is the flowchart that show how the flow of the research done.</span></p>
<div><img src="https://jurnal.harianregional.com/media/64395-1.jpg" alt="" style="width:380pt;height:199pt;">
<p><span class="font1" style="font-weight:bold;">Figure 1. </span><span class="font1">Research Stage</span></p>
</div><br clear="all">
<ul style="list-style:none;"><li>
<h4><a name="bookmark7"></a><span class="font1" style="font-weight:bold;"><a name="bookmark8"></a>2.2 &nbsp;&nbsp;&nbsp;Data Gathering</span></h4></li></ul>
<p><span class="font1">The data that being used is an indonesian tweet data. Data gathering is done using the Twitter API and tweepy library in Python. Data searching are performed by searching for specific words such as “PSBB” and “COVID-19” and filtering for retweets. The amount of the data that have been gathered is 300. The data is divided into 3 classes namely positive data, neutral data and negative data with the amount of data as much as 100 data each.</span></p>
<ul style="list-style:none;"><li>
<h4><a name="bookmark9"></a><span class="font1" style="font-weight:bold;"><a name="bookmark10"></a>2.3 &nbsp;&nbsp;&nbsp;Preprocessing</span></h4></li></ul>
<p><span class="font1">Preprocessing is a process to convert data that still does not have a meaning into data that has meaning and can be processed. The preprocessing stage is done to make the data &quot;clean&quot; so that errors in data processing can be reduced and make the process more efficient. Here are the flowchart that show how the stages in preprocessing.</span></p><img src="https://jurnal.harianregional.com/media/64395-2.jpg" alt="" style="width:346pt;height:260pt;">
<p><span class="font1" style="font-weight:bold;">Figure 2. </span><span class="font1">Preprocessing</span></p>
<p><span class="font1">Casefolding is a process to create the same form of data that contains only lowercase letters. Casefolding is done so that the existing data is equal. Stopword removal is a process for removing words that are very commonly used and have no meaning in performing sentiment analysis. Stopword removal is done to make the process run more efficiently. Stemming is the process of removing the prefix or suffix in the data so that it turns into a basic form. Stemming is done to equate data that has different writing. Tokenization is the process for creating tokens from the initial data. Tokens are a smaller part of the initial data. In this tokenization process also carried out the calculation of the number of words on the tweet which will be used in the process of sentiment analysis with SVM[5].</span></p>
<ul style="list-style:none;"><li>
<h4><a name="bookmark11"></a><span class="font1" style="font-weight:bold;"><a name="bookmark12"></a>2.4 &nbsp;&nbsp;&nbsp;TF-IDF</span></h4></li></ul>
<p><span class="font1">Term Frequency-Inverse Document Frequency (TF-IDF)is a method that is used to calculate the weight of extracted word. TF-IDF commonly used to find the common word in a document. TF-IDF is a method that integrate term frequency (TF), and inversed Document frequency model. Term frequency is used to calculate the appearance of term in one document, inversed document frequency (IDF) is used to calculate the appearance of terms in multiple document that is deemed as unimportant [5]. The stages of TF-IDF are as follows.</span></p>
<div>
<p><span class="font1" style="font-weight:bold;">2.5</span></p>
</div><br clear="all">
<div><img src="https://jurnal.harianregional.com/media/64395-3.jpg" alt="" style="width:296pt;height:192pt;">
<p><span class="font1" style="font-weight:bold;">Figure 3. </span><span class="font1">TF-IDF</span></p>
</div><br clear="all">
<div>
<p><span class="font1">a. Calculate term frequency (tft,d)</span></p>
</div><br clear="all">
<div>
<ul style="list-style:none;"><li>
<p><span class="font1">b. &nbsp;&nbsp;&nbsp;Calculate weighting term frequency (Wtf)</span></p></li></ul>
<h2><a name="bookmark13"></a><span class="font6" style="font-style:italic;"><a name="bookmark14"></a>_ f</span><span class="font6"> 1 + log </span><span class="font6" style="font-style:italic;">tft, d, jika tft, d &gt;&nbsp;0</span></h2>
<h3><a name="bookmark15"></a><span class="font6" style="font-style:italic;"><sup><a name="bookmark16"></a>Wt</sup></span><span class="font5" style="font-style:italic;">f</span><span class="font6"> = </span><span class="font7">{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="font6">0,</span></h3>
<ul style="list-style:none;"><li>
<p><span class="font1">c. &nbsp;&nbsp;&nbsp;Calculate document frequency (df)</span></p></li></ul>
</div><br clear="all">
<div>
<p><span class="font1">d. Calculate weight of inverse document frequency (idf)</span></p>
</div><br clear="all">
<div>
<h3><a name="bookmark17"></a><span class="font6" style="font-style:italic;"><sup><a name="bookmark18"></a>idf</sup></span><span class="font5" style="font-style:italic;">t</span><span class="font6"> = <sup>lo</sup>⅛</span></h3>
</div><br clear="all">
<div>
<p><span class="font1">e. Calculate weight of TF-IDF</span></p>
</div><br clear="all">
<div>
<p><span class="font6"><sup>w</sup></span><span class="font5">t,d </span><span class="font6">= </span><span class="font6" style="font-style:italic;"><sup>w</sup></span><span class="font5" style="font-style:italic;">tf</span><span class="font4" style="font-style:italic;">t,d</span><span class="font6"> × </span><span class="font6" style="font-style:italic;"><sup>id</sup>f</span><span class="font5" style="font-style:italic;">t</span></p>
<p><span class="font1">Description :</span></p>
<p><span class="font1">tft,d = term frequency</span></p>
<p><span class="font6" style="font-style:italic;">Wtf t</span><span class="font1" style="font-style:italic;">,</span><span class="font6" style="font-style:italic;">d</span><span class="font1"> = weight of term frequency df = document frequency of term N = total number of documents</span></p>
</div><br clear="all">
<div>
<p><span class="font6">Wt</span><span class="font1">,</span><span class="font6">d </span><span class="font1">= weight TF-IDF</span></p>
</div><br clear="all">
<div>
<p><span class="font1">(1)</span></p>
<p><span class="font1">(2)</span></p>
<p><span class="font1">(3)</span></p>
</div><br clear="all">
<div>
<h4><a name="bookmark19"></a><span class="font1" style="font-weight:bold;"><a name="bookmark20"></a>Support Vector Machine (SVM) Algorithm</span></h4>
<p><span class="font1">SVM is a linear classification method. SVM's main role in classifying is to define a separator in the search space that can separate different classes. This separator is commonly referred to as a hyperplane. One of the advantages of this SVM method is that it is quite good at classifying high-dimensional data because the method tries to determine the optimal direction of discrimination in the feature space by examining the right feature combination [1]. The stages of sentiment analysis with SVM are as follows.</span></p>
</div><br clear="all"><img src="https://jurnal.harianregional.com/media/64395-4.jpg" alt="" style="width:307pt;height:272pt;">
<p><span class="font1" style="font-weight:bold;">Figure 4. </span><span class="font1">SVM</span></p>
<p><span class="font1">In determining the outcome of a decision, the SVM method uses kernel functions. The SVM kernels used in this study are polynomial, linear and RBF kernels with the following functional equations[2].</span></p>
<p><span class="font1">Polynomial Kernel</span></p>
<p><a href="#bookmark21"><span class="font1" style="font-style:italic;">K (X</span><span class="font0" style="font-style:italic;">i</span><span class="font1" style="font-style:italic;">, X</span><span class="font0" style="font-style:italic;">j</span><span class="font1" style="font-style:italic;">)</span><span class="font1"> = </span><span class="font6" style="font-style:italic;">(χTχ<sub>j</sub></span><span class="font6"> + </span><span class="font6" style="font-style:italic;">C)</span><span class="font1">(4)</span></a></p>
<p><span class="font1">Linear Kernel</span></p>
<p><a href="#bookmark22"><span class="font6" style="font-style:italic;">K (X</span><span class="font4" style="font-style:italic;">t<sub>l</sub></span><span class="font6" style="font-style:italic;">X</span><span class="font4" style="font-style:italic;">j</span><span class="font6" style="font-style:italic;">) = χ</span><span class="font4" style="font-style:italic;">{</span><span class="font6" style="font-style:italic;">χ</span><span class="font4" style="font-style:italic;">j</span><span class="font1">(5)</span></a></p>
<p><span class="font1">RBF Kernel</span></p>
<p><a href="#bookmark23"><span class="font6" style="font-style:italic;">K (x</span><span class="font4" style="font-style:italic;">t</span><span class="font3" style="font-style:italic;">∣</span><span class="font6" style="font-style:italic;">X</span><span class="font4" style="font-style:italic;">j</span><span class="font6" style="font-style:italic;">) = eχp(-γ</span><span class="font3" style="font-style:italic;">∣</span><span class="font6" style="font-style:italic;">χ<sub>i</sub>-χ</span><span class="font4" style="font-style:italic;">j</span><span class="font3" style="font-style:italic;">∣</span><span class="font4" style="font-style:italic;">2</span><span class="font6" style="font-style:italic;">),γ</span><span class="font6"> &gt;&nbsp;0</span></a></p>
<p><span class="font1">The steps in using the SVM method are as follows:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1">a. &nbsp;&nbsp;&nbsp;Train the weighted data using </span><span class="font1" style="font-style:italic;">Sequential Training</span><span class="font1"> SVM</span></p></li>
<li>
<p><span class="font1">b. &nbsp;&nbsp;&nbsp;Initiate parameter that will be used seperti αi, λ</span><span class="font0">, </span><span class="font1">γ, C, dan ε.</span></p></li>
<li>
<p><span class="font1">c. &nbsp;&nbsp;&nbsp;Calculate the hessian matrix using following equiation :</span></p></li></ul>
<p><a href="#bookmark24"><span class="font1" style="font-style:italic;">D</span><span class="font0" style="font-style:italic;">ij </span><span class="font1" style="font-style:italic;">= </span><span class="font6" style="font-style:italic;">V</span><span class="font4" style="font-style:italic;">i</span><span class="font6" style="font-style:italic;">J</span><span class="font4" style="font-style:italic;">j </span><span class="font6" style="font-style:italic;">(K (χ<sub>l</sub></span><span class="font3" style="font-style:italic;">∣</span><span class="font6" style="font-style:italic;"> χ</span><span class="font4" style="font-style:italic;">j</span><span class="font6" style="font-style:italic;">)</span><span class="font6"> + λ<sup>2</sup>)</span></a></p>
<ul style="list-style:none;"><li>
<p><span class="font1">d. &nbsp;&nbsp;&nbsp;Starting from the 1st data to the nth data, perform the calculation iteration of the following equation[2].</span></p></li></ul>
<p><a href="#bookmark25"><span class="font6" style="font-style:italic;">Ei = ∑‰a<sub>j</sub>D<sub>lj</sub></span><span class="font1">(8)</span></a></p>
<p><a href="#bookmark26"><span class="font1" style="font-style:italic;">δαi</span><span class="font1"> = </span><span class="font6" style="font-style:italic;">min{max[γ(1 - Ei)</span><span class="font3" style="font-style:italic;">∣</span><span class="font6" style="font-style:italic;">-a<sub>i</sub>] </span><span class="font3" style="font-style:italic;">∣</span><span class="font6" style="font-style:italic;">C - a<sub>i</sub>)</span><span class="font1">(9)</span></a></p>
<p><a href="#bookmark27"><span class="font1" style="font-style:italic;">α</span><span class="font0" style="font-style:italic;">i</span><span class="font1"> = </span><span class="font6" style="font-style:italic;">^</span><span class="font4" style="font-style:italic;">t </span><span class="font6" style="font-style:italic;">+ δ⅞</span><span class="font4" style="font-style:italic;">t</span><span class="font1">(10)</span></a></p>
<ul style="list-style:none;"><li>
<p><span class="font1">e. &nbsp;&nbsp;&nbsp;From previous calculations, the largest </span><span class="font1" style="font-style:italic;">α</span><span class="font0" style="font-style:italic;">i</span><span class="font1"> value is sought and calculations are carried out to determine the bias using the following equation[2].</span></p></li></ul>
<p><a href="#bookmark28"><span class="font1" style="font-style:italic;">b = </span><span class="font6" style="font-style:italic;">—</span><span class="font4" style="font-style:italic;">1 </span><span class="font6" style="font-style:italic;">[(∑</span><span class="font4" style="font-style:italic;">f=</span><span class="font6" style="font-style:italic;"><sub>1</sub>a</span><span class="font4" style="font-style:italic;">t</span><span class="font6" style="font-style:italic;">y</span><span class="font4" style="font-style:italic;">t </span><span class="font6" style="font-style:italic;">K(χ</span><span class="font4" style="font-style:italic;">t</span><span class="font6" style="font-style:italic;">,χ<sup>-</sup>)) + (∑</span><span class="font4" style="font-style:italic;">tL</span><span class="font6" style="font-style:italic;"><sub>1</sub>a</span><span class="font4" style="font-style:italic;">t</span><span class="font6" style="font-style:italic;">y</span><span class="font4" style="font-style:italic;">i </span><span class="font6" style="font-style:italic;">K(χ</span><span class="font4" style="font-style:italic;">t</span><span class="font6" style="font-style:italic;">,χ<sup>+</sup>))]</span><span class="font1">(11)</span></a></p>
<ul style="list-style:none;"><li>
<p><span class="font1">f. &nbsp;&nbsp;&nbsp;To find out the results of the classification, testing is performed using the calculation function f(x). Function f(x) is obtained from the following equation[2].</span></p></li></ul>
<p><span class="font1" style="font-style:italic;">f(x) = </span><span class="font6" style="font-style:italic;">∑<sup>n</sup>=<sub>0</sub>a<sub>l</sub>y<sub>l</sub>K{x<sub>l</sub>,x<sup>-</sup>) + b</span><span class="font1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(12)</span></p>
<p><span class="font1">Variabel Description:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1">α</span><span class="font0">i &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="font1">= alfa, to find a vector support</span></p></li>
<li>
<p><span class="font1">γ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;= gamma, to control learning rate speed</span></p></li></ul>
<p><span class="font1" style="font-style:italic;">C</span><span class="font1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;= variabel </span><span class="font1" style="font-style:italic;">slack</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1">ε &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;= epsilon, to search for error values</span></p></li></ul>
<p><span class="font1" style="font-style:italic;">D</span><span class="font0" style="font-style:italic;">ij &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="font1" style="font-style:italic;">=</span><span class="font1"> value of hessian matrix</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1" style="font-style:italic;">x</span><span class="font0" style="font-style:italic;">i</span><span class="font1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;= i-th data</span></p></li>
<li>
<p><span class="font1" style="font-style:italic;">x</span><span class="font0" style="font-style:italic;">j</span><span class="font1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;= j-th data</span></p></li>
<li>
<p><span class="font1" style="font-style:italic;">y</span><span class="font0" style="font-style:italic;">i</span><span class="font1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;= i-th data class</span></p></li>
<li>
<p><span class="font1" style="font-style:italic;">b &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=</span><span class="font1"> bias value</span></p></li></ul>
<p><span class="font1" style="font-style:italic;">f(x) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=</span><span class="font1"> test function</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1" style="font-style:italic;">K (xi, xd) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=</span><span class="font1"> kernel function</span></p></li></ul>
<p><span class="font1">exp &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;= exponent</span></p>
<ul style="list-style:none;"><li>
<h4><a name="bookmark29"></a><span class="font1" style="font-weight:bold;"><a name="bookmark30"></a>2.6 Evaluation</span></h4></li></ul>
<p><span class="font1">The evaluation is conducted to measure evaluation performance of the proposed method. Evaluation is done by calculating the score of precision, recall, and f-measure of each class and calculate the average. Here's how to find precision, recall, and f-measure values for each class.</span></p>
<table border="1">
<tr><td style="vertical-align:middle;">
<p><span class="font1">Precision</span></p></td><td style="vertical-align:top;">
<p><span class="font6" style="font-style:italic;">Sum of correct prediction</span></p>
<p><span class="font6" style="font-style:italic;">Total sum of prediction</span><span class="font1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(^)</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font1">Recall</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6" style="font-style:italic;">_ Sum of correct prediction Totalamountofdata</span><span class="font1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(^)</span></p>
<p><span class="font6" style="font-style:italic;">2*Pr ecision*Recall</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font1">F-Measure</span></p></td><td style="vertical-align:top;">
<p><span class="font1">= &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(15)</span></p>
<p><span class="font6" style="font-style:italic;">Precision+Recall</span></p></td></tr>
</table>
<p><span class="font1">The average calculation is done by summing the precision, recall, or f-measure scores of all classes and divided by 3 because the amount of data of each class is already the same.</span></p>
<ul style="list-style:none;"><li>
<h4><a name="bookmark31"></a><span class="font1" style="font-weight:bold;"><a name="bookmark32"></a>3. &nbsp;&nbsp;&nbsp;Result and Discussion</span></h4></li></ul>
<p><span class="font1">From sentiment analysis with SVM that has been done, the prediction results are obtained as follows.</span></p>
<table border="1">
<tr><td colspan="5" style="vertical-align:bottom;">
<p><span class="font1" style="font-weight:bold;">Table 1. </span><span class="font1">Precision, Recall, F-Measure of Linear Kernel</span></p></td></tr>
<tr><td style="vertical-align:top;"></td><td style="vertical-align:bottom;">
<p><span class="font1">Positive</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">Neutral</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">Negative</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">Average</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font1">Precision</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">0.57</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">0.47</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">0.75</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">0.57</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font1">Recall</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">0.21</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">0.92</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">0.19</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">0.50</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font1">F-Measure</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0.33</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0.62</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0.29</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">0.44</span></p></td></tr>
</table>
<p><span class="font1">As can be seen from the Table 1, for positive class, the score of precision is 0.57 or 57%, recall’s score is 0.47 or 47%, and f-measure’ score is of 0.33 or 33%. For neutral class, the score of precision is 0.47 or 47%, recall’s score is 0.92 or 92%, and f-measure’s score is 0.62 or 62%. And for negative class, the score of precision is 0.75 or 100%, recall’s score 0.62 or 62%, and f-measure’s score is 0.33 or 33%. The average precision score is 0.57 or 57%, the average recall score is 0.62 or 62%, and the average f-measure score is 0.29 or 29%.</span></p>
<p><span class="font1">However, the results are not good enough (close to or below 50%) because there are still a lot of noise like unnormalized data in the dataset.</span></p>
<p><span class="font1" style="font-weight:bold;">Table 2. </span><span class="font1">Precision, Recall, F-Measure of Polynomial Kernel</span></p>
<table border="1">
<tr><td style="vertical-align:top;"></td><td style="vertical-align:bottom;">
<p><span class="font1">Positive</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">Neutral</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">Negative</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">Average</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font1">Precision</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">1.00</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">0.39</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">1.00</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">0.78</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font1">Recall</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">0.11</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">1.00</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">0.10</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">0.43</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font1">F-Measure</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">0.20</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">0.56</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">0.18</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">0.33</span></p></td></tr>
</table>
<p><span class="font1">As can be seen from the Table 2, for positive class, the score of precision is 1.00 or 100%, recall’s score is 0.11 or 11%, and f-measure’ score is of 0.20 or 20%. For neutral class, the score of precision is 0.39 or 39%, recall’s score is 1.00 or 100%, and f-measure’s score is 0.56 or 56%. And for negative class, the score of precision is 1.00 or 100%, recall’s score 0.10 or 10%, and f-measure’s score is 0.18 or 18%. The average precision score is 0.78 or 78%, the average recall score is 0.43 or 43%, and the average f-measure score is 0.33 or 33%. However, the results are not good enough (close to or below 50%) because there are still a lot of noise like unnormalized data in the dataset.</span></p>
<p><span class="font1" style="font-weight:bold;">Table 3. </span><span class="font1">Precision, Recall, F-Measure of RBF Kernel</span></p>
<table border="1">
<tr><td style="vertical-align:top;"></td><td style="vertical-align:bottom;">
<p><span class="font1">Positive</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">Neutral</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">Negative</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">Average</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font1">Precision</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">1.00</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">0.41</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">1.00</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">0.77</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font1">Recall</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">0.07</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">1.00</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">0.05</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">0.43</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font1">F-Measure</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">0.13</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">0.59</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">0.09</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">0.30</span></p></td></tr>
</table>
<p><span class="font1">As can be seen from the Table 3, for positive class, the score of precision is 1.00 or 100%, recall’s score is 0.07 or 7%, and f-measure’ score is of 0.13 or 13%. For neutral class, the score of precision is 0.41 or 41%, recall’s score is 1.00 or 100%, and f-measure’s score is 0.59 or 59%. And for negative class, the score of precision is 1.00 or 100%, recall’s score 0.05 or 5%, and f-measure’s score is 0.09or 9%. The average precision score is 0.77 or 77%, the average recall score is 0.43 or 43% and the average f-measure score is 0.30 or 30%. However, the results are not good enough (close to or below 50%) because there are still a lot of noise like unnormalized data in the dataset.</span></p>
<ul style="list-style:none;"><li>
<h4><a name="bookmark33"></a><span class="font1" style="font-weight:bold;"><a name="bookmark34"></a>4. &nbsp;&nbsp;&nbsp;Conclusion</span></h4></li></ul>
<p><span class="font1">The evaluation result show that SVM with linear kernel function is better than other two methods. The evaluation results of linear kernel function show that precision score is 57%, recall score is 50%, and the f-measure score is 44%, as for polynomial kernel function the precision score is 78% recall score is 43% and f-measure score is 33%, lastly for rbf kernel function the precision score is 77%, recall score is 43%, and f-measure score is 30%. From that result can be concluded that simpler kernel function suits better for this experiment. However, the results are not good enough (close to or below 50%) because there are still a lot of noise like unnormalized data in the dataset.. This problem can be remedied by further normalization of the data. It also can be seen that the percision score of support vector machine with polynomial kernel is greater than two others. So, it can be concluded that the application of linear kernel on support vector machine yield better result than polynomial kernel and rbf kernel.</span></p>
<h4><a name="bookmark35"></a><span class="font1" style="font-weight:bold;"><a name="bookmark36"></a>Reference</span></h4>
<ul style="list-style:none;"><li>
<p><span class="font1">[1] &nbsp;&nbsp;&nbsp;&nbsp;Aggarwal, C. C., &amp;&nbsp;Zhai, C. (2012). A survey of text classification algorithms. In </span><span class="font1" style="font-style:italic;">Mining</span></p></li></ul>
<p><span class="font1" style="font-style:italic;">text data</span><span class="font1"> (pp. 163-222). Springer, Boston, MA.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1">[2] &nbsp;&nbsp;&nbsp;&nbsp;C. A. A. Kaestner, “Support Vector Machines and Kernel Functions for Text</span></p></li></ul>
<p><span class="font1">Processing,” </span><span class="font1" style="font-style:italic;">Rev. Informática Teórica e Apl.</span><span class="font1">, vol. 20, no. 3, p. 130, 2013, doi:</span></p>
<p><span class="font1">10.22456/2175-2745.39702.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1">[3] &nbsp;&nbsp;&nbsp;&nbsp;L. Muflikhah and D. J. Haryanto, “High Performance of Polynomial Kernel at SVM</span></p></li></ul>
<p><span class="font1">Algorithm for Sentiment Analysis,” </span><span class="font1" style="font-style:italic;">J. Inf. Technol. Comput. Sci.</span><span class="font1">, vol. 3, no. 2, p. 194, 2018, doi: 10.25126/jitecs.20183260.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1">[4] &nbsp;&nbsp;&nbsp;&nbsp;Liu, B., 2012. Sentiment Analysis and Opinion Mining. In: Chicago: Morgan &amp;&nbsp;Claypool</span></p></li></ul>
<p><span class="font1">Publisher.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1">[5] &nbsp;&nbsp;&nbsp;&nbsp;Manning, C., Raghavan, P. &amp;&nbsp;Schütze, H. (2009). An Introduction to</span></p></li></ul>
<p><span class="font1">InformationRetrieval. Cambridge: Cambridge University Press.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1">[6] &nbsp;&nbsp;&nbsp;&nbsp;Pratiwi, S. N. D., &amp;&nbsp;Ulama, B. S. S. (2016). Klasifikasi Email Spam dengan</span></p></li></ul>
<p><span class="font1">Menggunakan Metode Support Vector Machine dan k-Nearest Neighbor. </span><span class="font1" style="font-style:italic;">Jurnal Sains dan Seni ITS</span><span class="font1">, </span><span class="font1" style="font-style:italic;">5</span><span class="font1">(2).</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1">[7] &nbsp;&nbsp;&nbsp;&nbsp;I. G. C. P. Yasa, N. A. Sanjaya ER, and L. A. A. R. Putri, “Sentiment Analysis of Snack</span></p></li></ul>
<p><span class="font1">Review Using the Naïve Bayes Method,” JELIKU, vol. 8, no. 3, pp. 333–338, 2020.</span></p>
<p><span class="font1">168</span></p>