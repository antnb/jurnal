---
layout: full_article
title: "Text Based Approach For Similar Traffic Incident Detection from Twitter"
author: "Myrna ermawati, Joko Lianto Buliali"
categories: lontar
canonical_url: https://jurnal.harianregional.com/lontar/full-38749 
citation_abstract_html_url: "https://jurnal.harianregional.com/lontar/id-38749"
citation_pdf_url: "https://jurnal.harianregional.com/lontar/full-38749"  
comments: true
---

<p><span class="font2" style="font-weight:bold;">LONTAR KOMPUTER VOL. 9, NO. 2, AUGUST 2018</span></p>
<p><span class="font2" style="font-weight:bold;">DOI : 10.24843/LKJITI.2018.v09.i02.p01</span></p>
<p><span class="font2" style="font-weight:bold;">Accredited B by RISTEKDIKTI Decree No. 51/E/KPT/2017</span></p>
<p><span class="font2" style="font-weight:bold;">p-ISSN 2088-1541</span></p>
<p><span class="font2" style="font-weight:bold;">e-ISSN 2541-5832</span></p><a name="caption1"></a>
<h1><a name="bookmark0"></a><span class="font3" style="font-weight:bold;"><a name="bookmark1"></a>Text Based Approach For</span><br><br><span class="font3" style="font-weight:bold;"><a name="bookmark2"></a>Similar Traffic Incident Detection from Twitter</span></h1>
<p><span class="font2">Myrna Ermawati<sup>1</sup>, Joko Lianto Buliali<sup>2</sup></span></p>
<p><span class="font2"><sup>1,2</sup> Department of Informatics, Institut Teknologi Sepuluh Nopember (ITS), Surabaya, Indonesia</span></p>
<p><a href="mailto:1myrna.winarso@gmail.com"><span class="font2"><sup>1</sup>myrna.winarso@gmail.com</span></a></p>
<p><a href="mailto:2joko@cs.its"><span class="font2" style="text-decoration:underline;"><sup>2</sup>joko@cs.its</span><span class="font2"> </span></a><span class="font2">.ac.id</span></p>
<p><span class="font2" style="font-weight:bold;font-style:italic;">Abstract</span></p>
<p><span class="font2" style="font-style:italic;">Microblog has been used as an information source to detect real-world event. Several related studies retrieved road traffic event based on textual content. Not only detect traffic incident, we found that it is necessary to recognize statuses with similar traffic incident content. Better representation of traffic information will help the handling of traffic incident by related parties. This study proposes text-based approach for identification of similar traffic incident from twitter posts. The proposed approach performs traffic incident information extraction and calculates information’s weight based on textual similarity upon traffic incident information gained. We evaluate the proposed method by using a traffic incident information retrieval system. We used Indonesian language corpus contains traffic incident tweets data. Best average f-measure 70% was achieved by retrieval system that tested using Jaccard coefficient. Therefore text matching such as Jaccard coefficient is more suitable to be implemented in very short text document such as extracted tweet document. The experiment result gives the conclusion that the proposed approach can be implemented for identification of similar traffic incident information from Twitter.</span></p>
<p><span class="font2" style="font-weight:bold;font-style:italic;">Keywords: </span><span class="font2" style="font-style:italic;">text similarity, information retrieval, information extraction, similar event detection, information weighting.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark3"></a><span class="font2" style="font-weight:bold;"><a name="bookmark4"></a>1. &nbsp;&nbsp;&nbsp;Introduction</span></h2></li></ul>
<p><span class="font2">Microblog has become one of the most accessible sources of information. Microblogging is part of social media that allows its users to write and share short messages (280 characters on Twitter) containing opinions, information, questions and also discussions. Microblogging services (such as Jaiku, Plurk and Twitter) are increasingly popular because of the ease of accessing and using them with the availability of social networking site apps for smartphones and tablets [1].</span></p>
<p><span class="font2">Microblog has also been widely used as a source of information for detection or recognition of real-world events, such as traffic incidents, earthquakes, tornadoes, wildfires, and music concerts [2]. Events can be defined as real word events occurring within a certain time period and timeframe [1][3]. In relation to traffic events or traffic information, people are also used to sharing information that occurs around them by posting a status on social media when passing on the road. Real-time traffic information such as that obtained from social networks helps users avoid traffic congestion, better plan the routes, and save fuel costs [4].</span></p>
<p><span class="font2">There have been many research and real-time event detection systems that utilize social media status as a source of information. Social media status and other text documents such as blogs, news sites, and emails are natural language text. Therefore we need NLP (Natural Language Processing) technique to extract meaningful information from a collection of natural language text such as Twitter post [5]. Many research related to extracting traffic information from Twitter have been conducted before, in example study by Wanichayapong et al [4], Endarnoto et al [7] and Indra [14]. Wanichayapong et al. extracted traffic information from twitter using NLP technique and syntactic analysis. Traffic information extracted was then further classified into two categories: points and links [4]. Another study by Khodra et al. extracted traffic information</span></p>
<p><span class="font2">from Twitter and then used the extracted results as heuristic data in finding the optimal route [6]. These studies retrieve real-world event’s information based on textual content.</span></p>
<p><span class="font2">For better information representation, it is necessary to recognize the social media status that similar, or have the same traffic incident content, with certain traffic incident information. The representation of efficient, structured and more detailed traffic incident information is expected to help the handling of events by related parties or for further data analysis. This is also to avoid repetition and storage of information with the same incident content.</span></p>
<p><span class="font2">This study proposes a text-based approach for identification of similar incident automatically from Twitter. We combine information extraction technique and text similarity weighting method as a hybrid, or compound, a technique to detect similar incident from Twitter post. This hybrid method assigns weight based on text similarity between traffic incident information. Our research will use this method in a retrieval system that tracks similar traffic incident information from Twitter post. The system will track previous tweets that have similarity with query tweet based on the text similarity among information entities.</span></p>
<p><span class="font2">We evaluate our proposed method by using Indonesian language corpus contains traffic incident tweet text. Tweet text data streams are taken from local Twitter account that reporting traffic condition in Surabaya and surrounding area. The rest of this paper is organized as follows: Section 2 presents the related study and research method including our proposed approach, design and implementation. Section 3 reports our experimental results and analysis. Finally, Section 4 concludes the paper.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font2" style="font-weight:bold;">2. &nbsp;&nbsp;&nbsp;Research Method</span></p>
<ul style="list-style:none;">
<li>
<p><span class="font2" style="font-weight:bold;">2.1. &nbsp;&nbsp;&nbsp;Literature Review</span></p>
<ul style="list-style:none;">
<li>
<p><span class="font2" style="font-weight:bold;">2.1.1. &nbsp;&nbsp;&nbsp;Information Extraction</span></p></li></ul></li></ul></li></ul>
<p><span class="font2">To process and analyze text using a machine or computer, we need structured information. Information extraction as a part of NLP is a process of finding information from a collection of natural language text and producing structured information in a specific format [5][7]. Information extraction is a technique of identifying and understanding relevant sections in a text. This relevant part is called an entity [8].</span></p>
<p><span class="font2">The information extraction process generally finds or recognizes entities and stores into structured information in a format that suits the requirement of the application [8][15]. Information extraction is used for example in the application or question-answering system, summarization, topic extraction, the introduction of bio-medical entities such as protein names, drug product identification in medical documents, and detection of real-world events or activities [9].</span></p>
<p><span class="font2">The main stage in information extraction is Named Entity Recognition (NER) [15]. NER is a process that aims to find and classify the names of entities in text into named groups or attributes of structured information [4][6]. Examples of naming an entity, or an attribute of information, are 'People', 'Date', 'Organization', 'Location', 'Point', 'Department', 'Product''. Some studies classified techniques in the information extraction into 5 approaches: 1) Regressionbased approaches, 2) Word dictionary approaches, 3) Rule-based approaches, 4) Machine learning-based approach, and 5) Statistical approach.</span></p>
<p><span class="font2">Endarnoto et al extracts traffic information from Twitter and provides visualization in mobile applications [7]. Information retrieval in this system is done by identifying entity name using rule based approach. Wanichayapong et al using the same method, the rule-based approach, but the difference is the use of a word dictionary [4]. They use word dictionaries in the tokenization process and filter tokens into several attributes, among which are verbs, points, and links. The dictionary is also used in the selection phase of twitter candidates.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font2" style="font-weight:bold;">2.1.2. &nbsp;&nbsp;&nbsp;Text Similarity</span></p></li></ul>
<p><span class="font7" style="font-weight:bold;">Cosine Similarity.</span></p>
<p><span class="font2">Cosine similarity is a method to measure the similarity of text by using the cosine value of the angle between two vectors [10][11]. The results of this calculation give a similarity value in a range of 0 to 1. Let </span><span class="font7" style="font-style:italic;">W (t t</span><span class="font7"> , </span><span class="font7" style="font-style:italic;">d j)</span><span class="font2"> be a weight of term </span><span class="font7" style="font-style:italic;">t<sub>i</sub></span><span class="font2"> in document </span><span class="font7" style="font-style:italic;">dj</span><span class="font2"> , cosine similarity value of query document </span><span class="font7" style="font-style:italic;">Q</span><span class="font2"> and document </span><span class="font7" style="font-style:italic;">dj</span><span class="font2"> is:</span></p>
<p><span class="font5"><sup>∑</sup></span><span class="font5" style="font-style:italic;">t i</span><span class="font5"><sup>[</sup></span><span class="font5" style="font-style:italic;">W</span><span class="font5"><sup>(</sup>⅛ ,q)] ∙ [</span><span class="font5" style="font-style:italic;">W</span><span class="font5">(</span><span class="font5" style="font-style:italic;">^i</span><span class="font5"> ,</span><span class="font5" style="font-style:italic;">d j</span><span class="font5">)] </span><span class="font7">cos </span><span class="font5" style="font-style:italic;">W</span><span class="font5"><sup>,</sup> </span><span class="font5" style="font-style:italic;">^jJ</span><span class="font5"> <sub>=</sub> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="font5" style="text-decoration:underline;">,</span><span class="font5"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="font5" style="text-decoration:underline;">,</span><span class="font5"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="font2">(1)</span></p>
<p><span class="font5">∑ |w( </span><span class="font5" style="font-style:italic;">Il</span><span class="font5"> )I<sub>∙ ∑</sub> |w(</span><span class="font5" style="font-style:italic;">d j</span><span class="font5">) I</span></p>
<p><span class="font2">There are many term weighting methods in the field of information retrieval and text categorization. TF-IDF (term’s frequency-inverse document frequency), or TF x IDF, is one of the popular methods used for term weighting in information retrieval. TF-IDF use weights that combine IDF factors with term frequencies TF [11]. Let </span><span class="font5">, </span><span class="font2">be the term weight associated with the term </span><span class="font2" style="font-style:italic;">k<sub>t</sub></span><span class="font2"> and the document </span><span class="font2" style="font-style:italic;">d<sub>i</sub></span><span class="font2"> . We define </span><span class="font5">, </span><span class="font2">as l &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<sup>,</sup> /</span></p>
<p><span class="font2" style="font-style:italic;">W</span><span class="font7"> = &nbsp;&nbsp;1+log</span><span class="font5" style="font-style:italic;">fi</span><span class="font5"> ,</span><span class="font5" style="font-style:italic;">j')</span><span class="font7"> ×log &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="font5">,</span><span class="font5" style="font-style:italic;">j</span><span class="font5"><sup>&gt;0</sup> </span><span class="font7">, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="font2">(2)</span></p>
<p><span class="font7">0 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="font7" style="font-style:italic;">Ot</span><span class="font7">ℎ</span><span class="font7" style="font-style:italic;">erwise</span></p>
<p><span class="font2">where </span><span class="font5"><sub>,</sub> </span><span class="font2">is term frequency, N is number of documents in collection, </span><span class="font7" style="font-style:italic;"><sup>n</sup>t</span><span class="font2"> is document frequency having term </span><span class="font7" style="font-style:italic;">ki</span><span class="font2"> .</span></p>
<p><span class="font7" style="font-weight:bold;">Jaccard Coefficient.</span></p>
<p><span class="font2">Similar documents are those that have the highest similarity values with the query. One of the simple techniques in calculating text similarity is to calculate the Jaccard coefficients. This coefficient is easy because we look for the same term divided by the total item of both. Jaccard coefficient is also known as a text matching method.</span></p>
<p><span class="font2">Using an example of the query: &quot;ides of march&quot; with two documents doc1: &quot;caesar died in march&quot;, doc2: &quot;the long march&quot;. The set q∩doc1 = {march}, q</span><span class="font4">∪</span><span class="font2">doc1 = {ides, of, march, caesar, died, in}. The jaccard coefficients between queries with doc1 and doc2 are shown in equations 2 and 3.</span></p>
<p><span class="font7" style="font-style:italic;">jaccard</span><span class="font7"> (</span><span class="font7" style="font-style:italic;">Q</span><span class="font7">, </span><span class="font7" style="font-style:italic;">doc</span><span class="font7">1)= &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="font2">(3)</span></p>
<p><span class="font7" style="font-style:italic;">jaccard</span><span class="font7"> (</span><span class="font7" style="font-style:italic;">Q</span><span class="font7">, </span><span class="font7" style="font-style:italic;">doc</span><span class="font7">2)= &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="font2">(4)</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark5"></a><span class="font2" style="font-weight:bold;"><a name="bookmark6"></a>2.2. &nbsp;&nbsp;&nbsp;Research Question</span></h2></li></ul>
<p><span class="font2">With problems background discussed in the previous section, we may conclude two research questions:</span></p>
<p><span class="font2">RQ1: How to extract traffic information from twitter posts into information entities in order to detect traffic incident information.</span></p>
<p><span class="font2">RQ2: How to assign text similarity weight on information and use this weight to rank similar event based on textual content relevance.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark7"></a><span class="font2" style="font-weight:bold;"><a name="bookmark8"></a>2.3. &nbsp;&nbsp;&nbsp;Proposed Approach : Event Information Retrieval System Model</span></h2></li></ul>
<p><span class="font2">We will implement our proposed approach in the event information retrieval system. The system begins by filtering candidate tweets as described in figure 1. Candidate tweet is a tweet with traffic information content. The next stage will perform traffic information extraction. This process extracts traffic information from candidate tweet content and produces information entities. In the next process the system will search previous tweets to detect the same, or similar, event information.</span></p>
<p><span class="font7">Filtering candidate tweet</span></p><img src="https://jurnal.harianregional.com/media/38749-1.jpg" alt="" style="width:216pt;height:36pt;"><img src="https://jurnal.harianregional.com/media/38749-2.jpg" alt="" style="width:404pt;height:107pt;">
<p><span class="font2" style="font-weight:bold;">Figure 1. </span><span class="font2">System Flow Diagram</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark9"></a><span class="font2" style="font-weight:bold;"><a name="bookmark10"></a>2.3.1. &nbsp;&nbsp;&nbsp;Filtering Candidate Tweet</span></h2></li></ul>
<p><span class="font2">The filtering stage, as the first stage in our system, aims to recognize a raw tweet that has traffic information content, which is then called candidate tweet. A tweet becomes candidate tweet when its text, or content, consists of one of the keywords listed in pre-registered traffic keyword list. Tweets with content other than traffic information are ignored.</span></p>
<p><span class="font2">Our system uses 30 keywords in the candidate tweet filtering process. These keywords are obtained by observing the traffic information content tweets. A number of important words that often appear in a traffic information tweets corpus are then selected as keywords. Table 1 shows some of the keywords used in our filtering stage.</span></p>
<p><span class="font2" style="font-weight:bold;text-decoration:underline;">Table 1. </span><span class="font2" style="text-decoration:underline;">Examples of traffic incident keyword</span></p>
<table border="1">
<tr><td style="vertical-align:top;">
<p><span class="font7">No.</span></p></td><td style="vertical-align:top;">
<p><span class="font7">Keywords</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font7">1</span></p>
<p><span class="font7">2</span></p>
<p><span class="font7">3</span></p>
<p><span class="font7">4</span></p>
<p><span class="font7">5</span></p>
<p><span class="font7">6</span></p>
<p><span class="font7">7</span></p></td><td style="vertical-align:middle;">
<p><span class="font7">Kecelakaan Tabrak Jatuh Mogok Macet Merambat Tol</span></p></td></tr>
</table>
<ul style="list-style:none;"><li>
<p><span class="font2" style="font-weight:bold;">2.3.2. &nbsp;&nbsp;&nbsp;Information Extraction</span></p></li></ul>
<p><span class="font7" style="font-weight:bold;">Preprocessing.</span></p>
<p><span class="font2">Early phase in our information extraction stage is preprocessing consists of normalization, altering word abbreviations, and case folding. Normalization removes substrings that usually appear on tweets but are not needed in our system, as mentioned and links. Figure 2 shows the example of removing mention and link, while figure 3 shows the example of abbreviation found that will be altered into its complete word. We can see some examples of preprocessing result in table 2. The second column is candidate tweet as the raw tweet to be processed. The last column shows a textual content of tweet after the preprocessing phase.</span></p>
<p><span class="font1">@y at oma 14 16.24 T ol perak arah waru km 3, sangat padat </span><span class="font0" style="text-decoration:line-through;">@e1OOs</span><span class="font1">s</span></p>
<p><span class="font0" style="text-decoration:line-through;">https:/ft.calEMJqNIBpN3</span></p>
<ul style="list-style:none;"><li>
<p><span class="font2" style="font-weight:bold;">Figure 2.</span><span class="font2"> &nbsp;&nbsp;&nbsp;Example of mentioned and link removal</span></p></li></ul>
<p><span class="font0" style="text-decoration:line-through;">RT @arleneflorencia:</span><span class="font1"> 10.27 bund dolog arah dim kota pdt merambat, lepas bund dolog arus lancar </span><span class="font4">∣</span><span class="font1">ge100ss https7⅛co∕feBGCQVEq</span><span class="font4">∪</span></p>
<ul style="list-style:none;"><li>
<p><span class="font2" style="font-weight:bold;">Figure 3.</span><span class="font2"> &nbsp;&nbsp;&nbsp;Example of abbreviation found and will be altered</span></p></li></ul>
<p><span class="font2" style="font-weight:bold;">Table 2. </span><span class="font2">Examples of preprocessing stage result</span></p>
<table border="1">
<tr><td style="vertical-align:middle;">
<p><span class="font7">No.</span></p></td><td style="vertical-align:middle;">
<p><span class="font7">Raw Candidate Tweet</span></p></td><td style="vertical-align:middle;">
<p><span class="font7">Text after Preprocessing</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font7">1</span></p></td><td style="vertical-align:middle;">
<p><span class="font7">RT @Firman_andika88: Kawasan Prempatan greges macet total tdk ada petugas mengatur lalin @e100ss</span></p></td><td style="vertical-align:middle;">
<p><span class="font7">kawasan prempatan greges macet total tidak ada petugas mengatur lalu lintas</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font7">2</span></p></td><td style="vertical-align:middle;">
<p><span class="font7">RT @KimNugraha004: Banjir di jalan raya pakal, sekitar 10-30 cm...padat merayap...@e100ss</span></p></td><td style="vertical-align:middle;">
<p><span class="font7">banjir di jalan raya pakal sekitar 10-30 cm padat merayap</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font7">3</span></p></td><td style="vertical-align:bottom;">
<p><span class="font7">11.59: Info awal #kecelakaan di Exit Tol Gunungsari arah Kedurus. Ada Truk Trailer menabrak Motor. Lokasinya...</span></p>
<p><a href="https://t.co/WDy9mpHb0e"><span class="font7">https://t.co/WDy9mpHb0e</span></a></p></td><td style="vertical-align:middle;">
<p><span class="font7">info awal di exit tol gunungsari arah kedurus ada truk trailer menabrak motor lokasinya</span></p></td></tr>
</table>
<p><span class="font7" style="font-weight:bold;">Dictionary Based NER.</span></p>
<p><span class="font2">Information extraction technique used in our experiment is a dictionary based NER [4] that utilize words dictionary. The information extraction on our system utilizes NER utility on LingPipe java. LingPipe is a toolkit in java programming for text processing by using linguistic computation. Table 3 shows examples of listed phrase and category in our dictionary.</span></p>
<table border="1">
<tr><td colspan="3" style="vertical-align:bottom;">
<p><span class="font2" style="font-weight:bold;">Table 3. </span><span class="font2">Examples of listed phrase and category</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font7">No.</span></p></td><td style="vertical-align:middle;">
<p><span class="font7">Phrase</span></p></td><td style="vertical-align:middle;">
<p><span class="font7">Category</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font7">1</span></p></td><td style="vertical-align:middle;">
<p><span class="font7">pertigaan</span></p></td><td style="vertical-align:middle;">
<p><span class="font7">location</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font7">2</span></p></td><td style="vertical-align:top;">
<p><span class="font7">tol</span></p></td><td style="vertical-align:top;">
<p><span class="font7">location</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font7">3</span></p></td><td style="vertical-align:bottom;">
<p><span class="font7">gate</span></p></td><td style="vertical-align:bottom;">
<p><span class="font7">location</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font7">4</span></p></td><td style="vertical-align:top;">
<p><span class="font7">tabrak</span></p></td><td style="vertical-align:top;">
<p><span class="font7">condition</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font7">5</span></p></td><td style="vertical-align:bottom;">
<p><span class="font7">macet total</span></p></td><td style="vertical-align:bottom;">
<p><span class="font7">condition</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font7">6</span></p></td><td style="vertical-align:bottom;">
<p><span class="font7">sepeda motor</span></p></td><td style="vertical-align:bottom;">
<p><span class="font7">object</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font7">7</span></p></td><td style="vertical-align:top;">
<p><span class="font7">container</span></p></td><td style="vertical-align:top;">
<p><span class="font7">object</span></p></td></tr>
</table>
<p><span class="font7" style="font-weight:bold;">Information Filling.</span></p>
<p><span class="font2">As the result of information extraction, recognized entities are then used to fill groups of information entities. This process stores extraction result into a more structured form [12][13]. Event information generally comprises entities: type of event, location, event time or period, the cause or condition, and who is involved or experiencing an event [4]. The determination of these information entities is also based on the information needs in our research. Because of these two backgrounds, this study uses 4 entities of traffic information: (1) hashtag, (2) location, (3) incident condition, (4) object. Table 4 shows an example of an information extraction result</span></p>
<p><span class="font2">using Lingpipe’s approximate dictionary. This table shows examples of extracted phrase and its category for each preprocessed text on the left column.</span></p>
<p><span class="font2" style="font-weight:bold;">Table 4. </span><span class="font2">Examples of extracted phrase and its category</span></p>
<table border="1">
<tr><td rowspan="2" style="vertical-align:middle;">
<p><span class="font7">Preprocessed Text</span></p></td><td colspan="4" style="vertical-align:bottom;">
<p><span class="font7">Extracted Phrase (information entities)</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font7">Hastag</span></p></td><td style="vertical-align:middle;">
<p><span class="font7">Condition</span></p></td><td style="vertical-align:middle;">
<p><span class="font7">Location</span></p></td><td style="vertical-align:middle;">
<p><span class="font7">Object</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font7">kawasan prempatan greges macet total tidak ada petugas mengatur lalu lintas</span></p></td><td style="vertical-align:top;"></td><td style="vertical-align:middle;">
<p><span class="font7">macet total tidak ada petugas lalu lintas</span></p></td><td style="vertical-align:top;">
<p><span class="font7">kawasan prempatan greges</span></p></td><td style="vertical-align:top;"></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font7">banjir di jalan raya pakal sekitar 10-30 cm padat merayap</span></p></td><td style="vertical-align:top;"></td><td style="vertical-align:top;">
<p><span class="font7">banjir padat merayap</span></p></td><td style="vertical-align:top;">
<p><span class="font7">di jalan raya pakal cm</span></p></td><td style="vertical-align:top;"></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font7">info awal di exit tol gunungsari arah kedurus ada truk trailer menabrak motor lokasinya</span></p></td><td style="vertical-align:top;">
<p><span class="font7">kecelakaan</span></p></td><td style="vertical-align:top;">
<p><span class="font7">ada truk trailer menabrak motor</span></p></td><td style="vertical-align:top;">
<p><span class="font7">di exit tol gunungsari arah kedurus</span></p></td><td style="vertical-align:top;">
<p><span class="font7">truk trailer motor</span></p></td></tr>
</table>
<ul style="list-style:none;"><li>
<h2><a name="bookmark11"></a><span class="font2" style="font-weight:bold;"><a name="bookmark12"></a>3. &nbsp;&nbsp;&nbsp;Result and Discussion</span><br><br><span class="font2" style="font-weight:bold;"><a name="bookmark13"></a>3.1. &nbsp;&nbsp;&nbsp;Traffic Information Tweet Data</span></h2></li></ul>
<p><span class="font2">We used data collection contains traffic incident tweets in Surabaya city and surrounding area. We evaluate our proposed approach using event information retrieval system. Therefore the corpus used in our retrieval system is Indonesian language corpus. Raw tweet data streams have taken from twitter timeline account Suara Surabaya (@e100ss). Twitter data streams have retrieved without a capture permission or data usage permission. Data crawling was done using twitter class library for java Twitter4j library.</span></p>
<p><span class="font2">We collected 6100 raw tweet data having a timestamp between ‘2017-11-17 15:49:52’ and ‘2017-12-25 10:04:37’. From the filtering stage, we obtained 2360 candidate tweets containing traffic incident information. Therefore after information extraction stage, we had 2360 traffic tweets, saved with its information entities such as showed in table 4, as a corpus, or document collection, for similar traffic incident detection in our traffic information retrieval system. We also manually observed, collected and labeled several candidate tweets used as query tweets and its relevant tweet for. Next subsection will give more brief explanation about the evaluation including query tweet tested and the evaluation result.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark14"></a><span class="font2" style="font-weight:bold;"><a name="bookmark15"></a>3.2. &nbsp;&nbsp;&nbsp;Experiment</span></h2></li></ul>
<p><span class="font2">Our experiment performed top-1 retrieval system comparing weighting method using three different methods for text similarity measurement: 1) cosine similarity using TF (term’s frequency) term weighting, 2) cosine similarity using TF-IDF (term’s frequency-inverse document frequency) term weighting, and 3) jaccard coefficient. Our idea is to analyze which text similarity measurement is more suitable for a very short text such as traffic entities extracted from a tweet which already short in a text.</span></p>
<p><span class="font2">This test has been done using 20 query tweets which have only one relevant previous tweet. Query tweet is a selected tweet that has content of traffic incident and has another related tweet named relevant tweet. A relevant tweet is a related tweet contains similar traffic incident information content with the query tweet. We had manually observed, collected and labeled several query tweets and its relevant tweet. We collected a small number of query tweets due to the limited number of real traffic incident information posted that have a relevant tweet in our tweets data collection.</span></p>
<p><span class="font2">While testing a query in the retrieval system, tweet documents in the corpus are ranked in decreasing order of their degree of similarity. We calculated average precision, recall, f-</span></p>
<p><span class="font2">measure, and average count of relevant tweet achieved the top-1 position as retrieval output. Table 5 shows three examples of query tweet and its single relevant tweet.</span></p>
<p><span class="font2" style="font-weight:bold;text-decoration:underline;">Table 5. </span><span class="font2" style="text-decoration:underline;">Examples of query tweet and it’s relevant tweet</span></p>
<table border="1">
<tr><td style="vertical-align:top;">
<p><span class="font7">Id.</span></p></td><td style="vertical-align:top;">
<p><span class="font7">Query Tweet</span></p></td><td style="vertical-align:top;">
<p><span class="font7">Relevant Tweet</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font7">Q2</span></p></td><td style="vertical-align:middle;">
<p><span class="font7">RT @kang_de2n: @e100ss ada kecelakaan tunggal di tol legundi arah mojokerto KM 716.200. Truk muat kayu pecah ban muatan tumpah ke badan ja…</span></p></td><td style="vertical-align:middle;">
<p><span class="font7">11.31: Info awal #kecelakaan di Tol Krian -Mojokerto KM 716.800. Truk muat kayu pecah ban, kemudian terguling di...</span></p>
<p><a href="https://t.co/v1KVxD0eac"><span class="font7">https://t.co/v1KVxD0eac</span></a></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font7">Q3</span></p></td><td style="vertical-align:middle;">
<p><span class="font7">Macet total Krian Surabaya 2 arah, truk as patah di Sidorejo. Cari alternatif. (rs) </span><a href="https://t.co/V5azxGvTNA"><span class="font7">https://t.co/V5azxGvTNA</span></a></p></td><td style="vertical-align:middle;">
<p><span class="font7">RT @xenopchilla: @e100ss Ini lho penyebab macet dua arah di raya sidorejo...</span></p>
<p><a href="https://t.co/Nd4ISgpuYH"><span class="font7">https://t.co/Nd4ISgpuYH</span></a></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font7">Q11</span></p></td><td style="vertical-align:middle;">
<p><span class="font7">RT @andhikanoviandy: @e100ss waspada , ada truk pecah ban sebelum res area tol waru arah sidoarjo</span></p></td><td style="vertical-align:top;">
<p><span class="font7">RT @josuryana: @e100ss ada truk berhenti krn ban pecah di tol km 12 waru arah sidoarjo</span></p></td></tr>
</table>
<p><span class="font2">By using query tweet having only one relevant tweet, the experiment evaluated the retrieval result based on first rank output. Table 6 and 7 show experiment result using proposed method tested using a retrieval system. Table 6 shows the real rank position of relevant tweet returned of query ID Q2, Q3, and Q11. As mentioned above, CS-TF is cosine similarity using TF term weighting and CS-TF.IDF is cosine similarity using TF.IDF term weighting. Rank number zero means retrieval output rank was out of top-20 output list. Low rank of relevant tweet returned when testing query ID Q3 due to its relevant tweet less informative. As we can read relevant tweet ID Q3 in table 5, there is no information about the cause of traffic jam at raya sidorejo because it is indicated by the picture in its hyperlink and not in its text such as “truk as patah”.</span></p>
<p><span class="font2" style="font-weight:bold;text-decoration:underline;">Table 6. </span><span class="font2" style="text-decoration:underline;">Retrieval output: relevant tweet rank of query ID Q2, Q3, Q11</span></p>
<table border="1">
<tr><td rowspan="2" style="vertical-align:bottom;">
<p><span class="font7">Query ID</span></p>
<p><span class="font7">CS</span></p></td><td colspan="2" style="vertical-align:top;">
<p><span class="font7">Relevant tweet rank number</span></p></td></tr>
<tr><td colspan="2" style="vertical-align:top;">
<p><span class="font7"><sup>1</sup>-TF<sup>2</sup> &nbsp;&nbsp;&nbsp;&nbsp;CS<sup>1</sup>-TF<sup>2</sup>.IDF<sup>3</sup> &nbsp;&nbsp;&nbsp;</span><span class="font6">Jaccard Coef.</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font7">Q2</span></p></td><td style="vertical-align:middle;">
<p><span class="font7">1 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;6</span></p></td><td style="vertical-align:middle;">
<p><span class="font7">1</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font7">Q3</span></p></td><td style="vertical-align:middle;">
<p><span class="font7">15 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0</span></p></td><td style="vertical-align:middle;">
<p><span class="font7">5</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font7">Q11</span></p></td><td style="vertical-align:middle;">
<p><span class="font7">1 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1</span></p></td><td style="vertical-align:middle;">
<p><span class="font7">1</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font7"><sup>1</sup></span><span class="font6">cosine similarity </span><span class="font7"><sup>2</sup></span><span class="font6">term’s frequency</span></p></td><td style="vertical-align:bottom;">
<p><span class="font5">3</span></p>
<p><span class="font6">Inverse document frequency</span></p></td><td style="vertical-align:top;"></td></tr>
</table>
<p><span class="font2" style="font-weight:bold;text-decoration:underline;">Table 7. </span><span class="font2" style="text-decoration:underline;">Average performance value of 20 query tweets</span></p>
<table border="1">
<tr><td rowspan="2" style="vertical-align:middle;">
<p><span class="font7">Retrieval Performance</span></p></td><td colspan="3" style="vertical-align:top;">
<p><span class="font7">Performance Value (%)</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font7">CS<sup>1</sup>-TF<sup>2</sup></span></p></td><td colspan="2" style="vertical-align:top;">
<p><span class="font7">CS<sup>1</sup>-TF<sup>2</sup>.IDF<sup>3</sup> &nbsp;&nbsp;&nbsp;</span><span class="font6">Jaccard Coef.</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font7">1<sup>st</sup> Rank Total Count</span></p></td><td style="vertical-align:middle;">
<p><span class="font7">12</span></p></td><td style="vertical-align:middle;">
<p><span class="font7">3</span></p></td><td style="vertical-align:middle;">
<p><span class="font7" style="font-weight:bold;">14</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font7">1<sup>st</sup> Rank Ratio</span></p></td><td style="vertical-align:middle;">
<p><span class="font7">0.6</span></p></td><td style="vertical-align:middle;">
<p><span class="font7">0.15</span></p></td><td style="vertical-align:middle;">
<p><span class="font7" style="font-weight:bold;">0.7</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font7">Average F-Measure</span></p></td><td style="vertical-align:middle;">
<p><span class="font7">60%</span></p></td><td style="vertical-align:middle;">
<p><span class="font7">15%</span></p></td><td style="vertical-align:middle;">
<p><span class="font7" style="font-weight:bold;">70%</span></p></td></tr>
</table>
<p><span class="font7"><sup>1</sup></span><span class="font6">cosine similarity </span><span class="font7"><sup>2</sup></span><span class="font6">term’s frequency </span><span class="font7"><sup>3</sup></span><span class="font6">Inverse document frequency</span></p>
<p><span class="font2">Table 7 shows the performance values of retrieval output based on top-1 retrieval using 20 query tweets. Total count of first-rank achieved higher value when we use jaccard coefficient. Best average f-measure 70% was achieved by retrieval system that tested using jaccard coefficient. The experiment showed that our retrieval performance achieved a good result in retrieving similar traffic incident tweet.</span></p>
<p><span class="font2">IDF term weighting comes from idea regarding the term specificity. The more a term occurs in many documents, the term becomes less specific depending on its meaning. This statistical term specificity is the inverse of the number of documents in which the term occurs. While TF and Jaccard coefficients are computed on a per document basis, term weighting IDF is computed over all the collection. This is the reason why TF-IDF term weighting achieved low retrieval performance compared to TF and Jaccard coefficient in our experiment. A document in our retrieval system is a quite short length, combined phrases extracted from a twitter post that already short in a text. Then we only need a similarity measurement, such as Jaccard coefficient, that simply looks the same term between these two short documents. Table 7 shows that text similarity measurement on a short text using jaccard coefficient has a better result than cosine similarity with TF and TF.IDF. Therefore jaccard coefficient is more suitable to be used as text similarity measurement for identification of similar traffic incident information from twitter.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark16"></a><span class="font2" style="font-weight:bold;"><a name="bookmark17"></a>4. &nbsp;&nbsp;&nbsp;Conclusion and Future Works</span></h2></li></ul>
<p><span class="font2">We had studied and analyzed our text based approach to track similar traffic incident information. The experiment showed that retrieval performance results achieved a good result in retrieving similar traffic incident tweet. Based on the retrieval performance result we make a conclusion that our text based approach can be implemented for identification of similar traffic incident information from twitter. The experiment result also gives conclusion that text matching such as jaccard coefficient is more suitable to be implemented in very short text document such as extracted tweet document.</span></p>
<p><span class="font2">Text similarity in our study has not considered the existence of different words with the same meaning in a traffic incident, for example the term ‘tabrakan beruntun' and 'kecelakaan beruntun'. Therefore the next research may overcome this problem with semantic analysis.</span></p>
<h2><a name="bookmark18"></a><span class="font2" style="font-weight:bold;"><a name="bookmark19"></a>References</span></h2>
<ul style="list-style:none;"><li>
<p><span class="font2">[1] &nbsp;&nbsp;&nbsp;F. Atefeh and W. Khreich, “A survey of techniques for event detection in Twitter”, Comput. Intell., vol. 31, no. 1, pp. 132–164, 2015.</span></p></li>
<li>
<p><span class="font2">[2] &nbsp;&nbsp;&nbsp;T. Sakaki, M. Okazaki, and Y.Matsuo, “Tweet analysis for real-time event detection and earthquake reporting system development”, IEEE Trans.Knowl. Data Eng., vol. 25, no. 4, pp. 919–931, Apr. 2013.</span></p></li>
<li>
<p><span class="font2">[3] &nbsp;&nbsp;&nbsp;J. Allan, “Topic Detection and Tracking: Event-Based Information Organization”, Norwell, MA, USA: Kluwer, 2002.</span></p></li>
<li>
<p><span class="font2">[4] &nbsp;&nbsp;&nbsp;N. Wanichayapong, W. Pruthipunyaskul, W. Pattara-Atikom, and P. Chaovalit, “Socialbased traffic information extraction and classification”, in Proc. 11th Int. Conf. ITST, St. Petersburg, Russia, pp. 107–112, 2011.</span></p></li>
<li>
<p><span class="font2">[5] &nbsp;&nbsp;&nbsp;E. D'Andrea P. Ducange B. Lazzerini F. Marcelloni &quot;Real-time detection of traffic from twitter stream analysis&quot; IEEE Trans. Intell. Transp. Syst. vol. 16 no. 4 pp. 1-15, Aug. 2015.</span></p></li>
<li>
<p><span class="font2">[6] &nbsp;&nbsp;&nbsp;Khodra, M.L., Purwarianti, A., “Optimal Path Finding based on Traffic Information Extraction from Twitter”, Prosiding International Conference on ICT for Smart Society 2013, Jakarta, 2013.</span></p></li>
<li>
<p><span class="font2">[7] &nbsp;&nbsp;&nbsp;Endarnoto, S., Pradipta, S., A.S, N., &amp;&nbsp;Purnama, J, “Traffic Condition Information</span></p></li></ul>
<p><span class="font2">Extraction &amp;&nbsp;Visualizations from Social Media Twitter for Android Mobile Application”, ICEEI (pp. 1-4). IEEE, 2011.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font2">[8] &nbsp;Jiang, J., “Information Extraction from Text, in Mining Text Data”, Springer, 2012.</span></p></li>
<li>
<p><span class="font2">[9] &nbsp;A. Hotho, A. Nürnberger, and G. Paaß, “A brief survey of text mining”, LDV Forum-GLDV J.</span></p></li></ul>
<p><span class="font2">Comput. Linguistics Lang. Technol., vol. 20, no. 1, pp. 19–62, May 2005.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font2">[10] &nbsp;&nbsp;&nbsp;C. D. Manning, P. Raghavan, and H. Schutze, “Introduction to Information Retrieval”, Camridge: Cambridge University Press, 2008.</span></p></li>
<li>
<p><span class="font2">[11] &nbsp;&nbsp;&nbsp;Fauzi, M. Ali; Arifin, Agus; Yuniarti, Anny, “Term Weighting Berbasis Indeks Buku dan Kelas untuk Perangkingan Dokumen Berbahasa Arab”, Lontar Komputer : Jurnal Ilmiah Teknologi Informasi, vol.5 no.2, Aug.2014.</span></p></li>
<li>
<p><span class="font2">[12] &nbsp;&nbsp;&nbsp;Khodra, M.L., Purwarianti, A., “Ekstraksi Informasi Transaksi Online pada Twitter”, Jurnal Cybermatika, vol.1, 2013.</span></p></li>
<li>
<p><span class="font2">[13] &nbsp;&nbsp;&nbsp;Khodra, M.L., Purwarianti, A., “Optimal Path Finding based on Traffic Information Extraction from Twitter”, Prosiding International Conference on ICT for Smart Society 2013, Jakarta 2013.</span></p></li>
<li>
<p><span class="font2">[14] &nbsp;&nbsp;&nbsp;N. Indra, “Sistem Pemberi Tahu Kemacetan Lalu Lintas di Kota Bandung Berbasis Media Sosial”, Laporan tugas akhir, InstitutTeknologi Bandung, Bandung: Program Studi Teknik Informatika.</span></p></li>
<li>
<p><span class="font2">[15] &nbsp;&nbsp;&nbsp;Manning, C., Information Extraction and Named Entity Recognition.California: Stanford University. 2012.</span></p></li></ul>
<p><span class="font2">71</span></p>