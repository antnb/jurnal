---
layout: full_article
title: "Penerapan Metode Adaboost Untuk Multi-Label Classification Pada Dokumen Teks"
author: "I Gede Angga Purnajiwa Arimbawa, Ngurah Agus Sanjaya ER"
categories: jik
canonical_url: https://jurnal.harianregional.com/jik/full-61503 
citation_abstract_html_url: "https://jurnal.harianregional.com/jik/id-61503"
citation_pdf_url: "https://jurnal.harianregional.com/jik/full-61503"  
comments: true
---

<p><span class="font2">p-ISSN: 2301-5373</span></p>
<p><span class="font2">e-ISSN: 2654-5101</span></p>
<p><span class="font2">Jurnal Elektronik Ilmu Komputer Udayana</span></p>
<p><span class="font2">Volume 9, No 1. August 2020</span></p><a name="caption1"></a>
<h1><a name="bookmark0"></a><span class="font3" style="font-weight:bold;font-style:italic;"><a name="bookmark1"></a>Penerapan Metode Adaboost Untuk Multi-Label Classification Pada Dokumen Teks</span></h1>
<p><span class="font2">I Gede Angga Purnajiwa Arimbawa<sup>a1</sup></span><span class="font2" style="font-weight:bold;">, </span><span class="font2">Dr. Ngurah Agus Sanjaya ER, S.Kom., M.Kom <sup>a2</sup></span></p>
<p><span class="font2"><sup>a</sup>Department Computer Science, Udayana University Bali, Indonesia</span></p>
<p><a href="mailto:1arimbawaangga@gmail.com"><span class="font2"><sup>1</sup>arimbawaangga@gmail.com</span></a></p>
<p><a href="mailto:2agus_sanjaya@unud.ac.id"><span class="font2"><sup>2</sup>agus_sanjaya@unud.ac.id</span></a></p>
<p><span class="font2" style="font-weight:bold;font-style:italic;">Abstract</span></p>
<p><span class="font2">Peningkatan jumlah data teks yang signifikan menjadikan alasan untuk menerapkan klasifikasi terhadap teks menjadi sangat jelas. Proses klasifikasi manual yang dilakukan manusia sangat tidak efisien dan efektif. Keterbatasan ini membuka peluang besar pada pengembangan klasifikasi teks secara otomatis. Pada kasus klasifikasi artikel lebih relevan menggunakan klasifikasi multi-label, dikarenakan sebuah artikel dapat dikategorikan ke dalam banyak label. Banyak pendekatan yang dapat digunakan untuk mengimplementasikan klasifikasi multi-label pada teks. Metode supervised-learning dalam bidang machine learning adalah cara yang populer untuk permasalahan ini. Dalam tinjauan yang dilakukan, terdapat jurnal yang melakukan analisis komparatif terhadap metode supervised dalam klasifikasi multi-label. Berdasarkan tinjauan yang dilakukan, Algoritma </span><span class="font2" style="font-style:italic;">AdaBoos</span><span class="font2">t memberikan hasil yang lebih baik dibandingkan algoritma lainnya. Penelitian ini memiliki tujuan untuk mengetahui hasil dan performa dari algoritma </span><span class="font2" style="font-style:italic;">AdaBoost</span><span class="font2"> dengan memanfaatkan dataset artikel komputer berbahasa inggris. Proses penelitian ini dimulai dari pengumpulan data artikel, </span><span class="font2" style="font-style:italic;">text processing</span><span class="font2">, klasifikasi dan evaluasi. Hasil dan performa algoritma </span><span class="font2" style="font-style:italic;">AdaBoost</span><span class="font2"> akan dibandingkan dengan 2 algoritma klasifikasi multi-label lainnya. Berdasarkan penelitian yang dilakukan algoritma </span><span class="font2" style="font-style:italic;">AdaBoost</span><span class="font2"> memberikan hasil lebih optimal pada dataset dengan pembobotan TF-IDF dibandingkan TF. Hasil </span><span class="font2" style="font-style:italic;">accuracy,precision, recall </span><span class="font2">dan </span><span class="font2" style="font-style:italic;">f-measure</span><span class="font2"> yang diberikan lebih tinggi jika dibandingkan dengan algoritma pembanding yang digunakan. Waktu komputasi yang digunakan algoritma </span><span class="font2" style="font-style:italic;">AdaBoost</span><span class="font2"> lebih cepat dibandingkan algoritma pembanding yang digunakan.</span></p>
<p><span class="font2" style="font-weight:bold;font-style:italic;">Keywords: </span><span class="font2" style="font-style:italic;">AdaBoost,Klasifikasi,Multi-label, Artikel</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark2"></a><span class="font2" style="font-weight:bold;"><a name="bookmark3"></a>1. &nbsp;&nbsp;&nbsp;Introduction</span></h2></li></ul>
<p><span class="font2">Penggunaan internet yang semakin meningkat menyebabkan pertumbuhan konten di internet sangat cepat dan pesat. Seperti contoh Wikipedia Indonesia yang selalu mengalami peningkatan pertumbuhan artikel, saat ini jumlah artikel yang dimiliki Wikipedia Indonesia mencapai 48,320,034 dengan lebih dari satu juta label yang dihasilkan oleh kurator [1].</span></p>
<p><span class="font2">Dalam banyak bidang penelitian, data yang berlabel mungkin berjumlah sedikit dan tidak mencukupi dibandingkan data yang berlabel. Dalam bidang tekstual, alasan untuk menerapkan klasifikasi terhadap teks menjadi sangat jelas, dikarenakan pertumbuhan data teks seperti artikel akademik, artikel berita, buku manual, e-mail, buku atau data teks lainnya yang semakin banyak dari hari ke hari. Pertumbuhan yang terjadi lebih cepat dibandingkan kemampuan pengguna informasi untuk mencari, mencerna dan menggunakannya.</span></p>
<p><span class="font2">Klasifikasi data merupakan salah satu cara untuk membantu pengguna informasi. Klasifikasi adalah proses untuk menemukan model yang dapat membedakan kelas data, dengan tujuan untuk dapat</span></p>
<p><span class="font2">memperkirakan kelas dari suatu objek yang labelnya tidak diketahui. Proses klasifikasi manual yang dilakukan manusia sangat tidak efisien dan efektif, bukan hanya karena permasalahan biaya dan waktu, kurator manual berpotensi menghasilkan label klasifikasi yang beragam dan tidak memadai. Ditambah lagi dengan kenyataan bahwa data teks lebih sulit untuk dimengerti dan dikategorikan karena hubungan antara runtutan kata dan kontennya tidak jelas dibandingkan dengan data angka. Keterbatasan dan kendala ini membuka peluang besar pada pengembangan klasifikasi teks secara otomatis.</span></p>
<p><span class="font2">Pada kasus klasifikasi artikel, klasifikasi multi-label menjadi lebih relevan dibandingkan klasifikasi binary tradisional. Seperti contoh artikel “Boosting algorithm: AdaBoost” pada website Medium.com memiliki label Machine Learnig, Data Science dan Algorithms. Klasifikasi multi-label adalah sebuah permasalahan klasifikasi yang memungkinkan untuk mengasosiasikan sebuah data ke dalam beberapa label, sedangkan klasifikasi binary adalah sebuah permasalahan klasifikasi untuk mengasosiasikan sebuah data ke dalam sebuah label.</span></p>
<p><span class="font2">Banyak pendekatan yang dapat digunakan untuk mengimplementasikan klasifikasi multi-label pada teks. Metode supervised-learning dalam bidang machine learning adalah cara yang populer untuk permasalahan ini. Penyelesain masalah klasifikasi multi-label dengan pendekatan supervised-learning dapat dibagi menjadi 2 yaitu problem transformation dan algorithm adaptation. Problem transformation adalah pendekatan dengan cara merubah permasalahan multi-label menjadi satu atau beberapa bermasalahan single-label, sedangkan algorithm adaptation adalah sebuah pendekatan dengan memodifikasi algoritma secara langsung untuk membuat prediksi multi-label.</span></p>
<p><span class="font2">Dalam tinjauan yang dilakukan, terdapat jurnal yang melakukan analisis komparatif terhadap metode supervised dalam klasifikasi multi-label. Terdapat 11 metode supervised problem transformation dan 5 metode algorithm adaptation yang dianalisis. Dari perbandingan yang dilakukan, Algoritma </span><span class="font2" style="font-style:italic;">AdaBoost </span><span class="font2">memberikan hasil yang lebih baik dibandingkan algoritma lainnya. </span><span class="font2" style="font-style:italic;">AdaBoost</span><span class="font2"> mampu meningkatkan akurasi dan meminimalkan Hamming loss error [2].</span></p>
<p><span class="font2">Dalam penelitian ini, peneliti ingin mengetahui hasil dan performa dari algoritma </span><span class="font2" style="font-style:italic;">AdaBoost</span><span class="font2"> dengan memanfaatkan dataset yang berbeda dari tinjauan yang dilakukan yaitu berupa artikel komputer berbahasa inggris. Peneliti menggunakan 2 metode pembobotan fitur pada dataset yaitu TF &amp;&nbsp;TF-IDF, alasan penggunaan 2 metode pembobotan fitur dikarenakan tidak terdapat referensi yang menyatakan pembobotan fitur terbaik untuk permasalahan klasifikasi multi-label, sehingga akan dilakukan perbandingan hasil antara 2 pembobotan fitur untuk mengetahui pembobotan fitur yang dapat memberikan hasil lebih optimal terhadap algoritma AdaBoost.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark4"></a><span class="font2" style="font-weight:bold;"><a name="bookmark5"></a>2. &nbsp;&nbsp;&nbsp;Metode Penelitian</span></h2></li></ul>
<p><span class="font2">Pada bagian metodologi penelitian ini menjelaskan gambaran langkah-langkah yang akan dilakukan dalam menjalankan penelitian ini, langkah-langkah tersebut meliputi pengumpulan data, alur metodologi penelitian, tahap </span><span class="font2" style="font-style:italic;">preprocessing</span><span class="font2">, tahap klasifikasi artikel dan tahap pengujian.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font2">2.1. &nbsp;&nbsp;&nbsp;Pengumpulan Data</span></p></li></ul>
<p><span class="font2">Pada pengumpulan data, data yang digunakan adalah data artikel dari website </span><span class="font2" style="font-style:italic;">medium.com</span><span class="font2">. Untuk mendapatkan data artikel akan dilakukan proses </span><span class="font2" style="font-style:italic;">scrapping</span><span class="font2">. Pengambilan data dari website </span><span class="font2" style="font-style:italic;">medium.com</span><span class="font2"> dikarenakan data yang disediakan sudah diberikan </span><span class="font2" style="font-style:italic;">tag</span><span class="font2"> oleh kurator atau penulis, </span><span class="font2" style="font-style:italic;">tag</span><span class="font2"> tersebut dimanfaatkan sebagai label pada dataset. Data yang diambil adalah judul artikel, isi artikel dan label artikel. Setiap artikel bisa memiliki lebih dari 1 label. Data yang digunakan sebanyak 500 data yang dibagi 90% untuk training dan 10% untuk data testing . Setelah data – data tersebut terkumpul, lalu akan disimpan ke dalam </span><span class="font2" style="font-style:italic;">database.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font2">2.2. &nbsp;&nbsp;&nbsp;Alur Penelitian</span></p></li></ul>
<p><span class="font2">Pada bagian ini akan digambarkan alur secara umum dari penelitian yang akan dilakukan penulis, yaitu dimulai dari pengumpulan data artikel dari medium.com yang kemudian setiap artikel disimpan dalam file berformat .txt, lalu data tersebut akan dilakukan tahap preprocessing, setelah itu dilakukan proses klasifikasi menggunakan algoritma </span><span class="font2" style="font-style:italic;">AdaBoost</span><span class="font2"> dan akan</span></p>
<p><span class="font2">menghasilkan label prediksi, label prediksi yang dihasilkan dapat lebih dari satu label. langkah-langkah ini akan dijelaskan pada Gambar 1 .</span></p><img src="https://jurnal.harianregional.com/media/61503-1.jpg" alt="" style="width:208pt;height:184pt;">
<p><span class="font2" style="font-weight:bold;">Gambar 1. </span><span class="font2">Alur Penelitian Secara Umum</span></p>
<ul style="list-style:none;"><li>
<p><span class="font2">2.3. &nbsp;&nbsp;&nbsp;Text Preprocessing</span></p></li></ul>
<p><span class="font2">Figure 2 menjelaskan detail tentang alur text </span><span class="font2" style="font-style:italic;">processing</span><span class="font2"> dan pembobotan fitur. Pada proses text </span><span class="font2" style="font-style:italic;">processing</span><span class="font2">, data artikel yang didapatkan dari proses </span><span class="font2" style="font-style:italic;">scrapping</span><span class="font2"> dikenakan proses </span><span class="font2" style="font-style:italic;">transform case </span><span class="font2">untuk menyamakan jenis huruf pada data, lalu </span><span class="font2" style="font-style:italic;">tokenized</span><span class="font2"> untuk memotong artikel menjadi </span><span class="font2" style="font-style:italic;">term </span><span class="font2">(kata) , lalu proses </span><span class="font2" style="font-style:italic;">stopword removal</span><span class="font2"> untuk menghapus kata-kata yang dianggap tidak penting dan </span><span class="font2" style="font-style:italic;">lemmatization</span><span class="font2"> untuk mengubah kata ke bentuk kata dasarnya, hasil dari proses – proses ini disebut sebagai data hasil </span><span class="font2" style="font-style:italic;">preprocessing</span><span class="font2">.</span></p>
<p><span class="font2">Setelah itu, data hasil </span><span class="font2" style="font-style:italic;">preprocessing</span><span class="font2"> dikonversi menjadi data angka sehingga nantinya bisa diproses oleh algoritma. Data hasil </span><span class="font2" style="font-style:italic;">preprocessing</span><span class="font2"> dikonversi menggunakan 2 metode pembobotan yaitu </span><span class="font2" style="font-style:italic;">Term Frequency</span><span class="font2"> (TF) dan </span><span class="font2" style="font-style:italic;">Term Frekuensi – Invervse Document Frequency </span><span class="font2">(TF-IDF).</span></p><img src="https://jurnal.harianregional.com/media/61503-2.jpg" alt="" style="width:308pt;height:186pt;">
<p><span class="font2" style="font-weight:bold;">Figure 2. </span><span class="font2">Text Preprocessing &amp;&nbsp;Pembobotan Fitur</span></p>
<ul style="list-style:none;"><li>
<p><span class="font2">2.4. &nbsp;&nbsp;&nbsp;Proses Klasifikasi</span></p></li></ul>
<p><span class="font2">Figure 3 menjelaskan detail proses training algoritma </span><span class="font2" style="font-style:italic;">AdaBoost.</span><span class="font2"> Permasalahan multi-label dipecah menjadi beberapa permasalahan klasifikasi binary. Untuk menentukan sebuah data terklasifikasi ke dalam sebuah label, diperlukan beberapa model. Pada awalnya, harus ditentukan berapa jumlah model yang akan digunakan untuk mengklasifikasikan sebuah data termasuk atau tidak ke dalam sebuah label. Pada penelitian ini, model yang digunakan adalah tree. Jumlah model yang akan digunakan dinyatakan dengan simbol nT. Mulanya setiap sampel pada dataset diberikan bobot sampel yang sama. Lalu dilakukan iterasi untuk menghasilkan tree sejumlah nT. Setiap tree dibentuk berdasarkan fitur yang dapat digunakan mengklasifikasikan dataset dengan hasil terbaik. Setelah tree terbentuk, lalu menentukan Amount of Say dari tree, Amount of Say merupakan nilai kekuatan voting model pada klasifikasi final. Setelah menentukan Amount of Say, dilakukan modifikasi bobot pada tiap sampel.</span></p>
<p><span class="font2">Sampel yang terklasifikasi dengan salah oleh tree yang dibentuk, bobotnya ditingkatnya. Sebaliknya, sampel yang terklasifikasi dengan benar oleh tree yang dibentuk, bobotnya dikurangi. Hal ini bertujuan agar tree yang selanjutnya dibentuk dapat fokus belajar pada keslahan sebelumnya dan memperbaiki kesalahan yang dilakukan tree pendahulunya. Karena terjadi pengurangan dan penambahan bobot pada tiap sampel, maka saat sampel dijumlahkan akan terjadi anomali saat semua bobot sampel dijumlahkan (saat semua bobot dijumlahkan, hasil tidak sama dengan 1), maka dilakukan normalisasi.</span></p>
<p><span class="font2">Tahap selanjutnya yaitu membuat dataset baru (dengan keadaan kosong) lalu diisikan data, yang datanya diambil secara acak dari dataset lama, pengambilan data secara acak dihentikan saat ukuran dataset baru sama dengan dataset lama. Pada proses pengambilan secara acak ini, dimungkinkan untuk terjadi pengambilan data yang sudah pernah diambil sebelumnya. Pada proses pembuatan dataset baru ini, tiap sampel yang sebelumnya terklasifikasi dengan salah</span></p>
<p><span class="font2">akan memiliki peluang terambil lebih dari 1 kali menjadi besar, karena bobotnya yang lebih besar dibandingkan bobot sampel yang sebelumnya terklasifikasi dengan benar.</span></p>
<p><span class="font2">Setelah dataset baru terbentuk, lalu berikan bobot yang sama pada setiap sampel. Lalu lakukan pembentukan tree kembali hingga jumlah tree yang terbentuk sama dengan nT.</span></p><img src="https://jurnal.harianregional.com/media/61503-3.jpg" alt="" style="width:383pt;height:257pt;">
<p><span class="font2" style="font-weight:bold;">Figure 3. </span><span class="font2">Training, Testing dan Evaluasi</span></p>
<p><span class="font2">In this eksperimen we used AdaBoost Algorithm. </span><span class="font7">Algoritma </span><span class="font7" style="font-style:italic;">AdaBoost</span><span class="font7"> dikenalkan oleh Yoav Freund dan Rober Schapire pada tahun 1995 </span><span class="font2">[3]. AdaBoost is an abbreviation of Adaptive Boosting. Boosting is a technique for combining several weak classifiers to make predictions with high accuracy.</span></p>
<p><span class="font2">Boosting is classified as Ensemble Learning. Ensemble Learning in general, is a model that makes predictions based on several different models. By combining several models, ensemble learning tends to be more flexible and less sensitive to data. Boosting trains several individual models sequentially. Each model learns from the mistakes made by the previous model.</span></p>
<p><span class="font2">This algorithm is a method with the concept of supervised learning used for classification. Although the AdaBoost algorithm can now be used in many statistical models, the AdaBoost algorithm was initially applied only to the regression model. The AdaBoost algorithm is used to improve the accuracy of predictions made by using the exponential loss function. The essence of the AdaBoost algorithm is to give more weight to the weak classifier which intends to force the algorithm to concentrate on the weak classifier. Weak classifier is a classification that produces predictions that are slightly better than random guessing.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font2" style="font-weight:bold;">Table 1. </span><span class="font2">AdaBoost Pseudocode</span></p></li></ul>
<p><span class="font6">Pseudocode</span></p>
<p><span class="font6" style="font-weight:bold;">Input : </span><span class="font6">Dataset </span><span class="font6" style="font-style:italic;">D</span><span class="font6"> = {(x1,y1),(x2,y2),...,(x</span><span class="font4">m</span><span class="font6">,y</span><span class="font4">m</span><span class="font6">)}</span></p>
<p><span class="font6">Base Learning Algorithm DecisionTree</span></p>
<p><span class="font6">Number of learning rounds T</span></p>
<p><span class="font6" style="font-weight:bold;">Process :</span></p>
<p><span class="font6">D1(i) = 1/m //initialize the weight distribution</span></p>
<p><span class="font6">For t = 1,...,T:</span></p>
<p><span class="font6">H</span><span class="font4">t </span><span class="font6">= DecisionTree(</span><span class="font6" style="font-style:italic;">D</span><span class="font6">,D</span><span class="font4">t</span><span class="font6">) &nbsp;&nbsp;//Train a weak learner h</span><span class="font4">t from </span><span class="font6" style="font-style:italic;">D</span><span class="font6"> using distribution D</span><span class="font4">t</span></p>
<p><span class="font6">E</span><span class="font4">t </span><span class="font6">= Pr</span><span class="font4">i~Di &nbsp;</span><span class="font6">//Measure the error of h</span><span class="font4">t</span></p>
<ul style="list-style:none;"><li>
<p><span class="font14">1-</span><span class="font14" style="font-style:italic;"> &nbsp;&nbsp;&nbsp;Et^</span></p></li></ul>
<p><span class="font6">a</span><span class="font4">t </span><span class="font6">= ½ (----</span><span class="font16">) </span><span class="font6">//Determine the weight of h</span><span class="font4">t</span></p>
<p><span class="font15" style="font-style:italic;">E<sub>t</sub></span></p>
<p><span class="font16" style="font-style:italic;"><sub>π =</sub> </span><span class="font16" style="font-style:italic;text-decoration:underline;">D</span><span class="font14" style="font-style:italic;text-decoration:underline;">tW</span><span class="font14" style="font-style:italic;"> &nbsp;&nbsp;&nbsp;&nbsp;</span><span class="font16" style="font-style:italic;">(ew(-a<sub>t</sub>)if h</span><span class="font14" style="font-style:italic;"><sub>t</sub></span><span class="font16" style="font-style:italic;">(x</span><span class="font14" style="font-style:italic;"><sub>l</sub></span><span class="font16" style="font-style:italic;">)= y</span><span class="font14" style="font-style:italic;"><sub>l</sub></span></p>
<p><span class="font6"><sup>t+1</sup> </span><span class="font15" style="font-style:italic;">Z</span><span class="font13" style="font-style:italic;">t</span><span class="font16"> <sup>x</sup> (.exp(α<sub>t</sub>) </span><span class="font16" style="font-style:italic;">if h</span><span class="font14" style="font-style:italic;"><sub>t</sub></span><span class="font16" style="font-style:italic;">(x<sub>i</sub>) ≠ y</span><span class="font14" style="font-style:italic;"><sub>i</sub></span></p>
<p><span class="font6">= </span><span class="font10" style="font-style:italic;font-variant:small-caps;text-decoration:line-through;">dm</span><span class="font9" style="font-style:italic;text-decoration:line-through;"> eχp(a<sup>t</sup>y<sub>i</sub>h<sup>t</sup>(x<sub>i</sub>))</span><span class="font6" style="font-style:italic;"> &nbsp;//Update</span><span class="font6"> the distributuion, where Z</span><span class="font4">t </span><span class="font6">is a</span></p>
<p><span class="font6">normalization factor which enables D</span><span class="font4">t+1 </span><span class="font6">be a distribution</span></p>
<p><span class="font6" style="font-weight:bold;">Output : </span><span class="font6">H(x) = sign(</span><span class="font16">∑</span><span class="font14">[=ι </span><span class="font16" style="font-style:italic;">a<sub>t</sub>h<sub>t</sub>Xx))</span></p>
<ul style="list-style:none;"><li>
<p><span class="font2">2.5. &nbsp;&nbsp;&nbsp;Pengujian dan Evaluasi</span></p></li></ul>
<p><span class="font2">Metode pengujian yang digunakan adalah </span><span class="font2" style="font-style:italic;">Cross Validation. Cross-validation (CV)</span><span class="font2"> adalah metode statistik yang dapat digunakan untuk mengevaluasi kinerja model atau algoritma dimana data dipisahkan menjadi dua subset yaitu data proses pembelajaran dan data validasi / evaluasi. Model atau algoritma dilatih oleh subset pembelajaran dan divalidasi oleh subset validasi. Selanjutnya pemilihan jenis </span><span class="font2" style="font-style:italic;">Cross Validatio</span><span class="font2">n dapat didasarkan pada ukuran dataset. Biasanya </span><span class="font2" style="font-style:italic;">Cross Validation K-fold</span><span class="font2"> digunakan karena dapat mengurangi waktu komputasi dengan tetap menjaga keakuratan estimasi.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font2">10 </span><span class="font2" style="font-style:italic;">fold Cross Validation</span><span class="font2"> adalah salah satu </span><span class="font2" style="font-style:italic;">K fold Cross Validation</span><span class="font2"> yang direkomendasikan untuk pemilihan model terbaik karena cenderung memberikan estimasi akurasi yang kurang bisa dibandingkan dengan </span><span class="font2" style="font-style:italic;">Cross Validation</span><span class="font2"> biasa, </span><span class="font2" style="font-style:italic;">leave-one-out Cross Validation</span><span class="font2"> dan </span><span class="font2" style="font-style:italic;">bootstrap</span><span class="font2">. Dalam 10 </span><span class="font2" style="font-style:italic;">fold Cross Validation</span><span class="font2">, data dibagi menjadi 10 </span><span class="font2" style="font-style:italic;">fold</span><span class="font2"> berukuran kira-kira sama, sehingga kita memiliki 10 subset data untuk mengevaluasi kinerja model atau algoritma. Untuk masing-masing dari 10 subset data tersebut, </span><span class="font2" style="font-style:italic;">Cross Validation</span><span class="font2"> akan menggunakan 9 </span><span class="font2" style="font-style:italic;">fold </span><span class="font2">untuk pelatihan dan 1 </span><span class="font2" style="font-style:italic;">fold</span><span class="font2"> untuk pengujian. Mesin akan mengetahui label dari data pada </span><span class="font2" style="font-style:italic;">fold </span><span class="font2">pelatihan untuk kebutuhan training, sedangkan mesin tidak akan mengetahui label dari data pada </span><span class="font2" style="font-style:italic;">fold</span><span class="font2"> pengujian.</span></p></li></ul>
<p><span class="font2">Pada penelitian ini akan dilakukan pengujian terhadap hasil klasifikasi dari data testing. Pengujian dimaksudkan untuk mengukur keakuratan hasil dari model yang digunakan. Pengukuran yang akan dilakukan adalah pengukuran </span><span class="font2" style="font-style:italic;">Accuracy, Precision, Recall dan F-measure. Accuracy</span><span class="font2"> adalah tingkat kedekatan antara nilai aktual dengan nilai prediksi. </span><span class="font2" style="font-style:italic;">Precision </span><span class="font2">adalah proporsi kasus yang diprediksi positif yang juga positif benar [4] pada data sebenarnya. </span><span class="font2" style="font-style:italic;">Recall</span><span class="font2"> adalah proporsi dari kasus positif kejadian sebenarnya yang diprediksi positif benar. </span><span class="font2" style="font-style:italic;">F-measure</span><span class="font2"> adalah rata-rata harmonik dari nilai </span><span class="font2" style="font-style:italic;">precision</span><span class="font2"> dan </span><span class="font2" style="font-style:italic;">recall [5].</span><span class="font2"> Dalam pengukuran terhadap kasus multi-label, </span><span class="font2" style="font-style:italic;">confused metrics</span><span class="font2"> tradisional tidak tepat untuk digunakan. Godbole &amp;&nbsp;Sarawagi [6] mengembangkan definisi dari </span><span class="font2" style="font-style:italic;">Accuracy, Precision, Recall dan F-measure </span><span class="font2">seperti persamaan dibawah ini, agar dapat digunakan terhadap kasus klasifikasi multi-label. Untuk setiap objek i,</span></p>
<ul style="list-style:none;"><li>
<p><span class="font2">• &nbsp;&nbsp;&nbsp;Ci melambangkan label yang benar</span></p></li>
<li>
<p><span class="font2">• &nbsp;&nbsp;&nbsp;Pi melambangkan label yang di prediksi</span></p></li>
<li>
<p><span class="font2">• &nbsp;&nbsp;&nbsp;n melambangkan jumlah observasi</span></p></li>
<li>
<p><span class="font2">• &nbsp;&nbsp;&nbsp;| | melambangkan jumlah data pada himpunan label</span></p></li></ul>
<p><span class="font15" style="font-style:italic;">n</span></p>
<ul style="list-style:none;"><li>
<p><span class="font16">1V | </span><span class="font16" style="font-style:italic;">Ci</span><span class="font16"> ∩ </span><span class="font16" style="font-style:italic;">Pi</span><span class="font16"> |</span></p></li></ul>
<p><a href="#bookmark6"><span class="font16" style="font-style:italic;">A<sub>mcy</sub>= -∑ Ci <sub>u</sub>p<sub>i</sub></span><span class="font16"> |(1)</span></a></p>
<p><span class="font15" style="font-style:italic;">i = 1</span></p>
<p><span class="font11"><sup>n</sup></span></p>
<p><a href="#bookmark7"><span class="font16" style="font-style:italic;">Precision =</span><span class="font16"> <sup>1</sup>∑ <sup>l</sup>⅛∩^(2)</span></a></p>
<ul style="list-style:none;"><li>
<p><a href="#bookmark8"><span class="font16" style="font-variant:small-caps;">-Zj</span><span class="font16"> </span><span class="font12">∣</span><span class="font16"> </span><span class="font16" style="font-style:italic;">Pi </span><span class="font12" style="font-style:italic;">∣</span><span class="font16" style="font-style:italic;"></span></a></p></li></ul>
<p><span class="font15" style="font-style:italic;">i=ι</span></p>
<p><span class="font15" style="font-style:italic;">n</span></p>
<p><a href="#bookmark9"><span class="font16" style="font-style:italic;"><sub>s</sub>ecal<sub>l</sub>= </span><span class="font16" style="font-variant:small-caps;">'V<sup>c</sup>-J<sup>p</sup></span><span class="font16">(3)</span></a></p>
<ul style="list-style:none;"><li>
<p><span class="font16" style="font-style:italic;">— &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="font12" style="font-style:italic;">∣</span><span class="font16" style="font-style:italic;"> Ci </span><span class="font12" style="font-style:italic;">∣</span></p></li></ul>
<p><span class="font15" style="font-style:italic;">i=ι</span></p>
<div>
<p><span class="font16" style="font-style:italic;">F - measure</span><span class="font16"> =</span></p>
</div><br clear="all">
<div>
<p><span class="font15" style="font-style:italic;">n</span></p>
<p><span class="font16">1y 2 | </span><span class="font16" style="font-style:italic;">Ci</span><span class="font16"> ∩ </span><span class="font16" style="font-style:italic;">Pi</span><span class="font16"> | </span><span class="font16" style="font-style:italic;">n∑</span><span class="font16"> | </span><span class="font16" style="font-style:italic;">Ci</span><span class="font16"> | + </span><span class="font12" style="font-style:italic;">∣</span><span class="font16" style="font-style:italic;">Pi</span><span class="font16"> |</span></p>
<p><span class="font15" style="font-style:italic;">i=ι</span></p>
</div><br clear="all">
<div>
<p><span class="font16">(4)</span></p>
</div><br clear="all">
<p><span class="font2">Untuk menguji performa dilakukan pengujian dengan mengukur rata-rata waktu komputasi algoritma. Waktu komputasi algoritma </span><span class="font2" style="font-style:italic;">AdaBoost</span><span class="font2"> akan dibandingkan dengan waktu komputasi algoritma lain yang termasuk </span><span class="font2" style="font-style:italic;">algorithm adaptation</span><span class="font2"> [2] dengan dataset yang sama. Untuk setiap objek i, S</span><span class="font0">i </span><span class="font2">melambangkan waktu komputasi.</span></p>
<p><span class="font15" style="font-style:italic;">n</span></p>
<div>
<p><span class="font17">Performa =</span></p>
</div><br clear="all">
<p><span class="font17"><sup>1</sup> ∑</span></p>
<div>
<p><span class="font17">(15)</span></p>
</div><br clear="all">
<p><span class="font17" style="font-style:italic;">n</span></p>
<p><span class="font15" style="font-style:italic;">i=ι</span></p>
<p><span class="font2">Algoritma yang digunakan sebagai pembanding adalah algoritma C4.5 dan </span><span class="font2" style="font-style:italic;">Backpropagation algorithm for Multilabel Learning (BP-MLL).</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark10"></a><span class="font2" style="font-weight:bold;"><a name="bookmark11"></a>3. &nbsp;&nbsp;&nbsp;Hasil dan Pembahasan</span></h2></li></ul>
<p><span class="font2">Untuk membuktikan algoritma AdaBoost bekerja dengan optimal, penulis melakukan eksmerimen dengan dataset 5 label dan 1.287 data. Label yang digunakan adalah </span><span class="font2" style="font-style:italic;">Algorithm, Big Data, E-Commerce, Machine Learning</span><span class="font2"> dan </span><span class="font2" style="font-style:italic;">Programig.</span></p>
<p><span class="font2" style="font-weight:bold;">Table 2. </span><span class="font2">Tabel Distribusi Pada Dataset</span></p>
<table border="1">
<tr><td style="vertical-align:middle;">
<p><span class="font7" style="font-weight:bold;">Label</span></p></td><td style="vertical-align:middle;">
<p><span class="font7" style="font-weight:bold;">Kemunculan</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font7">Programing</span></p></td><td style="vertical-align:bottom;">
<p><span class="font7">312</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font7">Machine Learning</span></p></td><td style="vertical-align:bottom;">
<p><span class="font7">412</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font7">Big data</span></p></td><td style="vertical-align:bottom;">
<p><span class="font7">319</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font7">Algorithm</span></p></td><td style="vertical-align:bottom;">
<p><span class="font7">303</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font7">E-Commerce</span></p></td><td style="vertical-align:middle;">
<p><span class="font7">317</span></p></td></tr>
</table>
<ul style="list-style:none;"><li>
<p><span class="font2">3.1. &nbsp;&nbsp;&nbsp;Performa Terbaik dari Metode Pembobotan</span></p></li></ul>
<p><span class="font2">Eksperimen menggunakan algoritma AdaBoost dengan tujuan membandingkan dataset dengan pembobotan TF atau TF-IDF yang menghasilkan hasil yang lebih optimal pada penerapan algoritma AdaBoost. Proses eksperimental menggunakan dua variabel beragam, yaitu variabel panjang fitur yang digunakan dalam dataset dan jumlah variabel estimator yang digunakan dalam algoritma AdaBoost. Panjang fitur dataset yang digunakan dalam percobaan ini mulai dari 100, 200, 300, 400, 500, 600, 700, 800, 900 dan 1000. Jumlah penduga yang digunakan dalam percobaan ini mulai dari 10, 20, 30, 40, 50, 60, 70, 80, 90 dan 100. Hasil percobaan ditunjukkan pada Gambar 4.</span></p>
<p><span class="font2">Dari percobaan yang dilakukan disimpulkan bahwa penggunaan dataset dengan bobot TF-IDF selalu menghasilkan akurasi, presisi, daya ingat dan ukuran-f yang lebih tinggi dibandingkan dengan dataset dengan bobot TF.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font2">3.2. &nbsp;&nbsp;&nbsp;Eksperimen Menggunakan Variasi Panjang Fitur</span></p></li></ul>
<p><span class="font2">Eksperimen yang menggunakan algoritma AdaBoost dengan tujuan membandingkan hasil klasifikasi menggunakan berbagai panjang fitur dan mengetahui panjang fitur yang memberikan hasil optimal menggunakan klasifikasi algoritma AdaBoost. Proses eksperimental menggunakan dua variabel beragam, yaitu variabel panjang fitur yang digunakan dalam dataset dan jumlah variabel estimator yang digunakan dalam algoritma AdaBoost. Panjang fitur dataset yang digunakan dalam percobaan ini mulai dari 100, 200, 300, 400, 500, 600, 700, 800, 900 dan 1000. Jumlah penduga yang digunakan dalam percobaan ini mulai dari 10, 20, 30, 40, 50, 60, 70, 80, 90 dan 100. Hasil percobaan ditunjukkan pada Gambar 5 dan 6.</span></p>
<p><span class="font2">Dari percobaan yang dilakukan, diketahui bahwa peningkatan penggunaan jumlah estimator dalam algoritma AdaBoost menyebabkan peningkatan hasil akurasi, presisi, recall dan f-mengukur dalam setiap dataset dengan berbagai panjang fitur. Hasil optimal dari percobaan</span></p>
<p><span class="font2">yang dilakukan adalah akurasi 0,987, presisi 0,99, recall 0,99 dan f-ukuran 0,989 dengan menggunakan 100 estimator dan dataset dengan 900 fitur panjang.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font2">3.3. &nbsp;&nbsp;&nbsp;Membandingkan Hasil AdaBoost dengan C4.5 dan BPMLL</span></p></li></ul>
<p><span class="font2">Perbandingan dibuat menggunakan hasil optimal dari masing-masing algoritma. Hasil dari algoritma AdaBoost digunakan saat menggunakan 100 estimator dan hasil BPMLL digunakan saat menggunakan 5 hidden layar, 50 epochs dan learning rate 0,1. Hasil percobaan ditunjukkan pada Gambar 6.</span></p>
<div>
<p><span class="font8">Perbandingan Accuracy</span></p>
<p><span class="font8">Menggunakan 30 Estimator</span></p>
</div><br clear="all">
<div>
<p><span class="font8">Perbandingan Precision</span></p>
<p><span class="font8">Menggunakan 30 Estimator</span></p>
</div><br clear="all">
<div><img src="https://jurnal.harianregional.com/media/61503-4.jpg" alt="" style="width:175pt;height:127pt;">
<p><span class="font1">■</span><span class="font5"> TF </span><span class="font1">■</span><span class="font5"> TF-IDF</span></p>
</div><br clear="all">
<div><img src="https://jurnal.harianregional.com/media/61503-5.jpg" alt="" style="width:175pt;height:127pt;">
<p><span class="font1">■</span><span class="font5"> TF </span><span class="font1">■</span><span class="font5"> TF-IDF</span></p>
</div><br clear="all">
<div><img src="https://jurnal.harianregional.com/media/61503-6.jpg" alt="" style="width:372pt;height:172pt;">
<p><span class="font1">■</span><span class="font5"> TF </span><span class="font1">■</span><span class="font5"> TF-IDF</span></p>
<p><span class="font1">■</span><span class="font5"> TF </span><span class="font1">■</span><span class="font5"> TF-IDF</span></p>
<p><span class="font2" style="font-weight:bold;">Figure 4. </span><span class="font2">Grafik Accuracy, Precision, Recall and F-Measure untuk membandingkan hasil TF and IDF dengan 30 Estimators</span></p>
</div><br clear="all">
<p><span class="font8">Perbandingan Akurasi Pada Variasi Panjang Fitur</span></p><img src="https://jurnal.harianregional.com/media/61503-7.jpg" alt="" style="width:394pt;height:151pt;">
<p><span class="font1">■</span><span class="font5"> 100 Feature </span><span class="font1">■</span><span class="font5"> 200 Feature </span><span class="font1">■</span><span class="font5"> 300 Feature </span><span class="font1">■</span><span class="font5"> 400 Feature </span><span class="font1">■</span><span class="font5"> 500 Feature</span></p>
<p><span class="font1">■</span><span class="font5"> 600 Feature </span><span class="font1">■</span><span class="font5"> 700 Feature </span><span class="font1">■</span><span class="font5"> 800 Feature </span><span class="font1">■</span><span class="font5"> 900 Feature </span><span class="font1">■</span><span class="font5"> 1000 Feature</span></p>
<p><span class="font8">Perbandingan Precision Pada Variasi Panjang Fitur</span></p><img src="https://jurnal.harianregional.com/media/61503-8.jpg" alt="" style="width:394pt;height:173pt;">
<p><span class="font1">■</span><span class="font5"> 100 Feature </span><span class="font1">■</span><span class="font5"> 200 Feature </span><span class="font1">■</span><span class="font5"> 300 Feature </span><span class="font1">■</span><span class="font5"> 400 Feature </span><span class="font1">■</span><span class="font5"> 500 Feature</span></p>
<p><span class="font1">■</span><span class="font5"> 600 Feature </span><span class="font1">■</span><span class="font5"> 700 Feature </span><span class="font1">■</span><span class="font5"> 800 Feature </span><span class="font1">■</span><span class="font5"> 900 Feature </span><span class="font1">■</span><span class="font5"> 1000 Feature</span></p>
<p><span class="font2" style="font-weight:bold;">Figure 5. </span><span class="font2">Grafik Accuracy dan Precision untuk membandingkan hasil dengan variasi panjang fitur</span></p>
<p><span class="font8">Perbandingan F-Measure Pada Variasi Panjang Fitur</span></p><img src="https://jurnal.harianregional.com/media/61503-9.jpg" alt="" style="width:377pt;height:162pt;">
<p><span class="font5">EstimatorEstimatorEstimatorEstimatorEstimatorEstimatorEstimatorEstimatorEstimatorEstimator</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1">■</span><span class="font5"> &nbsp;&nbsp;&nbsp;100 Feature </span><span class="font1">■</span><span class="font5"> 200 Feature </span><span class="font1">■</span><span class="font5"> 300 Feature </span><span class="font1">■</span><span class="font5"> 400 Feature </span><span class="font1">■</span><span class="font5"> 500 Feature</span></p></li>
<li>
<p><span class="font1">■</span><span class="font5"> &nbsp;&nbsp;&nbsp;600 Feature </span><span class="font1">■</span><span class="font5"> 700 Feature </span><span class="font1">■</span><span class="font5"> 800 Feature </span><span class="font1">■</span><span class="font5"> 900 Feature </span><span class="font1">■</span><span class="font5"> 1000 Feature</span></p></li></ul>
<p><span class="font8">Perbandingan Recall Pada Variasi Panjang Fitur</span></p><img src="https://jurnal.harianregional.com/media/61503-10.jpg" alt="" style="width:377pt;height:158pt;">
<p><span class="font5">EstimatorEstimatorEstimatorEstimatorEstimatorEstimatorEstimatorEstimatorEstimatorEstimator</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1">■</span><span class="font5"> &nbsp;&nbsp;&nbsp;100 Feature </span><span class="font1">■</span><span class="font5"> 200 Feature </span><span class="font1">■</span><span class="font5"> 300 Feature </span><span class="font1">■</span><span class="font5"> 400 Feature </span><span class="font1">■</span><span class="font5"> 500 Feature</span></p></li>
<li>
<p><span class="font1">■</span><span class="font5"> &nbsp;&nbsp;&nbsp;600 Feature </span><span class="font1">■</span><span class="font5"> 700 Feature </span><span class="font1">■</span><span class="font5"> 800 Feature </span><span class="font1">■</span><span class="font5"> 900 Feature </span><span class="font1">■</span><span class="font5"> 1000 Feature</span></p></li></ul>
<p><span class="font2" style="font-weight:bold;">Figure 6. </span><span class="font2">Grafik Recall dan F-Measure untuk membandingkan hasil dengan variasi panjang fitur</span></p>
<div>
<p><span class="font8">Accuracy Adaboost vs C4.5 vs BPMLL</span></p>
</div><br clear="all">
<div>
<p><span class="font8">Precision Adaboost vs C4.5 vs BPMLL</span></p>
</div><br clear="all">
<div><img src="https://jurnal.harianregional.com/media/61503-11.jpg" alt="" style="width:198pt;height:120pt;">
<p><span class="font1">■</span><span class="font5"> AdaBoost </span><span class="font1">■</span><span class="font5"> C4.5 </span><span class="font1">■</span><span class="font5"> BPMLL</span></p>
</div><br clear="all">
<div><img src="https://jurnal.harianregional.com/media/61503-12.jpg" alt="" style="width:198pt;height:120pt;">
<p><span class="font1">■</span><span class="font5"> AdaBoost </span><span class="font1">■</span><span class="font5"> C4.5 </span><span class="font1">■</span><span class="font5"> BPMLL</span></p>
</div><br clear="all">
<div><img src="https://jurnal.harianregional.com/media/61503-13.jpg" alt="" style="width:427pt;height:177pt;">
<p><span class="font2" style="font-weight:bold;">Figure 7. </span><span class="font2">Grafik Accuracy, Precision, Recall, F-Measure Membandingkan AdaBoost, C4.5 dan BPMLL</span></p>
</div><br clear="all">
<p><span class="font2">Dari percobaan yang dilakukan, algoritma AdaBoost memberikan hasil akurasi, presisi dan f-mengukur yang lebih tinggi dibandingkan dengan hasil dari algoritma C4.5 dan BPMLL, sedangkan untuk hasil recall algoritma AdaBoost dan BPMLL memiliki perbedaan yang sedikit dan berada di atas 0,9 , ini berarti algoritma AdaBoost dan BPMLL memiliki tingkat keberhasilan yang baik dalam mengklasifikasikan. Hasil recall dari algoritma AdaBoost dan BPMLL lebih tinggi dari pada algoritma C4.5. Dari percobaan yang dilakukan, dapat disimpulkan bahwa algoritma AdaBoost memberikan hasil yang lebih optimal dibandingkan dengan algoritma C4.5 dan BPMLL.</span></p>
<div>
<p><span class="font2">3.4.</span></p>
</div><br clear="all">
<p><span class="font2">Membandingkan Efisiensi AdaBoost dengan C4.5 dan BPMLL</span></p>
<p><span class="font2">Untuk mengetahui efisiensi dari algoritma AdaBoost dilakukan perbandingan waktu komputasi dari algoritma AdaBoost dengan algoritma waktu komputasi C4.5 dan BPMLL. Waktu komputasi dicatat dalam satuan detik fraksional (detik diwakili dalam format float). Perbandingan waktu komputasi antara algoritma AdaBoost dan C4.5 dilakukan. Hasil eksperimen yang digunakan adalah algoritma AdaBoost menggunakan 10 estimator dengan tingkat akurasi 0,65 hingga 0,68 (tingkat akurasi terendah yang diperoleh selama percobaan). Algoritma C4.5 yang digunakan memiliki tingkat akurasi 0,495 - 0,479. Dataset yang digunakan dalam percobaan ini adalah dataset dengan 5 label dan bobot TF-IDF. Hasil percobaan ditunjukkan pada Gambar 8.</span></p><img src="https://jurnal.harianregional.com/media/61503-14.jpg" alt="" style="width:353pt;height:162pt;">
<p><span class="font1">■</span><span class="font5"> AdaBoost </span><span class="font1">■</span><span class="font5"> C4.5</span></p>
<p><span class="font2" style="font-weight:bold;">Figure 8. </span><span class="font2">Grafik untuk membandingkan Waktu Komputasi AdaBoost &amp;&nbsp;C4.5</span></p>
<p><span class="font2">Dari percobaan yang dilakukan, diketahui bahwa algoritma C4.5 memiliki waktu komputasi yang jauh lebih cepat dibandingkan dengan algoritma AdaBoost. Algoritma AdaBoost membutuhkan waktu dari 0,413 hingga 1,931 untuk mencapai akurasi 0,65 - 0,68 sedangkan C4,5 hanya membutuhkan 0,053 - 0,249 untuk mendapatkan akurasi 0,495 - 0,479. Meskipun lebih cepat, algoritma C4.5 tidak dapat menandingi hasil yang diberikan oleh algoritma AdaBoost.</span></p>
<p><span class="font2">Dilakukan perbandingan waktu perhitungan antara algoritma AdaBoost dan BPMLL. Hasil eksperimen yang digunakan adalah algoritma AdaBoost menggunakan 30 estimator dengan tingkat akurasi 0,73 - 0,83. Algoritma BPMLL yang digunakan memiliki tingkat akurasi 0,74 hingga 0,83 dengan 5 hidden layer, 50 epochs dan learning rate 0,1. Dataset yang digunakan dalam percobaan ini adalah dataset dengan 5 label dan bobot TF-IDF. Hasil percobaan ditunjukkan pada Gambar 9.</span></p>
<p><span class="font2">Dari percobaan yang dilakukan, diketahui bahwa algoritma AdaBoost memiliki waktu komputasi yang jauh lebih cepat dibandingkan dengan algoritma BPMLL. Algoritma AdaBoost membutuhkan waktu dari 1.501 hingga 7.188 untuk mencapai akurasi 0.73 - 0.83 sementara BPMLL membutuhkan 52.12 - 86.54 untuk mendapatkan akurasi 0.74 - 0.83. Dengan demikian dapat disimpulkan bahwa algoritma AdaBoost membutuhkan waktu komputasi yang lebih sedikit daripada BPMLL untuk mencapai akurasi yang sama.</span></p>
<p><span class="font8">Waktu Komputasi Adaboost vs C4.5 vs BPMLL</span></p><img src="https://jurnal.harianregional.com/media/61503-15.jpg" alt="" style="width:318pt;height:131pt;">
<p><span class="font1">■</span><span class="font5"> AdaBoost </span><span class="font1">■</span><span class="font5"> BPMLL</span></p>
<p><span class="font2" style="font-weight:bold;">Figure 9. </span><span class="font2">Grafik untuk membandingkan Waktu Komputasi AdaBoost &amp;&nbsp;BPMLL</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark12"></a><span class="font2" style="font-weight:bold;"><a name="bookmark13"></a>4. &nbsp;&nbsp;&nbsp;Conclusion</span></h2></li></ul>
<p><span class="font7">Dari penelitian yang telah dilakukan didapatkan kesimpulan sebagai berikut</span><span class="font2">:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font2" style="font-style:italic;">a.</span><span class="font2"> &nbsp;Penggunaan Dataset TF-IDF menghasilkan hasil </span><span class="font2" style="font-style:italic;">accuracy, precision, recall</span><span class="font2"> dan </span><span class="font2" style="font-style:italic;">f-measure</span></p></li></ul>
<p><span class="font2">yang lebih tinggi dibandingkan dataste TF pada klasifikasi Algoritma </span><span class="font2" style="font-style:italic;">AdaBoost.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font2" style="font-style:italic;">b.</span><span class="font2"> &nbsp;Peningkatan jumlah estimator pada algoritma </span><span class="font2" style="font-style:italic;">AdaBoost</span><span class="font2"> menyebabkan peningkatan hasil</span></p></li></ul>
<p><span class="font2" style="font-style:italic;">accuracy, precision, recall</span><span class="font2"> dan </span><span class="font2" style="font-style:italic;">f-measure</span><span class="font2"> pada klasifikasi.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font2" style="font-style:italic;">c.</span><span class="font2"> &nbsp;&nbsp;&nbsp;Dari eksperimen yang dilakukan, penggunaan 100 estimator pada algoritma </span><span class="font2" style="font-style:italic;">AdaBoost</span><span class="font2"> dan menggunakan dataset TF-IDF dengan panjang fitur 900 memberikan hasil yang teroptimal.</span></p></li>
<li>
<p><span class="font2" style="font-style:italic;">d.</span><span class="font2"> &nbsp;Algoritma </span><span class="font2" style="font-style:italic;">AdaBoost</span><span class="font2"> memberikan hasil yang lebih optimal dibandingkan algoritma C4.5 dan</span></p></li></ul>
<p><span class="font2">BPMLL.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font2" style="font-style:italic;">e.</span><span class="font2"> &nbsp;Algoritma </span><span class="font2" style="font-style:italic;">AdaBoost</span><span class="font2"> memerlukan waktu komputasi yang lebih sedikit dibandingkan BPMLL</span></p></li></ul>
<p><span class="font2">untuk mencapai tingkat </span><span class="font2" style="font-style:italic;">accuracy</span><span class="font2"> yang setara. Sedangkan Algoritma </span><span class="font2" style="font-style:italic;">AdaBoost</span><span class="font2"> memerlukan waktu komputasi yang lebih banyak dibandingkan algoritma C4.5, namun hasil </span><span class="font2" style="font-style:italic;">accuracy, precision, recall</span><span class="font2"> dan </span><span class="font2" style="font-style:italic;">f-measure</span><span class="font2"> pada algoritma C4.5 tidak mampu menyaingi algoritma </span><span class="font2" style="font-style:italic;">AdaBoost.</span></p>
<h2><a name="bookmark14"></a><span class="font2" style="font-weight:bold;"><a name="bookmark15"></a>Referensi</span></h2>
<ul style="list-style:none;"><li>
<p><span class="font2">[1] &nbsp;&nbsp;&nbsp;Wikipedia. </span><span class="font2" style="font-style:italic;">Wikipedia:Statistik</span><span class="font2">. Retrieved from Wikipedia Ensiklopedia Bebas: </span><a href="https://id.wikipedia.org/wiki/Wikipedia:Statistik"><span class="font2">https://id.wikipedia.org/wiki/Wikipedia:Statistik </span></a><span class="font2">. 2019 (1)</span></p></li>
<li>
<p><span class="font2">[2] &nbsp;&nbsp;&nbsp;Dharmadhikari, S. C., Ingle, M., &amp;&nbsp;Kulkarni, P. A Comparative Analysis of Supervised Multi-label Text Classification Methods. </span><span class="font2" style="font-style:italic;">International Journal of Engineering Research and Applications (IJERA)</span><span class="font2">. 2011. (2)</span></p></li>
<li>
<p><span class="font2">[3] &nbsp;&nbsp;&nbsp;Schapire, R. E., &amp;&nbsp;Singer, Y. BoosTexter: A boosting-based system for text categorization.</span></p></li></ul>
<p><span class="font2" style="font-style:italic;">Machine learning</span><span class="font2">, 135-168. 2000. (3)</span></p>
<ul style="list-style:none;"><li>
<p><span class="font2">[4] &nbsp;&nbsp;&nbsp;Powers, D. M. Evaluation: from precision, recall and F-measure to ROC, informedness, markedness and correlation. 2011. (4)</span></p></li>
<li>
<p><span class="font2">[5] &nbsp;&nbsp;&nbsp;Han, J., &amp;&nbsp;Kamber, M. Data Mining: Concepts and Techniques. 2012. (5)</span></p></li>
<li>
<p><span class="font2">[6] &nbsp;&nbsp;&nbsp;Godbole, S., &amp;&nbsp;Sarawagi, S. Discriminative methods for multi-labeled classification. </span><span class="font2" style="font-style:italic;">Pacific-Asia conference on knowledge discovery and data mining</span><span class="font2"> (pp. 22-30). Springer. 2004. (6)</span></p></li></ul>
<p><span class="font2">140</span></p>