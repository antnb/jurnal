---
layout: full_article
title: "Analisis Sentimen dan Pemodelan Topik Ulasan Aplikasi Noice Menggunakan XGBoost dan LDA"
author: "Alim Ikegami, I Dewa Made Bayu Atmaja Darmawan"
categories: jnatia
canonical_url: https://jurnal.harianregional.com/jnatia/full-92679 
citation_abstract_html_url: "https://jurnal.harianregional.com/jnatia/id-92679"
citation_pdf_url: "https://jurnal.harianregional.com/jnatia/full-92679"  
comments: true
---

<p><span class="font2">JNATIA Volume 1, Nomor 1, November 2022</span></p>
<p><span class="font2">Jurnal Nasional Teknologi Informasi dan Aplikasinya</span></p><a name="caption1"></a>
<h1><a name="bookmark0"></a><span class="font4" style="font-weight:bold;"><a name="bookmark1"></a>Analisis Sentimen dan Pemodelan Topik Ulasan Aplikasi Noice Menggunakan XGBoost dan LDA</span></h1>
<p><span class="font2">Alim Ikegami<sup>a1</sup></span><span class="font2" style="font-weight:bold;">, </span><span class="font2">I Dewa Made Bayu Atmaja Darmawan<sup>a2</sup></span></p>
<p><span class="font2"><sup>a</sup>Program Studi Informatika, Universitas Udayana Jimbaran, Badung, Bali, Indonesia, 80361 </span><a href="mailto:1alimikegami1@gmail.com"><span class="font2"><sup>1</sup>alimikegami1@gmail.com</span></a></p>
<p><a href="mailto:2dewabayu@unud.ac.id"><span class="font2"><sup>2</sup>dewabayu@unud.ac.id</span></a><span class="font2"> </span><span class="font1">(Corresponding author)</span></p>
<h4><a name="bookmark2"></a><span class="font2" style="font-weight:bold;font-style:italic;"><a name="bookmark3"></a>Abstract</span></h4>
<p><span class="font2" style="font-style:italic;">In recent years, audio content has seen a rise in consumption. The COVID-19 pandemic also contributes to the rise in consumption. In the survey that was conducted in 2021, more than 40% of people in France, Germany, and Spain have been listening to more audio content since the first restriction on COVID-19 came into place. One of the rising startups in Indonesia that offers audio content with their original and exclusive content is Noice. To maintain their quality of service, it’s important to look into the reviews that were written for their application. To analyze the reviews, sentiment analysis and topic modeling can be used to extract the sentiment polarity and the topics that are discussed on each sentiment polarity. In this study, XGBoost and Latent Dirichlet Allocation are used to analyze the reviews that were written in Google Play Store. The result of the sentiment analysis yielded accuracy, precision, recall, and F1-score of</span><span class="font2"> 86,8%, 83,9%, 77,9%, and 80,2%</span><span class="font2" style="font-style:italic;">. While the topic modeling managed to extract 3 and 6 topics respectively for positive and negative reviews.</span></p>
<p><span class="font2" style="font-weight:bold;font-style:italic;">Keywords: </span><span class="font2" style="font-style:italic;">Sentiment Analysis, Topic Modeling, Noice, XGBoost, LDA</span></p>
<ul style="list-style:none;"><li>
<p><span class="font2" style="font-weight:bold;">1. &nbsp;&nbsp;&nbsp;Pendahuluan</span></p></li></ul>
<p><span class="font2">Konten audio merupakan salah satu bentuk konten yang dapat dinikmati dengan mudah melalui </span><span class="font2" style="font-style:italic;">smartphone</span><span class="font2"> yang kini berada di genggaman sebagian besar masyarakat di seluruh dunia. Konten audio disajikan dalam berbagai jenis, yaitu dapat berupa </span><span class="font2" style="font-style:italic;">podcast</span><span class="font2">, </span><span class="font2" style="font-style:italic;">audioseries</span><span class="font2">, ataupun </span><span class="font2" style="font-style:italic;">audiobook</span><span class="font2">. Dalam beberapa tahun terakhir ini, konsumsi masyarakat terhadap konten audio semakin meningkat. Terjadinya pandemi akibat virus COVID-19 juga mendorong konsumsi konten audio. Berdasarkan survei yang dilakukan oleh </span><span class="font2" style="font-style:italic;">Sortlist</span><span class="font2"> pada tahun 2021, lebih dari 40% masyarakat di Prancis, Jerman, dan Spanyol menyatakan bahwa konsumsi konten audio mereka meningkat sejak pertama kalinya terjadinya restriksi akibat COVID-19 [1].</span></p>
<p><span class="font2">Salah satu </span><span class="font2" style="font-style:italic;">platform</span><span class="font2"> konten audio yang menyuguhkan berbagai jenis konten audio dalam bahasa Indonesia adalah Noice. Noice menyediakan konten audio seperti </span><span class="font2" style="font-style:italic;">podcast</span><span class="font2">, radio, </span><span class="font2" style="font-style:italic;">audiobook</span><span class="font2">, maupun </span><span class="font2" style="font-style:italic;">audioseries</span><span class="font2">. Noice menghadirkan berbagai konten original atau eksklusif yang hanya dapat didengarkan melalui aplikasinya. Pada tahun 2022, Noice dinobatkan sebagai salah satu dari top 50 </span><span class="font2" style="font-style:italic;">startup</span><span class="font2"> di Asia pada list versi Tech In Asia [2]. Untuk menjaga kualitas layanan yang ditawarkan, ulasan dari pengguna aplikasi dapat memberikan berbagai informasi yang berharga terkait dengan pengalaman para pengguna dalam menggunakan aplikasi tersebut.</span></p>
<p><span class="font2">Banyaknya ulasan yang ada di internet menyebabkan sulitnya proses ekstraksi informasi dari ulasan tersebut jika proses penggalian informasi dilakukan secara manual dengan membaca keseluruhan ulasan satu persatu. Sehingga, dibutuhkan pendekatan yang berbeda untuk memperoleh informasi dari ulasan yang tersedia. Analisis sentimen dan pemodelan topik adalah alat analisis yang dapat digunakan untuk mengidentifikasi, mengekstraksi, dan mengukur sentimen dan topik dari suatu data tekstual yang sifatnya subjektif secara cepat, efektif, murah, dan dengan memperhitungkan tema umum yang dibahas dalam suatu dokumen [3].</span></p>
<p><span class="font2">Penelitian terkait analisis sentimen dan pemodelan topik pernah dilakukan sebelumnya pada </span><span class="font2" style="font-style:italic;">tweet</span><span class="font2"> mengenai edukasi daring selama adanya pandemi COVID-19 [4]. Pada penelitian tersebut, dilakukan perbandingan akurasi analisis sentimen melalui pendekatan </span><span class="font2" style="font-style:italic;">machine learning</span><span class="font2"> dan</span></p>
<p><span class="font2" style="font-style:italic;">deep learning</span><span class="font2"> yang menghasilkan kesimpulan bahwa akurasi yang dihasilkan lebih baik pada penggunaan algoritma </span><span class="font2" style="font-style:italic;">machine learning</span><span class="font2"> pada ukuran </span><span class="font2" style="font-style:italic;">dataset</span><span class="font2"> yang tidak terlalu besar. Penelitian tersebut juga menggunakan metode LSA dalam melakukan pemodelan topik pada masing-masing kelas sentimen dan masing-masing menghasilkan 10 topik pembahasan. Selain itu, penelitian analisis sentimen dan pemodelan topik juga pernah dilakukan untuk mengidentifikasikan kepuasan terhadap layanan pemerintah melalui metode </span><span class="font2" style="font-style:italic;">Support Vector Machine</span><span class="font2"> dan LDA [5]. Penelitian tersebut menghasilkan akurasi analisis sentimen sebesar 75% dan 5 topik pada masing-masing kelas sentimen.</span></p>
<p><span class="font2">Penelitian ini bertujuan untuk mengombinasikan analisis sentimen dan pemodelan topik dalam memperoleh informasi terkait dengan pengalaman pengguna dalam menggunakan aplikasi Noice. Melalui penggunaan analisis sentimen, ulasan dapat diklasifikasikan menjadi ulasan dengan sentimen positif dan negatif. Sedangkan, pemodelan topik digunakan untuk memperoleh topik yang dibahas pada masing-masing kelas sentimen. Metode analisis sentimen yang digunakan pada penelitian ini adalah XGBoost yang menghasilkan performa yang baik dalam permasalahan klasifikasi di penelitian sebelumnya [6]. XGBoost menerapkan mekanisme </span><span class="font2" style="font-style:italic;">decision tree</span><span class="font2"> untuk membuat </span><span class="font2" style="font-style:italic;">weak learner</span><span class="font2"> menjadi </span><span class="font2" style="font-style:italic;">learner</span><span class="font2"> yang lebih baik. Selain itu, XGBoost adalah bentuk peningkatan dari algoritma </span><span class="font2" style="font-style:italic;">gradient boosting</span><span class="font2"> yang menerapkan regularisasi untuk mengurangi </span><span class="font2" style="font-style:italic;">overfitting</span><span class="font2">. Sedangkan, metode pemodelan topik yang digunakan pada penelitian ini adalah LDA karena metode tersebut menghasilkan performa yang lebih baik jika dibandingkan dengan beberapa metode lainnya [7]. LDA adalah algoritma </span><span class="font2" style="font-style:italic;">unsupervised</span><span class="font2"> yang digunakan untuk mengekstraksi topik dari sekumpulan dokumen serta mengasumsikan bahwa setiap dokumen terdiri atas beberapa topik, yang mana setiap topiknya merupakan distribusi probabilitas dari kata yang ada [7]. Penelitian ini akan dilakukan dengan menggunakan bahasa pemrograman Python beserta bantuan dari </span><span class="font2" style="font-style:italic;">library-library</span><span class="font2"> yang tersedia.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font2" style="font-weight:bold;">2. &nbsp;&nbsp;&nbsp;Metode Penelitian</span></p>
<ul style="list-style:none;">
<li>
<p><span class="font2" style="font-weight:bold;">2.1 &nbsp;&nbsp;&nbsp;Alur Penelitian</span></p></li></ul></li></ul><img src="https://jurnal.harianregional.com/media/92679-1.png" alt="" style="width:375pt;height:96pt;">
<p><span class="font2" style="font-weight:bold;">Gambar 1</span><span class="font2">. Alur Penelitian</span></p>
<p><span class="font2">Alur dari penelitian ini ditunjukkan pada Gambar 1. Tahap pertama yang dilakukan adalah pengumpulan data ulasan aplikasi Noice dari Google Play Store. Setelah itu, dilakukan </span><span class="font2" style="font-style:italic;">text preprocessing</span><span class="font2"> untuk membersihkan data ulasan yang telah dikumpulkan. Untuk melakukan analisis sentimen dan pemodelan topik, dilakukan ekstraksi fitur terlebih dahulu untuk merepresentasikan data tekstual dalam bentuk yang dipahami oleh metode yang digunakan. Ekstraksi fitur dilakukan dengan dua metode, yaitu TF-IDF untuk analisis sentimen dan </span><span class="font2" style="font-style:italic;">bag-of-words</span><span class="font2"> untuk pemodelan topik. Setelah itu, dilakukan proses analisis sentimen dengan menggunakan XGBoost. Kemudian, dilakukan proses evaluasi untuk menilai kinerja model analisis sentimen yang dihasilkan. Proses evaluasi dilakukan dengan menggunakan </span><span class="font2" style="font-style:italic;">K-fold cross validation</span><span class="font2">, </span><span class="font2" style="font-style:italic;">grid search</span><span class="font2">, dan </span><span class="font2" style="font-style:italic;">confusion matrix</span><span class="font2">. Setelah dilakukan sentimen analisis, akan dilakukan pemodelan topik pada sentimen positif dan negatif menggunakan metode LDA. Kemudian, proses evaluasi pemodelan topik dilakukan menggunakan </span><span class="font2" style="font-style:italic;">topic coherence</span><span class="font2"> untuk menentukan jumlah topik yang merepresentasikan masing-masing kelas sentimen.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font2" style="font-weight:bold;">2.2 &nbsp;&nbsp;&nbsp;Pengumpulan Data</span></p></li></ul>
<p><span class="font2">Data ulasan aplikasi Noice yang digunakan pada penelitian ini merupakan data sekunder yang di-</span><span class="font2" style="font-style:italic;">scrape</span><span class="font2"> dari Google Play Store. Proses </span><span class="font2" style="font-style:italic;">scraping</span><span class="font2"> dilakukan dengan menggunakan </span><span class="font2" style="font-style:italic;">library </span><span class="font2">Google-Play-Scraper. Data ulasan aplikasi Noice adalah data teks berbahasa Indonesia dengan jumlah data sebanyak 8341 ulasan. Data ulasan yang diambil adalah ulasan pada tanggal 26</span></p>
<p><span class="font2">November 2019 hingga 24 September 2022. Kemudian, data tersebut dilabeli dengan memanfaatkan </span><span class="font2" style="font-style:italic;">rating</span><span class="font2"> dari masing-masing ulasan tersebut. Untuk </span><span class="font2" style="font-style:italic;">rating</span><span class="font2"> dengan jumlah bintang 1, 2, dan 3 akan dilabeli sebagai ulasan dengan sentimen negatif. Sedangkan, ulasan dengan rating yang jumlah bintangnya adalah 4 dan 5 dilabeli sebagai sentimen positif. Melalui proses </span><span class="font2" style="font-style:italic;">labeling </span><span class="font2">tersebut, diperoleh sentimen negatif sebanyak 2055 ulasan dan sentimen positif sebanyak 6286 ulasan.</span></p>
<ul style="list-style:none;"><li>
<h4><a name="bookmark4"></a><span class="font2" style="font-weight:bold;"><a name="bookmark5"></a>2.3</span><span class="font2" style="font-weight:bold;font-style:italic;"> &nbsp;&nbsp;&nbsp;Text Preprocessing</span></h4></li></ul>
<p><span class="font2">Adapun beberapa tahapan </span><span class="font2" style="font-style:italic;">preprocessing</span><span class="font2"> yang akan dilakukan pada penelitian ini ditunjukkan pada Gambar 2.</span></p><img src="https://jurnal.harianregional.com/media/92679-2.png" alt="" style="width:318pt;height:106pt;">
<p><span class="font2" style="font-weight:bold;">Gambar 2</span><span class="font2">. Alur </span><span class="font2" style="font-style:italic;">Text Preprocessing</span></p>
<p><span class="font2">Langkah pertama dalam </span><span class="font2" style="font-style:italic;">text preprocessing</span><span class="font2"> yang dilakukan adalah </span><span class="font2" style="font-style:italic;">noise removal</span><span class="font2">, yaitu proses untuk menghilangkan tanda baca, karakter, ataupun angka [8]. Setelah melalui tahapan </span><span class="font2" style="font-style:italic;">noise removal</span><span class="font2">, dilakukan </span><span class="font2" style="font-style:italic;">case folding</span><span class="font2"> untuk mengubah huruf kapital menjadi huruf kecil. Hal ini dilakukan dengan tujuan agar setiap karakter pada suatu </span><span class="font2" style="font-style:italic;">dataset</span><span class="font2"> direpresentasikan dalam bentuk yang sama, yaitu berupa huruf kecil [9]. Setelah melakukan </span><span class="font2" style="font-style:italic;">case folding</span><span class="font2"> dan setiap kata sudah dalam bentuk yang sama, maka </span><span class="font2" style="font-style:italic;">normalization</span><span class="font2"> dilakukan untuk menormalisasikan kata yang bukan standar, kata yang disingkat, ataupun kata yang mengalami kesalahan penulisan [10]. Hasil dari proses </span><span class="font2" style="font-style:italic;">normalization</span><span class="font2"> akan diterapkan </span><span class="font2" style="font-style:italic;">tokenization</span><span class="font2"> untuk memecah suatu data tekstual menjadi bagian yang lebih kecil atau disebut dengan token. Proses ini akan memecah suatu kalimat menjadi sekumpulan kata [11]. Setelah itu, dilakukan s</span><span class="font2" style="font-style:italic;">topword removal</span><span class="font2"> yang merupakan proses untuk memperoleh kata-kata yang penting dari hasil </span><span class="font2" style="font-style:italic;">tokenization</span><span class="font2"> dengan menghilangkan kata-kata yang tidak memiliki arti [8]. Kemudian, dilakukan </span><span class="font2" style="font-style:italic;">Stemming</span><span class="font2"> yang merupakan proses untuk mengubah suatu kata yang mengandung imbuhan menjadi akar katanya [12]. Proses </span><span class="font2" style="font-style:italic;">text preprocessing</span><span class="font2"> akan dilakukan dengan menggunakan bahasa pemrograman Python.</span></p>
<ul style="list-style:none;"><li>
<h4><a name="bookmark6"></a><span class="font2" style="font-weight:bold;"><a name="bookmark7"></a>2.4</span><span class="font2" style="font-weight:bold;font-style:italic;"> &nbsp;&nbsp;&nbsp;Bag-of-Words</span><span class="font2" style="font-weight:bold;"> (BOW)</span></h4></li></ul>
<p><span class="font2" style="font-style:italic;">Bag-of-words</span><span class="font2"> (BOW) adalah salah satu jenis cara untuk mengekstraksi fitur dari suatu kalimat maupun dokumen. Model BOW adalah model representasi yang akan mentransformasikan suatu data tekstual menjadi vektor dengan panjang yang telah ditentukan melalui proses perhitungan kata-kata yang muncul berulang kali. Pada representasi ini, kalimat maupun dokumen dianggap sebagai kumpulan kata yang tidak berurutan menggunakan vektor dengan ukuran yang telah ditentukan dan mengandung jumlah kemunculan kata yang mengabaikan tata bahasa maupun urutan kata. Penggunaan BOW dapat dilakukan dengan dua tahap, yaitu menentukan kata yang ada pada seluruh kalimat atau dokumen dan menentukan metode penilaian untuk kemunculan setiap kata yang telah diidentifikasi sebelumnya. Metode penilaian tersebut dapat berupa cara yang sederhana seperti menggunakan nilai biner yang menentukan kemunculan suatu kata ataupun menggunakan nilai non-biner yang menunjukkan frekuensi kemunculan kata tersebut [13]. Pada penelitian ini, hasil </span><span class="font2" style="font-style:italic;">text preprocessing</span><span class="font2"> yang berupa kata yang telah di-</span><span class="font2" style="font-style:italic;">tokenize</span><span class="font2"> dari suatu kalimat akan digunakan untuk menghasilkan fitur yang dapat dipahami oleh LDA melalui penerapan </span><span class="font2" style="font-style:italic;">bag-of-words</span><span class="font2">.</span></p>
<ul style="list-style:none;"><li>
<h4><a name="bookmark8"></a><span class="font2" style="font-weight:bold;"><a name="bookmark9"></a>2.5</span><span class="font2" style="font-weight:bold;font-style:italic;"> &nbsp;&nbsp;&nbsp;Term Frequency-Inverse Document Frequency</span><span class="font2" style="font-weight:bold;"> (TF-IDF)</span></h4></li></ul>
<p><span class="font2" style="font-style:italic;">Term Frequency-Inverse Document Frequency</span><span class="font2"> (TF-IDF) adalah skema pembobotan yang bermanfaat dalam ranah </span><span class="font2" style="font-style:italic;">information retrieval</span><span class="font2"> dan </span><span class="font2" style="font-style:italic;">text mining</span><span class="font2">. TF-IDF memberikan informasi mengenai pentingnya suatu kata pada dokumen dari suatu </span><span class="font2" style="font-style:italic;">corpus</span><span class="font2"> [14]. </span><span class="font2" style="font-style:italic;">Term frequency</span><span class="font2"> (TF) pada TF-IDF menyatakan kemunculan suatu kata pada dokumen. Sehingga, nilai TF yang tinggi untuk suatu kata menandakan bahwa kata tersebut penting untuk suatu dokumen. Sedangkan,</span></p>
<p><span class="font2">IDF menyatakan invers dari DF yang digunakan untuk menentukan seberapa penting suatu kata pada sekumpulan dokumen. Nilai IDF yang tinggi menyatakan bahwa kemunculan kata tersebut jumlahnya sedikit sehingga dianggap merupakan kata yang penting [15]. Pada penelitian ini, hasil </span><span class="font2" style="font-style:italic;">text preprocessing</span><span class="font2"> akan digunakan untuk menghasilkan fitur yang dapat digunakan oleh model </span><span class="font2" style="font-style:italic;">machine learning</span><span class="font2"> melalui penggunaan TF-IDF. Untuk suatu kata t pada dokumen d, nilai TF-IDF dapat dihitung melalui persamaan berikut:</span></p>
<div>
<p><span class="font10" style="font-style:italic;">TF (t, d')</span></p>
</div><br clear="all">
<p><span class="font8" style="font-style:italic;">Jumlah kemunculan kata t pada dokumen</span></p>
<div>
<p><span class="font2">(2)</span></p>
</div><br clear="all">
<div>
<p><span class="font2">(1)</span></p>
</div><br clear="all">
<p><span class="font8" style="font-style:italic;">Jumlah kata pada dokumen d</span></p>
<div>
<p><span class="font10" style="font-style:italic;">IDF (t)</span><span class="font10"> = </span><span class="font10" style="font-style:italic;">log(</span></p>
</div><br clear="all">
<p><span class="font8" style="font-style:italic;">Jumlah dokumen</span></p>
<p><span class="font8" style="font-style:italic;">Jumlah dokumen yang mengandung kata</span></p>
<p><span class="font10" style="font-style:italic;">TF-IDF(t,d) = TF(t,d)x IDF(t)</span><span class="font2"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(3)</span></p>
<ul style="list-style:none;"><li>
<h4><a name="bookmark10"></a><span class="font2" style="font-weight:bold;"><a name="bookmark11"></a>2.6</span><span class="font2" style="font-weight:bold;font-style:italic;"> &nbsp;&nbsp;&nbsp;Extreme Gradient Boosting</span><span class="font2" style="font-weight:bold;"> (XGBoost)</span></h4></li></ul>
<p><span class="font2" style="font-style:italic;">Extreme gradient boosting</span><span class="font2"> (XGBoost) adalah suatu algoritma </span><span class="font2" style="font-style:italic;">machine learning</span><span class="font2"> yang diaplikasikan untuk permasalahan klasifikasi dan regresi. XGBoost merupakan algoritma yang berupa peningkatan dari algoritma </span><span class="font2" style="font-style:italic;">gradient boosting</span><span class="font2">. XGBoost menerapkan mekanisme </span><span class="font2" style="font-style:italic;">decision tree</span><span class="font2"> untuk membuat </span><span class="font2" style="font-style:italic;">weak learner</span><span class="font2"> menjadi </span><span class="font2" style="font-style:italic;">learner</span><span class="font2"> yang lebih baik. Peningkatan yang dilakukan pada XGBoost adalah penggunaan regularisasi yang bertujuan untuk mengontrol serta mengurangi terjadinya </span><span class="font2" style="font-style:italic;">overfitting</span><span class="font2"> pada model yang dihasilkan agar model tersebut dapat memberikan performa yang lebih baik [16]. Pada penerapan XGBoost dalam analisis sentimen, XGBoost akan menggunakan hasil ekstraksi TF-IDF yaitu matriks dengan bobot kata sebagai fiturnya. Adapun langkah-langkah proses klasifikasi dengan algoritma XGBoost sebagai berikut:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font2">1. &nbsp;&nbsp;&nbsp;Melakukan prediksi awal</span></p></li></ul>
<p><span class="font2">Langkah pertama dalam XGBoost adalah membuat prediksi awal, yaitu setiap objek data memiliki probabilitas sebesar 0,5 untuk diklasifikasikan ke dalam suatu kelas [17].</span></p>
<ul style="list-style:none;"><li>
<p><span class="font2">2. &nbsp;&nbsp;&nbsp;Menghitung </span><span class="font2" style="font-style:italic;">residual</span></p></li></ul>
<p><span class="font2">Setelah melakukan prediksi awal, maka akan dilakukan pembuatan </span><span class="font2" style="font-style:italic;">tree</span><span class="font2"> berdasarkan </span><span class="font2" style="font-style:italic;">residual</span><span class="font2"> dari prediksi awal [17]. </span><span class="font2" style="font-style:italic;">Residual</span><span class="font2"> dapat dihitung melalui persamaan (4).</span></p>
<p><span class="font10" style="font-style:italic;">Residual = nilai observasi — nilai prediksi</span><span class="font2"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(4)</span></p>
<ul style="list-style:none;"><li>
<p><span class="font2">3. &nbsp;&nbsp;&nbsp;Menghitung </span><span class="font2" style="font-style:italic;">gain</span></p></li></ul>
<p><span class="font2">Sebelum menghitung </span><span class="font2" style="font-style:italic;">gain</span><span class="font2">, perlu dihitung nilai </span><span class="font2" style="font-style:italic;">similarity score</span><span class="font2"> dari setiap </span><span class="font2" style="font-style:italic;">node</span><span class="font2"> melalui persamaan (5) [17].</span></p>
<div>
<p><span class="font10" style="font-style:italic;">Similarity score =</span></p>
</div><br clear="all">
<div>
<p><span class="font8" style="font-style:italic;text-decoration:underline;">(∑ &nbsp;&nbsp;&nbsp;&nbsp;4</span><span class="font7" style="font-style:italic;text-decoration:underline;">j</span><span class="font8" style="font-style:italic;text-decoration:underline;">)<sup>2</sup></span></p>
<p><span class="font8" style="font-style:italic;">∑</span><span class="font8"> &nbsp;&nbsp;</span><span class="font6">∣</span><span class="font8">(pMι-p)</span><span class="font6">∣</span><span class="font8">+;</span></p>
</div><br clear="all">
<div>
<p><span class="font2">(5)</span></p>
</div><br clear="all">
<p><span class="font2">Keterangan:</span></p>
<p><span class="font10" style="font-style:italic;">r</span><span class="font7" style="font-style:italic;"><sub>i</sub></span><span class="font2"> = residual ke-i, </span><span class="font10" style="font-style:italic;">p</span><span class="font2"> = probabilitas sebelumnya, </span><span class="font9">A </span><span class="font2">= parameter regularisasi</span></p>
<p><span class="font2">Setelah menghitung nilai </span><span class="font2" style="font-style:italic;">simalirity score</span><span class="font2">, maka nilai </span><span class="font2" style="font-style:italic;">gain</span><span class="font2"> dapat dihitung melalui persamaan (6). Fitur dan </span><span class="font2" style="font-style:italic;">split point</span><span class="font2"> terbesar dari fitur tersebut akan dipilih untuk melakukan </span><span class="font2" style="font-style:italic;">splitting</span><span class="font2"> apabila diperoleh nilai </span><span class="font2" style="font-style:italic;">gain</span><span class="font2"> terbesar [17].</span></p>
<p><span class="font10" style="font-style:italic;">Gain = Left Similarity + Right Similarity — Root Similarity</span><span class="font2"> (6)</span></p>
<ul style="list-style:none;"><li>
<p><span class="font2">4. &nbsp;&nbsp;&nbsp;Menghitung </span><span class="font2" style="font-style:italic;">cover</span></p></li></ul>
<p><span class="font2">Nilai </span><span class="font2" style="font-style:italic;">cover</span><span class="font2"> digunakan untuk menentukan jumlah minimum </span><span class="font2" style="font-style:italic;">residual</span><span class="font2"> pada </span><span class="font2" style="font-style:italic;">leaf</span><span class="font2"> dari suatu </span><span class="font2" style="font-style:italic;">tree</span><span class="font2"> [17]. Nilai </span><span class="font2" style="font-style:italic;">cover</span><span class="font2"> dapat dihitung melalui persamaan (7).</span></p>
<h3><a name="bookmark12"></a><span class="font10" style="font-style:italic;"><a name="bookmark13"></a>Cover = ∑</span><span class="font10"> |px<sup>(</sup>1—p)| &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="font2">(7)</span></h3>
<ul style="list-style:none;"><li>
<p><span class="font2">5. &nbsp;&nbsp;&nbsp;Menghitung probabilitas kelas</span></p></li></ul>
<p><span class="font2">Untuk memprediksi probabilitas kelas dari suatu objek data, maka perlu dihitung </span><span class="font2" style="font-style:italic;">output </span><span class="font2">dari </span><span class="font2" style="font-style:italic;">node</span><span class="font2">-nya melalui persamaan (8) [17].</span></p>
<div>
<p><span class="font8" style="font-style:italic;">Residuals</span></p>
<p><span class="font8">∑ &nbsp;&nbsp;KpMl-p)|+;</span></p>
</div><br clear="all">
<div>
<p><span class="font10" style="font-style:italic;">Output =</span></p>
</div><br clear="all">
<div>
<p><span class="font2">(8)</span></p>
</div><br clear="all">
<p><span class="font2">Setelah itu, nilai prediksi probabilitas awal yang didefinisikan pada langkah pertama perlu diubah menjadi bentuk log(odds). Untuk itu, digunakan persamaan (9) [17].</span></p>
<h2><a name="bookmark14"></a><span class="font10" style="font-style:italic;"><a name="bookmark15"></a>log(odds) = log</span><span class="font8"> Q-?</span><span class="font10">) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="font2">(9)</span></h2>
<p><span class="font2">Kemudian, akan dihitung log(odds) dari objek data melalui persamaan (10) [17].</span></p>
<h2><a name="bookmark16"></a><span class="font10" style="font-style:italic;"><a name="bookmark17"></a>Log(odds)Prediction = Log(odds) + (ε x Output)</span><span class="font2"> (10)</span></h2>
<p><span class="font2">Untuk memperoleh probabilitas kelas dari objek data tersebut, dapat dikonversi kembali log(odds) tersebut menjadi probabilitas melalui persamaan (11) [17].</span></p>
<p><span class="font7" style="font-style:italic;"><sub>e</sub> lo%lo% (odds)</span></p>
<h2><a name="bookmark18"></a><span class="font10" style="font-style:italic;"><a name="bookmark19"></a>Probability = —</span><span class="font2">(11)</span></h2>
<p><span class="font7" style="font-style:italic;">J</span><span class="font8"> &nbsp;&nbsp;&nbsp;&nbsp;l+e </span><span class="font7" style="font-style:italic;">loglog (odds) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<sup>v</sup> '</span></p>
<p><span class="font2">Keterangan:</span></p>
<p><span class="font2">P = prediksi, </span><span class="font9">ε </span><span class="font2">= </span><span class="font2" style="font-style:italic;">learning rate</span></p>
<p><span class="font2">Probabilitas tersebut merupakan probabilitas peluang untuk tergolong ke dalam suatu kelas. Proses perhitungan akan diulang kembali dari langkah ke-2 untuk melanjutkan pembuatan </span><span class="font2" style="font-style:italic;">tree</span><span class="font2"> lainnya [17].</span></p>
<ul style="list-style:none;"><li>
<h4><a name="bookmark20"></a><span class="font2" style="font-weight:bold;"><a name="bookmark21"></a>2.7</span><span class="font2" style="font-weight:bold;font-style:italic;"> &nbsp;&nbsp;&nbsp;K-fold Cross Validation</span></h4></li></ul>
<p><span class="font2" style="font-style:italic;">K-fold cross validation</span><span class="font2"> metode statistik yang digunakan untuk mempartisi suatu data menjadi bagian </span><span class="font2" style="font-style:italic;">training</span><span class="font2"> dan </span><span class="font2" style="font-style:italic;">testing</span><span class="font2">. Metode ini digunakan untuk membagi data secara berulang menjadi dua bagian, yaitu bagian </span><span class="font2" style="font-style:italic;">training</span><span class="font2"> dan bagian </span><span class="font2" style="font-style:italic;">testing</span><span class="font2">. Yang mana, setiap data memiliki peluang untuk menjadi data </span><span class="font2" style="font-style:italic;">testing</span><span class="font2"> [18]. </span><span class="font2" style="font-style:italic;">K-fold cross validation</span><span class="font2"> diterapkan dalam menentukan </span><span class="font2" style="font-style:italic;">hyperparameter</span><span class="font2"> model analisis sentimen untuk memperoleh rata-rata nilai evaluasi yang diujikan dalam berbagai kondisi data.</span></p>
<ul style="list-style:none;"><li>
<h4><a name="bookmark22"></a><span class="font2" style="font-weight:bold;"><a name="bookmark23"></a>2.8</span><span class="font2" style="font-weight:bold;font-style:italic;"> &nbsp;&nbsp;&nbsp;Grid Search</span></h4></li></ul>
<p><span class="font2" style="font-style:italic;">Grid search</span><span class="font2"> adalah metode yang digunakan untuk mengidentifikasi parameter optimal bagi suatu model agar model tersebut dapat memprediksi data tidak berlabel dengan akurat. Melalui </span><span class="font2" style="font-style:italic;">grid search</span><span class="font2">, proses pencarian parameter yang sesuai bagi suatu model dapat dilakukan dengan lebih mudah. Metode </span><span class="font2" style="font-style:italic;">grid search</span><span class="font2"> digunakan dengan mendefinisikan rentang nilai suatu </span><span class="font2" style="font-style:italic;">hyperparameter</span><span class="font2">. Kemudian, </span><span class="font2" style="font-style:italic;">grid search</span><span class="font2"> akan membuat model berdasarkan kombinasi dari rentang nilai yang telah didefinisikan sebelumnya, yang mana rentang </span><span class="font2" style="font-style:italic;">hyperparameter</span><span class="font2"> tersebut disebut sebagai </span><span class="font2" style="font-style:italic;">grid</span><span class="font2"> [19]. Metode ini diterapkan pada proses </span><span class="font2" style="font-style:italic;">training</span><span class="font2"> model analisis sentimen.</span></p>
<ul style="list-style:none;"><li>
<h4><a name="bookmark24"></a><span class="font2" style="font-weight:bold;"><a name="bookmark25"></a>2.9</span><span class="font2" style="font-weight:bold;font-style:italic;"> &nbsp;&nbsp;&nbsp;Confusion Matrix</span></h4></li></ul>
<p><span class="font2">Untuk melakukan evaluasi terhadap model analisis sentimen yang dihasilkan, yaitu dalam penelitian ini merupakan model XGBoost, akan digunakan </span><span class="font2" style="font-style:italic;">confusion matrix</span><span class="font2">. </span><span class="font2" style="font-style:italic;">Confusion matrix </span><span class="font2">digunakan untuk menentukan efektifitas pemodelan permasalahan klasifikasi [20]. </span><span class="font2" style="font-style:italic;">Confusion matrix</span><span class="font2"> akan digunakan untuk menilai hasil prediksi dari model analisis sentimen terhadap data ulasan yang diberikan kepada model untuk menilai kinerja dari model tersebut. Adapun bentuk dari </span><span class="font2" style="font-style:italic;">confusion matrix</span><span class="font2"> ditunjukkan pada Tabel 1.</span></p>
<p><span class="font2" style="font-weight:bold;">Tabel 1. </span><span class="font2" style="font-style:italic;">Confusion Matrix</span></p>
<table border="1">
<tr><td style="vertical-align:middle;">
<p><span class="font2">Hasil Prediksi</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font2">Positif &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Negatif</span></p></td></tr>
</table>
<table border="1">
<tr><td rowspan="2" style="vertical-align:top;">
<p><span class="font2">Kelas Seharusnya</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Positif</span></p></td><td style="vertical-align:top;">
<p><span class="font2">TP (</span><span class="font2" style="font-style:italic;">True Positive</span><span class="font2">)</span></p></td><td style="vertical-align:top;">
<p><span class="font2">FN (</span><span class="font2" style="font-style:italic;">False Negative</span><span class="font2">)</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font2">Negatif</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">FP (</span><span class="font2" style="font-style:italic;">False Positive</span><span class="font2">)</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">TN (</span><span class="font2" style="font-style:italic;">True Negative</span><span class="font2">)</span></p></td></tr>
</table>
<p><span class="font2">Dari </span><span class="font2" style="font-style:italic;">confusion matrix</span><span class="font2">, dapat diperoleh empat metrik evaluasi yaitu akurasi, </span><span class="font2" style="font-style:italic;">precision</span><span class="font2">, </span><span class="font2" style="font-style:italic;">recall</span><span class="font2">, dan </span><span class="font2" style="font-style:italic;">F1-score</span><span class="font2">. Keempat metrik evalusi tersebut merupakan metrik yang banyak digunakan [21]. </span><span class="font2" style="font-style:italic;">Confusion matrix</span><span class="font2"> diterapkan pada hasil prediksi dari model analisis sentimen untuk memperoleh akurasi, </span><span class="font2" style="font-style:italic;">precision</span><span class="font2">, </span><span class="font2" style="font-style:italic;">recall</span><span class="font2">, dan </span><span class="font2" style="font-style:italic;">F1-score</span><span class="font2"> dari model analisis sentimen. Adapun persamaan yang digunakan untuk menghitung nilai akurasi, </span><span class="font2" style="font-style:italic;">precision</span><span class="font2">, </span><span class="font2" style="font-style:italic;">recall</span><span class="font2">, dan </span><span class="font2" style="font-style:italic;">F1-score</span><span class="font2"> adalah sebagai berikut:</span></p>
<p><span class="font8" style="font-style:italic;">TP+TN</span></p>
<h3><a name="bookmark26"></a><span class="font10" style="font-style:italic;"><a name="bookmark27"></a>Akurasi</span><span class="font10"> = ------------- </span><span class="font2">(12)</span></h3>
<p><span class="font8" style="font-style:italic;">TP</span><span class="font8"> + </span><span class="font8" style="font-style:italic;">TN</span><span class="font8"> + </span><span class="font8" style="font-style:italic;">FP</span><span class="font8"> + </span><span class="font8" style="font-style:italic;">FN &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<sup>v z</sup></span></p>
<div>
<p><span class="font10" style="font-style:italic;">F</span><span class="font3" style="font-style:italic;">1</span><span class="font10"> — </span><span class="font10" style="font-style:italic;">Score</span></p>
</div><br clear="all">
<div>
<p><span class="font2">(15)</span></p>
</div><br clear="all">
<table border="1">
<tr><td rowspan="2" style="vertical-align:middle;">
<p><span class="font10" style="font-style:italic;">Precision</span></p></td><td style="vertical-align:bottom;">
<p><span class="font8" style="font-style:italic;">_ &nbsp;&nbsp;TP</span></p></td><td rowspan="2" style="vertical-align:middle;">
<p><span class="font2">(13)</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font8" style="font-style:italic;">TP + FP</span></p></td></tr>
<tr><td rowspan="2" style="vertical-align:middle;">
<p><span class="font10" style="font-style:italic;">Recall =</span></p></td><td style="vertical-align:bottom;">
<p><span class="font8" style="font-style:italic;">TP + TN</span></p></td><td rowspan="2" style="vertical-align:middle;">
<p><span class="font2">(14)</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font8" style="font-style:italic;">TP + FN</span></p></td></tr>
</table>
<p><span class="font1" style="font-style:italic;">2 </span><span class="font8" style="font-style:italic;">x recall x precision recall + precision</span></p>
<ul style="list-style:none;"><li>
<p><span class="font2" style="font-weight:bold;">2.10 &nbsp;&nbsp;&nbsp;Latent Dirichlet Allocation (LDA)</span></p></li></ul>
<p><span class="font2">LDA adalah model probabilistik yang dikenal sebagai salah satu algoritma pemodelan topik yang populer [7] LDA dapat digunakan untuk memahami arti semantik dari suatu teks sehingga dapat mengidentifikasi topik utamanya [22]. LDA menggunakan asumsi dasar bahwa setiap topik direpresentasikan oleh kata yang serupa dan setiap dokumen dapat direpresentasikan oleh beberapa topik. LDA bertujuan untuk memetakan setiap dokumen ke suatu topik yang mengandung kata-kata pada dokumen tersebut. Karena LDA menganggap setiap dokumen sebagai model </span><span class="font2" style="font-style:italic;">bag-of-words</span><span class="font2">, maka urutan kata atau perubahan konten pada dokumen tidak perlu dilakukan [23]. Pada penelitian ini, LDA akan diterapkan pada representasi ulasan yang dihasilkan melalui penerapan </span><span class="font2" style="font-style:italic;">bag-of-words</span><span class="font2">.</span></p>
<ul style="list-style:none;"><li>
<h4><a name="bookmark28"></a><span class="font2" style="font-weight:bold;"><a name="bookmark29"></a>2.11</span><span class="font2" style="font-weight:bold;font-style:italic;"> &nbsp;&nbsp;&nbsp;Topic Coherence</span></h4></li></ul>
<p><span class="font2" style="font-style:italic;">Topic coherence</span><span class="font2"> digunakan untuk menghitung nilai dari satu topik dengan menghitung derajat kemiripan dari aspek semantik antara kata-kata dengan hasil </span><span class="font2" style="font-style:italic;">scoring</span><span class="font2"> yang tinggi pada suatu topik. Hasil perhitungan tersebut digunakan untuk membedakan topik yang dapat dipahami secara semantik dan topik yang hanya berupa artifak dari </span><span class="font2" style="font-style:italic;">statistical inference</span><span class="font2"> [24]. Terdapat berbagai </span><span class="font2" style="font-style:italic;">coherence measure</span><span class="font2"> yang digunakan dalam menghitung </span><span class="font2" style="font-style:italic;">topic coherence</span><span class="font2">, beberapa diantaranya adalah c_v, c_p, c_uci, c_umass, c_npmi, dan c_a. Pada penelitian ini, digunakan c_v yang berbasis </span><span class="font2" style="font-style:italic;">sliding window</span><span class="font2">, </span><span class="font2" style="font-style:italic;">one-set segmentation</span><span class="font2"> terhadap kata-kata dengan </span><span class="font2" style="font-style:italic;">scoring</span><span class="font2"> yang tinggi, dan </span><span class="font2" style="font-style:italic;">indirect confirmation measure</span><span class="font2"> yang menggunakan </span><span class="font2" style="font-style:italic;">normalized pointwise mutual information </span><span class="font2">(NPMI) dan </span><span class="font2" style="font-style:italic;">cosine similarity</span><span class="font2"> [25]. Pada penelitian ini, </span><span class="font2" style="font-style:italic;">topic coherence</span><span class="font2"> diterapkan pada model LDA yang telah dihasilkan untuk menentukan jumlah topik terbaik berdasarkan nilai </span><span class="font2" style="font-style:italic;">topic coherence</span><span class="font2"> yang dihasilkan.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font2" style="font-weight:bold;">3. &nbsp;&nbsp;&nbsp;Hasil dan Pembahasan</span></p>
<ul style="list-style:none;">
<li>
<h4><a name="bookmark30"></a><span class="font2" style="font-weight:bold;"><a name="bookmark31"></a>3.1</span><span class="font2" style="font-weight:bold;font-style:italic;"> &nbsp;&nbsp;&nbsp;Text Preprocessing</span></h4></li></ul></li></ul>
<p><span class="font2">Tahap pertama yag dilakukan pada </span><span class="font2" style="font-style:italic;">dataset</span><span class="font2"> adalah menerapkan </span><span class="font2" style="font-style:italic;">text preprocessing</span><span class="font2"> pada seluruh ulasan yang ada di </span><span class="font2" style="font-style:italic;">dataset</span><span class="font2"> yang telah dikumpulkan. Adapun proses </span><span class="font2" style="font-style:italic;">text preprocessing</span><span class="font2"> yang dilakukan ditunjukkan pada Tabel 2.</span></p>
<p><span class="font2" style="font-weight:bold;">Tabel 2. </span><span class="font2">Tahap </span><span class="font2" style="font-style:italic;">Text Preprocessing</span></p>
<table border="1">
<tr><td style="vertical-align:middle;">
<p><span class="font2">Langkah</span></p>
<p><span class="font2" style="font-style:italic;">Preprocessing</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">Teks</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font2">Kondisi Awal Teks</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">Aplikasi yg menarik, bisa mendengar cerita&quot; yg seru juga</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font2" style="font-style:italic;">Noise Removal</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">Aplikasi yg menarik bisa mendengar cerita yg seru juga</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font2" style="font-style:italic;">Case Folding</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">aplikasi yg menarik bisa mendengar cerita yg seru juga</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font2" style="font-style:italic;">Normalization</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">aplikasi yang menarik bisa mendengar cerita yang seru juga</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font2" style="font-style:italic;">Tokenization</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">[‘aplikasi’, ‘yang’, ‘menarik’, ‘bisa’, ‘mendengar’, ‘cerita’, ‘yang’, ‘seru’, ‘juga’]</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font2" style="font-style:italic;">Stopword Removal</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">[‘aplikasi’, ‘menarik’, ‘mendengar’, ‘cerita’, ‘seru’]</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font2" style="font-style:italic;">Stemming</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">[‘aplikasi’, ‘tarik’, ‘dengar’, ‘cerita’, ‘seru’]</span></p></td></tr>
</table>
<p><span class="font2">Pada penelitian ini, proses </span><span class="font2" style="font-style:italic;">text preprocessing</span><span class="font2"> dilakukan dengan menggunakan bahasa pemrograman Python. Proses ini dilakukan dengan memanfaatkan </span><span class="font2" style="font-style:italic;">library</span><span class="font2"> NLTK untuk melakukan </span><span class="font2" style="font-style:italic;">tokenizing</span><span class="font2"> dan </span><span class="font2" style="font-style:italic;">stopword removal</span><span class="font2"> serta </span><span class="font2" style="font-style:italic;">library</span><span class="font2"> Sastrawi untuk melakukan </span><span class="font2" style="font-style:italic;">stemming</span><span class="font2">. Untuk proses normalisasi, penulis menggunakan kamus kata yang digunakan pada penelitian sebelumnya [26]. Setelah menerapkan keseluruhan tahapan </span><span class="font2" style="font-style:italic;">text preprocessing</span><span class="font2"> pada 8341 ulasan, akan dilakukan proses penghapusan data yang hasil </span><span class="font2" style="font-style:italic;">text preprocessing</span><span class="font2">-nya tidak lagi menyisakan kata apapun. Dari hasil penghapusan data tersebut, diperoleh data sebanyak 8155 ulasan yang akan diolah pada tahapan berikutnya, yang mana sebanyak 2034 dari data tersebut adalah ulasan negatif dan sebanyak 6121 adalah ulasan positif.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font2" style="font-weight:bold;">3.2 &nbsp;&nbsp;&nbsp;Ekstraksi Fitur</span></p></li></ul>
<p><span class="font2">Pada penelitian ini, proses ekstraksi fitur pada </span><span class="font2" style="font-style:italic;">dataset</span><span class="font2"> yang telah dilakukan </span><span class="font2" style="font-style:italic;">preprocessing</span><span class="font2"> akan dilakukan dengan menggunakan TF-IDF dan </span><span class="font2" style="font-style:italic;">bag-of-words</span><span class="font2">. Hasil ekstraksi fitur menggunakan TF-IDF akan dijadikan sebagai </span><span class="font2" style="font-style:italic;">input</span><span class="font2"> dari model analisis sentimen. Dalam proses pemodelan topik, LDA akan menggunakan </span><span class="font2" style="font-style:italic;">document-term matrix</span><span class="font2"> (DTM) yang disusun menggunakan </span><span class="font2" style="font-style:italic;">bag-of-words </span><span class="font2">dan </span><span class="font2" style="font-style:italic;">dictionary</span><span class="font2"> yang mengandung setiap kata pada </span><span class="font2" style="font-style:italic;">corpus</span><span class="font2">. Hasil penerapan TF-IDF dapat dilihat pada gambar 3, yaitu berupa </span><span class="font2" style="font-style:italic;">sparse matrix</span><span class="font2"> yang berisikan bobot TF-IDF dengan jumlah baris sebanyak jumlah ulasan dan jumlah kolom sebanyak jumlah kata yang menjadi fiturnya. Sedangkan, hasil penerapan ekstraksi fitur dapat dilihat pada gambar 4. Pada hasil penerapan </span><span class="font2" style="font-style:italic;">bag-of-words</span><span class="font2"> dengan menggunakan </span><span class="font2" style="font-style:italic;">library</span><span class="font2"> Gensim, diperoleh </span><span class="font2" style="font-style:italic;">list</span><span class="font2"> yang berisikan pasangan indeks dari suatu kata beserta jumlah kemunculannya pada setiap kalimat atau ulasan pada </span><span class="font2" style="font-style:italic;">dataset</span><span class="font2"> yang digunakan.</span></p>
<p><span class="font0">[41]: PrintCbentukmatriks: &quot;, tf_x_train.shape) print(&quot;matriks: &quot;, tf_x_train)</span></p>
<p><span class="font0">bentuk matriks: (6524, 4337)</span></p>
<p><span class="font0">matriks: &nbsp;&nbsp;&nbsp;(0, 2761) &nbsp;&nbsp;0.6946802473480708</span></p>
<p><span class="font0">(0, 3563) &nbsp;&nbsp;&nbsp;&nbsp;0.719318673429533</span></p>
<p><span class="font0">(1, 1881) &nbsp;&nbsp;&nbsp;&nbsp;0.1558024387418681</span></p>
<p><span class="font0">(1, 3946) &nbsp;&nbsp;&nbsp;&nbsp;0.17302712753359992</span></p>
<p><span class="font0">(1, 2830) &nbsp;&nbsp;&nbsp;&nbsp;0.13007074235777372</span></p>
<p><span class="font0">(1, 260) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.30601061614313796</span></p>
<p><span class="font0">(1, 3871) &nbsp;&nbsp;&nbsp;&nbsp;0.19810649152894022</span></p>
<p><span class="font0">(1, 390) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.33909292564436494</span></p>
<p><span class="font0">(1, 679) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.24207102258848268</span></p>
<p><span class="font2" style="font-weight:bold;">Gambar 3. </span><span class="font2">Hasil Ekstraksi TF-IDF</span></p>
<p><span class="font5">[47]: review_dtm</span></p>
<p><span class="font5">[47]: [[(0, 1)],</span></p>
<p><span class="font5">[(1, 1)], [(2<sub>f</sub> 1)], [(3<sub>f</sub> 1), (4, 1), (5, 1)], [(6, 1), (7, 1), (8, 1), (9, 1)], [(10, D, (11, 1), (12, D, (13, 1), (14, 1), (15, 1), (16, 1), (17. 1).</span></p>
<p><span class="font2" style="font-weight:bold;">Gambar 4</span><span class="font2">. Hasil Ekstraksi </span><span class="font2" style="font-style:italic;">Bag-of-Words</span></p>
<ul style="list-style:none;"><li>
<p><span class="font2" style="font-weight:bold;">3.3 &nbsp;&nbsp;&nbsp;Analisis Sentimen Dengan XGBoost</span></p></li></ul>
<p><span class="font2">Setelah melalui fase </span><span class="font2" style="font-style:italic;">text preprocessing</span><span class="font2"> dan pembobotan, analisis sentimen dapat dilakukan dengan menggunakan hasil ekstraksi fitur TF-IDF. Proses analisis sentimen akan dilakukan dengan menggunakan algoritma XGBoost melalui </span><span class="font2" style="font-style:italic;">library</span><span class="font2"> XGBoost. Karena XGBoost memiliki banyak </span><span class="font2" style="font-style:italic;">hyperparameter</span><span class="font2">, maka akan digunakan </span><span class="font2" style="font-style:italic;">grid search</span><span class="font2"> beserta </span><span class="font2" style="font-style:italic;">K-fold cross validation</span><span class="font2"> untuk menentukan kombinasi </span><span class="font2" style="font-style:italic;">hyperparameter</span><span class="font2"> yang dapat memberikan akurasi paling optimal. </span><span class="font2" style="font-style:italic;">Hyperparameter</span><span class="font2"> yang akan disesuaikan pada penelitian ini adalah tiga dari tujuh </span><span class="font2" style="font-style:italic;">hyperparameter </span><span class="font2">yang dinyatakan memiliki pengaruh yang signifikan terhadap performa model XGBoost, yaitu “max_depth” yang berkaitan dengan kedalaman maksimum dari </span><span class="font2" style="font-style:italic;">tree</span><span class="font2">, “learning_rate” yang berkaitan dengan </span><span class="font2" style="font-style:italic;">step size</span><span class="font2">, dan “max_leaves” yang berkaitan dengan jumlah maksimum </span><span class="font2" style="font-style:italic;">node </span><span class="font2">yang ditambahkan [27]. Untuk </span><span class="font2" style="font-style:italic;">hyperparameter</span><span class="font2"> “max_depth”, akan digunakan rentang nilai 3, 4, 5, 7, dan 9. Untuk </span><span class="font2" style="font-style:italic;">hyperparameter</span><span class="font2"> “learning_rate”, akan digunakan rentang nilai 0,1, 0,3, dan 0,5. Untuk </span><span class="font2" style="font-style:italic;">hyperparameter</span><span class="font2"> “learning_rate”, akan digunakan rentang nilai 0, 3, 5, 7, dan 10.</span></p>
<p><span class="font2" style="font-style:italic;">Dataset</span><span class="font2"> akan dibagi menjadi dua bagian, yaitu data </span><span class="font2" style="font-style:italic;">training</span><span class="font2"> sebesar 80% dan data </span><span class="font2" style="font-style:italic;">testing </span><span class="font2">sebesar 20%. Proses </span><span class="font2" style="font-style:italic;">grid search</span><span class="font2"> dan </span><span class="font2" style="font-style:italic;">K-fold cross validation</span><span class="font2"> akan dilakukan terlebih dahulu pada data </span><span class="font2" style="font-style:italic;">training</span><span class="font2"> untuk memperoleh kombinasi </span><span class="font2" style="font-style:italic;">hyperparameter</span><span class="font2"> terbaik berdasarkan akurasi dari model yang dihasilkan. Proses </span><span class="font2" style="font-style:italic;">grid search</span><span class="font2"> dan </span><span class="font2" style="font-style:italic;">K-fold cross validation</span><span class="font2"> dilakukan dengan menggunakan GridSearchCV pada library </span><span class="font2" style="font-style:italic;">scikit-learn</span><span class="font2">. Pada proses tersebut, model XGBoost dengan performa terbaik dihasilkan dengan menggunakan kombinasi </span><span class="font2" style="font-style:italic;">hyperparameter </span><span class="font2">learning_rate bernilai 0,3, max_depth bernilai 7, dan max_leaves bernilai 0. Pada kombinasi </span><span class="font2" style="font-style:italic;">hyperparameter</span><span class="font2"> tersebut, diperoleh akurasi sebesar 86,1% dengan menggunakan 5 </span><span class="font2" style="font-style:italic;">fold</span><span class="font2"> pada data </span><span class="font2" style="font-style:italic;">training</span><span class="font2">. </span><span class="font2" style="font-style:italic;">Confusion matrix</span><span class="font2"> dari model dengan kombinasi </span><span class="font2" style="font-style:italic;">hyperparameter</span><span class="font2"> terbaik ditunjukkan pada Gambar 5. Pada model tersebut, diperoleh akurasi, </span><span class="font2" style="font-style:italic;">precision</span><span class="font2">, </span><span class="font2" style="font-style:italic;">recall</span><span class="font2">, dan </span><span class="font2" style="font-style:italic;">F1 score</span><span class="font2"> yang berturut-turut bernilai 86,8%, 83,9%, 77,9%, dan 80,2%. Adapun hasil klasifikasi dari model yang dihasilkan dan dapat dilihat pada tabel 3.</span></p><img src="https://jurnal.harianregional.com/media/92679-3.jpg" alt="" style="width:237pt;height:159pt;">
<p><span class="font2" style="font-weight:bold;">Gambar 5</span><span class="font2">. </span><span class="font2" style="font-style:italic;">Confusion Matrix</span><span class="font2"> Dari Model Yang Dihasilkan</span></p>
<p><span class="font2" style="font-weight:bold;">Tabel 3. </span><span class="font2">Hasil Klasifikasi</span></p>
<table border="1">
<tr><td style="vertical-align:middle;">
<p><span class="font2">Ulasan</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">Sentimen</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font2">Gabisa dipake, &quot;Aduh error&quot; katanya.</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">Negatif</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font2">bagus isi podcastnya</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">Positif</span></p></td></tr>
</table>
<ul style="list-style:none;"><li>
<p><span class="font2" style="font-weight:bold;">3.4 &nbsp;&nbsp;&nbsp;Pemodelan Topik Dengan LDA</span></p></li></ul>
<p><span class="font2">Pada penelitian ini, pemodelan topik melalui LDA dilakukan pada masing-masing sentimen ulasan, yaitu ulasan dengan sentimen positif dan ulasan dengan sentimen negatif. Hal tersebut dilakukan untuk memperoleh informasi mengenai kelebihan maupun kekurangan dari aplikasi Noice melalui topik-topik yang dibahas pada masing-masing kelas sentimen. Dalam menentukan jumlah topik yang sesuai, digunakan </span><span class="font2" style="font-style:italic;">topic coherence</span><span class="font2"> untuk menentukan jumlah topik yang ideal pada masing-masing kelas sentimen. Pada tahap ini, penulis menggunakan </span><span class="font2" style="font-style:italic;">library</span><span class="font2"> Gensim untuk mengimplementasikan LDA.</span></p><img src="https://jurnal.harianregional.com/media/92679-4.jpg" alt="" style="width:218pt;height:145pt;">
<p><span class="font2" style="font-weight:bold;">Gambar 6</span><span class="font2">. Perbandingan </span><span class="font2" style="font-style:italic;">Topic Coherence</span><span class="font2"> Pemodelan LDA Pada Sentimen Positif</span></p><img src="https://jurnal.harianregional.com/media/92679-5.jpg" alt="" style="width:207pt;height:138pt;">
<p><span class="font2" style="font-weight:bold;">Gambar 7. </span><span class="font2">Perbandingan </span><span class="font2" style="font-style:italic;">Topic Coherence</span><span class="font2"> Pemodelan LDA Pada Sentimen Negatif</span></p>
<p><span class="font2">Ditunjukkan pada gambar 6, pada ulasan dengan sentimen positif, jumlah topik yang menghasilkan </span><span class="font2" style="font-style:italic;">topic coherence</span><span class="font2"> terbaik adalah sebanyak tiga topik dengan </span><span class="font2" style="font-style:italic;">topic coherence</span><span class="font2"> yang bernilai 0,439. Untuk ulasan dengan sentimen negatif, ditunjukkan pada gambar 7 bahwa jumlah topik yang menghasilkan </span><span class="font2" style="font-style:italic;">topic coherence</span><span class="font2"> terbaik adalah sebanyak enam topik dengan </span><span class="font2" style="font-style:italic;">topic coherence</span><span class="font2"> yang bernilai 0,390. Hasil penerapan pemodelan topik pada ulasan dengan sentimen positif dan negatif ditunjukkan pada Tabel 4 dan 5.</span></p>
<p><span class="font2" style="font-weight:bold;">Tabel 4. </span><span class="font2">Hasil Pemodelan Topik Pada Ulasan Dengan Sentimen Positif</span></p>
<p><span class="font2">Topik &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Kata</span></p>
<ul style="list-style:none;"><li>
<p><span class="font2">1 &nbsp;&nbsp;&nbsp;&quot;noice&quot;, &quot;keren&quot;, &quot;bagus&quot;, &quot;podcast&quot;, &quot;nya&quot;, &quot;banget&quot;, &quot;dengar&quot;, &quot;aplikasi&quot;, &quot;suka&quot;, &quot;radio&quot;'</span></p></li>
<li>
<p><span class="font2" style="font-style:italic;">2</span><span class="font2"> &nbsp;&nbsp;&nbsp;&quot;mantap&quot;, &quot;aplikasi&quot;, &quot;hiya&quot;, &quot;keren&quot;, &quot;banget&quot;, &quot;pokok&quot;, &quot;nya&quot;, &quot;seru&quot;, &quot;gara&quot;, &quot;wow&quot;</span></p></li>
<li>
<p><span class="font2">3 &nbsp;&nbsp;&nbsp;&quot;cok&quot;, &quot;muslim&quot;, &quot;dengar&quot;, &quot;podcast&quot;, &quot;musuh&quot;, &quot;masyarakat&quot;, &quot;unduh&quot;, &quot;aplikasi&quot;, &quot;radio&quot;, &quot;good&quot;</span></p></li></ul>
<p><span class="font2">Pada ulasan dengan sentimen positif, topik pertama dapat diinterpretasikan sebagai topik yang membahas kepuasan pengguna terhadap aplikasi Noice beserta konten </span><span class="font2" style="font-style:italic;">podcast</span><span class="font2"> dan radionya melalui kata “keren”, “suka”, ataupun “bagus”. Pada topik kedua, diinterpretasikan bahwa topik tersebut membahas mengenai kepuasan pengguna terhadap aplikasi Noice melalui kata “mantap”, “keren”, ataupun “seru” serta alasan yang menyebabkan pengguna menggunakan aplikasi Noice. Pada topik ketiga, diinterpretasikan bahwa topik tersebut membahas mengenai pengguna yang menggunakan aplikasi Noice untuk mendengarkan konten “Musuh Masyarakat” yang dibawakan oleh Coki Pardede dan Tretan Muslim.</span></p>
<p><span class="font2" style="font-weight:bold;">Tabel 5. </span><span class="font2">Hasil Pemodelan Topik Pada Ulasan Dengan Sentimen Negatif</span></p>
<p><span class="font2">Topik &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Kata</span></p>
<ul style="list-style:none;"><li>
<p><span class="font2">1 &nbsp;&nbsp;&nbsp;&quot;mati&quot;, &quot;bagus&quot;, &quot;dengar&quot;, &quot;radio&quot;, &quot;bikin&quot;, &quot;malas&quot;, &quot;politik&quot;, &quot;screen&quot;, &quot;podcastnya&quot;, &quot;kayak&quot;</span></p></li>
<li>
<p><span class="font2" style="font-style:italic;">2</span><span class="font2"> &nbsp;&nbsp;&nbsp;&nbsp;&quot;aplikasi&quot;, &quot;noice&quot;, &quot;ya&quot;, &quot;nya&quot;, &quot;tolong&quot;, &quot;dengar&quot;, &quot;baik&quot;, &quot;detik&quot;, &quot;buka&quot;, &quot;suka&quot;</span></p></li>
<li>
<p><span class="font2" style="font-style:italic;">3</span><span class="font2"> &nbsp;&nbsp;&nbsp;&quot;musik&quot;, &quot;baik&quot;, &quot;putar&quot;, &quot;dengar&quot;, &quot;app&quot;, &quot;tolong&quot;, &quot;unduh&quot;, &quot;eror&quot;, &quot;putus&quot;, &quot;podcast&quot;</span></p></li>
<li>
<p><span class="font2" style="font-style:italic;">4</span><span class="font2"> &nbsp;&nbsp;&nbsp;&quot;lagu&quot;, &quot;error&quot;, &quot;aplikasi&quot;, &quot;nya&quot;, &quot;podcast&quot;, &quot;baru&quot;, &quot;dengar&quot;, &quot;banget&quot;, &quot;koneksi&quot;, &quot;buka&quot;</span></p></li>
<li>
<p><span class="font2" style="font-style:italic;">5</span><span class="font2"> &nbsp;&nbsp;&nbsp;&quot;cok&quot;, &quot;muslim&quot;, &quot;podcast&quot;, &quot;suka&quot;, &quot;mulu&quot;, &quot;dengar&quot;, &quot;gue&quot;, &quot;koneksi&quot;, &quot;tingkat&quot;, &quot;mati&quot;</span></p></li>
<li>
<p><span class="font2" style="font-style:italic;">6</span><span class="font2"> &nbsp;&nbsp;&nbsp;&quot;podcast&quot;, &quot;nya&quot;, &quot;putar&quot;, &quot;nih&quot;, &quot;kuota&quot;, &quot;jam&quot;, &quot;payah&quot;, &quot;makan&quot;, &quot;hidup&quot;, &quot;habis&quot;'</span></p></li></ul>
<p><span class="font2">Pada ulasan dengan sentimen negatif, topik pertama membahas mengenai permasalahan aplikasi Noice yang mati sendiri ketika sedang digunakan serta hal-hal yang menyebabkan pengguna merasa malas dalam menggunakan aplikasi Noice. Pada topik kedua, diinterpretasikan bahwa topik ini membahas mengenai permintaan perbaikan permasalahan yang ada pada aplikasi beserta masalah-masalah yang sering dihadapi pengguna baik permasalahan dalam membuka aplikasi maupun dalam pemutaran kontennya. Pada topik ketiga, diinterpretasikan bahwa pengguna merasa kurangnya koleksi serta permasalahan konten musik pada Aplikasi Noice, adanya </span><span class="font2" style="font-style:italic;">error</span><span class="font2">, permasalahan dalam mengunduh aplikasi ataupun konten, serta adanya permasalahan konten yang putus-putus ketika pengguna mendengarkan suatu konten. Pada topik keempat, diinterpretasikan bahwa topik ini membahas mengenai kurangnya koleksi serta permasalahan lagu di aplikasi Noice, keluhan terkait </span><span class="font2" style="font-style:italic;">error</span><span class="font2"> di aplikasi Noice, permasalahan dalam membuka aplikasi, dan permasalahan koneksi dalam mendengarkan konten di aplikasi Noice. Pada topik kelima, diinterpretasikan bahwa pengguna mengunduh aplikasi hanya karena adanya konten milik Coki Pardede dan Tretan Muslim, adanya</span></p>
<p><span class="font2">permasalahan koneksi ketika mengakses konten pada aplikasi Noice, serta permintaan untuk meningkatkan aplikasi Noice agar menjadi lebih baik. Pada topik keenam, diinterpretasikan bahwa topik tersebut membahas mengenai permasalahan pemutaran konten, pengiriman kode verifikasi yang lama, serta aplikasi Noice yang banyak memakan kuota.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font2" style="font-weight:bold;">4. &nbsp;&nbsp;&nbsp;Kesimpulan</span></p></li></ul>
<p><span class="font2">Dari 8341 ulasan aplikasi Noice yang diperoleh melalui Google Play Store, sebanyak 6286 dari ulasan tersebut merupakan sentimen positif dan sebanyak 2055 merupakan sentimen negatif. Dari proses analisis sentimen yang dilakukan, diperoleh model XGBoost yang mampu mengklasifikasikan sentimen pada ulasan aplikasi Noice dengan akurasi, </span><span class="font2" style="font-style:italic;">precision</span><span class="font2">, </span><span class="font2" style="font-style:italic;">recall</span><span class="font2">, dan </span><span class="font2" style="font-style:italic;">F1-score</span><span class="font2"> yang bernilai 86,8%, 83,9%, 77,9%, dan 80,2%. Model XGBoost tersebut menggunakan </span><span class="font2" style="font-style:italic;">hyperparameter</span><span class="font2"> learning_rate yang bernilai 0,3, max_depth yang bernilai 7, dan max_leaves yang bernilai 0.</span></p>
<p><span class="font2">Berdasarkan pemodelan topik yang telah dilakukan pada ulasan dengan sentimen positif dan negatif melalui LDA, diperoleh jumlah topik yang menghasilkan </span><span class="font2" style="font-style:italic;">topic coherence</span><span class="font2"> terbaik pada ulasan dengan sentimen positif yaitu sebanyak 3 topik. Sedangkan, jumlah topik yang menghasilkan </span><span class="font2" style="font-style:italic;">topic coherence</span><span class="font2"> terbaik pada ulasan dengan sentimen negatif adalah sebanyak 6 topik. Pada sentimen positif, ulasan umumnya berisikan pujian terhadap aplikasi, konten yang disukai oleh penulis ulasan, serta alasan pengguna mengunduh aplikasi Noice. Sedangkan, topik yang dibahas pada sentimen negatif membahas mengenai permasalahan yang lebih spesifik seperti permasalahan koneksi, permasalahan pembukaan aplikasi, permasalahan pemutaran atau pengunduhan konten, penggunaan kuota, pengiriman kode verifikasi, ataupun aplikasi yang mati dengan sendirinya.</span></p>
<p><span class="font2" style="font-weight:bold;">Referensi</span></p>
<ul style="list-style:none;"><li>
<p><span class="font2">[1] &nbsp;&nbsp;&nbsp;Sortlist, “COVID-19 Boosts Audio Consumption by 76.2%: 2021 Survey”, 26 Agustus 2022.</span></p></li></ul>
<p><span class="font2">[Online]. Tersedia: &nbsp;&nbsp;&nbsp;&nbsp;</span><a href="https://www.sortlist.com/datahub/reports/covid-19-boosts-audio-"><span class="font2" style="text-decoration:underline;">https://www.sortlist.com/datahub/reports/covid-19-boosts-audio-</span></a></p>
<p><span class="font2" style="text-decoration:underline;">consumption-by-76-2-2021-survey/</span><span class="font2">. 29 September 2022.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font2">[2] &nbsp;&nbsp;&nbsp;IndoTelko, “Noice masuk 50 besar startup TOP Indonesia versi Tech In Asia”, 22 Februari 2022. Tersedia: </span><a href="https://www.indotelko.com/read/1645464215/noice-masuk-50-besar-startup-top-indonesia-versi-tech-in-asia"><span class="font2" style="text-decoration:underline;">https://www.indotelko.com/read/1645464215/noice-masuk-50-besar-startup-top-indonesia-versi-tech-in-asia</span></a><span class="font2">. 1 Oktober 2022.</span></p></li>
<li>
<p><span class="font2">[3] &nbsp;&nbsp;&nbsp;C. A. Melton, O. A. Olusanya, N. Ammar, dan A. Shaban-Nehad, “Public sentiment analysis and topic modeling regarding COVID-19 vaccines on the Reddit social media platform: A call to action for strengthening vaccine confidence,” </span><span class="font2" style="font-style:italic;">Journal of Infection and Public Health</span><span class="font2">, vol. 14, no. 10, 2021.</span></p></li>
<li>
<p><span class="font2">[4] &nbsp;&nbsp;&nbsp;M. Muhajid, E. Lee, F. Rustam, P. B. Washington, S. Ullah, A. A. Reshi, dan I. Ashraf, “Sentiment Analysis and Topic Modeling on Tweets about Online Education during COVID-19,” </span><span class="font2" style="font-style:italic;">Applied Sciences</span><span class="font2">, vol. 11, no. 18, 2021.</span></p></li>
<li>
<p><span class="font2">[5] &nbsp;&nbsp;&nbsp;M. N. Aziz, A. Firmanto, A. M. Fajrin, dan R. V. Hari Ginardi, &quot;Sentiment Analysis and Topic Modelling for Identification of Government Service Satisfaction,&quot; </span><span class="font2" style="font-style:italic;">2018 5th International Conference on Information Technology, Computer, and Electrical Engineering (ICITACEE)</span><span class="font2">, pp. 125-130, 2018.</span></p></li>
<li>
<p><span class="font2">[6] &nbsp;&nbsp;&nbsp;H. Ullah, B. Ahmad, I. Sana, A. Sattar, A. Khan, S. Akbar, dan M. Z. Asghar, “Comparative study for machine learning classifier recommendation to predict political affiliation based on online reviews,” </span><span class="font2" style="font-style:italic;">CAAI Transactions on Intelligence Technology</span><span class="font2">, vol. 6, no. 3, p. 251– 264, 2021.</span></p></li>
<li>
<p><span class="font2">[7] &nbsp;&nbsp;&nbsp;R. Albalawi, T. H. Yeap, M. Benyoucef, “Using Topic Modeling Methods for Short-Text Data: A Comparative Analysis”, </span><span class="font2" style="font-style:italic;">Frontiers in Artificial Intelligence</span><span class="font2">, vol. 3, no. 42, 2020.</span></p></li>
<li>
<p><span class="font2">[8] &nbsp;&nbsp;&nbsp;Y. D. Kirana dan S. A. Faraby, “Sentiment Analysis of Beauty Product Reviews Using the K-Nearest Neighbor (KNN) and TF-IDF Methods with Chi-Square Feature Selection,” </span><span class="font2" style="font-style:italic;">Journal of Data Science and Its Applications</span><span class="font2">, vol. 4, no. 1, p. 31 - 42, 2021.</span></p></li>
<li>
<p><span class="font2">[9] &nbsp;&nbsp;&nbsp;A. R. L. Pratama dan W. Astuti, “Implementation of Enhance Confix Stripping Stemmer Algorithm for Multiclass Dataset Classification in News Text using K-Nearest Neighbor,” </span><span class="font2" style="font-style:italic;">Journal of Data Science and Its Applications</span><span class="font2">, vol. 4, no. 1, p. 11 - 17, 2021.</span></p></li>
<li>
<p><span class="font2">[10] &nbsp;&nbsp;&nbsp;P. Z. Amalia dan E. Winarko, “Aspect-Based Sentiment Analysis on Indonesian Restaurant Review Using a Combination of Convolutional Neural Network and Contextualized Word Embedding,” </span><span class="font2" style="font-style:italic;">IJCCS (Indonesian Journal of Computing and Cybernetics Systems)</span><span class="font2">, vol. 15, no. 3, p. 285 - 294, 2021.</span></p></li>
<li>
<p><span class="font2">[11] &nbsp;&nbsp;&nbsp;H. S. Hota, D. K. Sharma, dan N. Verma, “Lexicon-based sentiment analysis using Twitter data: a case of COVID-19 outbreak in India and abroad,” </span><span class="font2" style="font-style:italic;">Data Science for COVID-19</span><span class="font2">, p. 275 - 295, 2021.</span></p></li>
<li>
<p><span class="font2">[12] &nbsp;&nbsp;&nbsp;W. Bourequat dan H. Mourad, “Sentiment Analysis Approach for Analyzing iPhone Release using Support Vector Machine,” </span><span class="font2" style="font-style:italic;">International Journal of Advances in Data and Information Systems</span><span class="font2">, vol. 4, no. 1, p. 36 - 44, 2021.</span></p></li>
<li>
<p><span class="font2">[13] &nbsp;&nbsp;&nbsp;A. Beheshti, S. Ghodratnama, M. Elahi, dan H. Farhood, Social Data Analytics, Florida: CRC Press, 2022, p. 67.</span></p></li>
<li>
<p><span class="font2">[14] &nbsp;&nbsp;&nbsp;S. Kalra, L. Li, dan H. R. Tizhoosh, “Automatic Classification of Pathology Reports using TF-IDF Features”, </span><span class="font2" style="font-style:italic;">arXiv preprint arXiv:1903.07406</span><span class="font2">, 2019.</span></p></li>
<li>
<p><span class="font2">[15] &nbsp;&nbsp;&nbsp;SW. Kim dan JM. Gil, “Research paper classification systems based on TF-IDF and LDA schemes,”, </span><span class="font2" style="font-style:italic;">Human-centric Computing and Information Sciences</span><span class="font2">, vol. 9, no. 30, 2019.</span></p></li>
<li>
<p><span class="font2">[16] &nbsp;&nbsp;&nbsp;A. M. AL-Shatnwai dan M. Faris, “Predicting Customer Retention using XGBoost and Balancing Methods,” </span><span class="font2" style="font-style:italic;">International Journal of Advanced Computer Science and Applications(IJACSA),</span><span class="font2"> vol. 11, no. 7, 2020</span></p></li>
<li>
<p><span class="font2">[17] &nbsp;&nbsp;&nbsp;H. Manoharan dan Dr. J. Dhilipan, “Diabetes Mellitus Prediction on Class Balanced Data Set using XGBoost Algorithms,” </span><span class="font2" style="font-style:italic;">Journal of Xi'an Shiyou University, Natural Science Edition</span><span class="font2">, vol. 18, no. 1, 2022.</span></p></li>
<li>
<p><span class="font2">[18] &nbsp;&nbsp;&nbsp;N. Qomariah, “Sentiment Analysis on Coffee Consumer Perceptions on Social Media Twitter Using Multinomial Naïve Bayes” </span><span class="font2" style="font-style:italic;">Journal of Intelligent Computing and Health Informatics</span><span class="font2">, vol. 2, no. 1, 2021.</span></p></li>
<li>
<p><span class="font2">[19] &nbsp;&nbsp;&nbsp;S. G. C G dan B. Sumathi, “Grid Search Tuning of Hyperparameters in Random Forest Classifier for Customer Feedback Sentiment Prediction,” </span><span class="font2" style="font-style:italic;">(IJACSA) International Journal of Advanced Computer Science and Applications</span><span class="font2">, vol. 11, no. 9, 2020.</span></p></li>
<li>
<p><span class="font2">[20] &nbsp;&nbsp;&nbsp;A. Nurkholis, D. Alita, A. Munandar, “Comparison of Kernel Support Vector Machine Multi-Class in PPKM Sentiment Analysis on Twitter,” </span><span class="font2" style="font-style:italic;">Jurnal RESTI (Rekayasa Sistem Dan Teknologi Informasi)</span><span class="font2">, vol. 6, no. 2, p. 227 - 233, 2022.</span></p></li>
<li>
<p><span class="font2">[21] &nbsp;&nbsp;&nbsp;C. Sitaula dan T. B. Shahi, “Multi-channel CNN to classify nepali covid-19 related tweets using hybrid features,” </span><span class="font2" style="font-style:italic;">arXiv preprint arXiv:2203</span><span class="font2">, 2022.</span></p></li>
<li>
<p><span class="font2">[22] &nbsp;&nbsp;&nbsp;G. Papadia, M. Pacella, V. Giliberti, “Topic Modeling for Automatic Analysis of Natural Language: A Case Study in an Italian Customer Support Center,” </span><span class="font2" style="font-style:italic;">Algorithms</span><span class="font2">, vol. 15, no. 6, 2022.</span></p></li>
<li>
<p><span class="font2">[23] &nbsp;&nbsp;&nbsp;T. D. Tandjung dan D. H. Fudholi, “Topic Modeling with Latent-Dirichlet Allocation for the Discovery of State-of-the-Art in Research: A Literature Review,” </span><span class="font2" style="font-style:italic;">Harbin Gongye Daxue Xuebao/Journal of Harbin Institute of Technology</span><span class="font2">, vol. 54, no. 8, 2022.</span></p></li>
<li>
<p><span class="font2">[24] &nbsp;&nbsp;&nbsp;S. Devi, C. Dhavale, L. Moharkar, S. Khanvilkar, “Impact of Online Education and Sentiment Analysis from Twitter Data using Topic Modeling Algorithms,” </span><span class="font2" style="font-style:italic;">International Journal of Applied Sciences and Smart Technologies</span><span class="font2">, vol. 4, no. 1, p. 21 - 34, 2022.</span></p></li>
<li>
<p><span class="font2">[25] &nbsp;&nbsp;&nbsp;S. Mifrah dan E. H. Benlahmar, “Topic Modeling Coherence: A Comparative Study between LDA and NMF Models using COVID’19 Corpus,” </span><span class="font2" style="font-style:italic;">International Journal of Advanced Trends in Computer Science and Engineering</span><span class="font2">, vol. 9, no. 4, p. 5756 - 5761, 2020.</span></p></li>
<li>
<p><span class="font2">[26] &nbsp;&nbsp;&nbsp;M. O. Ibrohim dan I. Budi, “Multi-label Hate Speech and Abusive Language Detection in Indonesian Twitter,” </span><span class="font2" style="font-style:italic;">Association for Computational Linguistics</span><span class="font2">, p. 46 - 57.</span></p></li>
<li>
<p><span class="font2">[27] &nbsp;&nbsp;&nbsp;Y. Wang dan X. S. Ni, “A XGBoost risk model via feature selection and Bayesian hyperparameter optimization,” </span><span class="font2" style="font-style:italic;">arXiv preprint arXiv:1901.08433</span><span class="font2">, 2019.</span></p></li></ul>
<p><span class="font9">336</span></p>