---
layout: full_article
title: "Efektifitas Algoritma K-NN dan Random Forest Dalam Mengenali Gender Berdasarkan Suara"
author: "Berlin Pratama, I Ketut Gede Suhartana"
categories: jnatia
canonical_url: https://jurnal.harianregional.com/jnatia/full-92539 
citation_abstract_html_url: "https://jurnal.harianregional.com/jnatia/id-92539"
citation_pdf_url: "https://jurnal.harianregional.com/jnatia/full-92539"  
comments: true
---

<p><span class="font1">JNATIA Volume 1, Nomor 1, November 2022</span></p>
<p><span class="font1">Jurnal Nasional Teknologi Informasi dan Aplikasinya</span></p><a name="caption1"></a>
<h1><a name="bookmark0"></a><span class="font2" style="font-weight:bold;"><a name="bookmark1"></a>Efektifitas Algoritma K-NN dan Random Forest Dalam Mengenali Gender Berdasarkan Suara</span></h1>
<p><span class="font1">Berlin Pratama<sup>a1</sup></span><span class="font1" style="font-weight:bold;">, </span><span class="font1">I Ketut Gede Suhartana<sup>a2</sup></span></p>
<p><span class="font1"><sup>a</sup>Informatics Departement, Udayana University</span></p>
<p><span class="font1">Badung, Bali, Indonesia </span><a href="mailto:1berlinprtm1@gmail.com"><span class="font1"><sup>1</sup>berlinprtm1@gmail.com</span></a><span class="font1"> </span><a href="mailto:2ikg.suhartana@unud.ac.id"><span class="font1"><sup>2</sup>ikg.suhartana@unud.ac.id</span></a></p>
<p><span class="font1" style="font-weight:bold;font-style:italic;">Abstract</span></p>
<p><span class="font1" style="font-style:italic;">Gender is the grammatical classification of words and other words related to it that broadly relates to the existence of two sexuality or neutrality</span><span class="font1">[1]</span><span class="font1" style="font-style:italic;">. Human beings have the ability to recognize one's gender through hearing and vision. Within the many differences that in each individual, there are some similarities between men and women that can be directly observed. Women that can be observed directly. One of them is their voice, although the voice of each individual human being is different, but there are similarities between the voices of one and another woman and also man’s voice. If listen carefully, woman's voice tends to be higher when compared to men's voices. Through these differences, it’s possible to identify human voice through computer media by paying attention to comparison of the frequency of the voice, so that it can be classified into male or female voices</span><span class="font1">[2]</span><span class="font1" style="font-style:italic;">. In computer science this is called sound analysis, but often human sounds differ from the original after processing by computer. In this case, we try to differentiate human voices by gender using the K-Nearest Neighbor and Random Forest algorithms. The K-Nearest Neighbor algorithm has an accuracy of 76%, while Random Forest has an accuracy of 97%.</span></p>
<p><span class="font1" style="font-weight:bold;font-style:italic;">Keywords: </span><span class="font1" style="font-style:italic;">Random Forest, K-Nearest Neighbor, Voice Recognition, Female, Male</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark2"></a><span class="font1" style="font-weight:bold;"><a name="bookmark3"></a>1. &nbsp;&nbsp;&nbsp;Pendahuluan</span></h2></li></ul>
<p><span class="font1">Suara manusia memiliki berbagai bentuk yang berbeda, mereka dapat dilihat dari persepsi fisik manusia tentang suara diantaranya, bentuk, jenis suara, nada, timbre, dan volume. Persepsi fisik ini dapat didengar dengan jelas sewaktu diucapkan oleh pria atau Wanita. Tentunya akan lebih mudah lagi jika seseorang dapat mendengar langsung lawan bicaranya[2]. Semakin berkembangnya teknologi pada era sekarang, menjadikan pengidentifikasian individu lebih mudah berkat bantuan komputer, salah satu bentuk identitas diri adalah biometrik. Suara yang dulunya mudah dikenali oleh manusia melalui pendengaran dan penglihatannya, sekarang akan dibantu oleh komputer[2]. Metode </span><span class="font1" style="font-style:italic;">random forest</span><span class="font1"> bersifat relatif </span><span class="font1" style="font-style:italic;">robust</span><span class="font1"> kepada </span><span class="font1" style="font-style:italic;">outliers</span><span class="font1"> dan noise, hal itu menjadikannya unggul. Ketika membandingkan metode </span><span class="font1" style="font-style:italic;">random forest</span><span class="font1"> dengan metode klasifikasi pohon keputusan lainnya seperti, </span><span class="font1" style="font-style:italic;">ADTree, LADTree, C4.5, CART, Random Tree, REPTree</span><span class="font1"> dan </span><span class="font1" style="font-style:italic;">BFTree</span><span class="font1"> metode </span><span class="font1" style="font-style:italic;">random forest</span><span class="font1"> memiliki tingkat keakuratan sebesar 96,65% dalam hal pengklasifikasian </span><span class="font1" style="font-style:italic;">file audio</span><span class="font1">[3]. Selain itu, penelitian ini juga menggunakan metode </span><span class="font1" style="font-style:italic;">K-Nearest Neighbor</span><span class="font1"> sebagai faktor pembanding tingkat akurasi di akhir. Metode K-NN memiliki kelebihan yaitu tahan terhadap data latih dengan banyak </span><span class="font1" style="font-style:italic;">noise</span><span class="font1"> dan keefektifan apabila data latihnya berjumlah banyak. Selain itu proses klasifikasi metode K-NN mudah direpresentasikan dibandingkan dengan metode klasifikasi lain[4].</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark4"></a><span class="font1" style="font-weight:bold;"><a name="bookmark5"></a>2. &nbsp;&nbsp;&nbsp;Metode Penelitian</span><br><br><span class="font1" style="font-weight:bold;"><a name="bookmark6"></a>2.1 &nbsp;&nbsp;&nbsp;Dataset</span></h2></li></ul>
<p><span class="font1">Penelitian ini menggunakan data sekunder untuk proses pengklasifikasian. Dataset sejumlah 3.168 </span><span class="font1" style="font-style:italic;">sample</span><span class="font1"> rekaman suara, yang dikumpulkan dari suara laki-laki dan perempuan. Suara dilakukan </span><span class="font1" style="font-style:italic;">pre-processing</span><span class="font1"> menggunakan analisis akustik dalam R menggunakan </span><span class="font1" style="font-style:italic;">seewave</span><span class="font1"> dan </span><span class="font1" style="font-style:italic;">tuner packages.</span><span class="font1"> Frekuensi yang dianalisis berada di antara 0Hz-280Hz. Diperoleh dalam bentuk </span><span class="font1" style="font-style:italic;">spreadsheet</span><span class="font1"> yang berisi data akustik dari hasil ekstraksi </span><span class="font1" style="font-style:italic;">file audio</span><span class="font1"> yang berbentuk .wav menjadi</span></p>
<p><span class="font1">bentuk .csv. Dataset dibuat oleh Kory Backer yang dimuat dalam situs opensource Kaggle pada tautan:</span></p>
<p><a href="https://www.kaggle.com/datasets/primaryobjecta/voicegender"><span class="font1">https://www.kaggle.com/datasets/primaryobjecta/voicegender</span></a><span class="font1">.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1" style="font-weight:bold;">2.2 &nbsp;&nbsp;&nbsp;Properti Akustik</span></p></li></ul>
<p><span class="font1" style="font-weight:bold;">Tabel 1. </span><span class="font1">Properti Akustik Suara</span></p>
<table border="1">
<tr><td style="vertical-align:bottom;">
<p><span class="font1">No.</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1" style="font-style:italic;">Properti Akustik</span></p></td><td style="vertical-align:top;"></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font1">1.</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1" style="font-style:italic;">Q75</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1" style="font-style:italic;">third quantile (in kHz)</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font1">2.</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1" style="font-style:italic;">IQR</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1" style="font-style:italic;">interquantile range (in kHz)</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font1">3.</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1" style="font-style:italic;">Skew</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1" style="font-style:italic;">skewness</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font1">3.</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1" style="font-style:italic;">Kurt</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1" style="font-style:italic;">kurtosis</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font1">4.</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1" style="font-style:italic;">sp.ent</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1" style="font-style:italic;">spectral entropy</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font1">5.</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1" style="font-style:italic;">sfm</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1" style="font-style:italic;">spectral flatness</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font1">6.</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1" style="font-style:italic;">mode</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1" style="font-style:italic;">mode frequency</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font1">7.</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1" style="font-style:italic;">centroid</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1" style="font-style:italic;">frequency centroid</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font1">8.</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1" style="font-style:italic;">peakf</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1" style="font-style:italic;">peak frequency (frequency with highest energy)</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font1">9.</span></p></td><td style="vertical-align:top;">
<p><span class="font1" style="font-style:italic;">meanfun</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1" style="font-style:italic;">average of fundamental frequency measured across acoustic signal</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font1">10.</span></p></td><td style="vertical-align:top;">
<p><span class="font1" style="font-style:italic;">minfun</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1" style="font-style:italic;">minimum fundamental frequency measured across acoustic signal</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font1">11.</span></p></td><td style="vertical-align:top;">
<p><span class="font1" style="font-style:italic;">maxfun</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1" style="font-style:italic;">maximum fundamental frequency measured across acoustic signal</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font1">12.</span></p></td><td style="vertical-align:top;">
<p><span class="font1" style="font-style:italic;">meandom</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1" style="font-style:italic;">average of dominant frequency measured across acoustic signal</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font1">13.</span></p></td><td style="vertical-align:top;">
<p><span class="font1" style="font-style:italic;">mindom</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1" style="font-style:italic;">minimum of dominant frequency measured across acoustic signal</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font1">14.</span></p></td><td style="vertical-align:top;">
<p><span class="font1" style="font-style:italic;">maxdom</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1" style="font-style:italic;">maximum of dominant frequency measured across acoustic signal</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font1">15.</span></p></td><td style="vertical-align:top;">
<p><span class="font1" style="font-style:italic;">dfrange</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1" style="font-style:italic;">range of dominant frequency measured across acoustic signal</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font1">16.</span></p></td><td style="vertical-align:top;">
<p><span class="font1" style="font-style:italic;">modindx</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1" style="font-style:italic;">modulation index. Calculated as the accumulated absolute difference between adjacent measurements of fundamental frequencies divided by the frequency range</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font1">17.</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1" style="font-style:italic;">label</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1" style="font-style:italic;">male or female</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font1">18.</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4" style="font-style:italic;">meanfreq</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1" style="font-style:italic;">mean frequency (in kHz)</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font1">19.</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1" style="font-style:italic;">sd</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1" style="font-style:italic;">standard deviation of frequency</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font1">20.</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1" style="font-style:italic;">median</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1" style="font-style:italic;">median frequency (in kHz)</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font1">21.</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">Q25</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1" style="font-style:italic;">First quantile</span></p></td></tr>
</table>
<ul style="list-style:none;"><li>
<p><span class="font1" style="font-weight:bold;">2.3</span><span class="font1" style="font-weight:bold;font-style:italic;"> &nbsp;&nbsp;&nbsp;K-Nearest Neighbor K-NN)</span></p></li></ul>
<p><span class="font1" style="font-style:italic;">K-Nearest Neighbor</span><span class="font1"> (K-NN) merupakan model klasifikasi yang menggunakan kelas terbanyak dengan jarak terdekat dalam grup data yang telah di-</span><span class="font1" style="font-style:italic;">training</span><span class="font1"> untuk menentukan kategori kelas. Algoritma </span><span class="font1" style="font-style:italic;">K-Nearest Neighbor</span><span class="font1"> (K-NN) menjalankan perintah klasifikasi berdasarkan pada jarak terdekat dari sampel uji ke sampel terlatih untuk menetapkan K-NNnya[6]. Sebagian besar dari K-NN diambil untuk menjadi prediksi dari sampel ujinya Jarak objek terdekat biasanya dihitung berdasarkan jarak </span><span class="font1" style="font-style:italic;">Eucledian</span><span class="font1">. Berikut merupakan metode penghitungan K-NN:</span></p>
<p><span class="font1">di= </span><span class="font6">J∑L</span><span class="font5">ι</span><span class="font6">(<sup>x</sup></span><span class="font5">2&quot; </span><span class="font6">- ^</span><span class="font5">i&quot; </span><span class="font6">)2</span></p>
<div>
<p><span class="font1">(1)</span></p>
</div><br clear="all">
<p><span class="font1">Keterangan:</span></p>
<p><span class="font1">x = Sampel dari data</span></p>
<p><span class="font1">x</span><span class="font0">2 </span><span class="font1">= Data yang akan diujikan I = Parameter dari data</span></p>
<p><span class="font1">d = Selisih atau Jarak</span></p>
<p><span class="font1">p = Luas dari data</span></p>
<p><span class="font1">Langkah-langkah dari teknik K-Nearest Neighbor yaitu mulai dari input data terlatih, kemudian label data terlatih, nilai k, dan juga data pengujian</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1" style="font-weight:bold;">2.4</span><span class="font1" style="font-weight:bold;font-style:italic;"> &nbsp;&nbsp;&nbsp;Random Forest</span></p></li></ul>
<p><span class="font1" style="font-style:italic;">Random Forest Algorithm</span><span class="font1"> merupakan suatu algoritma pembelajaran mesin yang berguna dalam klasifikasi. </span><span class="font1" style="font-style:italic;">Random forest</span><span class="font1"> mempunyai bagian yaitu pohon keputusan, yang berfungsi untuk membedakan antara data satu dengan yang lainnya[5]. </span><span class="font1" style="font-style:italic;">Random Forest Algorithm</span><span class="font1"> dapat juga dianggap sebagai bentuk perkembangan dari metode klasifikasi </span><span class="font1" style="font-style:italic;">Decision Tree</span><span class="font1"> yang didasarkan dari pemilihan atribut random disetiap node untuk membentuk klasifikasi. Proses klasifikasinya berdasar pada jumlah suara terbanyak dari </span><span class="font1" style="font-style:italic;">decision tree</span><span class="font1"> yang didapat. Berdasarkan teknis yang diterapkan oleh </span><span class="font1" style="font-style:italic;">Random Forest</span><span class="font1">, menjadikan efisiensi hasil prediksi. Beberapa kelebihan algoritma </span><span class="font1" style="font-style:italic;">Random Forest,</span><span class="font1"> antara lain:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1">a. &nbsp;&nbsp;&nbsp;Memberi solusi untuk </span><span class="font1" style="font-style:italic;">overfitting</span></p></li>
<li>
<p><span class="font1">b. &nbsp;&nbsp;&nbsp;Tingkat sensitivitas terhadap </span><span class="font1" style="font-style:italic;">data outlier</span><span class="font1"> rendah</span></p></li>
<li>
<p><span class="font1">c. &nbsp;&nbsp;&nbsp;Memiliki parameter yang fleksibel (dapat diubah).</span></p></li></ul>
<p><span class="font1">Random forest memiliki karakteristik yang dapat meminimumkan korelasi yang dapat menurunkan hasil kesalahan prediksi random forest. Pada random forest pemilihan pemilah hanya melibatkan beberapa variabel prediktor yang terambil secara acak. Algoritma random forest dijelaskan sebagai berikut[7].</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1">a. &nbsp;&nbsp;&nbsp;Mengambil n data sampel dari dataset awal dengan menggunakan teknik </span><span class="font1" style="font-style:italic;">resampling bootstrap </span><span class="font1">dengan pengambilan.</span></p></li>
<li>
<p><span class="font1">b. &nbsp;&nbsp;&nbsp;Menata pohon klasifikasi dari setiap dataset hasil </span><span class="font1" style="font-style:italic;">resampling bootstrap</span><span class="font1">, dengan penentuan pemilah terbaik didasarkan pada variabel prediktor yang diambil secara acak. Jumlah variabel yang diambil secara acak dapat ditentukan melalui perhitungan </span><span class="font1" style="font-style:italic;">l0g</span><span class="font0" style="font-style:italic;">2 </span><span class="font1" style="font-style:italic;">(Z</span><span class="font1"> + 1) dimana z adalah banyaknya variabel prediktor atau √</span><span class="font6">Z</span><span class="font1">[8].</span></p></li></ul>
<ul style="list-style:none;"><li>
<h2><a name="bookmark7"></a><span class="font1" style="font-weight:bold;"><a name="bookmark8"></a>2.5 &nbsp;&nbsp;&nbsp;Alur Kerja Sistem</span></h2><img src="https://jurnal.harianregional.com/media/92539-1.jpg" alt="" style="width:425pt;height:41pt;"><img src="https://jurnal.harianregional.com/media/92539-2.jpg" alt="" style="width:426pt;height:42pt;"></li></ul>
<p><span class="font1" style="font-weight:bold;">Gambar 1. </span><span class="font1">Alur Kerja Sistem</span></p>
<p><span class="font1">Mengacu pada Gambar 1. Dijelaskan bahwa alur kerja sistem untuk pengujian ini diawali dari menginput data audio berupa </span><span class="font1" style="font-style:italic;">file</span><span class="font1"> berformat .csv yang berisi properti akustik lalu kemudian diidentifikasi menggunakan algoritma K-NN dan </span><span class="font1" style="font-style:italic;">Random Forest</span><span class="font1"> secara terpisah, kemudian akan menghasilkan output berupa prediksi gender suara.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark9"></a><span class="font1" style="font-weight:bold;"><a name="bookmark10"></a>2.6 &nbsp;&nbsp;&nbsp;Evaluasi</span></h2></li></ul>
<p><span class="font1">Dalam evaluasi, menggunakan bantuan </span><span class="font1" style="font-style:italic;">confusion matrix</span><span class="font1"> untuk menghitung </span><span class="font1" style="font-style:italic;">precision, recall, f1-score,</span><span class="font1"> dan akurasi seperti yang tertera pada Tabel 2</span><span class="font1" style="font-style:italic;">. Confusion Matrix</span><span class="font1"> menampilkan performa klasifikasi dari sebuah </span><span class="font1" style="font-style:italic;">classifier</span><span class="font1"> yang sehubungan dengan data uji.</span></p>
<p><span class="font1" style="font-weight:bold;">Tabel 2. </span><span class="font1" style="font-style:italic;">Confusion Matrix</span></p>
<table border="1">
<tr><td style="vertical-align:top;"></td><td style="vertical-align:bottom;">
<p><span class="font1" style="font-style:italic;">Male</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1" style="font-style:italic;">Female</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font1" style="font-style:italic;">Male</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">TP</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">FP</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font1" style="font-style:italic;">Female</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">FN</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">TN</span></p></td></tr>
<tr><td style="vertical-align:top;"></td><td style="vertical-align:top;"></td><td style="vertical-align:top;"></td></tr>
</table>
<p><span class="font1">Keterangan :</span></p>
<p><span class="font1">TP = </span><span class="font1" style="font-style:italic;">True Positive</span><span class="font1"> (total prediksi benar dari data positif)</span></p>
<p><span class="font1">FN = </span><span class="font1" style="font-style:italic;">False Negative</span><span class="font1"> (total prediksi negatif tetapi data positif)</span></p>
<p><span class="font1">TN &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;= </span><span class="font1" style="font-style:italic;">True Negative</span><span class="font1"> (total prediksi benar dari data negatif)</span></p>
<p><span class="font1">FP &nbsp;&nbsp;&nbsp;&nbsp;= </span><span class="font1" style="font-style:italic;">False Positive</span><span class="font1"> (total prediksi positif tetapi data negatif)</span></p>
<p><span class="font1">Adapun rumus untuk menghitung </span><span class="font1" style="font-style:italic;">precision, recall, F1-Score,</span><span class="font1"> dan akurasi adalah sebagai berikut:</span></p>
<div>
<p><span class="font1" style="font-style:italic;">Precision</span><span class="font6"> =</span></p>
</div><br clear="all">
<div>
<p><span class="font3" style="font-style:italic;">TP+TN</span></p>
<p><span class="font3" style="font-style:italic;">TP+TN+FP+FN</span></p>
</div><br clear="all">
<div>
<p><span class="font1" style="font-style:italic;">X</span><span class="font6"> 100%</span></p>
</div><br clear="all">
<div>
<p><span class="font1">(2)</span></p>
</div><br clear="all">
<ul style="list-style:none;"><li>
<h2><a name="bookmark11"></a><span class="font1" style="font-weight:bold;"><a name="bookmark12"></a>3. &nbsp;&nbsp;&nbsp;Hasil dan Pembahasan</span></h2></li></ul>
<p><span class="font1">Data sejumlah 3.168 kemudian dibagi menjadi dua jenis dengan presentase 80% data latih (</span><span class="font1" style="font-style:italic;">training</span><span class="font1">) dan 20% data uji (</span><span class="font1" style="font-style:italic;">testing</span><span class="font1">). Kemudian, lanjut pada dua metode atau algoritma dilakukan proses klasifikasi, didapatkan hasil </span><span class="font1" style="font-style:italic;">precision,,recall,,f1-score</span><span class="font1"> dan akurasi seperti yang tertera pada Tabel 2.</span></p>
<p><span class="font1" style="font-weight:bold;">Tabel 2. </span><span class="font1">Hasil </span><span class="font1" style="font-style:italic;">Precision,,Recall, F1-Score K-Nearest Neighbor</span></p>
<table border="1">
<tr><td style="vertical-align:top;"></td><td style="vertical-align:bottom;">
<p><span class="font1" style="font-style:italic;">Precision</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1" style="font-style:italic;">Recall</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1" style="font-style:italic;">F1-Score</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font1" style="font-style:italic;">Female</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">0.75</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">0.80</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">0.77</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font1" style="font-style:italic;">Male</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">0.82</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">0.78</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">0.80</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font1" style="font-style:italic;">Accuracy</span></p></td><td style="vertical-align:top;"></td><td style="vertical-align:top;"></td><td style="vertical-align:bottom;">
<p><span class="font1">0.79</span></p></td></tr>
</table>
<p><span class="font1">Pengimplementasian algoritma K-Nearest Neighbor menghasilkan tingkat akurasi sebesar 78.54%. Hasil </span><span class="font1" style="font-style:italic;">precision</span><span class="font1"> ada di angka 0.75 untuk kelas wanita dan 0.82 untuk kelas pria. Hasil recall ada di angka 0.80 untuk wanita dan 0.78 untuk pria. Hasil F1-Score adalah 0.77 untuk wanita, 0.80 untuk pria, dan 0.79 untuk akurasi. Data hasil klasifikasi juga dimasukkan ke dalam tabel </span><span class="font1" style="font-style:italic;">confusion matrix</span><span class="font1"> yang terdapat pada Tabel 3.</span></p>
<p><span class="font1" style="font-weight:bold;">Tabel 3. </span><span class="font1">Confusion Matrix K-Nearest Neighbor</span></p>
<table border="1">
<tr><td style="vertical-align:bottom;">
<p><span class="font1" style="font-style:italic;">Matrix</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1" style="font-style:italic;">female</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1" style="font-style:italic;">male</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1" style="font-style:italic;">all</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font1" style="font-style:italic;">Female</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">231</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">59</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">290</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font1" style="font-style:italic;">Male</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">77</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">267</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">344</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font1" style="font-style:italic;">all</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">308</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">326</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">634</span></p></td></tr>
</table>
<p><span class="font1" style="font-weight:bold;">Tabel-4. </span><span class="font1">Hasil </span><span class="font1" style="font-style:italic;">Precision,,Recall, F1-Score Random Forest</span></p>
<table border="1">
<tr><td style="vertical-align:top;"></td><td style="vertical-align:bottom;">
<p><span class="font1" style="font-style:italic;">Precision</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1" style="font-style:italic;">Recall</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1" style="font-style:italic;">F1-Score</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font1" style="font-style:italic;">Female</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">0.99</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">0.97</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">0.98</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font1" style="font-style:italic;">Male</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">0.97</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">0.99</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">0.98</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font1" style="font-style:italic;">Accuracy</span></p></td><td style="vertical-align:top;"></td><td style="vertical-align:top;"></td><td style="vertical-align:bottom;">
<p><span class="font1">0.85</span></p></td></tr>
</table>
<p><span class="font1">Mengacu pada Tabel 4. Pengimplementasian algoritma </span><span class="font1" style="font-style:italic;">Random Forest</span><span class="font1"> menghasilkan tingkat akurasi tertinggi, yaitu sebesar 97.94%. Hasil </span><span class="font1" style="font-style:italic;">precision</span><span class="font1"> ada di angka 0.99 untuk kelas wanita dan 0.97 untuk kelas pria. Hasil </span><span class="font1" style="font-style:italic;">recall</span><span class="font1"> ada di angka 0.97 untuk wanita dan 0.99 untuk pria. Hasil </span><span class="font1" style="font-style:italic;">F1-Score</span><span class="font1"> adalah 0.98 untuk wanita, 0.898 untuk pria, dan 0.85 untuk akurasi. Data hasil klasifikasi juga dimasukkan ke dalam tabel </span><span class="font1" style="font-style:italic;">confusion matrix</span><span class="font1"> seperti pada Tabel 5.</span></p>
<p><span class="font1" style="font-weight:bold;">Tabel 5. </span><span class="font1" style="font-style:italic;">Confusion Matrix Random Forest</span></p>
<table border="1">
<tr><td style="vertical-align:bottom;">
<p><span class="font1" style="font-style:italic;">Matrix</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1" style="font-style:italic;">Female</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1" style="font-style:italic;">Male</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1" style="font-style:italic;">All</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font1" style="font-style:italic;">Female</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">305</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">10</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">315</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font1" style="font-style:italic;">Male</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">3</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">316</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">319</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font1" style="font-style:italic;">all</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">308</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">326</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">634</span></p></td></tr>
</table>
<ul style="list-style:none;"><li>
<h2><a name="bookmark13"></a><span class="font1" style="font-weight:bold;"><a name="bookmark14"></a>4. &nbsp;&nbsp;&nbsp;Kesimpulan</span></h2></li></ul>
<p><span class="font1">Hasil dari pengujian menampilkan bahwa metode </span><span class="font1" style="font-style:italic;">Random Forest</span><span class="font1"> menghasilkan performa yang lebih baik dibandingkan dengan </span><span class="font1" style="font-style:italic;">K-Nearest Neighbor.</span><span class="font1"> Metode </span><span class="font1" style="font-style:italic;">Random Forest</span><span class="font1"> menghasilkan tingkat akurasi sejumlah 97.94% dengan rata-rata </span><span class="font1" style="font-style:italic;">precision, recall,</span><span class="font1"> dan </span><span class="font1" style="font-style:italic;">f1-score</span><span class="font1"> sebesar 98% dan tingkat akurasi </span><span class="font1" style="font-style:italic;">f1-score</span><span class="font1"> sebesar 85%, dibandingkan dengan </span><span class="font1" style="font-style:italic;">K-Nearest Neighbor</span><span class="font1"> yang memiliki tingkat akurasi sejumlah 78.54% dengan rata-rata </span><span class="font1" style="font-style:italic;">precision, recall,</span><span class="font1"> dan </span><span class="font1" style="font-style:italic;">f1-score</span><span class="font1"> sebesar 78%. Hasil tersebut dapat menyatakan bahwa </span><span class="font1" style="font-style:italic;">Random Forest</span><span class="font1"> dapat membedakan suara berdasarkan gender lebih baik dibandingkan </span><span class="font1" style="font-style:italic;">K-Nearest Neighbor.</span></p>
<h2><a name="bookmark15"></a><span class="font1" style="font-weight:bold;"><a name="bookmark16"></a>References</span></h2>
<ul style="list-style:none;"><li>
<p><span class="font1">[1] &nbsp;&nbsp;&nbsp;C. Kurniawan, H. Irsyad, “Perbandingan Metode K-Nearest Neighbor dan Naïve Bayes Untuk Klasifikasi Gender Berdasarkan Mata” </span><span class="font1" style="font-style:italic;">Jurnal Algoritme</span><span class="font1">, vol. 2, no.2, pp. 82-91, 2022.</span></p></li>
<li>
<p><span class="font1">[2] &nbsp;&nbsp;&nbsp;I.S. Pratama, F. I. Kurniadiname, &quot;Klasifikasi Jenis Kelamin Berdasarkan Pitch Suara Menggunakan Metode Pitch Detection Algorithm&quot; </span><span class="font1" style="font-style:italic;">Jurnal Sistem Komputer dan Kecerdasan Buatan,</span><span class="font1"> vol. 2, no. 1, p. 1-4, 2018.</span></p></li>
<li>
<p><span class="font1">[3] &nbsp;&nbsp;&nbsp;A. Sarofi, Irhamah, A. Mukarromah, “Identifikasi Genre Musik dengan Menggunakan Metode Random Forest” </span><span class="font1" style="font-style:italic;">Jurnal Sains dan Seni ITS</span><span class="font1">, vol. 9, no. 1.</span></p></li>
<li>
<p><span class="font1">[4] &nbsp;&nbsp;&nbsp;Mursyidah, Jamilah, and Zayya, “Pengenalan Karakter Suara Laki-Laki Aceh Menggunakan Metode FFT (Fast Fourier Transform)” J. Infomedia, vol. 2, no. 1, pp. 20–24, 2017.</span></p></li>
<li>
<p><span class="font1">[5] &nbsp;&nbsp;&nbsp;S. V. Thambi, K. T. Sreekumar, C. Santhosh Kumar, and P. C. Reghu Raj, “Random Forest Algorithm for Improving the Performance of Speech/non-speech Detection,” 2014 1st Int. Conf. Comput. Syst. Commun. ICCSC 2014, no. December, pp. 28–32, 2003, doi: 10.1109/COMPSC.2014.7032615.</span></p></li>
<li>
<p><span class="font1">[6] &nbsp;&nbsp;&nbsp;R. Yessivirna, Marji, and D. E. Ratnawati, “Klasifikasi Suara Berdasarkan Gender (Jenis Kelamin) Dengan Metode KNearest Neighbor (KNN)” </span><span class="font1" style="font-style:italic;">Jurnal Ilmu Komputer</span><span class="font1">., vol. 1, pp.1–9, 2011.</span></p></li>
<li>
<p><span class="font1">[7] &nbsp;&nbsp;&nbsp;S. Shankar, Raghaveni, J. Rudraraju, P., and V. Sravya. (2020). “Classification of gender by voice recognition using machine learning algorithms”. </span><span class="font1" style="font-style:italic;">Journal of Critical Reviews</span><span class="font1">, </span><span class="font1" style="font-style:italic;">7</span><span class="font1">(9), 1217– 1229. </span><a href="https://doi.org/10.31838/jcr.07.09.222"><span class="font1">https://doi.org/10.31838/jcr.07.09.222</span></a><span class="font1">.</span></p></li>
<li>
<p><span class="font1">[8] &nbsp;&nbsp;&nbsp;M. Azhar, H. F. Pardede, “Klasifikasi Dialek Pengujar Bahasa Inggris Menggunakan Random Forest” </span><span class="font1" style="font-style:italic;">Jurnal Media Informatika Budidarma,</span><span class="font1"> vol. 5, no. 2, pp. 439-446, 2021.</span></p></li></ul>
<p><span class="font1">284</span></p>