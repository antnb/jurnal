---
layout: full_article
title: "KINERJA JACKKNIFE RIDGE REGRESSION DALAM MENGATASI MULTIKOLINEARITAS"
author: "HANY DEVITA, I KOMANG GDE SUKARSA, I PUTU EKA N. KENCANA"
categories: mtk
canonical_url: https://jurnal.harianregional.com/mtk/full-11996 
citation_abstract_html_url: "https://jurnal.harianregional.com/mtk/id-11996"
citation_pdf_url: "https://jurnal.harianregional.com/mtk/full-11996"  
comments: true
---

<p><span class="font5">E-Jurnal Matematika Vol. 3 (4), November 2014, pp. 146 -153</span></p>
<p><span class="font5">ISSN: 2303-1751</span></p><a name="caption1"></a>
<h1><a name="bookmark0"></a><span class="font8" style="font-weight:bold;"><a name="bookmark1"></a>KINERJA </span><span class="font8" style="font-weight:bold;font-style:italic;">JACKKNIFE RIDGE REGRESSION</span><span class="font8" style="font-weight:bold;"> DALAM MENGATASI MULTIKOLINEARITAS</span></h1>
<p><span class="font7">Hany Devita<sup>§1</sup>, I Komang Gde Sukarsa<sup>2</sup>, I Putu Eka N. Kencana<sup>3</sup></span></p>
<p><span class="font5"><sup>1</sup>Jurusan Matematika, Fakultas MIPA - Universitas Udayana [Email: </span><a href="mailto:hanydevita92@gmail.com"><span class="font5">hanydevita92@gmail.com</span></a><span class="font5">] <sup>2</sup>Jurusan Matematika, Fakultas MIPA - Universitas Udayana [Email: </span><a href="mailto:sukarsakomang@yahoo.com"><span class="font5">sukarsakomang@yahoo.com</span></a><span class="font5">]</span></p>
<p><span class="font5"><sup>3</sup>Jurusan Matematika, Fakultas MIPA - Universitas Udayana [Email: </span><a href="mailto:i.putu.enk@gmail.com"><span class="font5">i.putu.enk@gmail.com</span></a><span class="font5">] <sup>§</sup></span><span class="font5" style="font-style:italic;">Corresponding Author</span></p>
<h2><a name="bookmark2"></a><span class="font6" style="font-weight:bold;"><a name="bookmark3"></a>ABSTRACT</span></h2>
<p><span class="font6" style="font-style:italic;">Ordinary least square is a parameter estimations for minimizing residual sum of squares. If the multicollinearity was found in the data, unbias estimator with minimum variance could not be reached. Multicollinearity is a linear correlation between independent variabels in model. Jackknife Ridge Regression(JRR) as an extension of Generalized Ridge Regression (GRR) for solving multicollinearity. Generalized Ridge Regression is used to overcome the bias of estimators caused of presents multicollinearity by adding different bias parameter for each independent variabel in least square equation after transforming the data into an orthoghonal form. Beside that, JRR can reduce the bias of the ridge estimator. The result showed that JRR model out performs GRR model</span><span class="font7">.</span></p>
<p><span class="font6" style="font-weight:bold;font-style:italic;">Keywords</span><span class="font6" style="font-style:italic;">: ordinary least square, multicollinearity, Generalized Ridge Regression, Jackknife Ridge Regression</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark4"></a><span class="font6" style="font-weight:bold;"><a name="bookmark5"></a>1. &nbsp;&nbsp;&nbsp;PENDAHULUAN</span></h2></li></ul>
<p><span class="font6">Analisis regresi merupakan salah satu alat statistika yang digunakan untuk menggambarkan hubungan antara satu peubah tak bebas dengan satu atau lebih peubah bebas (Bowerman &amp;&nbsp;O'Connel [1]). Dalam pembentukan model regresi dilakukan pendugaan terhadap parameter regresi dalam model untuk menghasilkan penduga terbaik dengan menggunakan metode kuadrat terkecil. Metode kuadrat terkecil adalah metode untuk menduga parameter dalam model regresi dengan meminimumkan jumlah kuadratnya. Jika penduga tak bias dan ragam minimum tidak dapat dihasilkan maka mengindikasikan adanya multikolinearitas pada model.</span></p>
<p><span class="font6">Multikolinearitas merupakan suatu keadaan terjadinya hubungan linear antara peubah-peubah bebas dalam model yang menyebabkan model menjadi bias sehingga nilai penduga parameternya menjadi tidak stabil. Untuk mengetahui ada tidaknya</span></p>
<p><span class="font6">masalah multikolinearitas dapat menggunakan nilai </span><span class="font6" style="font-style:italic;">Variance Inflation Factory</span><span class="font6"> (VIF). Jika nilai VIF &gt;&nbsp;5 maka peubah bebas dalam model mengalami multikolinearitas (Neter, et al. [5]). Ada berbagai metode yang digunakan dalam mengatasi multikolinearitas yaitu metode regresi stepwise, analisis komponen utama, </span><span class="font6" style="font-style:italic;">ridge regression</span><span class="font6"> dan </span><span class="font6" style="font-style:italic;">generalized ridge regression</span><span class="font6">. Pada setiap metode memiliki kekurangan dan kelebihan namun setiap metode dapat digunakan dalam mengatasi masalah multikolinearitas.</span></p>
<p><span class="font6">Pada penelitian ini, penulis menggunakan metode </span><span class="font6" style="font-style:italic;">Jackknife Ridge Regression</span><span class="font6"> yaitu pengembangan dari metode generalized ridge regression dengan lebih menekankan pengurangan bias pada penduga ridge (Ozkale [6]). Tujuan dari penelitian ini adalah untuk mengetahui kinerja </span><span class="font6" style="font-style:italic;">Jackknife Ridge Regression</span><span class="font6"> dalam mengatasi masalah multikolinearitas dan untuk mengetahui</span></p>
<p><span class="font6">kelayakan model yang dihasilkan </span><span class="font6" style="font-style:italic;">Jackknife Ridge Regression</span><span class="font6"> dengan melihat nilai MSE dan R<sup>2</sup> yang dihasilkan pada model.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark6"></a><span class="font6" style="font-weight:bold;"><a name="bookmark7"></a>2. &nbsp;&nbsp;&nbsp;TINJAUAN PUSTAKA</span></h2>
<ul style="list-style:none;">
<li>
<p><span class="font6">2.1. &nbsp;&nbsp;&nbsp;Analisis Regresi Berganda</span></p></li></ul></li></ul>
<p><span class="font6">Analisis regresi linear berganda adalah analisis regresi yang menghubungkan antara satu peubah tak bebas </span><span class="font6" style="font-style:italic;">Y</span><span class="font6"> dengan banyak peubah bebas </span><span class="font6" style="font-style:italic;">X</span><span class="font6">. Persamaan regresi linear berganda dapat dijabarkan menjadi notasi matriks, sebagai bentuk perluasan dari model regresi linear secara umum yang bertujuan dapat mengindikasikan langkah-langkah penting dalam menemukan solusi. Notasi matriks yang terbentuk dari persamaan regresi linear berganda sebagai berikut:</span></p>
<p><span class="font6" style="font-style:italic;">^n</span><span class="font3"> ×1</span><span class="font6">= &nbsp;&nbsp;&nbsp;</span><span class="font3">×</span><span class="font6" style="font-style:italic;">pβp</span><span class="font3">×1</span><span class="font6"><sup>+</sup> </span><span class="font6" style="font-style:italic;">^n</span><span class="font3"> ×1</span></p>
<p><span class="font6">dengan;</span></p>
<p><span class="font6" style="font-style:italic;">n</span><span class="font6"> = jumlah pengamatan </span><span class="font6" style="font-style:italic;">p</span><span class="font6"> = banyaknya parameter </span><span class="font6" style="font-style:italic;">Y</span><span class="font6"> = vektor peubah tak bebas </span><span class="font6" style="font-style:italic;">β</span><span class="font6"> = vektor parameter regresi </span><span class="font6" style="font-style:italic;">X</span><span class="font6"> = matriks peubah bebas </span><span class="font6" style="font-style:italic;">ε</span><span class="font6"> = vektor peubah acak (sisaan) normal bebas</span></p>
<p><span class="font6">dengan nilai harapan </span><span class="font6" style="font-style:italic;">E</span><span class="font6">(</span><span class="font6" style="font-style:italic;">ε</span><span class="font6">) = 0 dan matriks ragam-peragam </span><span class="font6" style="font-style:italic;">σ<sup>2</sup></span><span class="font6"> (</span><span class="font6" style="font-style:italic;">ε</span><span class="font6">)= </span><span class="font6" style="font-style:italic;">σ<sup>2</sup>I</span><span class="font6">.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font6">2.1.1 &nbsp;&nbsp;&nbsp;Pengujian Hipotesis pada Regresi</span></p></li></ul>
<p><span class="font6">Linear Berganda</span></p>
<p><span class="font6">Pengujian hipotesis bertujuan untuk menguji kecocokan model. Terdapat dua pengujian yaitu:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font6">1. &nbsp;&nbsp;&nbsp;Uji </span><span class="font6" style="font-style:italic;">F</span><span class="font6"> ( Uji Signifikansi Model)</span></p></li></ul>
<p><span class="font6">Uji &nbsp;&nbsp;&nbsp;&nbsp;</span><span class="font6" style="font-style:italic;">F</span><span class="font6"> &nbsp;&nbsp;&nbsp;&nbsp;digunakan &nbsp;&nbsp;&nbsp;&nbsp;untuk</span></p>
<p><span class="font6">menggambarkan ada atau tidak hubungan linear antara peubah tak bebas Y dengan semua peubah bebas secara simultan yang ada dalam model.</span></p>
<p><span class="font6">Hipotesis yang diuji:</span></p>
<p><span class="font6" style="font-style:italic;">U<sub>0</sub></span><span class="font6"> : &nbsp;= &nbsp;=⋯= &nbsp;&nbsp;&nbsp;=0</span></p>
<p><span class="font6" style="font-style:italic;">H^</span><span class="font6"> : &nbsp;&nbsp;≠0 minimal untuk satu</span></p>
<p><span class="font6">nilai </span><span class="font6" style="font-style:italic;">k, k=1,2,..,p-1</span></p>
<p><span class="font6">Statistik ujinya (Neter, et al. [5]) adalah:</span></p>
<p><span class="font1">∗ </span><span class="font6" style="font-style:italic;">_JKR</span><span class="font1" style="text-decoration:underline;">(</span><span class="font1">*ι </span><span class="font1" style="text-decoration:underline;">,…,</span><span class="font1"> ¾-l</span><span class="font1" style="text-decoration:underline;">)</span><span class="font1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="font6" style="font-style:italic;">n</span><span class="font5"><sup>-</sup></span><span class="font6" style="font-style:italic;">P</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1">r<sup>∗</sup>= &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;×</span></p></li></ul>
<p><span class="font6" style="font-style:italic;">P</span><span class="font1">-1 &nbsp;&nbsp;&nbsp;&nbsp;</span><span class="font5"><sup>×</sup></span><span class="font6" style="font-style:italic;">JKG</span><span class="font1"> (*ι ,…, ¾-l)</span></p>
<p><span class="font6" style="font-style:italic;">_ KTR </span><span class="font5"><sup>=</sup></span></p>
<p><span class="font6">Kaidah keputusan:</span></p>
<p><span class="font6">Jika </span><span class="font6" style="font-style:italic;">F</span><span class="font3">∗ </span><span class="font6">≤</span><span class="font6" style="font-style:italic;">F</span><span class="font3">(, , &nbsp;&nbsp;&nbsp;&nbsp;) </span><span class="font6">maka </span><span class="font4" style="font-style:italic;font-variant:small-caps;">Hq</span><span class="font6"> diterima</span></p>
<p><span class="font6">Jika </span><span class="font6" style="font-style:italic;">F</span><span class="font3">∗ </span><span class="font6">&gt;</span><span class="font6" style="font-style:italic;">F</span><span class="font3">(, , &nbsp;&nbsp;&nbsp;&nbsp;) </span><span class="font6">maka </span><span class="font4" style="font-style:italic;font-variant:small-caps;">Hq</span><span class="font6"> ditolak</span></p>
<ul style="list-style:none;"><li>
<p><span class="font6">2. &nbsp;&nbsp;&nbsp;Uji </span><span class="font6" style="font-style:italic;">t</span><span class="font6"> (Uji Parsial Model)</span></p></li></ul>
<p><span class="font6">Uji </span><span class="font6" style="font-style:italic;">t</span><span class="font6"> digunakan jika pada uji signifikansi (uji </span><span class="font6" style="font-style:italic;">F</span><span class="font6">) menghasilkan kesimpulan </span><span class="font4" style="font-style:italic;font-variant:small-caps;">Hq</span><span class="font6"> ditolak yang berarti minimal ada satu variabel yang berpengaruh siginifikan terhadap model. Tujuan uji </span><span class="font6" style="font-style:italic;">t</span><span class="font6"> untuk mengetahui ada atau tidak hubungan linear antara peubah tak bebas </span><span class="font6" style="font-style:italic;">Y </span><span class="font6">dengan masing-masing peubah bebas yang ada dalam model.</span></p>
<p><span class="font6">Hipotesis yang diuji:</span></p>
<p><a href="#bookmark8"><span class="font6" style="font-style:italic;">H<sub>0</sub></span><span class="font6"> :=0</span></a></p>
<p><a href="#bookmark9"><span class="font6" style="font-style:italic;">Hi</span><span class="font6"> :≠0</span></a></p>
<p><span class="font6">Statistik ujinya (Neter, et al. [5]) adalah:</span></p>
<p><a href="#bookmark10"><span class="font6"><sup>∗</sup>=</span></a></p>
<p><span class="font6">t =</span></p>
<p><span class="font6" style="font-style:italic;">Se</span><span class="font6"> ( ̂</span><span class="font6" style="font-style:italic;">k</span><span class="font6">)</span></p>
<p><span class="font6">Keterangan; </span><span class="font6" style="font-style:italic;">Se</span><span class="font6"> (</span><span class="font6" style="font-style:italic;">k</span><span class="font6">)= standard </span><span class="font6" style="font-style:italic;">error</span><span class="font6"> penduga koefisien regresi</span></p>
<p><span class="font6">Kaidah Keputusan:</span></p>
<p><span class="font6">Jika | </span><span class="font6" style="font-style:italic;">t</span><span class="font3">∗</span><span class="font6">|≤ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;maka </span><span class="font4" style="font-style:italic;font-variant:small-caps;">Hq</span><span class="font6"> diterima</span></p>
<p><span class="font6"><sup>,</sup></span></p>
<p><span class="font6">Jika | </span><span class="font6" style="font-style:italic;">t</span><span class="font6"><sup>∗</sup>|&gt; </span><span class="font6" style="font-style:italic;">ta</span><span class="font6"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;maka </span><span class="font6" style="font-style:italic;">H<sub>0</sub></span><span class="font6"> ditolak</span></p>
<ul style="list-style:none;"><li>
<p><span class="font6">2.2. &nbsp;&nbsp;&nbsp;Metode Kuadrat Terkecil</span></p></li></ul>
<p><span class="font6">Metode kuadrat terkecil adalah metode untuk menduga parameter dalam model regresi dengan cara meminimumkan jumlah kuadrat galatnya (Neter, et al. [5]). Vektor koefisien regresi dugaan </span><span class="font6" style="font-style:italic;">βQ</span><span class="font6"> , </span><span class="font6" style="font-style:italic;">βl</span><span class="font6">,…,</span><span class="font6" style="font-style:italic;">βp-l</span><span class="font6"> dituliskan sebagai berikut:</span></p>
<p><span class="font3">× . </span><span class="font6">=[ &nbsp;⋮]</span></p>
<p><span class="font6">Persamaan normal kuadrat terkecil bagi model linear umum adala</span></p>
<p><span class="font6" style="font-style:italic;">X<sup>r</sup>Xb</span><span class="font6"> = ′</span><span class="font6" style="font-style:italic;">Y</span></p>
<p><span class="font6">Dengan penduga kuadrat terkecilnya adalah:</span></p>
<p><span class="font6" style="font-style:italic;">b<sub>p</sub></span><span class="font3"> ×i</span><span class="font6">=(</span><span class="font6" style="font-style:italic;">X<sup>r</sup>X</span><span class="font3"><sup>)</sup> \ × </span><span class="font6" style="font-style:italic;">V<sup>x</sup></span><span class="font3"><sup> ′ </sup></span><span class="font6" style="font-style:italic;"><sup>Y</sup>V</span><span class="font3"> × 1</span></p>
<p><span class="font6">Untuk model regresi, penduga-penduga kuadrat terkecil ini juga merupakan penduga</span></p>
<p><span class="font6">kemungkinan maksimum dan memenuhi asumsi-asumsi yang harus dipenuhi yaitu galat menyebar normal dengan nilai tengah 0 dan ragam konstan ,tidak terdapat korelasi antar galat, dan tidak terdapat pola hubungan yang terbentuk antar peubah-peubah bebas.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font6">2.3.</span><span class="font6" style="font-style:italic;"> &nbsp;&nbsp;&nbsp;Generalized Ridge Regression</span></p></li></ul>
<p><span class="font6">Dalam metode </span><span class="font6" style="font-style:italic;">Generalized Ridge Regression</span><span class="font6"> (GRR) dilakukan transformasi terhadap data sehingga peubah bebas menjadi peubah bebas yang </span><span class="font6" style="font-style:italic;">orthogonal</span><span class="font6">[4] terhadap peubah tak bebas . Pertama-tama diasumsikan bahwa Ʌ merupakan matriks × dengan anggota dari diagonal utamanya merupakan nilai eigen ( &nbsp;&nbsp;, &nbsp;&nbsp;,…, &nbsp;&nbsp;) dari matriks ′</span></p>
<p><span class="font6">dan jika <sub>×</sub> merupakan matriks </span><span class="font6" style="font-style:italic;">orthogonal </span><span class="font6">dari vektor eigen yang bersesuaian dengan λ</span><span class="font6" style="font-weight:bold;">, </span><span class="font6">maka &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=Ʌ. Misalkan = &nbsp;&nbsp;&nbsp;dan</span></p>
<p><span class="font6">= &nbsp;′ . Model linear persamaan regresi yang</span></p>
<p><span class="font6">dihasilkan menjadi &nbsp;&nbsp;&nbsp;&nbsp;+ . Penduga yang</span></p>
<p><span class="font6">diperoleh dari metode kuadrat terkecil menjadi ̂=Λ &nbsp;&nbsp;′ . Vektor penduga parameter awal</span></p>
<p><span class="font6">dapat dihitung menjadi = &nbsp;̂. Penduga</span></p>
<p><span class="font6">GRR merupakan solusi dari (Λ+Κ) ̂ &nbsp;=</span></p>
<p><span class="font6">′ , dengan </span><span class="font6" style="font-style:italic;">K</span><span class="font6"> merupakan matriks diagonal dengan anggota ( &nbsp;, &nbsp;,…, &nbsp;&nbsp;). &nbsp;Koefisien</span></p>
<p><span class="font6" style="font-style:italic;">generalized ridge</span><span class="font6"> pada model awal yaitu</span></p>
<p><span class="font6"><sup>̂</sup> &nbsp;&nbsp;= &nbsp;̂</span></p>
<p><span class="font6">Pertimbangan &nbsp;&nbsp;&nbsp;untuk &nbsp;&nbsp;&nbsp;pemilihan</span></p>
<p><span class="font6">parameter bias pada </span><span class="font6" style="font-style:italic;">K</span><span class="font6"> berdasarkan pada nilai MSE. Untuk menentukan nilai digunakan pendekatan iteratif (Hoerl &amp;&nbsp;Kennard [3]) yang diawali dengan menentukan solusi kuadrat terkecil, didapatkan penduga awal untuk</span></p>
<p><span class="font6"><sup>k</sup>? =f^ , </span><span class="font6" style="font-style:italic;">j = <sup>1</sup>'<sup>2</sup>'-,p Uj</span></p>
<p><span class="font6">Penduga awal dari digunakan untuk menghitung penduga awal </span><span class="font6" style="font-style:italic;">generalized ridge </span><span class="font6">dari</span></p>
<p><span class="font6">̂ </span><span class="font3">, </span><span class="font6">=(Λ+Κ ) &nbsp;&nbsp;′</span></p>
<p><span class="font6">dengan,K = &nbsp;&nbsp;&nbsp;&nbsp;(k ,k ,…,k ).</span></p>
<p><span class="font6">Selanjutnya pendugaan awal ̂ &nbsp;<sub>,</sub> digunakan</span></p>
<p><span class="font6">untuk menghitung pendugaan</span></p>
<div>
<p><span class="font3">/T^</span></p>
</div><br clear="all">
<div>
<p><span class="font6"><sup>k =( ̂</sup> &nbsp;</span><span class="font2">, </span><span class="font6"><sup>) ,</sup></span></p>
</div><br clear="all">
<div>
<p><span class="font6">j = 1,2,^,P</span></p>
</div><br clear="all">
<p><span class="font6">Nilai k ini menghitung pendugaan seterusnya. Proses iterasi</span></p>
<div>
<p><span class="font6">dapat digunakan dari ̂ &nbsp;<sub>,</sub> , dan</span></p>
<p><span class="font6">dilanjutkan hingga</span></p>
</div><br clear="all">
<p><span class="font6">penduga parameter yang stabil didapatkan.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font6">2.4.</span><span class="font6" style="font-style:italic;"> &nbsp;&nbsp;&nbsp;Jackknife Ridge Regression</span></p></li></ul>
<p><span class="font6">Metode </span><span class="font6" style="font-style:italic;">Jackknife</span><span class="font6"> diperkenalkan pertama kali oleh Hinkley pada tahun 1977 yang merupakan pengembangan dari metode </span><span class="font6" style="font-style:italic;">Generalized Ridge Regression</span><span class="font6">. Model awal seperti model umum regresi linear yaitu</span></p>
<p><a href="#bookmark11"><span class="font6">=+</span></a></p>
<p><span class="font6">dengan = &nbsp;&nbsp;&nbsp;&nbsp;dan = &nbsp;′ . G adalah</span></p>
<p><span class="font6">matriks berukuran &nbsp;&nbsp;&nbsp;× yang kolom-</span></p>
<p><a href="#bookmark12"><span class="font6">kolomnya dinormalisasi vektor eigen dari matriks ′ . Matriks &nbsp;&nbsp;&nbsp;&nbsp;==Λ.</span></a></p>
<p><span class="font6">Penduga </span><span class="font6" style="font-style:italic;">generalized regression</span><span class="font6"> dari dapat ditulis sebagai:</span></p>
<p><a href="#bookmark13"><span class="font6">̂ &nbsp;=( Λ+Κ) &nbsp;&nbsp;&nbsp;== Λ ̂</span></a></p>
<p><a href="#bookmark14"><span class="font6">=( -) ̂</span></a></p>
<p><span class="font6">dengan </span><span class="font6" style="font-style:italic;">K</span><span class="font6"> = matriks diagonal dengan anggota ( &nbsp;, &nbsp;,…, &nbsp;), &nbsp;= Λ+Κ. Pada = &nbsp;′ dan</span></p>
<p><span class="font6">= , penduga </span><span class="font6" style="font-style:italic;">generalized regression</span></p>
<p><span class="font6">(GRE) dari adalah:</span></p>
<p><a href="#bookmark15"><span class="font6"><sup>̂</sup> &nbsp;&nbsp;= &nbsp;̂ &nbsp;&nbsp;&nbsp;= &nbsp;&nbsp;&nbsp;&nbsp;<sub>∗</sub>′</span></a></p>
<p><a href="#bookmark16"><span class="font6">dengan <sub>∗</sub> = &nbsp;&nbsp;&nbsp;&nbsp;+.</span></a></p>
<p><a href="#bookmark17"><span class="font6">Menurut Hinkley (1997) metode </span><span class="font6" style="font-style:italic;">Jackknife</span><span class="font6"> berasal dari ̂ sebagai berikut: ̂ &nbsp;&nbsp;=[ -() ] ̂</span></a></p>
<p><span class="font6">Aplikasi metode </span><span class="font6" style="font-style:italic;">Jackniffe</span><span class="font6"> dihitung dengan mentransformasi ulang agar mendapatkan penduga parameter dari regresi awal.</span></p>
<p><span class="font6">Penduga </span><span class="font6" style="font-style:italic;">jackknife ridge</span><span class="font6"> diperoleh dengan langka-langkah sebagai berikut:</span></p>
<p><a href="#bookmark18"><span class="font6"><sup>̂</sup> &nbsp;=̂</span></a></p>
<p><a href="#bookmark19"><span class="font6">̂ &nbsp;&nbsp;&nbsp;= &nbsp;[ +( &nbsp;&nbsp;&nbsp;&nbsp;)][ -()] ̂</span></a></p>
<p><span class="font6">= &nbsp;[ +( &nbsp;&nbsp;&nbsp;&nbsp;)]( Λ)Λ ′</span></p>
<p><a href="#bookmark20"><span class="font6">= &nbsp;[ +( &nbsp;&nbsp;&nbsp;&nbsp;)]′ ′</span></a></p>
<p><a href="#bookmark21"><span class="font6">=[ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;+ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;′]′</span></a></p>
<p><span class="font6">karena</span></p>
<p><a href="#bookmark22"><span class="font6">= &nbsp;&nbsp;&nbsp;+ &nbsp;= &nbsp;[ &nbsp;&nbsp;&nbsp;+]</span></a></p>
<p><span class="font6">maka;</span></p>
<p><span class="font6" style="font-style:italic;">GA~<sup>1</sup>G'</span><span class="font6">=(</span><span class="font6" style="font-style:italic;">X<sup>,</sup>X</span><span class="font6"> +</span><span class="font6" style="font-style:italic;">K</span><span class="font3">∗</span><span class="font6"><sup>)</sup> ^<sup>1</sup> = ∗ <sup>-1</sup> dan</span></p>
<p><span class="font6" style="font-style:italic;">GA-<sup>1</sup>KA~<sup>1</sup>G'</span><span class="font6"> = </span><span class="font3">∗ </span><span class="font6" style="font-style:italic;"><sup>1</sup>K</span><span class="font3">∗</span><span class="font6" style="font-style:italic;">A</span><span class="font6"><sub>∗</sub></span></p>
<p><span class="font6">dengan </span><span class="font6" style="font-style:italic;">K</span><span class="font3">∗</span><span class="font6"><sup>=</sup></span><span class="font6" style="font-style:italic;">GKG</span><span class="font6"> ′</span></p>
<p><span class="font6">Setelah mendapatkan penduga koefisien regresi dari metode </span><span class="font6" style="font-style:italic;">Jackknife Ridge Regression</span><span class="font6">, perlu dipastikan apakah peubah-peubah bebas yang terlibat dalam model sudah tidak &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;mengindikasikan &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;adanya</span></p>
<p><span class="font6">multikolinearitas dengan kembali melihat nilai </span><span class="font6" style="font-style:italic;">Variance Inflation Factors</span><span class="font6"> (VIF). </span><span class="font6" style="font-style:italic;">VIF</span><span class="font2" style="font-style:italic;">j</span><span class="font6" style="font-style:italic;">(K) </span><span class="font6">adalah fungsi dari K yang merupakan unsur diagonal ke j dalam matriks;</span></p>
<p><span class="font6">(</span><span class="font6" style="font-style:italic;">X'X</span><span class="font6"> +</span><span class="font6" style="font-style:italic;">K</span><span class="font6">) </span><span class="font6" style="font-style:italic;">-<sup>1</sup>x<sup>,</sup>x</span><span class="font6">(</span><span class="font6" style="font-style:italic;">X'X</span><span class="font6"> +</span><span class="font6" style="font-style:italic;">K</span><span class="font3">) ^<sup>1 </sup></span><span class="font6">Apabila nilai VIF dari masing-masing peubah bebas ≤ 5 maka dipastikan bahwa peubah-peubah bebas sudah terbebas dari masalah multikolinearitas</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark23"></a><span class="font6" style="font-weight:bold;"><a name="bookmark24"></a>3. &nbsp;&nbsp;&nbsp;METODE PENELITIAN</span></h2></li></ul>
<p><span class="font6">Penelitian ini menggunakan data sekunder yang merupakan data yang diperoleh secara tidak langsung. Dalam hal ini data yang digunakan adalah data mengenai kebutuhan akan tenaga kerja pada 17 Rumah Sakit Angkatan Laut U.S dari Tabel 13.3 dalam buku Bowerman dan O’Connel(1997).</span></p>
<p><span class="font6">Langkah-langkah yang dilakukan dalam metode penelitian ini adalah: &nbsp;&nbsp;&nbsp;1)</span></p>
<p><span class="font6">Mengkonfirmasi adanya multikolinearitas dengan melihat nilai VIF, 2) Melakukan analisi regresi linear berganda pada data, 3) Membakukan data, 4) Melakukan proses orthogonalisasi pada peubah-peubah bebas, 5) Menentukan nilai K yang merupakan matriks diagonal dengan anggota (</span><span class="font6" style="font-style:italic;">k<sub>1</sub></span><span class="font6"> , ^2 ,…, ^5) dan penduga koefisien </span><span class="font6" style="font-style:italic;">generalized ridge</span><span class="font6"> dari peubah bebas &nbsp;&nbsp;&nbsp;orthogonal &nbsp;&nbsp;&nbsp;dengan</span></p>
<p><span class="font6">menggunakan metode iterasi. Pendugaaan </span><span class="font6" style="text-decoration:underline;"><sup>̂</sup></span><span class="font6"><sup>2</sup> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;.</span></p>
<p><span class="font6">awal untuk </span><span class="font6" style="font-style:italic;">k*j</span><span class="font6"> = — , digunakan untuk menghitung parameter </span><span class="font6" style="font-style:italic;">generalized ridge</span><span class="font6"> untuk peubah bebas orthogonal: &nbsp;&nbsp;̂ </span><span class="font6" style="font-style:italic;">GR</span><span class="font6"> =( Λ+</span></p>
<p><span class="font6">Κ) </span><span class="font6" style="font-style:italic;"><sup>1</sup>Z'y</span><span class="font6">, 6) Menentukan penduga awal </span><span class="font6" style="font-style:italic;">jackknife ridge regression</span><span class="font6"> yaitu ̂ <sup>= </sup>[</span><span class="font6" style="font-style:italic;">I</span><span class="font6">-(</span><span class="font6" style="font-style:italic;">A~<sup>1</sup>K</span><span class="font6">)<sup>2</sup>] <sup>̂</sup> </span><span class="font6" style="font-style:italic;">LS</span><span class="font6"> , 7) Mentransformasikan penduga awal </span><span class="font6" style="font-style:italic;">jackknife ridge regression</span><span class="font6"> yaitu</span></p>
<p><span class="font6">A &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;^ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;H r &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;∙∙ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1 1 &nbsp;&nbsp;∙ &nbsp;&nbsp;&nbsp;77 &nbsp;&nbsp;&nbsp;∕<sup>,</sup></span></p>
<p><span class="font6" style="font-style:italic;">β</span><span class="font6">= &nbsp;̂ </span><span class="font6" style="font-style:italic;">JK</span><span class="font6"> [2], 8) Menguji model </span><span class="font6" style="font-style:italic;">jackknife</span></p>
<p><span class="font6" style="font-style:italic;">ridge regression</span><span class="font6"> dan mendeteksi tidak adanya multikolinearitas dengan melihat nilai VIF, 9) Menguji kelayakan model yang dihasilkan </span><span class="font6" style="font-style:italic;">jackknife ridge regression</span><span class="font6"> dengan model yang dihasilkan </span><span class="font6" style="font-style:italic;">generalized ridge regression </span><span class="font6">dengan melihat nilai MSE.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark25"></a><span class="font6" style="font-weight:bold;"><a name="bookmark26"></a>4. &nbsp;&nbsp;&nbsp;HASIL DAN PEMBAHASAN</span></h2>
<ul style="list-style:none;">
<li>
<p><span class="font6">4.1. &nbsp;&nbsp;&nbsp;Mendeteksi Adanya Multikolinearitas</span></p></li></ul></li></ul>
<p><span class="font6">pada Model Regresi</span></p>
<p><span class="font7">Langkah yang dilakukan dalam mendeteksi adanya multikolinearitas dengan menggunakan metode kuadrat terkecil terhadap data kebutuhan tenaga kerja di 17 Rumah Sakit Angkatan Laut U.S yang ditunjukkan pada tabel penduga koefisien regresi (Tabel 1).</span><span class="font6">Hasil analisis regresi linear berganda dengan menggunakan metode kuadrat terkecil terhadap data kebutuhan akan tenaga kerja pada 17 Rumah Sakit Angkatan Laut U.S menghasilkan model regresi linear berganda yaitu Y = 1963 - 15,9 X</span><span class="font2">1 </span><span class="font6">+ 0,0559 X</span><span class="font2">2 </span><span class="font6">+ 1,59 X</span><span class="font2">3 </span><span class="font6">- 4,22 X</span><span class="font2">4 </span><span class="font6">- 394 X</span><span class="font2">5</span><span class="font6">. Setelah mendapatkan model regresi, langkah selanjutnya melakukan uji kecocokan model regresi secara simultan dengan melakukan uji F. Dalam melakukan uji F hipotesis yang digunakan sebagai berikut:</span></p>
<p><span class="font6" style="font-style:italic;">H<sub>0</sub></span><span class="font6"> : &nbsp;= &nbsp;=⋯= &nbsp;&nbsp;&nbsp;=0</span></p>
<p><span class="font6" style="font-style:italic;">Hy</span><span class="font6"> : &nbsp;&nbsp;</span><span class="font3">( &nbsp;&nbsp;,…, &nbsp;&nbsp;) </span><span class="font6">≠ 0 minimal untuk satu</span></p>
<p><span class="font6">nilai k, k=1,2,..,</span><span class="font6" style="font-style:italic;">p-</span><span class="font6">1</span></p>
<p><span class="font6">dengan kaidah keputusan tolak </span><span class="font4" style="font-style:italic;font-variant:small-caps;">Hq</span><span class="font6"> apabila </span><span class="font6" style="font-style:italic;">p-value</span><span class="font6"> &lt;&nbsp;</span><span class="font6" style="font-style:italic;">a</span><span class="font6"> dan begitu juga sebaliknya. Dengan menggunakan tingkat toleransi (</span><span class="font6" style="font-style:italic;">a</span><span class="font6">) sebesar 0,05, maka dari Tabel 2 didapatkan kesimpulan bahwa minimal ada peubah bebas yaitu X</span><span class="font2">1</span><span class="font6">, X</span><span class="font2">2 , </span><span class="font6">X</span><span class="font2">3</span><span class="font6">, X</span><span class="font2">4</span><span class="font6">, dan X</span><span class="font2">5 </span><span class="font6">berpengaruh signifikan terhadap model</span></p>
<p><span class="font6">Langkah selanjutnya adalah melakukan pengujian model regresi secara parsial (uji </span><span class="font6" style="font-style:italic;">t</span><span class="font6">) yang bertujuan untuk mengetahui signifikan atau tidaknya pengaruh masing-masing peubah bebas terhadap peubah terikat. Dalam melakukan uji </span><span class="font6" style="font-style:italic;">t</span><span class="font6"> hipotesis yang digunakan sebagai berikut:</span></p>
<p><span class="font6" style="font-style:italic;">H<sub>0</sub></span><span class="font6">: β<sub>fc</sub> — O (peubah bebas X secara individu tidak berpengaruh secara signifikan terhadap nilai dugaan Y)</span></p>
<p><span class="font6" style="font-style:italic;">H<sub>0</sub></span><span class="font6">: β<sub>fc</sub> ≠ O (peubah bebas X secara individu berpengaruh secara signifikan terhadap nilai dugaan Y)</span></p>
<p><span class="font6">dengan kaidah keputusan tolak </span><span class="font6" style="font-style:italic;">H<sub>0</sub></span><span class="font6"> apabila </span><span class="font6" style="font-style:italic;">p-value</span><span class="font6"> &lt;&nbsp;</span><span class="font6" style="font-style:italic;">a</span><span class="font6"> dan begitu juga sebaliknya.</span></p>
<p><span class="font6">Dari Tabel 1 dengan menggunakan tingkat toleransi (a) sebesar 0,05, maka terdapat empat peubah yang nilai tidak signifikan X</span><span class="font2">1</span><span class="font6">, X</span><span class="font2">3</span><span class="font6">, X</span><span class="font2">4</span><span class="font6">, dan X</span><span class="font2">5</span><span class="font6">.</span></p>
<p><span class="font6">Tabel 1 Penduga Koefisien Regresi</span></p>
<table border="1">
<tr><td style="vertical-align:middle;">
<p><span class="font6" style="font-style:italic;">Predictor</span></p></td><td style="vertical-align:middle;">
<p><span class="font6" style="font-style:italic;">Coef</span></p></td><td style="vertical-align:middle;">
<p><span class="font6" style="font-style:italic;">SE Coef</span></p></td><td style="vertical-align:middle;">
<p><span class="font6" style="font-style:italic;">T</span></p></td><td style="vertical-align:middle;">
<p><span class="font6" style="font-style:italic;">P</span></p></td><td style="vertical-align:middle;">
<p><span class="font6" style="font-style:italic;">VIF</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font6" style="font-style:italic;">Constant</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">1963</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">1071</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">1,83</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">0,094</span></p></td><td style="vertical-align:top;"></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">X</span><span class="font2">1</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">-15,85</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">97,65</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">-0,16</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">0,874</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">9597,6</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">X</span><span class="font2">2</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">0,05593</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">0,02126</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">2,63</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">0,023</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">7,9</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">X</span><span class="font2">3</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">1,59</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">3,092</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">0,51</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">0,617</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">8933,1</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">X</span><span class="font2">4</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">-4,219</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">7,177</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">-0,59</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">0,569</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">23,3</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">X</span><span class="font2">5</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">-394,3</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">209,6</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">-1,88</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">0,087</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">4,3</span></p></td></tr>
</table>
<p><span class="font6">Tabel. 2 Analisis Ragam</span></p>
<table border="1">
<tr><td style="vertical-align:top;">
<p><span class="font6" style="font-style:italic;">Source</span></p></td><td style="vertical-align:top;">
<p><span class="font6">DF</span></p></td><td style="vertical-align:top;">
<p><span class="font6">SS</span></p></td><td style="vertical-align:top;">
<p><span class="font6">MS</span></p></td><td style="vertical-align:top;">
<p><span class="font6">F</span></p></td><td style="vertical-align:top;">
<p><span class="font6">P</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font6" style="font-style:italic;">Regression</span></p></td><td style="vertical-align:middle;">
<p><span class="font6">5</span></p></td><td style="vertical-align:middle;">
<p><span class="font6">490177488</span></p></td><td style="vertical-align:middle;">
<p><span class="font6">98035498</span></p></td><td style="vertical-align:middle;">
<p><span class="font6">237,79</span></p></td><td style="vertical-align:middle;">
<p><span class="font6">0,000</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font6" style="font-style:italic;">Residual Error</span></p></td><td style="vertical-align:middle;">
<p><span class="font6">11</span></p></td><td style="vertical-align:middle;">
<p><span class="font6">4535052</span></p></td><td style="vertical-align:middle;">
<p><span class="font6">412277</span></p></td><td style="vertical-align:top;"></td><td style="vertical-align:top;"></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font6" style="font-style:italic;">Total</span></p></td><td style="vertical-align:middle;">
<p><span class="font6">16</span></p></td><td style="vertical-align:middle;">
<p><span class="font6">494712540</span></p></td><td style="vertical-align:top;"></td><td style="vertical-align:top;"></td><td style="vertical-align:top;"></td></tr>
</table>
<p><span class="font6">Namun kesimpulan yang berbeda didapat ketika melakukan pengujian univariat yaitu semua peubah bebas berpengaruh signifikan terhadap model. Setelah melakukan uji parsial didapatkan dari lima peubah bebas terdapat empat peubah bebas yang tidak berpengaruh secara signifikan terhadap model yaitu X</span><span class="font2">1</span><span class="font6">, X</span><span class="font2">3</span><span class="font6">, X</span><span class="font2">4</span><span class="font6">, dan X</span><span class="font2">5</span><span class="font6">. Pada hasil analisis regresi linear berganda diperoleh nilai </span><span class="font6" style="font-style:italic;">R<sup>2</sup></span><span class="font6"> yang besar yaitu 0,987 tetapi tidak diikuti dengan hasil uji hipotesis yang berpengaruh signifikan dari masing-masing koefisien regresi. Hal ini mengindikasikan adanya penyimpangan yang terjadi pada model, dimana seharusnya minimal terdapat tiga atau separuh dari semua peubah bebas yang berpengaruh signifikan terhadap model.</span></p>
<p><span class="font6">Penyimpangan-penyimpangan di atas diakibatkan oleh koefisien regresi yang tidak dapat diduga dengan tepat. Hal tersebut</span></p>
<p><span class="font6">mengindikasikan adanya pelanggaran terhadap asumsi pendugaan parameter menggunakan metode kuadrat terkecil yaitu asumsi multikolinearitas. Untuk mengetahui adanya multikolinearitas pada peubah bebas akan dilakukan analisis terhadap nilai koefisien korelasi antar peubah bebas dan nilai VIF dari masing-masing peubah bebas.</span></p>
<p><span class="font6">Untuk mendeteksi adanya multikolinearitas pada peubah akan dilihat dari nilai korelasi antar peubah dan nilai VIF dari setiap peubah bebas.</span></p>
<p><span class="font6">Dari Tabel 3 menunjukkan bahwa korelasi antar peubah bebas cukup besar yaitu mendekati satu yang berarti bahwa terjadi kolinearitas yang kuat antar peubah bebas, namun korelasi antara X</span><span class="font2">5 </span><span class="font6">dengan peubah bebas yang lain tidak sekuat terhadap peubah bebas lainnya. Dari sini dapat disimpulkan bahwa terjadi multikolinearitas antar peubah bebas. Untuk memperkuat kesimpulan tersebut hal ini</span></p>
<p><span class="font6">dipertegas dengan melihat nilai VIF dari masing-masing peubah bebas.</span></p>
<p><span class="font6">Tabel 3. Koefisien Korelasi Antar Peubah</span></p>
<table border="1">
<tr><td style="vertical-align:top;"></td><td style="vertical-align:top;">
<p><span class="font6">X</span><span class="font2">1</span></p></td><td style="vertical-align:top;">
<p><span class="font6">X</span><span class="font2">2</span></p></td><td style="vertical-align:top;">
<p><span class="font6">X</span><span class="font2">3</span></p></td><td style="vertical-align:top;">
<p><span class="font6">X</span><span class="font2">4</span></p></td><td style="vertical-align:top;">
<p><span class="font6">X</span><span class="font2">5</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font6">X</span><span class="font2">1</span></p></td><td style="vertical-align:top;">
<p><span class="font6">1</span></p></td><td style="vertical-align:top;">
<p><span class="font6">0,9073</span></p></td><td style="vertical-align:top;">
<p><span class="font6">0,999</span></p></td><td style="vertical-align:top;">
<p><span class="font6">0,9356</span></p></td><td style="vertical-align:top;">
<p><span class="font6">0,6711</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font6">X</span><span class="font2">2</span></p></td><td style="vertical-align:top;"></td><td style="vertical-align:top;">
<p><span class="font6">1</span></p></td><td style="vertical-align:top;">
<p><span class="font6">0,9071</span></p></td><td style="vertical-align:top;">
<p><span class="font6">0,9104</span></p></td><td style="vertical-align:top;">
<p><span class="font6">0,4466</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font6">X</span><span class="font2">3</span></p></td><td style="vertical-align:top;"></td><td style="vertical-align:top;"></td><td style="vertical-align:top;">
<p><span class="font6">1</span></p></td><td style="vertical-align:top;">
<p><span class="font6">0,9331</span></p></td><td style="vertical-align:top;">
<p><span class="font6">0,6711</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font6">X</span><span class="font2">4</span></p></td><td style="vertical-align:top;"></td><td style="vertical-align:top;"></td><td style="vertical-align:top;"></td><td style="vertical-align:top;">
<p><span class="font6">1</span></p></td><td style="vertical-align:top;">
<p><span class="font6">0,4628</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font6">X</span><span class="font2">5</span></p></td><td style="vertical-align:top;"></td><td style="vertical-align:top;"></td><td style="vertical-align:top;"></td><td style="vertical-align:top;"></td><td style="vertical-align:top;">
<p><span class="font6">1</span></p></td></tr>
</table>
<p><span class="font6">Tabel 4. Nilai VIF Peubah Bebas</span></p>
<table border="1">
<tr><td style="vertical-align:top;">
<p><span class="font6" style="font-style:italic;">Predictor</span></p></td><td style="vertical-align:top;">
<p><span class="font6">VIF</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">X</span><span class="font2">1</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">9597,6</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">X<sub>2</sub></span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">7,9</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">X</span><span class="font2">3</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">8933,1</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">X</span><span class="font2">4</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">23,3</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">X</span><span class="font2">5</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">4,3</span></p></td></tr>
</table>
<p><span class="font6">Nilai VIF pada Tabel 4 menunjukkan bahwa peubah bebas X</span><span class="font2">1</span><span class="font6">, X</span><span class="font2">2</span><span class="font6">, X</span><span class="font2">3</span><span class="font6">, dan X</span><span class="font2">4 </span><span class="font6">mengindikasikan bahwa keempat peubah bebas terlibat masalah multikolinearitas karena nilai VIF lebih dari 5. Dari hasil uraian di atas, maka dapat disimpulkan bahwa model mengandung multikolinearitas. Untuk mengatasi masalah itu diperlukan metode alternatif yaitu </span><span class="font6" style="font-style:italic;">jackknife ridge regression</span><span class="font6">.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font6">4.2. &nbsp;&nbsp;&nbsp;Pembakuan Peubah dengan Pemusatan</span></p></li></ul>
<p><span class="font6">dan Penskalaan</span></p>
<p><span class="font6">Pembakuan </span><span class="font6" style="font-style:italic;">(Standardized)</span><span class="font6"> peubah dilakukan dengan pemusatan dan penskalaan </span><span class="font6" style="font-style:italic;">(Centering and Scaling)</span><span class="font6"> untuk meminimumkan kesalahan pembulatan[5]. Peubah baru dari hasil pembakuan </span><span class="font6" style="font-style:italic;">centering </span><span class="font6">dan </span><span class="font6" style="font-style:italic;">scaling</span><span class="font6"> dengan rumus sebagai berikut:</span></p>
<p><span class="font6">_</span></p>
<p><a href="#bookmark27"><span class="font3" style="font-style:italic;">Y <sup>l</sup> SS</span></a></p>
<p><a href="#bookmark28"><span class="font0" style="font-style:italic;">y^y</span></a></p>
<p><a href="#bookmark29"><span class="font3" style="font-style:italic;">_ <sup>x</sup>kl _ </span><span class="font6" style="font-style:italic;">%</span><span class="font3" style="font-style:italic;">kl</span><span class="font6"> <sup>-</sup> </span><span class="font6" style="font-style:italic;">X</span><span class="font3" style="font-style:italic;">k &quot;&nbsp;&nbsp;= </span><span class="font6" style="font-style:italic;">S</span><span class="font3" style="font-style:italic;">k </span><span class="font6" style="font-style:italic;">=S</span></a></p>
<p><span class="font6">Setelah data dibakukan melalui </span><span class="font6" style="font-style:italic;">centering</span><span class="font6"> dan </span><span class="font6" style="font-style:italic;">scaling</span><span class="font6"> , dilakukan analisis regresi berganda terhadap data. Hasil yang didapat ternyata nilai VIF data kebutuhan tenaga kerja di 17 rumah sakit angkatan laut U.S untuk X</span><span class="font2">1</span><span class="font6">, X</span><span class="font2">2</span><span class="font6">, X</span><span class="font2">3</span><span class="font6">, dan X</span><span class="font2">4 </span><span class="font6">masih lebih besar dari 5. Hal ini menandakan bahwa data masih mengalami masalah multikoliearitas.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font6">4.3. &nbsp;&nbsp;&nbsp;Penyelesaian Masalah Multikolinearitas dengan </span><span class="font6" style="font-style:italic;">Jackknife Ridge Regression</span></p></li></ul>
<p><span class="font6">Pada &nbsp;&nbsp;&nbsp;&nbsp;analisis &nbsp;&nbsp;&nbsp;&nbsp;regresi &nbsp;&nbsp;&nbsp;&nbsp;dengan</span></p>
<p><span class="font6">menggunakan </span><span class="font6" style="font-style:italic;">Jackknife Ridge Regression</span><span class="font6">, data yang digunakan adalah data yang sudah mengalami proses </span><span class="font6" style="font-style:italic;">centering</span><span class="font6"> dan </span><span class="font6" style="font-style:italic;">scaling. </span><span class="font6">Untuk mengatasi masalah multikolinearitas pada metode </span><span class="font6" style="font-style:italic;">Jackknife Ridge Regression </span><span class="font6">dengan menambahkan konstansa bias yang berbeda </span><span class="font6" style="font-style:italic;">(k<sub>1</sub>,k<sub>2</sub>,..., k<sub>p</sub>)</span><span class="font6"> pada diagonal utama matriks </span><span class="font6" style="font-style:italic;">X'X</span><span class="font6"> dan memperkecil nilai masing-masing konstanta bias dalam persamaan kuadrat terkecil setelah sebelumnya peubah-peubah bebasnya mengalami proses orthogonalisasi.</span></p>
<p><span class="font6">Nilai konstanta bias &nbsp;&nbsp;</span><span class="font6" style="font-style:italic;">k<sub>1</sub>,k<sub>2</sub>^,,k<sub>5</sub></span></p>
<p><span class="font6">diperoleh melalui proses iterasi sampai ditemukan penduga koefisien regresi yang stabil. Iterasi berhenti pada iterasi kedua. Nilai konstanta bias </span><span class="font6" style="font-style:italic;">k<sub>1</sub>,k<sub>2</sub>,^,k<sub>s</sub></span><span class="font6"> yang diperoleh dari iterasi kedua yaitu 34,8536, 7,12881x10<sup>4</sup>, 4,8317x10<sup>8</sup>, 7,21441x10<sup>3</sup>, 1,9907x10<sup>7</sup>.</span></p>
<p><span class="font6">Langkah selanjutnya adalah pendugaan koefisien regresi untuk </span><span class="font6" style="font-style:italic;">Jackknife Ridge Regression</span><span class="font6"> pada peubah awal dan nilai VIF dari masing-masing peubah dapat dilihat pada Tabel 5. Analisis ragam untuk model </span><span class="font6" style="font-style:italic;">Jakknife Ridge Regression</span><span class="font6"> dapat dilihat pada Tabel 6.</span></p>
<div>
<p><span class="font6">Tabel 5. Penduga Koefisien </span><span class="font6" style="font-style:italic;">Jackknife Ridge Regression</span></p>
<table border="1">
<tr><td style="vertical-align:bottom;">
<p><span class="font6" style="font-style:italic;">Independe nt Variabel</span></p></td><td style="vertical-align:middle;">
<p><span class="font6" style="font-style:italic;">Regression Coefficient</span></p></td><td style="vertical-align:middle;">
<p><span class="font6" style="font-style:italic;">Standard Error</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6" style="font-style:italic;">Standardized Regresssion Coefficient</span></p></td><td style="vertical-align:middle;">
<p><span class="font6">VIF</span></p></td><td style="vertical-align:middle;">
<p><span class="font6">t</span><span class="font2">0</span></p></td><td style="vertical-align:middle;">
<p><span class="font6">t</span><span class="font2">0.025,11</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font6">Intercept</span></p></td><td style="vertical-align:middle;">
<p><span class="font6">-2.014,64</span></p></td><td style="vertical-align:top;"></td><td style="vertical-align:top;"></td><td style="vertical-align:top;"></td><td style="vertical-align:top;"></td><td style="vertical-align:top;"></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">X</span><span class="font2">1</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">7,09463</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">2,30785</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">0,2054</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">7,777x10<sup>-4</sup></span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">3,0741</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">2,201</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">X</span><span class="font2">2</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">0,05013</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">0,0174</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">0,1918</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">1,8781x10<sup>-10</sup></span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">2,870</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">2,201</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">X</span><span class="font2">3</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">0,23270</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">0,07574</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">0,2053</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">4,0468x10<sup>-18</sup></span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">3,0723</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">2,201</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">X</span><span class="font2">4</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">10,04817</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">3,4426</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">0,1950</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">1,8282x10<sup>-8</sup></span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">2,9187</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">2,201</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font6">X</span><span class="font2">5</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">495,68</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">234,618</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">0,1412</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">2,4605x10<sup>-15</sup></span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">2,112</span></p></td><td style="vertical-align:bottom;">
<p><span class="font6">2,201</span></p></td></tr>
</table>
</div><br clear="all">
<div>
<p><span class="font6">Tabel 6. Analisis Ragam </span><span class="font6" style="font-style:italic;">Jackknife Ridge Regression</span></p>
<table border="1">
<tr><td style="vertical-align:middle;">
<p><span class="font6" style="font-style:italic;">Source</span></p></td><td style="vertical-align:middle;">
<p><span class="font6">DF</span></p></td><td style="vertical-align:middle;">
<p><span class="font6">SS</span></p></td><td style="vertical-align:middle;">
<p><span class="font6">MS</span></p></td><td style="vertical-align:middle;">
<p><span class="font6">F</span><span class="font2">0</span></p></td><td style="vertical-align:middle;">
<p><span class="font6">F</span><span class="font2">(0.05,5,11)</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font6" style="font-style:italic;">Regression</span></p></td><td style="vertical-align:middle;">
<p><span class="font6">5</span></p></td><td style="vertical-align:middle;">
<p><span class="font6">372.031.338</span></p></td><td style="vertical-align:middle;">
<p><span class="font6">74.406.267</span></p></td><td style="vertical-align:middle;">
<p><span class="font6">33,66</span></p></td><td style="vertical-align:middle;">
<p><span class="font6">3,20</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font6" style="font-style:italic;">Residual Error</span></p></td><td style="vertical-align:middle;">
<p><span class="font6">11</span></p></td><td style="vertical-align:middle;">
<p><span class="font6">24.310.231</span></p></td><td style="vertical-align:middle;">
<p><span class="font6">2.210.021</span></p></td><td style="vertical-align:top;"></td><td style="vertical-align:top;"></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font6" style="font-style:italic;">Total</span></p></td><td style="vertical-align:middle;">
<p><span class="font6">16</span></p></td><td style="vertical-align:middle;">
<p><span class="font6">494.712.540</span></p></td><td style="vertical-align:top;"></td><td style="vertical-align:top;"></td><td style="vertical-align:top;"></td></tr>
</table>
</div><br clear="all">
<p><span class="font6">Model regresi untuk metode </span><span class="font6" style="font-style:italic;">Jackknife Ridge Regression</span><span class="font6"> adalah </span><span class="font6" style="font-style:italic;">Y</span><span class="font6">=-2.014,64+ 7,094*ι + 0,05013</span><span class="font6" style="font-style:italic;">X<sub>2</sub></span><span class="font6"> + 0,2327</span><span class="font6" style="font-style:italic;">X3</span><span class="font6"> + 10,0481¾ + 495,68</span><span class="font6" style="font-style:italic;">Xs</span><span class="font6"> . Metode </span><span class="font6" style="font-style:italic;">Jackknife Ridge Regression</span><span class="font6"> dapat mengatasi masalah multikolinearitas. Pada Tabel 5 terlihat bahwa nilai VIF dari masing-masing peubah bebas yang dihasilkan lebih kecil dari 5 yang berarti masing-masing peubah bebas pada model sudah tidak lagi terlibat masalah multikolinearitas. Nilai koefisien determinasi yang dihasilkan sebesar 0,9940 dengan MSE sebesar 2.210.021.</span></p>
<p><span class="font6">Dari hasil yang didapatkan pada Tabel 6 diperoleh nilai </span><span class="font4" style="font-style:italic;font-variant:small-caps;">Fq</span><span class="font6"> sebesar 33,66 maka </span><span class="font4" style="font-style:italic;font-variant:small-caps;">Hq</span><span class="font6"> ditolak yang berarti bahwa semua peubah bebas mempunyai pengaruh yang signifikan pada model. Langkah selanjutnya adalah menguji masing-masing pengaruh peubah bebas terhadap model dengan menggunakan uji </span><span class="font6" style="font-style:italic;">t</span><span class="font6">. Nilai </span><span class="font6" style="font-style:italic;">t0</span><span class="font6"> dari masing-masing peubah bebas dapat dilihat pada tabel 5, maka terdapat satu peubah bebas yang tidak signifikan yaitu </span><span class="font6" style="font-style:italic;">Xs</span><span class="font6"> .</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark30"></a><span class="font6" style="font-weight:bold;"><a name="bookmark31"></a>5. &nbsp;&nbsp;&nbsp;SIMPULAN</span></h2></li></ul>
<p><span class="font6">Dari penelitian yang dilakukan dapat ditarik beberapa kesimpulan yaitu:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font4">1.</span><span class="font6"> &nbsp;&nbsp;&nbsp;Metode </span><span class="font6" style="font-style:italic;">Jackknife Ridge Regression</span><span class="font6"> dapat mengatasi masalah multikolinearitas dengan baik. Hal ini dapat dilihat dari nilai VIF setiap peubah bebas lebih kecil dari 5.</span></p></li>
<li>
<p><span class="font4">2.</span><span class="font6"> &nbsp;&nbsp;&nbsp;Metode </span><span class="font6" style="font-style:italic;">Jackknife Ridge Regression </span><span class="font6">menghasilkan MSE sebesar 2.210.021. Hal ini menunjukkan </span><span class="font6" style="font-style:italic;">Jackknife Ridge Regression</span><span class="font6"> memiliki galat atau </span><span class="font6" style="font-style:italic;">error</span><span class="font6"> yang kecil.</span></p></li>
<li>
<p><span class="font4">3.</span><span class="font6"> &nbsp;&nbsp;&nbsp;Metode </span><span class="font6" style="font-style:italic;">Jackknife Ridge Regression </span><span class="font6">menghasilkan nilai koefisien determinasi (</span><span class="font6" style="font-style:italic;">R<sup>2</sup></span><span class="font6">) sebesar 0.9940. &nbsp;Ini menunjukkan</span></p></li></ul>
<p><span class="font6">peubah bebas pada metode </span><span class="font6" style="font-style:italic;">Jackknife Ridge Regression</span><span class="font6"> &nbsp;&nbsp;&nbsp;dapat &nbsp;&nbsp;&nbsp;menggambarkan</span></p>
<p><span class="font6">keragaman peubah tak bebas sebesar 99,40 %.</span></p>
<p><span class="font6">Metode </span><span class="font6" style="font-style:italic;">Generalized Ridge Regression </span><span class="font6">dan </span><span class="font6" style="font-style:italic;">Jackknife Ridge Regression</span><span class="font6"> dapat mengatasi masalah multikolinearitas dengan baik namun terdapat metode yang merupakan kombinasi dari kedua metode tersebut yaitu metode </span><span class="font6" style="font-style:italic;">Modified Jackknife Ridge Regression </span><span class="font6">yang diusulkan oleh Batah </span><span class="font6" style="font-style:italic;">et al</span><span class="font6"> (2008) yang</span></p>
<p><span class="font6">dapat digunakan sebagai referensi untuk penelitian selanjutnya.</span></p>
<h2><a name="bookmark32"></a><span class="font6" style="font-weight:bold;"><a name="bookmark33"></a>DAFTAR PUSTAKA</span></h2>
<ul style="list-style:none;"><li>
<p><span class="font6">[1] &nbsp;&nbsp;&nbsp;Bowerman, B. &amp;&nbsp;O'Connel, R. T., 1997. </span><span class="font6" style="font-style:italic;">Applied Statistics Improving Business Processes.</span><span class="font6"> 1 ed. United States of America: Tom Casson.</span></p></li>
<li>
<p><span class="font6">[2] &nbsp;&nbsp;&nbsp;Gore, Sharad, Thekke V. Ramanathan &amp;&nbsp;Feras Sh. M. Batah, 2008. The Efficiency Of Modified Jackknife And Ridge Type Regression Estimators: A Comparison. </span><span class="font6" style="font-style:italic;">Surveys in Mathematics and its Applications,</span><span class="font6"> Volume III, pp. 111-122.</span></p></li>
<li>
<p><span class="font6">[3] &nbsp;&nbsp;&nbsp;Hoerl, A.E. and R.W. Kennard. 1970. “Ridge Regression: &nbsp;Applications to</span></p></li></ul>
<p><span class="font6">Nonorthogonal &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Problems”.</span></p>
<p><span class="font6" style="font-style:italic;">Technometrics</span><span class="font6">, Vol. 12, No. 1. (Feb., 1970b), &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;pp. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;69-82.</span></p>
<p><a href="http://statgen.ucr.edu/download/course/S"><span class="font6">http://statgen.ucr.edu/download/course/S</span></a><span class="font6"> TAT288/hoerl70b.pdf. Diakses tanggal 14 Juni 2012.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font6">[4] &nbsp;&nbsp;&nbsp;Montgomery, D.C. and E.A. Peck. 1991. </span><span class="font6" style="font-style:italic;">Introduction to Linear Regression Analysis</span><span class="font6">, </span><span class="font6" style="font-style:italic;">Second Edition</span><span class="font6">. New York: John Wiley and Sons, Inc.</span></p></li>
<li>
<p><span class="font6">[5] &nbsp;&nbsp;&nbsp;Neter, J., Wasserman, W. &amp;&nbsp;Kutner, M. H., 1997. </span><span class="font6" style="font-style:italic;">Model Linear Terapan.</span><span class="font6"> 2 ed. Diterjemahkan oleh Bambang Sumantri. Bogor: Jurusan Statistika FMIPA IPB.</span></p></li>
<li>
<p><span class="font6">[6] &nbsp;&nbsp;&nbsp;Ozkale, M. R., 2008. A Jackknifed Ridge Estimator in The Linear Regression Model with Heteroscedastic or Correlated Errors</span><span class="font6" style="font-style:italic;">. Statistics and Probability Letters</span><span class="font6">, Volume I, pp. 3159-3169.</span></p></li></ul>
<p><span class="font5">153</span></p>