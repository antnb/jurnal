---
layout: full_article
title: "Klasifikasi Emosi Lirik Lagu dengan Long Short Term Memory dan Word2Vec"
author: "I Putu Diska Fortunawan, Ngurah Agus Sanjaya ER"
categories: jnatia
canonical_url: https://jurnal.harianregional.com/jnatia/full-102528 
citation_abstract_html_url: "https://jurnal.harianregional.com/jnatia/id-102528"
citation_pdf_url: "https://jurnal.harianregional.com/jnatia/full-102528"  
comments: true
---

<p><span class="font0">JNATIA Volume 1, Nomor 4, Agustus 2023</span></p>
<p><span class="font0">Jurnal Nasional Teknologi Informasi dan Aplikasinya</span></p>
<p><span class="font0">p-ISSN: 2986-3929</span></p>
<p><span class="font2" style="font-weight:bold;">Klasifikasi Emosi Lirik Lagu dengan Long Short-Term Memory dan Word2Vec</span></p>
<p><span class="font0">I Putu Diska Fortunawan<sup>1</sup></span><span class="font0" style="font-weight:bold;">, </span><span class="font0">Ngurah Agus Sanjaya ER <sup>2</sup></span></p>
<p><span class="font0">Program Studi Informatika, Fakultas Matematika dan Ilmu Pengetahuan Alam, Universitas Udayana</span></p>
<p><span class="font0">Jalan Raya Kampus Udayana, Bukit Jimbaran, Kuta Selatan, Badung, Bali Indonesia</span></p>
<p><a href="mailto:1diskafortunawan@gmail.com"><span class="font0"><sup>1</sup>diskafortunawan@gmail.com</span></a><span class="font0"> </span><a href="mailto:2agus_sanjaya@unud.ac.id"><span class="font0"><sup>2</sup>agus_sanjaya@unud.ac.id</span></a></p>
<p><span class="font0" style="font-weight:bold;font-style:italic;">Abstract</span></p>
<p><span class="font0" style="font-style:italic;">This research focuses on the classification of emotions in song lyrics using LSTM (Long ShortTerm Memory) and Word2Vec embedding. Emotion classification in lyrics plays a crucial role in music recommendation systems, sentiment analysis, and understanding the affective aspects of music. The study explores the effectiveness of LSTM, a type of recurrent neural network (RNN), in capturing the sequential dependencies and patterns in lyrics, combined with Word2Vec embedding to represent the semantic meaning of words.The dataset consists of a collection of song lyrics labeled with 2 emotions. The lyrics are preprocessed and converted into word vectors using the Word2Vec model. The LSTM model is then trained on the preprocessed lyrics data, aiming to predict the corresponding emotion category for a given set of lyrics. Experimental results demonstrate that the proposed approach achieves a maximum accuracy of 72.8% in classifying emotions in song lyrics. The LSTM model leverages the sequential information in the lyrics to capture the emotional context effectively. The Word2Vec embedding enhances the representation of words, allowing the model to understand the semantic relationships between words and better discriminate between different emotional categories.</span></p>
<p><span class="font0" style="font-weight:bold;font-style:italic;">Keywords: </span><span class="font0" style="font-style:italic;">Text Processing, Classification, LSTM, Word2Vec</span></p>
<p><span class="font0">dah” yang berisikan kumpulan lagu-lagu sedih yang merupakan kebalikan dari emosi Bahagia. Data yang digunakan hanya memiliki label “Bahagia” dan “sedih” dengan nilai 1 pada label jika merupakan lagu Bahagia dan nilai 0 jika merupakan lagu sedih.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font0" style="font-weight:bold;">2.2 &nbsp;&nbsp;&nbsp;Preprocessing</span></p></li></ul>
<p><span class="font0">Setelah data didapatkan dan dikumpulkan, perlu dilakukan preprocessing sebelum data siap untuk dijadikan sebagai data training. Proses ini akan menghilangkan noise atau data yang sekiranya tidak penting dan tidak diperlukan. Tahapan preprocessing yang dilakukan adalah:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font0" style="font-weight:bold;">a. &nbsp;&nbsp;&nbsp;Case Folding</span></p></li></ul>
<p><span class="font0">Pada tahapan ini, jika ditemukan character yang merupakan uppercase maka character ini akan diubah menjadi lowercase</span></p>
<ul style="list-style:none;"><li>
<p><span class="font0" style="font-weight:bold;">b. &nbsp;&nbsp;&nbsp;Punctuation Removal</span></p></li></ul>
<p><span class="font0">Proses ini menghilangkan/menghapus tanda baca yang ada pada lirik lagu seperti koma(,), titik(.) dan tanda baca lain yang tidak diperlukan dalam proses.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font0" style="font-weight:bold;">c. &nbsp;&nbsp;&nbsp;Normalization</span></p></li></ul>
<p><span class="font0">Tahapan ini akan mengubah kata-kata yang merupakan bahasa gaul ataupun bahasa yang tidak baku ke dalam bentuk bakunya.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font0" style="font-weight:bold;">d. &nbsp;&nbsp;&nbsp;Stemming</span></p></li></ul>
<p><span class="font0">Menghilangkan imbuhan pada kata, imbuhan ini termasuk awalan, sisipan, maupun akhiran. Sehingga kata menjadi kata dasar.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font0" style="font-weight:bold;">e. &nbsp;&nbsp;&nbsp;Stopword Removal</span></p></li></ul>
<p><span class="font0">Menghilangkan kata-kata yang sering muncul yang bersifat umum atau tidak memiliki makna terhadap kalimat.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font0" style="font-weight:bold;">f. &nbsp;&nbsp;&nbsp;Tokenization</span></p></li></ul>
<p><span class="font0">Kalimat akan dipecah menjadi bagian yang lebih kecil yaitu kata.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font0" style="font-weight:bold;">2.3 &nbsp;&nbsp;&nbsp;Word2Vec Embedding</span></p></li></ul>
<p><span class="font0">Untuk mengerti lebih dalam mengenai konteks yang ada dalam lirik lagu, kita memerlukan word embedding khususnya Word2Vec. Word2Vec dapat memecahkan masalah mewakili hubungan kata kontekstual dalam ruang fitur yang dapat dihitung [2]. Metode Word2Vec berfokus pada ide bahwa kata-kata yang sering muncul bersama memiliki kesamaan makna atau konteks. Word2Vec memanfaatkan data teks yang besar untuk melatih model yang dapat menghasilkan representasi vektor kata-kata tersebut. Ada 2 argumen yang akan digunakan yaitu max_input_length dan embed dimension.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font0" style="font-weight:bold;">2.4 &nbsp;&nbsp;&nbsp;Long Short-Term Memory (LSTM)</span></p></li></ul>
<p><span class="font0">LSTM merupakan salah satu contoh model RNN (Recurrent Neural Network). LSTM dapat bekerja lebih baik dibandingkan RNN karena LSTM dapat mengatasi masalah vanishing gradient yang ditemukan pada RNN [3]. Masalah ini diatasi dengan menggunakan blok memory-cell yang terdiri dari input gate, forget gate dan output gate untuk mengganti lapisan RNN [4]. LSTM memiliki memiliki koneksi berulang atau struktur yang seperti rantai Fungsi-fungsi tiap gate pada LSTM adalah:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1" style="font-weight:bold;">a.</span><span class="font0" style="font-weight:bold;"> &nbsp;&nbsp;&nbsp;Forget Gate</span></p></li></ul>
<p><span class="font0">Gerbang ini bertugas untuk melupakan beberapa informasi yang tidak relevan dan sudah tidak diperlukan oleh sebuah sistem. Alhasil, LSTM dapat menyajikan kumpulan informasi yang lengkap, tetapi tetap aktual sesuai dengan kebutuhan.</span></p><img src="https://jurnal.harianregional.com/media/102528-1.jpg" alt="" style="width:260pt;height:83pt;">
<p><span class="font0" style="font-weight:bold;">Gambar 1. </span><span class="font0">Forget gate [5]</span></p>
<p><span class="font0">Untuk menentukan apakah informasi dari state sebelumnya disimpan atau tidak, ditentukan dengan fungsi sigmoid, fungsi ini akan menghasilkan </span><span class="font4">f</span><span class="font3"><sub>t</sub> </span><span class="font0">antara 0 dan 1. Jika dihasilkan 0 maka semua informasi akan dilupakan, sebaliknya jika dihasilkan 1 maka tidak ada informasi yang dilupakan.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1" style="font-weight:bold;">b.</span><span class="font0" style="font-weight:bold;"> &nbsp;&nbsp;&nbsp;Input Gate</span></p></li></ul><img src="https://jurnal.harianregional.com/media/102528-2.jpg" alt="" style="width:274pt;height:84pt;">
<p><span class="font0" style="font-weight:bold;">Gambar 2. </span><span class="font0">Input Gate [5]</span></p>
<p><span class="font0">Tugas input gate adalah untuk menambahkan informasi yang sebelumnya telah diseleksi terlebih dahulu melalui gerbang forget gate. Gerbang ini tidak dimiliki oleh RNN yang hanya memungkinkan satu input data untuk satu output data. Dalam input gate kemudian dikenal istilah input modulation gate. Sesuai namanya, input modulation gate berfungsi untuk memodulasi informasi yang ada, sehingga dapat mengurangi kecepatan konvergensi dari data zero-mean. Pada gate ini juga diaplikasi fungsi sigmoid yang juga akan memiliki nilai antara 0 dan 1. Sekarang informasi baru yang perlu diteruskan ke state cell adalah fungsi dari state tersembunyi pada timestamp t-1 sebelumnya dan masukan x pada timestamp t. Fungsi aktivasi di sini adalah tanh. Karena fungsi tanh, nilai informasi baru akan berada di antara -1 dan 1. Jika nilai Nt negatif, informasi dikurangi dari keadaan sel, dan jika nilainya positif, informasi ditambahkan ke state cell pada timestamp saat ini.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1" style="font-weight:bold;">c.</span><span class="font0" style="font-weight:bold;"> &nbsp;&nbsp;&nbsp;Output Gate</span></p></li></ul><img src="https://jurnal.harianregional.com/media/102528-3.jpg" alt="" style="width:260pt;height:80pt;">
<p><span class="font0" style="font-weight:bold;">Gambar 3. </span><span class="font0">Output Gate [5]</span></p>
<p><span class="font0">Output gate menjadi gerbang terakhir untuk menghasilkan informasi data yang komplet dan aktual. Gerbang ini bisa menjadi yang terakhir atas sebuah informasi atau hanya menjadi bagian dari tahap pertama saja, sebelum akhirnya informasi akan diproses lewat input gate di sel berikutnya. Perhitungan pada output gate juga sangat mirip dengan gategate sebelumnya, nilainya juga akan berada diantara 0 dan 1. Untuk menghitung status hidden state saat ini, digunakan Ot dan tanh dari cell state yang diperbarui.</span></p>
<ul style="list-style:none;"><li><a name="caption1"></a>
<h1><a name="bookmark0"></a><span class="font0" style="font-weight:bold;"><a name="bookmark1"></a>3. &nbsp;&nbsp;&nbsp;Hasil dan Pembahasan</span></h1>
<ul style="list-style:none;">
<li>
<h2><a name="bookmark2"></a><span class="font0" style="font-weight:bold;"><a name="bookmark3"></a>3.1. &nbsp;&nbsp;&nbsp;Data Understanding</span></h2></li></ul></li></ul>
<p><span class="font0">Data yang digunakan diperoleh dari Genius, data yang digunakan hanyalah data teks, yaitu lirik lagu itu sendiri tanpa menggunakan data audio dari lagu. Dataset yang digunakan berjumlah 90 lagu dengan label 1 yang berarti lagu bahagia, sedangkan label 0 yang merupakan lagu sedih, Setiap label terdiri dari masing masing 45 lagu.Data yang dikumpulkan dapat dilihat pada Gambar 4.</span></p>
<p><span class="font0" style="font-weight:bold;">Pengambilan Data</span></p>
<p><span class="font0" style="font-weight:bold;">lyrics</span></p>
<p><span class="font0" style="font-weight:bold;">0 Sandarkan lelahmu dan ceritakan Tentang apapu... 1 Menyesal<sub>j</sub> tak kusampaikan Cinta monyetku ke K... 2 Kapan terakhir kali kamu dapat tertidur tenan... 3 Salahkah bila ku mencinta Salahkah bila semua ... 4 Kuingin cinta hadir untuk selamanya Bukan han...</span></p>
<p><span class="font0" style="font-weight:bold;">85 Biar aku sentuhmu Berikan ku rasa itu Pelukmu ... 86 Hujan tak juga reda Ku harus menyaksikan cinta... 87 Belum sempat ku membagi Kebahagia-anku Belum s... 88 Pedihnya tanya yang tak terjawab Mampu menjat... 89 Tika wangimu saja bisa Memindahkan duniaku Ma...</span></p>
<p><span class="font0" style="font-weight:bold;">Gambar 4. </span><span class="font0">Hasil Pengambilan Data</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark4"></a><span class="font0" style="font-weight:bold;"><a name="bookmark5"></a>3.2. &nbsp;&nbsp;&nbsp;Data Preprocessing and Preparation</span></h2></li></ul>
<p><span class="font0">Data yang telah didapatkan tadi kemudian dikenakan preprocessing sebelum diproses lebih lanjut rincian tahapannya dapat dilihat pada Tabel 1.</span></p>
<p><span class="font0" style="font-weight:bold;">Tabel 1. </span><span class="font0">Preprocessing data</span></p>
<table border="1">
<tr><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">Tahapan</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">Hasil</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font0">Data Awal</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">Menari bersamaku Temani hingga akhir waktu Jalani bersamaku Kau pasti 'kan bahagia Kutemani dirimu Di setiap perjalanan cinta</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font0">Case Folding</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">menari bersamaku temani hingga akhir waktu jalani bersamaku kau pasti 'kan bahagia kutemani dirimu di setiap perjalanan cinta</span></p></td></tr>
</table>
<table border="1">
<tr><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">Tahapan</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">Hasil</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font0">Normalization</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">menari bersamaku temani hingga akhir waktu jalani bersamaku kau pasti akan bahagia kutemani dirimu di setiap perjalanan cinta</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font0">Punctuation Removal</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">menari bersamaku temani hingga akhir waktu jalani bersamaku kau pasti akan bahagia kutemani dirimu di setiap perjalanan cinta</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font0">Stemming</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">menari bersama teman hingga akhir waktu jalani bersama kau pasti akan bahagia teman kamu setiap jalan cinta</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font0">Stopword Removal</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">menari bersama teman hingga akhir jalani bersama bahagia teman kamu setiap jalan cinta</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font0">Tokenization</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">menari, bersama, teman, hingga, akhir, jalani, bahagia, kamu, setiap, cinta</span></p></td></tr>
</table>
<p><span class="font0">Setelah dilakukan tokenization ditemukan sebanyak 1686 kamus data atau jumlah kata unik dari lirik lagu yang telah dikumpulkan. Setelah itu, data akan dibagi menjadi data latih dan data uji, data uji diambil dari 20% dataset yang telah didapatkan</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark6"></a><span class="font0" style="font-weight:bold;"><a name="bookmark7"></a>3.3. &nbsp;&nbsp;&nbsp;Model LSTM</span></h2></li></ul>
<p><span class="font0">Pemodelan diawali dengan melakukan penambahan lapisan embedding untuk mengubah kata ke dalam bentuk vector dengan max_input length = jumlah unique word, serta embed dim = 100. Digunakan pula 2 layer LSTM dengan unit masing masing sebanyak 64 unit dan dropout rate 0.1 Detail dari model yang digunakan adalah sebagai berikut:</span></p>
<p><span class="font0" style="font-weight:bold;">Tabel 2</span><span class="font0">. Model LSTM</span></p>
<table border="1">
<tr><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">Layer</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">Jumlah</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">Addition</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font0">Embedding</span></p></td><td style="vertical-align:top;"></td><td style="vertical-align:middle;">
<p><span class="font0">Max_input_length = 1686, embed dim = 100</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font0">LSTM</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">64 Unit</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">Dropout Rate = 0.1</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font0">LSTM</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">64 Unit</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">Dropout Rate = 0.1</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font0">Dense</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">1 Unit</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">Activation = sigmoid</span></p></td></tr>
</table>
<ul style="list-style:none;"><li>
<h2><a name="bookmark8"></a><span class="font0" style="font-weight:bold;"><a name="bookmark9"></a>3.4. &nbsp;&nbsp;&nbsp;Evaluasi Model</span></h2></li></ul>
<p><span class="font0">Training dilakukan sebanyak 3 kali dengan epoch dan jumlah data yang berbeda-beda, seperti pada tabel berikut:</span></p>
<p><span class="font0" style="font-weight:bold;">Tabel 3. </span><span class="font0">Hasil Training</span></p>
<table border="1">
<tr><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">Keterangan</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">Hasil</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font0">Epoch 50 dataset 60</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">52.6%</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font0">Epoch 100 dataset 90</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">68.3%</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font0">Epoch 50 dataset 60</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">58.8%</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font0">Epoch 100 Dataset 90</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">72.8 %</span></p></td></tr>
</table>
<ul style="list-style:none;"><li>
<h1><a name="bookmark10"></a><span class="font0" style="font-weight:bold;"><a name="bookmark11"></a>4. &nbsp;&nbsp;&nbsp;Kesimpulan</span></h1></li></ul>
<p><span class="font0">Dari Penelitian yang telah dilakukan, didapatkan hasil akurasi tertinggi yaitu 72.8 %, nilai tersebut akan berubah sesuai dengan perubahan hyperparameter. Akurasi dapat ditingkatkan dengan menambah dataset dan cleani</span></p>
<p><span class="font0" style="font-weight:bold;">Daftar Pustaka</span></p>
<ul style="list-style:none;"><li>
<p><span class="font0">[1] &nbsp;&nbsp;&nbsp;Wang, J.H., Liu, T.W., Luo, X. and Wang, L., 2018, October. An LSTM approach to short text sentiment classification with word embeddings. In Proceedings of the 30th conference on computational linguistics and speech processing (ROCLING 2018) (pp. 214-223).</span></p></li>
<li>
<p><span class="font0">[2] &nbsp;&nbsp;&nbsp;Sari, W.K., Rini, D.P., Malik, R.F. and Azhar, I.S.B., 2020. Multilabel Text Classification in News Articles Using Long-Term Memory with Word2Vec. Jurnal RESTI (Rekayasa Sistem dan Teknologi Informasi), 4(2), pp.276-285.</span></p></li>
<li>
<p><span class="font0">[3] &nbsp;&nbsp;Nugroho, K.S., Akbar, I. and Suksmawati, A.N., 2023. Deteksi Depresi dan Kecemasan</span></p></li></ul>
<p><span class="font0">Pengguna Twitter Menggunakan Bidirectional LSTM. arXiv preprint arXiv:2301.04521.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font0">[4] &nbsp;&nbsp;&nbsp;Fajri, F.N. and Syaiful, S., 2022. Klasifikasi Nama Paket Pengadaan Menggunakan Long</span></p></li></ul>
<p><span class="font0">Short-Term Memory (LSTM) Pada Data Pengadaan. Building of Informatics, Technology and Science (BITS), 4(3), pp.1625-1633.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font0">[5] &nbsp;&nbsp;&nbsp;Eddine, B.C. (2021) LSTM Model for the Prediction of PM2.5 Concentration in city of Algiers.</span></p></li></ul>
<p><span class="font0">1208</span></p>