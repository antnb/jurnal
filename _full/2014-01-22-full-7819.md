---
layout: full_article
title: "PERBANDINGAN REGRESI KOMPONEN UTAMA DAN ROBPCA DALAM MENGATASI MULTIKOLINEARITAS DAN PENCILAN PADA REGRESI LINEAR BERGANDA"
author: "NI WAYAN YULIANI, I KOMANG GDE SUKARSA, I GUSTI AYU MADE SRINADI"
categories: mtk
canonical_url: https://jurnal.harianregional.com/mtk/full-7819 
citation_abstract_html_url: "https://jurnal.harianregional.com/mtk/id-7819"
citation_pdf_url: "https://jurnal.harianregional.com/mtk/full-7819"  
comments: true
---

<p><span class="font2">E-Jurnal Matematika Vol. 2, No.4, Nopember 2013, 1- 5</span></p>
<p><span class="font2">ISSN: 2303-1751</span></p>
<p><span class="font6" style="font-weight:bold;">PERBANDINGAN REGRESI KOMPONEN UTAMA DAN ROBPCA DALAM MENGATASI MULTIKOLINEARITAS DAN PENCILAN PADA REGRESI LINEAR BERGANDA</span></p>
<p><span class="font3" style="font-weight:bold;font-variant:small-caps;">Ni Wayan Yuliani<sup>1</sup>,</span><span class="font5" style="font-weight:bold;"> I </span><span class="font3" style="font-weight:bold;font-variant:small-caps;">Komang Gde Sukarsa<sup>2</sup>, </span><span class="font5" style="font-weight:bold;">I </span><span class="font3" style="font-weight:bold;font-variant:small-caps;">Gusti Ayu Made Srinadi<sup>3</sup></span></p>
<ul style="list-style:none;"><li>
<p><span class="font3"><sup>1,2,3</sup>Jurusan Matematika FMIPA Universitas Udayana, Bukit Jimbaran-Bali e-mail: </span><a href="mailto:yuliani_ani@rocketmail.com"><span class="font3"><sup>1</sup>yuliani_ani@rocketmail.com,</span></a><a href="mailto:2nwidana@yahoo.co.id"><span class="font3"> <sup>2</sup>s</span></a><a href="mailto:ukarsakomang@yahoo.co.id"><span class="font3">ukarsakomang@yahoo.co.id</span></a><span class="font3">, </span><a href="mailto:srinadiigustiayumade@yahoo.co.id"><span class="font3"><sup>3</sup>srinadiigustiayumade@yahoo.co.id</span></a></p></li></ul>
<p><span class="font5" style="font-weight:bold;font-style:italic;">Abstract</span></p>
<p><span class="font5" style="font-style:italic;">Multiple linear regression analysis with a lot of independent variable always makes many problems because there is a relationship between two or more independent variables. The independent variables which correlated each other are called multicollinearity. Principal component analysis which based on variance covariance matrix is very sensitive toward the existence of outlier in the observing data. Therefore in order to overcome the problem of outlier it is needed a method of robust estimator toward outlier. ROBPCA is a robust method for PCA toward the existence of outlier in the data. In order to obtain the robust principal component is needed a combination of Projection Pursuit (PP) with Minimum Covariant Determinant (MCD). The results showed that the ROBPCA method has a bias parameter and Mean Square Error (MSE) parameter lower than Principal Component Regression method. This case shows that the ROBPCA method better cope with the multicollinearity observational data influenced by outlier.</span></p>
<p><span class="font5" style="font-weight:bold;font-style:italic;">Keywords</span><span class="font5" style="font-style:italic;">: Multiple Linear Regression, Principal Component Regression, ROBPCA (Robust Principal Component Analysis), multicollinearity, Outlier</span></p>
<ul style="list-style:none;"><li><a name="caption1"></a>
<h2><a name="bookmark0"></a><span class="font5" style="font-weight:bold;"><a name="bookmark1"></a>1. &nbsp;&nbsp;&nbsp;Pendahuluan</span></h2></li></ul>
<p><span class="font5">Analisis regresi linear berganda adalah salah satu metode statistika yang digunakan untuk mengetahui pengaruh sebuah variabel tidak bebas </span><span class="font5" style="font-style:italic;">(dependent variable)</span><span class="font5"> dengan dua atau lebih variabel bebas </span><span class="font5" style="font-style:italic;">(independent variable)</span><span class="font5">[2]. Adapun tujuan dari analisis regresi linier berganda adalah mengetahui seberapa besar pengaruh beberapa variabel bebas terhadap variabel tidak bebas dan juga dapat meramalkan nilai variabel tidak bebas apabila seluruh variabel bebas sudah diketahui nilainya.</span></p>
<p><span class="font5">Pada analisis regresi linier berganda dengan banyak </span><span class="font4">variabel </span><span class="font5">bebas, sering timbul masalah karena adanya hubungan antara dua atau lebih variabel bebas. Variabel bebas yang saling berkorelasi disebut multikolineari. Permasalahan yang terjadi pada analisis regresi berganda dapat mengakibatkan hasil analisis yang</span></p>
<ul style="list-style:none;"><li>
<p><span class="font3"><sup>1</sup></span><span class="font2"> &nbsp;&nbsp;&nbsp;Mahasiswa Jurusan Matematika FMIPA Universitas Udayana</span></p></li>
<li>
<p><span class="font3"><sup>2 ,3</sup> </span><span class="font2">Staf Pengajar Jurusan Matematika FMIPA Universitas Udayana &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1</span></p></li></ul>
<p><span class="font5">kurang akurat. Multikolinearitas merupakan salah satu masalah yang terjadi pada analisis regresi linear berganda. Masalah lain yang dapat memengaruhi hasil analisis data adalah pencilan </span><span class="font5" style="font-style:italic;">(outlier)</span><span class="font5">. Pada penelitian ini akan dibahas dua permasalahan statistik tersebut.</span></p>
<p><span class="font5">Pada kasus multikolinearitas, korelasi antar variabel akan menyebabkan jumlah kuadrat galat yang semakin besar sehingga menghasilkan keputusan yang tidak </span><span class="font5" style="font-style:italic;">significant</span><span class="font5">. Kasus multikolinearitas juga sangat berpengaruh pada bentuk matriks. Pada pendugaan parameter </span><span class="font5" style="font-style:italic;">β</span><span class="font5"> = </span><span class="font5" style="font-style:italic;">(X</span><span class="font5"> X)<sup>-1</sup> </span><span class="font5" style="font-style:italic;">X Y,</span><span class="font5"> apabila terjadi multikolinearitas maka matriks </span><span class="font5" style="font-style:italic;">X X singular</span><span class="font5">, sehingga persamaan untuk pendugaan estimasi parameter tidak lagi mempunyai penyelesaian yang tunggal. Hal ini akan berdampak pada dugaan koefisien variabel tidak tunggal, melainkan tidak terhingga banyaknya sehingga tidak mungkin untuk menduganya [3].</span></p>
<p><span class="font5">Metode regresi komponen utama </span><span class="font5" style="font-style:italic;">(Principal Component Regression) </span><span class="font5">merupakan salah satu teknik dalam mengatasi multikolinearitas dengan cara mereduksi variabel–variabel yang ada menjadi beberapa variabel baru yang saling bebas dan merupakan kombinasi linier dari variabel asal (Montgomery [1]).</span></p>
<p><span class="font5">Dalam menentukan komponen utama pada metode Regresi Komponen Utama yakni melalui tahapan </span><span class="font5" style="font-style:italic;">Principal Component Analysis</span><span class="font5"> (PCA). Analisis komponen utama yang berdasarkan matriks varian kovarian sangat sensitif terhadap adanya pencilan pada data pengamatan, sehingga untuk mengatasi masalah pencilan diperlukan suatu metode penduga yang tegar terhadap pencilan. </span><span class="font5" style="font-style:italic;">ROBPCA (Robust Principal Component Analysis)</span><span class="font5"> adalah suatu metode yang kuat </span><span class="font5" style="font-style:italic;">(robust) </span><span class="font5">untuk PCA terhadap keberadaan pencilan pada data, untuk mendapatkan komponen utama yang </span><span class="font5" style="font-style:italic;">robust</span><span class="font5"> diperlukan penggabungkan konsep </span><span class="font5" style="font-style:italic;">Projection Pursuit</span><span class="font5"> (PP) dengan penduga </span><span class="font5" style="font-style:italic;">robust Minimum Covariance Determinant </span><span class="font5">(MCD)[4].</span></p>
<p><span class="font5">Penduga </span><span class="font5" style="font-style:italic;">robust</span><span class="font5"> MCD merupakan nilai matriks rata-rata dan matriks kovarian dari sebagian pengamatan yang meminimumkan determinan matriks kovarian. Penduga ini didapat dengan cara mencari </span><span class="font5" style="font-style:italic;">h</span><span class="font5"> pengamatan yang memberikan nilai minimum dari matrik kovarian (Sunaryo, [4]).</span></p>
<p><span class="font5">Nilai matriks rata-rata </span><span class="font5" style="font-style:italic;">t<sub>ι</sub></span><span class="font5"> dan matriks kovarians </span><span class="font5" style="font-style:italic;">C</span><span class="font2" style="font-style:italic;">i</span><span class="font5"> dirumuskan sebagai:</span></p>
<p><span class="font5" style="font-style:italic;">t</span><span class="font2" style="font-style:italic;">,</span><span class="font5"> = </span><span class="font2">1 </span><span class="font5" style="font-style:italic;">(H<sub>t</sub>) .V’</span><span class="font5"> (1.1)</span></p>
<p><span class="font5" style="font-style:italic;">C</span><span class="font2" style="font-style:italic;">i</span><span class="font5"> =</span><span class="font2">1 </span><span class="font5" style="font-style:italic;">(H<sub>b</sub>-V∖t</span><span class="font2" style="font-style:italic;">ιm</span><span class="font5" style="font-style:italic;">H<sub>b</sub>-V∙(t</span><span class="font2" style="font-style:italic;">ι</span><span class="font5" style="font-style:italic;">)<sup>τ</sup>)</span><span class="font5"> (1.2)</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark2"></a><span class="font5" style="font-weight:bold;"><a name="bookmark3"></a>2. &nbsp;&nbsp;&nbsp;Metode Penelitian</span></h2></li></ul>
<p><span class="font5">Data yang digunakan pada penelitian ini adalah data simulasi yang diperoleh dengan membangkitkan data yang berdistribusi normal, pemeriksaan multikolinearitas, pemeriksaan pencilan, serta penyelesaian Regresi Komponen Utama dan </span><span class="font5" style="font-style:italic;">Robust Principle Component Analisys</span><span class="font5">. Software yang digunakan adalah MINITAB 15 dan R i386 2.15.2.</span></p>
<p><span class="font5">Langkah – langkah yang dilakukan dalam penelitian ini yakni:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font5">1. &nbsp;&nbsp;&nbsp;Membangkitkan data yang mengandung multikolinearitas dengan empat variabel bebas dan satu variabel tidak bebas, amatan yang dibangkitkan sebanyak 100 amatan (n=100). Nilai sisaan (f) yang dibangkitkan berdistribusi normal dengan rataan nol dan ragam satu. Nilai sisaan yang dibangkitkan berukuran 100 amatan.</span></p></li>
<li>
<p><span class="font5">2. &nbsp;&nbsp;&nbsp;Melakukan analisis regresi linear berganda setelah membentuk vaiabel tidak bebas dari beberapa variabel bebas. Pada langkah ini model regresi yang didapat tidak sesuai dengan yang diharapkan sehingga diperlukan suatu analisis untuk mendapatkan nilai penduga yang mendekati nilai yang diharapkan.</span></p></li>
<li>
<p><span class="font5">3. &nbsp;&nbsp;&nbsp;Menganalisis data bangkitan dengan metode regresi Komponen utama. Hasil analisis ini akan menjadi nilai penduga yang fit untuk mencari bias parameter.</span></p></li>
<li>
<p><span class="font5">4. &nbsp;&nbsp;&nbsp;Membangkitkan pencilan yang berdistribusi normal (N(40;0,05)) dengan persentase pencilan 10%, 15%, dan 20%. Selanjutnya menambahkan pencilan pada masing-masing peubah bebas dan melakukan analisis komponen utama.</span></p></li>
<li>
<p><span class="font5">5. &nbsp;&nbsp;&nbsp;Melakukan analisis dengan </span><span class="font5" style="font-style:italic;">Robust Principle Component Analisys</span><span class="font5"> (ROBPCA) pada data pengamatan yang dipengaruhi oleh pencilan.</span></p></li>
<li>
<p><span class="font5">6. &nbsp;&nbsp;&nbsp;Langkah terakhir yakni membandingkan dan menganalisis kedua metode tersebut. Yang digunakan sebagai pembanding adalah nilai bias parameter dan nilai </span><span class="font5" style="font-style:italic;">Mean Square Error.</span></p></li></ul>
<ul style="list-style:none;"><li>
<p><span class="font5" style="font-weight:bold;">3. &nbsp;&nbsp;&nbsp;Hasil dan Pembahasan</span></p>
<ul style="list-style:none;">
<li>
<h2><a name="bookmark4"></a><span class="font5" style="font-weight:bold;"><a name="bookmark5"></a>3.1 &nbsp;&nbsp;&nbsp;Perbandingan Regresi Komponen Utama (RKU) dan </span><span class="font5" style="font-weight:bold;font-style:italic;">Robust Principle Component Analysis</span><span class="font5" style="font-weight:bold;"> (ROBPCA)</span></h2></li></ul></li></ul>
<p><span class="font5">Bias parameter merupakan nilai harapan dari selisih antara nilai estimasi dan nilai yang sebenarnya. Nilai yang digunakan sebagai acuan adalah nilai penduga dari metode Regresi Komponen Utama yang tidak dipengaruhi oleh pencilan, sedangkan nilai yang digunakan sebagai nilai estimasi adalah nilai penduga dari metode Regresi Komponen Utama dan </span><span class="font5" style="font-style:italic;">Robust Principle Component Analysis </span><span class="font5">yang dipengaruhi oleh pencilan dengan persentase 10%, 15%, dan 20%. Bias parameter untuk 100 kali ulangan diperoleh dengan rumus berikut ini:</span></p>
<p><span class="font1">(∑<sup>1</sup>00 </span><span class="font2" style="font-style:italic;">B<sup>fit</sup> \</span><span class="font1"> &nbsp;&nbsp;&nbsp;∕∑<sup>1</sup>0<sup>0</sup> </span><span class="font2" style="font-style:italic;">β<sup>p</sup>∖</span></p><a name="caption2"></a>
<h1><a name="bookmark6"></a><span class="font5" style="font-style:italic;"><a name="bookmark7"></a>BIAS (β<sub>i</sub>)</span><span class="font5"> = ( </span><span class="font0" style="font-style:italic;text-decoration:line-through;"><sup>1</sup></span><span class="font0" style="text-decoration:line-through;">=1 </span><span class="font0" style="font-style:italic;text-decoration:line-through;"><sup>j</sup></span><span class="font5"> I-I --'=i∆L.), </span><span class="font5" style="font-style:italic;">i</span><span class="font5"> = 1,... ,4 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(3.1)</span></h1>
<p><span class="font5" style="font-style:italic;"><sup>1 ij</sup></span><span class="font2"> \ &nbsp;&nbsp;&nbsp;100 &nbsp;&nbsp;&nbsp;/ &nbsp;&nbsp;&nbsp;&nbsp;\ &nbsp;100 &nbsp;&nbsp;∕ <sup>, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</sup></span><span class="font5" style="font-style:italic;"><sup>, &nbsp;&nbsp;&nbsp;, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;j</sup></span></p>
<p><span class="font5" style="font-style:italic;">Mean Square Error</span><span class="font5"> (MSE) suatu estimator merupakan nilai harapan dari bias kuadrat. </span><span class="font5" style="font-style:italic;">Mean Square Error</span><span class="font5"> parameter untuk 100 kali ulangan diperoleh dengan menggunakan rumus berikut ini:</span></p>
<div>
<p><span class="font5" style="font-style:italic;">MSE(β</span><span class="font2" style="font-style:italic;"><sub>l</sub></span><span class="font5" style="font-style:italic;">) =</span></p>
</div><br clear="all">
<div>
<p><span class="font2" style="font-style:italic;">∑^<sup>fl</sup> ,-</span></p>
</div><br clear="all">
<div>
<p><span class="font2">100</span></p>
</div><br clear="all">
<div>
<h1><a name="bookmark8"></a><span class="font5" style="font-style:italic;"><a name="bookmark9"></a>l</span><span class="font5"> = 1,... ,4</span></h1>
</div><br clear="all">
<div>
<p><span class="font5">(3.2)</span></p>
</div><br clear="all">
<div>
<p><span class="font5">Hasil perhitungan bias parameter dan </span><span class="font5" style="font-style:italic;">Mean Square Error</span><span class="font5"> untuk 100 kali</span></p>
</div><br clear="all">
<p><span class="font5">ulangan disajikan berturut-turut pada Tabel 1 dan Tabel 2.</span></p>
<p><span class="font5">Tabel 1. Perbandingan Regresi Komponen Utama Dan ROBPCA Berdasarkan Nilai Bias Parameter</span></p>
<table border="1">
<tr><td rowspan="2" style="vertical-align:middle;">
<p><span class="font4">Pencilan</span></p></td><td rowspan="2" style="vertical-align:middle;">
<p><span class="font4">Komponen</span></p></td><td colspan="2" style="vertical-align:top;">
<p><span class="font4">Nilai Bias Parameter</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font4">Regresi Komponen Utama</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">ROBPCA</span></p></td></tr>
<tr><td rowspan="5" style="vertical-align:middle;">
<p><span class="font4">10%</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">Intercept</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">19,6368</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">1,3057</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font4">PC1</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">1,4974</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0,3775</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font4">PC2</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0,4915</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0,1309</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font4">PC3</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0,0803</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0,0023</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font4">PC4</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0,6893</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0,1160</span></p></td></tr>
<tr><td rowspan="5" style="vertical-align:middle;">
<p><span class="font4">15%</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">Intercept</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">29,8135</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">6,3881</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font4">PC1</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">1,5809</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0,3581</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font4">PC2</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0,5197</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0,0714</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font4">PC3</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0,2581</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0,0610</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font4">PC4</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0,9431</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0,3668</span></p></td></tr>
<tr><td rowspan="5" style="vertical-align:middle;">
<p><span class="font4">20%</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">Intercept</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">39,8165</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">13,0083</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font4">PC1</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">1,1576</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0,1045</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font4">PC2</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0,4013</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0,1743</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font4">PC3</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">1,4120</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0,0457</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font4">PC4</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">1,1039</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0,4341</span></p></td></tr>
</table>
<p><span class="font4">Sumber : Data diolah (2013)</span></p>
<p><span class="font5">Estimasi yang baik adalah estimasi yang menghasilkan nilai bias yang rendah atau kecil. Semakin besar nilai bias, maka semakin jauh penyimpangan dari nilai yang sebenarnya. Pada Tabel 1 munjukkan bahwa nilai penduga dari metode ROBPCA selalu lebih kecil dibandingkan dengan Regresi Komponen Utama. Oleh Karena itu nilai penduga dari metode ROBPCA lebih baik dibandingkan dengan metode Regresi Komponen Utama. Hal ini karena metode ROBPCA dapat mengatasi data pengamatan yang dipengaruhi oleh pencilan.</span></p>
<p><span class="font5">Tabel 2. Perbandingan Regresi Komponen Utama Dan ROBPCA Berdasarkan Nilai </span><span class="font5" style="font-style:italic;">Mean Square Error</span><span class="font5"> Parameter</span></p>
<table border="1">
<tr><td rowspan="2" style="vertical-align:middle;">
<p><span class="font4">Pencilan</span></p></td><td rowspan="2" style="vertical-align:middle;">
<p><span class="font4">Komponen</span></p></td><td colspan="2" style="vertical-align:top;">
<p><span class="font4">Nilai Bias Parameter</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font4">Regresi Komponen Utama</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">ROBPCA</span></p></td></tr>
<tr><td rowspan="5" style="vertical-align:middle;">
<p><span class="font4">10%</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">Intercept</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">392,0726</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">6,6843</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font4">PC1</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">3,9182</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">1,5095</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font4">PC2</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">2,8191</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">2,4226</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font4">PC3</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0,1875</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0,0206</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font4">PC4</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">2,7543</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">1,5256</span></p></td></tr>
<tr><td rowspan="5" style="vertical-align:middle;">
<p><span class="font4">15%</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">Intercept</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">891,3347</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">48,4942</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font4">PC1</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">4,0961</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">1,4267</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font4">PC2</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">3,1972</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">3,0118</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font4">PC3</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0,4456</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0,0494</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font4">PC4</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">3,0174</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">1,6895</span></p></td></tr>
<tr><td rowspan="5" style="vertical-align:middle;">
<p><span class="font4">20%</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">Intercept</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">1587,84599</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">173,4866</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font4">PC1</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">3,012465527</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">1,8322</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font4">PC2</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">2,682504765</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">2,2665</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font4">PC3</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">2,164030949</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0,0714</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font4">PC4</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">3,060462252</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">1,8983</span></p></td></tr>
</table>
<p><span class="font4">Sumber : Data diolah (2013)</span></p>
<p><span class="font5">Semakin kecil nilai </span><span class="font5" style="font-style:italic;">Mean Square Error</span><span class="font5"> suatu estimator, maka hasil estimasinya akan semakin baik. Pada Tabel 2 munjukkan bahwa nilai penduga dari metode ROBPCA selalu lebih kecil dibandingkan dengan Regresi Komponen Utama. Sehingga nilai penduga dari metode ROBPCA lebih baik dibandingkan dengan metode Regresi Komponen Utama. Hal ini karena metode ROBPCA dapat mengatasi data pengamatan yang dipengaruhi oleh pencilan.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark10"></a><span class="font5" style="font-weight:bold;"><a name="bookmark11"></a>4. &nbsp;&nbsp;&nbsp;Kesimpulan</span></h2></li></ul>
<p><span class="font5">Pada penelitian ini nilai penduga dari metode ROBPCA memiliki nilai bias parameter dan nilai </span><span class="font5" style="font-style:italic;">Mean Square Error</span><span class="font5"> (MSE) yang lebih kecil dibandingkan dengan nilai penduga dari metode Regresi Komponen Utama, sehingga metode ROBPCA memiliki nilai estimasi yang lebih baik dibandingkan dengan metode Regresi Komponen Utama.</span></p>
<h2><a name="bookmark12"></a><span class="font5" style="font-weight:bold;"><a name="bookmark13"></a>Daftar Pustaka</span></h2>
<ul style="list-style:none;"><li>
<p><span class="font5">[1] &nbsp;&nbsp;&nbsp;Montgomery, D.C. dan Peck, E.A. (1991) </span><span class="font5" style="font-style:italic;">Introduction to Linear Regression Analysis</span><span class="font5">, 2<sup>nd</sup> edition, A Wiley-Interscience,New York.</span></p></li>
<li>
<p><span class="font5">[2] &nbsp;&nbsp;&nbsp;Neter, J. (1997) </span><span class="font5" style="font-style:italic;">Model Linear Terapan</span><span class="font5">, Bandung: Diterjemahkan oleh Bambang Sumantri, IPB.</span></p></li>
<li>
<p><span class="font5">[3] &nbsp;Notiragayu.2008.</span><span class="font5" style="font-style:italic;">Pembandingan &nbsp;Beberapa Metode Analisis Regresi</span></p></li></ul>
<p><span class="font5" style="font-style:italic;">Komponen Utama Robust</span><span class="font5">.Prosiding Seminar Hasil Penelitian dan Pengabdian kepada Masyarakat, Universitas Lampung.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font5">[4] &nbsp;Sunaryo, S. (2011) </span><span class="font5" style="font-style:italic;">Mengatasi Masalah Multikolinearitas dan Outlier</span></p></li></ul>
<p><span class="font5" style="font-style:italic;">dengan Pendekatan ROBPCA (Studi Kasus: Angka Kematian Bayi di Jawa Timur)</span><span class="font5">, Jurnal Matematika, Saint dan Teknologi, Jurusan Statistika, ITS, vol. 12, Nomor 1, Maret, pp. 1-10.</span></p>
<p><span class="font3">5</span></p>