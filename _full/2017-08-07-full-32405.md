---
layout: full_article
title: "Penerapan Dizcretization dan Teknik Bagging Untuk Meningkatkan Akurasi Klasifikasi Berbasis Ensemble pada Algoritma C4.5 dalam Mendiagnosa Diabetes"
author: "Mirqotussa’adah Mirqotussa’adah, Much Aziz Muslim, Endang Sugiharti, Budi Prasetiyo, Siti Alimah"
categories: lontar
canonical_url: https://jurnal.harianregional.com/lontar/full-32405 
citation_abstract_html_url: "https://jurnal.harianregional.com/lontar/id-32405"
citation_pdf_url: "https://jurnal.harianregional.com/lontar/full-32405"  
comments: true
---

<p><span class="font1" style="font-weight:bold;">LONTAR KOMPUTER VOL. 8, NO. 2, AGUSTUS 2017</span></p>
<p><span class="font1" style="font-weight:bold;">DOI : 10.24843/LKJITI.2017.v08.i02.p07</span></p>
<p><span class="font1" style="font-weight:bold;">p-ISSN 2088-1541</span></p>
<p><span class="font1" style="font-weight:bold;">e-ISSN 2541-5832</span></p><a name="caption1"></a>
<h1><a name="bookmark0"></a><span class="font2" style="font-weight:bold;"><a name="bookmark1"></a>Penerapan Dizcretization dan Teknik Bagging Untuk Meningkatkan Akurasi Klasifikasi Berbasis Ensemble pada Algoritma C4.5 dalam Mendiagnosa Diabetes</span></h1>
<p><span class="font1">Mirqotussa’adah<sup>a1</sup>, Much Aziz Muslim<sup>a2</sup>, Endang Sugiharti<sup>a3</sup>, Budi Prasetiyo<sup>a4</sup>, Siti Alimah<sup>b5</sup></span></p>
<p><span class="font1"><sup>a</sup>Jurusan, Fakultas, Universitas</span></p>
<p><span class="font1">Menyertakan alamat institusi dan negara <sup>a</sup>Jurusan Ilmu Komputer, FMIPA, Universitas Negeri Semarang Kampus Sekaran Gunungpati Semarang, Indonesia <sup>b</sup>Jurusan Biologi, FMIPA, Universitas Negeri Semarang Kampus Sekaran Gunungpati Semarang, Indonesia</span></p>
<p><a href="mailto:1mirqotussaadah@students.unnes.ac.id"><span class="font1"><sup>1</sup>mirqotussaadah@students.unnes.ac.id</span></a><span class="font1"> </span><a href="mailto:2a212muslim@mail.unnes.ac.id"><span class="font1"><sup>2</sup>a212muslim@mail.unnes.ac.id</span></a><span class="font1">, </span><a href="mailto:3endanghs02@yahoo.com"><span class="font1"><sup>3</sup>endanghs02@yahoo.com</span></a><span class="font1"> </span><a href="mailto:4budipras@mail.unes.ac.id"><span class="font1"><sup>4</sup>budipras@mail.unes.ac.id</span></a><span class="font1">, </span><a href="mailto:5siti_alimah@mail.unnes.ac.id"><span class="font1"><sup>5</sup>siti_alimah@mail.unnes.ac.id</span></a></p>
<p><span class="font1" style="font-weight:bold;font-style:italic;">Abstrak</span></p>
<p><span class="font1" style="font-style:italic;">Pada bidang kesehatan, data mining dapat dimanfaatkan untuk memprediksi suatu penyakit dari data rekam medis pasien, diantaranya diabetes. Ada beberapa model data mining salah satunya klasifikasi. Di bidang klasifikasi, ada banyak cabang yang berkembang yaitu pohon keputusan (decision tree). Salah satu decision tree yang populer adalah C4.5. Dalam riset ini, data yang digunakan adalah pima indian diabetes dataset yang diambil dari UCI repository of machine learning. Pada dataset ini seluruh atributnya bertipe numerik yang bersifat continuous dan untuk menangani data continuous digunakan discretization. Akurasi sangat penting dalam pengklasifikasian, ensemble method adalah metode yang digunakan untuk meningkatkan akurasi algoritma klasifikasi dengan membangun beberapa classifier dari data training. Dari hasil penelitian, dengan menerapkan discretization dan teknik bagging untuk klasifikasi berbasis ensemble pada algoritma C4.5 dapat meningkatkan akurasi sebesar 6,26%. Dengan akurasi awal 68,61%, setelah diterapkan discretization dan teknik bagging menjadi 74,87%.</span></p>
<p><span class="font1" style="font-weight:bold;font-style:italic;">Kata kunci: </span><span class="font1" style="font-style:italic;">Data mining, Decision tree, C4.5, Discretization, Ensemble, Bagging, Diabetes.</span></p>
<p><span class="font1" style="font-weight:bold;font-style:italic;">Abstract</span></p>
<p><span class="font1" style="font-style:italic;">In the field of health, data mining can be used to predict a disease from patient medical record data, diabetes. There are several data mining models which one is classification. In the access field, there are many branches that are developing the decision tree (decision tree). One popular decision tree is C4.5. In this study, the data used were pima indian diabetes dataset taken from UCI machine learning repository. In this dataset all attributes are of continuous numeric type and for combined continuous data discretization is used. Accuracy is very important in the classification, ensemble method is a method used to improve the accuracy of classification algorithm by building some classifier of training data. From the research results, by applying discretization and bagging techniques to ensemble-based classification on C4.5 algorithm can increase the accuracy of 6.26%. With an initial accuracy of 68.61%, after applied discretization and bagging techniques to 74.87%..</span></p>
<p><span class="font1" style="font-weight:bold;font-style:italic;">Keywords: </span><span class="font1" style="font-style:italic;">Data mining, Decision tree, C4.5, Discretization, Ensemble, Bagging, Diabetes.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark2"></a><span class="font1" style="font-weight:bold;"><a name="bookmark3"></a>1. &nbsp;&nbsp;&nbsp;Pendahuluan</span></h2></li></ul>
<p><span class="font1">Dengan kemajuan teknologi informasi dewasa ini, kebutuhan akan informasi yang akurat sangat dibutuhkan dalam kehidupan sehari-hari. Namun, sering kali informasi tersebut masih harus digali ulang dari data yang jumlahnya sangat besar. Oleh karena itu data tersebut dapat dimanfaatkan atau diolah menjadi pengetahuan dengan istilah yang sering disebut </span><span class="font1" style="font-style:italic;">data mining. </span><span class="font1">Klasifikasi merupakan bagian penting dari pembelajaran mesin dan aplikasi data mining. Ada banyak metode yang berbeda untuk membandingkan dan menentukan hasil klasifikasi terbaik [1].</span></p>
<p><span class="font1">Di bidang klasifikasi, ada banyak cabang yang berkembang yaitu pohon keputusan (</span><span class="font1" style="font-style:italic;">decision tree</span><span class="font1">), klasifikasi </span><span class="font1" style="font-style:italic;">Bayesian</span><span class="font1">, jaringan saraf dan algoritma genetika [2]. Dalam penelitiannya mengatakan </span><span class="font1" style="font-style:italic;">decision tree</span><span class="font1"> memang populer dan sering digunakan dalam klasifikasi karena memiliki hasil yang cukup baik jika dibanding algoritma lainnya. Salah satu </span><span class="font1" style="font-style:italic;">decision tree</span><span class="font1"> yang populer adalah C4.5 [2].</span></p>
<p><span class="font1">Pada bidang kesehatan, </span><span class="font1" style="font-style:italic;">data mining</span><span class="font1"> dapat dimanfaatkan untuk memprediksi suatu penyakit dari data rekam medis pasien. Dengan metode klasifikasi pada </span><span class="font1" style="font-style:italic;">data mining</span><span class="font1">, data seperti umur, jenis kelamin, tekanan darah dan atribut lainnya, dapat digunakan menjadi faktor pendukung dalam memprediksi kemungkinan pasien terkena suatu penyakit [3]. Algoritma klasifikasi </span><span class="font1" style="font-style:italic;">data mining</span><span class="font1"> tersebut dapat dimanfaatkan dan membantu ahli medis dalam mendiagnosa suatu penyakit, salah satunya adalah </span><span class="font1" style="font-style:italic;">diabetes.</span><span class="font1"> Penyakit diabetes merupakan salah satu penyakit yang mematikan, faktor resiko tinggi dalam keluarga yang menyebabkan penyakit </span><span class="font1" style="font-style:italic;">diabetes </span><span class="font1">antara lain dikarenakan orang gemuk yang tidak melakukan latihan fisik, dan orang-orang yang memiliki gaya hidup yang tidak sehat dan makanan yang berlebih dari apa yang dibutuhkan oleh tubuh [4].</span></p>
<p><span class="font1">Penelitian diagnosa dilakukan dengan menggunakan </span><span class="font1" style="font-style:italic;">dataset pima indian diabetes</span><span class="font1">. </span><span class="font1" style="font-style:italic;">Dataset</span><span class="font1"> yang digunakan dalam penelitian ini adalah </span><span class="font1" style="font-style:italic;">dataset pima indian diabetes</span><span class="font1"> yang diperoleh dari UCI </span><span class="font1" style="font-style:italic;">repository of machine learning datasets</span><span class="font1">. Proses pengolahan dan ekstraksi pengetahuan dari data menjadi tugas penting yang sering dilakukan oleh algoritma pembelajaran. Salah satu tugas yang paling umum dilakukan oleh algoritma pembelajaran adalah pembuatan aturan klasifikasi dari contoh kelas berlabel [5]. Contohnya dijelaskan oleh serangkaian atribut numerik, nominal, atau kontinyu. Banyak algoritma pembelajaran dirancang secara jelas untuk menangani data numerik atau nominal, sementara beberapa algoritma berperforma lebih baik dengan atribut bernilai diskrit terlepas dari kenyataan bahwa mereka juga dapat menangani atribut kontinyu [6]. Sebagian besar aplikasi </span><span class="font1" style="font-style:italic;">data mining</span><span class="font1"> hanya bisa diterapkan pada fitur diskrit. Namun, data di dunia nyata seringkali bersifat kontinyu. Bahkan untuk algoritma yang bisa langsung menangani fitur kontinyu, pembelajaran seringkali kurang efisien dan efektif. Oleh karena itu </span><span class="font1" style="font-style:italic;">discretization</span><span class="font1"> membahas masalah ini dengan menemukan interval angka yang lebih ringkas untuk diwakili dan ditentukan [7]. Salah satu contohnya, algoritma pohon keputusan ID3 bekerja dengan baik pada masalah klasifikasi memiliki dataset dengan nilai-nilai diskrit [8].</span></p>
<p><span class="font1">Diskritisasi atribut kontinyu merupakan salah satu langkah pengolahan data penting dari ekstraksi pengetahuan. Metode diskritisasi yang efektif tidak hanya dapat mengurangi permintaan memori sistem dan meningkatkan efisiensi algoritma data mining dan </span><span class="font1" style="font-style:italic;">machine learning</span><span class="font1">, namun juga membuat pengetahuan yang diambil dari </span><span class="font1" style="font-style:italic;">dataset discretized</span><span class="font1"> lebih ringkas, mudah dipahami dan digunakan [7]. </span><span class="font1" style="font-style:italic;">Discretization</span><span class="font1"> adalah proses mengubah nilai atribut kontinyu menjadi sejumlah interval yang terbatas dan berasosiasi dengan masing-masing interval dengan nilai numerik yang diskrit. Proses diskritisasi dilakukan sebelum proses pembelajaran [5].</span></p>
<p><span class="font1">Akurasi sangat penting dalam pengklasifikasian. </span><span class="font1" style="font-style:italic;">Ensemble method</span><span class="font1"> adalah metode yang digunakan untuk meningkatkan akurasi algoritma klasifikasi dengan membangun beberapa </span><span class="font1" style="font-style:italic;">classifier</span><span class="font1"> dari data </span><span class="font1" style="font-style:italic;">training</span><span class="font1"> kemudian pada saat klasifikasi metode ini menggunakan </span><span class="font1" style="font-style:italic;">voting/aggregating</span><span class="font1"> dari </span><span class="font1" style="font-style:italic;">classifier-classifer</span><span class="font1"> tersebut [9]. Salah satu contoh dari </span><span class="font1" style="font-style:italic;">ensemble method </span><span class="font1">adalah </span><span class="font1" style="font-style:italic;">bootstrap aggregating</span><span class="font1"> yang biasa disingkat “</span><span class="font1" style="font-style:italic;">bagging”</span><span class="font1">. Metode bagging adalah metode resampling yang telah berhasil diterapkan pada area supervised learning untuk meningkatkan akurasi prediksi [10].</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark4"></a><span class="font1" style="font-weight:bold;"><a name="bookmark5"></a>2. &nbsp;&nbsp;&nbsp;Metodologi Penelitian</span></h2></li></ul>
<p><span class="font1">Metodologi yang digunakan pada penelitian ini terdiri dari beberapa tahap yaitu studi pendahuluan, pengumpulan data, analisis data, perancangan sistem dan penarikan kesimpulan. Studi pendahuluan yaitu merumuskan perumusan permasalahan penelitian. Selanjutnya ke tahap pengumpulan data, pada tahap ini menggunakan studi pustaka dan metode dokumentasi. Studi pustaka adalah pengumpulan bahan, informasi, keterangan dan teori dalam buku serta konsultasi dengan para ahli atau narasumber serta rujukan dari artikel, jurnal dan karya ilmiah lainnya yang relevan dan berhubungan dengan objek penelitian, serta metode yang digunakan dalam penelitian. Metode dokumentasi adalah teknik pengumpulan data yang diambil dari sumber atau sudah tersedia tanpa melakukan pencatatan data. Pada penelitian ini digunakan </span><span class="font1" style="font-style:italic;">dataset pima indian diabetes</span><span class="font1"> yang diambil dari UCI </span><span class="font1" style="font-style:italic;">repository of machine learning datasets</span><span class="font1">. Selanjutnya tahap analisis data, yaitu menjelaskan teknik penyelesaian metode yang digunakan dalam penelitian. Pada penelitian ini teknik analisis data yang dijelaskan adalah metode </span><span class="font1" style="font-style:italic;">discretization</span><span class="font1"> pada </span><span class="font1" style="font-style:italic;">pre-processing</span><span class="font1"> dalam menangani atribut yang bersifat </span><span class="font1" style="font-style:italic;">continuous</span><span class="font1"> dan teknik </span><span class="font1" style="font-style:italic;">bagging</span><span class="font1"> pada algoritma C4.5 yang diilustrasikan pada Gambar 1.</span></p><img src="https://jurnal.harianregional.com/media/32405-1.jpg" alt="" style="width:346pt;height:450pt;">
<p><span class="font1" style="font-weight:bold;">Gambar 1. </span><span class="font1">Flowchart Penggabungan Algoritma C4.5 dan Teknik </span><span class="font1" style="font-style:italic;">Bagging</span></p>
<p><span class="font1">Pada Gambar 1 pengolahan awal atau yang biasa disebut tahap </span><span class="font1" style="font-style:italic;">pre</span><span class="font1">-</span><span class="font1" style="font-style:italic;">processing</span><span class="font1">, yaitu data yang sudah didapat dibersihkan dan dipilah sehingga mendapatkan data baru untuk data </span><span class="font1" style="font-style:italic;">training</span><span class="font1"> dan data </span><span class="font1" style="font-style:italic;">testing</span><span class="font1"> dari atribut yang sudah ditentukan. Pembagian Training dan testing menggunakan </span><span class="font1" style="font-style:italic;">k-fold cross validation</span><span class="font1"> dengan </span><span class="font1" style="font-style:italic;">default k=10.</span><span class="font1"> Pada data </span><span class="font1" style="font-style:italic;">training</span><span class="font1">, lakukan </span><span class="font1" style="font-style:italic;">bootstrap</span><span class="font1"> data sebanyak 10 kali. Dan pada setiap </span><span class="font1" style="font-style:italic;">bootstrap</span><span class="font1"> dilakukan proses C4.5 yang akan dijelaskan pada Gambar 2, sehingga diperoleh 10 buah pohon klasifikasi. Selanjutnya, tahap </span><span class="font1" style="font-style:italic;">aggregating</span><span class="font1"> yaitu dilakukan pendugaan gabungan berdasarkan hasil pendugaan 10 buah pohon klasifikasi yang terbentuk menggunakan aturan </span><span class="font1" style="font-style:italic;">majority vote</span><span class="font1"> (suara terbanyak) sehingga mendapatkan model baru yang akan digunakan untuk pengujian data </span><span class="font1" style="font-style:italic;">testing</span><span class="font1">. Hasil prediksi gabungan yang telah diperoleh selanjutnya digunakan untuk menguji ketepatan klasifikasi pada penerapan metode </span><span class="font1" style="font-style:italic;">bagging.</span><span class="font1"> Uji ketepatan klasifikasi dilakukan menggunakan </span><span class="font1" style="font-style:italic;">confusion matrix</span><span class="font1">. Pengukuran akurasi dengan </span><span class="font1" style="font-style:italic;">confusion matriks</span><span class="font1"> dapat dilihat pada Tabel 1 [11].</span></p>
<p><span class="font1" style="font-weight:bold;">Tabel 1. </span><span class="font1">Confusion Matrix</span></p>
<table border="1">
<tr><td rowspan="2" style="vertical-align:top;"></td><td colspan="3" style="vertical-align:bottom;">
<p><span class="font1">Predicted Class</span></p></td></tr>
<tr><td colspan="2" style="vertical-align:bottom;">
<p><span class="font1">Positive</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">Negative</span></p></td></tr>
<tr><td rowspan="2" style="vertical-align:middle;">
<p><span class="font1">Actual Class</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">Positive</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">True Positive (TP)</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">False Negative (FN)</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font1">Negative</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">False Positive (FP)</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">True Negative (TN)</span></p></td></tr>
</table>
<p><span class="font1">Formulasi perhitungan yang digunakan adalah sebagai berikut :</span></p>
<div>
<p><span class="font5" style="font-style:italic;">Accuracy =</span></p>
</div><br clear="all">
<div>
<p><span class="font4" style="font-style:italic;">TP+TN</span></p>
<p><span class="font4" style="font-style:italic;">TP+FN+FP+TN</span></p>
</div><br clear="all">
<div>
<p><span class="font1">(1)</span></p>
</div><br clear="all">
<p><span class="font1">Tahapan alur kerja proses algoritma C4.5 diilustrasikan pada Gambar 2.</span></p>
<div><img src="https://jurnal.harianregional.com/media/32405-2.jpg" alt="" style="width:117pt;height:388pt;">
</div><br clear="all">
<p><span class="font1" style="font-weight:bold;">Gambar 2. </span><span class="font1">Flowchart Algoritma C4.5</span></p>
<p><span class="font1">Berikut penjelasan dari tiap proses yang terdapat pada Gambar 2, yaitu menghitung nilai </span><span class="font1" style="font-style:italic;">entropy, gain dan split</span><span class="font1"> dari masing-masing atribut data </span><span class="font1" style="font-style:italic;">training</span><span class="font1"> yang ada sehingga menghasilkan </span><span class="font1" style="font-style:italic;">gain ratio</span><span class="font1">. Rumus untuk menghitung entropy, gain, split dan gain ratio bisa dilihat pada persamaan 2, 3, 4 dan 5 berikut [12]:</span></p>
<div>
<p><span class="font5" style="font-style:italic;">Entropy(S) =</span><span class="font5"> ∑</span><span class="font4">P=<sub>1</sub> </span><span class="font5">- </span><span class="font5" style="font-style:italic;">p</span><span class="font4" style="font-style:italic;">i</span><span class="font5" style="font-style:italic;">* log<sub>2</sub>p<sub>i</sub></span></p>
<p><span class="font5" style="font-style:italic;">Gain(S,A) = Entropy(S) —</span><span class="font4"> ∑P-<sub>1</sub>γ7 * </span><span class="font5" style="font-style:italic;">Entropy(S<sub>i</sub>) </span><span class="font6">∣</span><span class="font4">s</span><span class="font6">∣</span></p>
<p><span class="font5" style="font-style:italic;">SplitEntropy<sub>A</sub><sup>(</sup>S) = —</span><span class="font4"> ∑F<sub>+</sub>J^* </span><span class="font5" style="font-style:italic;">log<sub>2</sub> ^ </span><span class="font4">Pl &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Pl</span></p>
<p><span class="font5" style="font-style:italic;">GainRatio(A) = </span><span class="font3" style="font-style:italic;font-variant:small-caps;">-^<sup>a</sup>-</span></p>
<p><span class="font4" style="font-style:italic;">SplitEntropy(A)</span></p>
</div><br clear="all">
<div>
<p><span class="font1">(2)</span></p>
</div><br clear="all">
<div>
<p><span class="font1">(3)</span></p>
</div><br clear="all">
<div>
<p><span class="font1">(4)</span></p>
</div><br clear="all">
<div>
<p><span class="font1">(5)</span></p>
</div><br clear="all">
<p><span class="font1">Dimana:</span></p>
<p><span class="font1">S &nbsp;&nbsp;&nbsp;&nbsp;= Himpunan Kasus</span></p>
<p><span class="font1">A &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;= Atribut</span></p>
<p><span class="font1">n &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;= jumlah partisi atribut A</span></p>
<p><span class="font1">|Si| &nbsp;&nbsp;&nbsp;&nbsp;= jumlah kasus pada partisi ke-i</span></p>
<p><span class="font1">|S| &nbsp;&nbsp;&nbsp;&nbsp;= jumlah kasus dalam S</span></p>
<p><span class="font1">Ph &nbsp;&nbsp;&nbsp;&nbsp;= Proporsi dari S_i terhadap S</span></p>
<p><span class="font1">Atribut yang memiliki </span><span class="font1" style="font-style:italic;">gain ratio</span><span class="font1"> terbesar dipilih untuk membuat simpul akar. Selanjutnya, menghitung nilai </span><span class="font1" style="font-style:italic;">entropy, gain dan split</span><span class="font1"> dari masing-masing atribut dengan menghilangkan atribut yang telah dipilih sebelumnya. Atribut yang memiliki </span><span class="font1" style="font-style:italic;">gain ratio</span><span class="font1"> terbesar dipilih untuk membuat simpul internal. Ulangi perhitungan tersebut hingga semua atribut memiliki kelas. Jika semua atribut/pohon sudah memiliki kelas, maka tampilkan pohon keputusan awal dan </span><span class="font1" style="font-style:italic;">generate</span><span class="font1"> aturan keputusan awal.</span></p>
<p><span class="font1">Selanjutnya, ke tahap perancangan sistem, pada penelitian ini perancangan sistem dilakukan sebagai alat uji penerapan metode </span><span class="font1" style="font-style:italic;">discretization</span><span class="font1"> dalam menangani atribut yang bersifat </span><span class="font1" style="font-style:italic;">continuous</span><span class="font1"> dan teknik </span><span class="font1" style="font-style:italic;">bagging</span><span class="font1"> untuk meningkatkan akurasi klasifikasi berbasis </span><span class="font1" style="font-style:italic;">ensemble</span><span class="font1"> pada Algoritma C4.5 dalam mendiagnosa </span><span class="font1" style="font-style:italic;">diabetes</span><span class="font1"> dengan menggunakan </span><span class="font1" style="font-style:italic;">Rapidminer</span><span class="font1">. Tahap yang terakhir adalah penarikan kesimpulan, simpulan dalam penelitian ini adalah mendapatkan model dan membandingkan tingkat akurasi algoritma C4.5 yang menerapakan metode </span><span class="font1" style="font-style:italic;">discretization</span><span class="font1"> dan teknik </span><span class="font1" style="font-style:italic;">bagging</span><span class="font1"> dalam mendiagnosa </span><span class="font1" style="font-style:italic;">diabetes</span><span class="font1"> sehingga didapatkan metode yang terbaik.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark6"></a><span class="font1" style="font-weight:bold;"><a name="bookmark7"></a>3. &nbsp;&nbsp;&nbsp;Hasil dan Pembahasan</span></h2></li></ul>
<p><span class="font1">Pada penelitian ini, data yang digunakan adalah </span><span class="font1" style="font-style:italic;">dataset</span><span class="font1"> yang diambil dari UCI </span><span class="font1" style="font-style:italic;">repository of machine learning</span><span class="font1">. </span><span class="font1" style="font-style:italic;">Pima indian diabetes dataset</span><span class="font1"> ini terdiri dari 768 data klinis yang semuanya berasal dari jenis kelamin wanita dengan umur sekurang-kurangnya 21 tahun yang terbagi dalam 8 atribut dan 1 atribut kelas yang digunakan untuk mendiagnosa ada tidaknya diabetes pada seseorang. </span><span class="font1" style="font-style:italic;">Pima indian diabetes dataset</span><span class="font1"> terdiri dari 8 data </span><span class="font1" style="font-style:italic;">numeric</span><span class="font1"> dan 1 data </span><span class="font1" style="font-style:italic;">nominal</span><span class="font1">. Tabel 2 menunjukkan deskripsi atribut dari </span><span class="font1" style="font-style:italic;">dataset pima indian diabetes</span><span class="font1">.</span></p>
<p><span class="font1" style="font-weight:bold;">Tabel 2</span><span class="font1">. Atribut Dataset Pima Indian Diabetes</span></p>
<table border="1">
<tr><td style="vertical-align:bottom;">
<p><span class="font0">Atribut</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">Singkatan</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">Deskripsi</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">Satuan</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">Tipe Data</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0">Pregnant</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">Pregnant</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">Angka kehamilan</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">-</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">Numerik</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font0">Plasma-Glucose</span></p></td><td style="vertical-align:top;">
<p><span class="font0">Glucose</span></p></td><td style="vertical-align:top;">
<p><span class="font0">Kadar glukosa 2 jam setelah makan</span></p></td><td style="vertical-align:top;">
<p><span class="font0">Mg/dL</span></p></td><td style="vertical-align:top;">
<p><span class="font0">Numerik</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0">Diastolic Blood-</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">DBP</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">Tekanan darah</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">Mm Hg</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">Numerik</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0">Pressure</span></p></td><td colspan="4" style="vertical-align:top;"></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0">Tricepts Skin Fold</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">TSFT</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">Ketebalan kulit</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">Mm</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">Numerik</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font0">Thickness</span></p></td><td colspan="4" style="vertical-align:top;"></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0">Insulin</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">INS</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">Insulin</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">Mu U/ml</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">Numerik</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0">Body Mass Index</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">BMI</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">Berat Tubuh</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">Kg/m </span><span class="font8"><sup>2</sup></span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">Numerik</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0">Diabetes Pedigree Function</span></p></td><td style="vertical-align:top;">
<p><span class="font0">Pedigree</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">Riwayat Diabetes dalam keluarga</span></p></td><td style="vertical-align:top;">
<p><span class="font0">-</span></p></td><td style="vertical-align:top;">
<p><span class="font0">Numerik</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0">Age</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">Age</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">Umur</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">Years</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">Numerik</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font0">Class Variable</span></p></td><td style="vertical-align:top;">
<p><span class="font0">Class</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">Positif diabetes (1) dan</span></p>
<p><span class="font0">Negatif diabetes (0)</span></p></td><td style="vertical-align:top;">
<p><span class="font0">-</span></p></td><td style="vertical-align:top;">
<p><span class="font0">Nominal</span></p></td></tr>
</table>
<p><span class="font1">Sebelum dilakukan proses klasifikasi menggunakan algoritma C4.5, data harus dipersiapkan terlebih dahulu agar siap untuk diolah (dikenal dengan istilah </span><span class="font1" style="font-style:italic;">pre-processing</span><span class="font1">) dengan tujuan meminimalkan kesalahan dan mengoptimalkan hasil </span><span class="font1" style="font-style:italic;">mining</span><span class="font1"> dari </span><span class="font1" style="font-style:italic;">classifier</span><span class="font1"> yang digunakan. Tahap persiapan sesuai dengan tahapan data </span><span class="font1" style="font-style:italic;">mining.</span><span class="font1"> Tabel 3 menunjukkan beberapa data dari </span><span class="font1" style="font-style:italic;">dataset pima Indian diabetes.</span></p>
<p><span class="font1" style="font-weight:bold;">Tabel 3</span><span class="font1">. Dataset Pima Indian Diabetes</span></p>
<table border="1">
<tr><td style="vertical-align:bottom;">
<p><span class="font0">Preg</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">Plas</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">Pres</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">Skin</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">Insu</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">Mass</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">Pedi</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">Age</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">Class</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0">7</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">136</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">74</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">26</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">135</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">26</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">0,647</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">51</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">tested_negative</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font0">5</span></p></td><td style="vertical-align:top;">
<p><span class="font0">155</span></p></td><td style="vertical-align:top;">
<p><span class="font0">84</span></p></td><td style="vertical-align:top;">
<p><span class="font0">44</span></p></td><td style="vertical-align:top;">
<p><span class="font0">545</span></p></td><td style="vertical-align:top;">
<p><span class="font0">38,7</span></p></td><td style="vertical-align:top;">
<p><span class="font0">0,619</span></p></td><td style="vertical-align:top;">
<p><span class="font0">34</span></p></td><td style="vertical-align:top;">
<p><span class="font0">tested_negative</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font0">1</span></p></td><td style="vertical-align:top;">
<p><span class="font0">119</span></p></td><td style="vertical-align:top;">
<p><span class="font0">86</span></p></td><td style="vertical-align:top;">
<p><span class="font0">39</span></p></td><td style="vertical-align:top;">
<p><span class="font0">220</span></p></td><td style="vertical-align:top;">
<p><span class="font0">45,6</span></p></td><td style="vertical-align:top;">
<p><span class="font0">0,808</span></p></td><td style="vertical-align:top;">
<p><span class="font0">29</span></p></td><td style="vertical-align:top;">
<p><span class="font0">tested_positive</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0">4</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">96</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">56</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">17</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">49</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">20,8</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">0,340</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">26</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">tested_negative</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0">5</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">108</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">72</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">43</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">75</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">36,1</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">0,263</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">33</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">tested_negative</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font0">0</span></p></td><td style="vertical-align:top;">
<p><span class="font0">78</span></p></td><td style="vertical-align:top;">
<p><span class="font0">88</span></p></td><td style="vertical-align:top;">
<p><span class="font0">29</span></p></td><td style="vertical-align:top;">
<p><span class="font0">40</span></p></td><td style="vertical-align:top;">
<p><span class="font0">36,9</span></p></td><td style="vertical-align:top;">
<p><span class="font0">0,434</span></p></td><td style="vertical-align:top;">
<p><span class="font0">21</span></p></td><td style="vertical-align:top;">
<p><span class="font0">tested_negative</span></p></td></tr>
</table>
<p><span class="font1">Pada tahap </span><span class="font1" style="font-style:italic;">cleaning,</span><span class="font1"> karena dalam </span><span class="font1" style="font-style:italic;">record</span><span class="font1"> data terdapat data yang bernilai kosong atau dapat disebut juga dengan data yang salah (</span><span class="font1" style="font-style:italic;">missing value</span><span class="font1">). Oleh karena itu, diberikan perlakuan pada</span></p>
<p><span class="font1">data yang salah (</span><span class="font1" style="font-style:italic;">missing value</span><span class="font1">). </span><span class="font1" style="font-style:italic;">Missing value</span><span class="font1"> dapat diisi secara manual dan juga dapat diisi berdasarkan model </span><span class="font1" style="font-style:italic;">average</span><span class="font1"> yaitu dengan menggantikan nilai yang kosong dengan nilai rataan berdasarkan nilai yang tersedia untuk fitur tersebut [13].</span></p>
<p><span class="font1">Selanjutnya, pada tahap transformasi data, dataset di-diskritisasi menggunakan </span><span class="font1" style="font-style:italic;">Entropy-Based Discretization</span><span class="font1">. Ini dilakukan untuk mentransformasikan data bertipe </span><span class="font1" style="font-style:italic;">numeric</span><span class="font1"> ke dalam pola yang dapat dikenali guna mendapatkan nilai entropi untuk mencari nilai </span><span class="font1" style="font-style:italic;">Information Gain</span><span class="font1"> (Persamaan 3) dari atribut bertipe </span><span class="font1" style="font-style:italic;">numeric</span><span class="font1">. Diskritisasi atribut bertujuan untuk menyederhanakan permasalahan dan meningkatkan akurasi dalam proses pembelajaran. Tabel 4 menunjukkan diskritisasi atribut dataset pima Indian diabetes dan Tabel 5 menunjukkan data setelah didiskritisasi.</span></p>
<p><span class="font1" style="font-weight:bold;">Tabel 4. </span><span class="font1">Diskritisasi atribut dataset pima Indian diabetes</span></p>
<table border="1">
<tr><td style="vertical-align:bottom;">
<p><span class="font0">Atribut</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">Diskritisasi</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0">Pregnant</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">(</span><span class="font7">≤</span><span class="font0">6), (</span><span class="font7">&gt;</span><span class="font0">6)</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font0">Plasma-Glucose</span></p></td><td style="vertical-align:top;">
<p><span class="font0">(</span><span class="font7">≤</span><span class="font0">127), (</span><span class="font7">&gt;</span><span class="font0">127)</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font0">Diastolic Blood-Pressure</span></p></td><td style="vertical-align:top;">
<p><span class="font0">(</span><span class="font7">≤</span><span class="font0">68), (</span><span class="font7">&gt;</span><span class="font0">68)</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0">Tricepts Skin Fold Thickness</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">(</span><span class="font7">≤</span><span class="font0">23), (</span><span class="font7">&gt;</span><span class="font0">23)</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font0">Insulin</span></p></td><td style="vertical-align:top;">
<p><span class="font0">(</span><span class="font7">≤</span><span class="font0">87), (</span><span class="font7">&gt;</span><span class="font0">87)</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0">Body Mass Index</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">(</span><span class="font7">≤</span><span class="font0">27,3), (</span><span class="font7">&gt;</span><span class="font0">27,3)</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0">Diabetes Pedigree Function</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">(</span><span class="font7">≤</span><span class="font0">0,527), (</span><span class="font7">&gt;</span><span class="font0">0,527)</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0">Age</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">(</span><span class="font7">≤</span><span class="font0">28), (</span><span class="font7">&gt;</span><span class="font0">28)</span></p></td></tr>
</table>
<p><span class="font1" style="font-weight:bold;">Tabel 5</span><span class="font1">. Data setelah didiskritisasi</span></p>
<table border="1">
<tr><td style="vertical-align:bottom;">
<p><span class="font0">Preg</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">Plas</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">Pres</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">Skin</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">Insu</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">Mass</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">Pedi</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">Age</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">Class</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font7">&gt;</span><span class="font0">6</span></p></td><td style="vertical-align:bottom;">
<p><span class="font7">&gt;</span><span class="font0">127</span></p></td><td style="vertical-align:bottom;">
<p><span class="font7">&gt;</span><span class="font0">68</span></p></td><td style="vertical-align:bottom;">
<p><span class="font7">&gt;</span><span class="font0">23</span></p></td><td style="vertical-align:bottom;">
<p><span class="font7">&gt;</span><span class="font0">87</span></p></td><td style="vertical-align:bottom;">
<p><span class="font7">≤</span><span class="font0">27,3</span></p></td><td style="vertical-align:bottom;">
<p><span class="font7">&gt;</span><span class="font0">0,527</span></p></td><td style="vertical-align:bottom;">
<p><span class="font7">&gt;</span><span class="font0">28</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">tested_negative</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font7">≤</span><span class="font0">6</span></p></td><td style="vertical-align:bottom;">
<p><span class="font7">&gt;</span><span class="font0">127</span></p></td><td style="vertical-align:bottom;">
<p><span class="font7">&gt;</span><span class="font0">68</span></p></td><td style="vertical-align:bottom;">
<p><span class="font7">&gt;</span><span class="font0">23</span></p></td><td style="vertical-align:bottom;">
<p><span class="font7">&gt;</span><span class="font0">87</span></p></td><td style="vertical-align:bottom;">
<p><span class="font7">&gt;</span><span class="font0">27,3</span></p></td><td style="vertical-align:bottom;">
<p><span class="font7">&gt;</span><span class="font0">0,527</span></p></td><td style="vertical-align:bottom;">
<p><span class="font7">&gt;</span><span class="font0">28</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">tested_negative</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font7">≤</span><span class="font0">6</span></p></td><td style="vertical-align:bottom;">
<p><span class="font7">≤</span><span class="font0">127</span></p></td><td style="vertical-align:bottom;">
<p><span class="font7">&gt;</span><span class="font0">68</span></p></td><td style="vertical-align:bottom;">
<p><span class="font7">&gt;</span><span class="font0">23</span></p></td><td style="vertical-align:bottom;">
<p><span class="font7">&gt;</span><span class="font0">87</span></p></td><td style="vertical-align:bottom;">
<p><span class="font7">&gt;</span><span class="font0">27,3</span></p></td><td style="vertical-align:bottom;">
<p><span class="font7">&gt;</span><span class="font0">0,527</span></p></td><td style="vertical-align:bottom;">
<p><span class="font7">&gt;</span><span class="font0">28</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">tested_positive</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font7">≤</span><span class="font0">6</span></p></td><td style="vertical-align:bottom;">
<p><span class="font7">≤</span><span class="font0">127</span></p></td><td style="vertical-align:bottom;">
<p><span class="font7">≤</span><span class="font0">68</span></p></td><td style="vertical-align:bottom;">
<p><span class="font7">≤</span><span class="font0">23</span></p></td><td style="vertical-align:bottom;">
<p><span class="font7">≤</span><span class="font0">87</span></p></td><td style="vertical-align:bottom;">
<p><span class="font7">≤</span><span class="font0">27,3</span></p></td><td style="vertical-align:bottom;">
<p><span class="font7">≤</span><span class="font0">0,527</span></p></td><td style="vertical-align:bottom;">
<p><span class="font7">≤</span><span class="font0">28</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">tested_negative</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font7">≤</span><span class="font0">6</span></p></td><td style="vertical-align:bottom;">
<p><span class="font7">≤</span><span class="font0">127</span></p></td><td style="vertical-align:bottom;">
<p><span class="font7">&gt;</span><span class="font0">68</span></p></td><td style="vertical-align:bottom;">
<p><span class="font7">&gt;</span><span class="font0">23</span></p></td><td style="vertical-align:bottom;">
<p><span class="font7">≤</span><span class="font0">87</span></p></td><td style="vertical-align:bottom;">
<p><span class="font7">&gt;</span><span class="font0">27,3</span></p></td><td style="vertical-align:bottom;">
<p><span class="font7">≤</span><span class="font0">0,527</span></p></td><td style="vertical-align:bottom;">
<p><span class="font7">&gt;</span><span class="font0">28</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">tested_negative</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font7">≤</span><span class="font0">6</span></p></td><td style="vertical-align:bottom;">
<p><span class="font7">≤</span><span class="font0">127</span></p></td><td style="vertical-align:bottom;">
<p><span class="font7">&gt;</span><span class="font0">68</span></p></td><td style="vertical-align:bottom;">
<p><span class="font7">&gt;</span><span class="font0">23</span></p></td><td style="vertical-align:bottom;">
<p><span class="font7">≤</span><span class="font0">87</span></p></td><td style="vertical-align:bottom;">
<p><span class="font7">&gt;</span><span class="font0">27,3</span></p></td><td style="vertical-align:bottom;">
<p><span class="font7">≤</span><span class="font0">0,527</span></p></td><td style="vertical-align:bottom;">
<p><span class="font7">≤</span><span class="font0">28</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">tested_negative</span></p></td></tr>
</table>
<p><span class="font1">Setelah melalui tahap </span><span class="font1" style="font-style:italic;">pre-processing</span><span class="font1">, selanjutnya dilakukan tahap proses data mining. Penelitian ini diimplementasikan kedalam </span><span class="font1" style="font-style:italic;">tool Rapidminer</span><span class="font1">. </span><span class="font1" style="font-style:italic;">Rapidminer</span><span class="font1"> adalah koleksi dari algoritma </span><span class="font1" style="font-style:italic;">learning machine</span><span class="font1"> yang digunakan untuk tugas-tugas </span><span class="font1" style="font-style:italic;">data mining</span><span class="font1">. </span><span class="font1" style="font-style:italic;">Rapidminer</span><span class="font1"> berisi </span><span class="font1" style="font-style:italic;">tool</span><span class="font1"> untuk data </span><span class="font1" style="font-style:italic;">pre-processing</span><span class="font1">, klasifikasi, regresi, </span><span class="font1" style="font-style:italic;">clustering</span><span class="font1">, </span><span class="font1" style="font-style:italic;">rule association</span><span class="font1">, dan memvisualisasikan data tersebut menjadi mudah untuk dapat dipahami. Pada bagian ini, hasil eksperimen dianalisis untuk mengevaluasi kinerja algoritma </span><span class="font1" style="font-style:italic;">data mining</span><span class="font1"> yang diusulkan. Fitur yang dipilih yaitu </span><span class="font1" style="font-style:italic;">discretization</span><span class="font1"> untuk menangani atribut </span><span class="font1" style="font-style:italic;">continuous</span><span class="font1"> (</span><span class="font1" style="font-style:italic;">numeric</span><span class="font1">) dan teknik </span><span class="font1" style="font-style:italic;">bagging</span><span class="font1"> untuk klasifikasi berbasis </span><span class="font1" style="font-style:italic;">ensemble</span><span class="font1"> pada algoritma C4.5 guna meningkatkan akurasi dalam mendiagnosa </span><span class="font1" style="font-style:italic;">diabetes</span><span class="font1">. Gambar 3 menunjukkan pohon klasifikasi yang terbentuk pada proses </span><span class="font1" style="font-style:italic;">bagging</span><span class="font1">.</span></p>
<div><img src="https://jurnal.harianregional.com/media/32405-3.jpg" alt="" style="width:188pt;height:252pt;">
</div><br clear="all">
<div><img src="https://jurnal.harianregional.com/media/32405-4.jpg" alt="" style="width:226pt;height:262pt;">
</div><br clear="all">
<p><span class="font1" style="font-weight:bold;">Gambar 3. </span><span class="font1">Hasil pohon yang dihasilkan </span><span class="font1" style="font-style:italic;">bagging</span></p>
<p><span class="font1">Hasil prediksi gabungan yang telah diperoleh selanjutnya digunakan untuk menguji ketepatan klasifikasi pada penerapan metode </span><span class="font1" style="font-style:italic;">bagging</span><span class="font1">. Uji ketepatan klasifikasi dilakukan menggunakan matriks konfusi pada Tabel 6. Sedangkan Tabel 7 menunjukkan presentase keakuratan dari algoritma C4.5 dalam mendiagnosa </span><span class="font1" style="font-style:italic;">diabetes</span><span class="font1">.</span></p>
<p><span class="font1" style="font-weight:bold;">Tabel 6. </span><span class="font1">Matriks konfuksi hasil klasifikasi</span></p>
<p><span class="font1">Prediksi</span></p>
<table border="1">
<tr><td style="vertical-align:top;"></td><td style="vertical-align:bottom;">
<p><span class="font1">Tested_positive</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">Tested_negative</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font1">Tested_positive</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">113</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">38</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font1">Tested_negative</span></p></td><td style="vertical-align:top;">
<p><span class="font1">155</span></p></td><td style="vertical-align:top;">
<p><span class="font1">462</span></p></td></tr>
</table>
<p><span class="font1" style="font-weight:bold;">Tabel 7. </span><span class="font1">Tingkat akurasi algoritma C4.5</span></p>
<table border="1">
<tr><td style="vertical-align:bottom;">
<p><span class="font1">Data</span></p>
<p><span class="font1">Diabetes</span></p></td><td style="vertical-align:top;">
<p><span class="font1">C4.5</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">C4.5 + Bagging</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1" style="font-style:italic;">Discretization +</span><span class="font1"> C4.5</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1" style="font-style:italic;">Discretization</span><span class="font1"> + C4.5 + </span><span class="font1" style="font-style:italic;">Bagging</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font1">Akurasi</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">68,61%</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">69,79%</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">74,61%</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">74,87%</span></p></td></tr>
</table>
<p><span class="font1">Hasil eksperimen dengan menggunakan C4.5 didapatkan akurasi sebesar 68,61%. Eksperimen dengan menambahkan discretization didapatkan akurasi sebesar 74,61%., mengalami kenaikan akurasi sebesar 6,26%. Sedangkan hasil eksperimen ketiga yaitu dengan menambahkan teknik bagging pada algoritma C4.5 didapatkan akurasi sebesar 69,79%. Hasil dari kedua eksperimen tersebut menjelaskan bahwa dengan menerapkan </span><span class="font1" style="font-style:italic;">discretization </span><span class="font1">ataupun teknik bagging dapat meningkatkan akurasi. </span><span class="font1" style="font-style:italic;">Discretization</span><span class="font1"> dapat meningkatkan akurasi dikarenakan </span><span class="font1" style="font-style:italic;">discretization</span><span class="font1"> memperbaiki kualitas data sebelum dilakukan proses </span><span class="font1" style="font-style:italic;">learning</span><span class="font1"> dilakukan. Sedangkan </span><span class="font1" style="font-style:italic;">bagging</span><span class="font1"> dapat meningkatkan akurasi karena mengurangi </span><span class="font1" style="font-style:italic;">variance</span><span class="font1"> dan </span><span class="font1" style="font-style:italic;">overfitting</span><span class="font1"> pada model. Bagging cocok untuk algoritma yang sifatnya </span><span class="font1" style="font-style:italic;">unstable learning algorithms</span><span class="font1"> dimana model akan berubah jika data </span><span class="font1" style="font-style:italic;">training</span><span class="font1">-nya ikut dirubah, contohnya adalah algrotima CART dan C4.5. Oleh karena itu, hasil akhir dari eksperimen dengan menerapkan </span><span class="font1" style="font-style:italic;">discretization</span><span class="font1"> dan teknik </span><span class="font1" style="font-style:italic;">bagging</span><span class="font1"> pada algoritma klasifikasi dapat meningkatkan performa akurasi secara signifikan pada algoritma C4.5 yaitu didapatkan akurasi sebesar 74,87%.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark8"></a><span class="font1" style="font-weight:bold;"><a name="bookmark9"></a>4. &nbsp;&nbsp;&nbsp;Kesimpulan</span></h2></li></ul>
<p><span class="font1">Dari empat kali eksperimen, yaitu menggunakan algoritma C4.5 menghasilkan akurasi 68,61%. Eksperimen kedua dengan menambahkan teknik </span><span class="font1" style="font-style:italic;">bagging</span><span class="font1"> pada algoritma C4.5 menghasilkan akurasi 69,79%. Selanjutnya eksperimen ketiga yaitu menambahkan teknik </span><span class="font1" style="font-style:italic;">bagging</span><span class="font1"> pada algoritma C4.5 menghasilkan akurasi 74,61%. Dari ketiga eksperimen, teknik </span><span class="font1" style="font-style:italic;">discretization</span><span class="font1"> dan teknik </span><span class="font1" style="font-style:italic;">bagging</span><span class="font1"> terbukti efektif dapat meningkatkan hasil akurasi algoritma C4.5 pada klasifikasi </span><span class="font1" style="font-style:italic;">dataset diabetes</span><span class="font1">. Teknik </span><span class="font1" style="font-style:italic;">discretization</span><span class="font1"> selain dapat mengubah atribut </span><span class="font1" style="font-style:italic;">continuous</span><span class="font1"> menjadi diskrit juga dapat meningkatkan hasil akurasi. Selanjutnya, eksperimen keempat yaitu dengan menggabungkan teknik </span><span class="font1" style="font-style:italic;">discretization</span><span class="font1"> dan teknik </span><span class="font1" style="font-style:italic;">bagging</span><span class="font1"> pada algoritma C4.5 menghasilkan akurasi sebesar 74,87%. Dari hasil penelitian dengan menggunakan </span><span class="font1" style="font-style:italic;">discretization</span><span class="font1"> dan teknik </span><span class="font1" style="font-style:italic;">bagging</span><span class="font1"> pada algoritma C4.5 menunjukan peningkatan 6,26%. Dengan akurasi awal 68,61%, setelah diterapkan </span><span class="font1" style="font-style:italic;">discretization</span><span class="font1"> dan teknik </span><span class="font1" style="font-style:italic;">bagging</span><span class="font1"> menjadi 74,87%. Dapat disimpulkan bahwa penerapan </span><span class="font1" style="font-style:italic;">discretization</span><span class="font1"> dan teknik </span><span class="font1" style="font-style:italic;">bagging</span><span class="font1"> dapat meningkatkan akurasi algoritma C4.5 pada klasifikasi </span><span class="font1" style="font-style:italic;">dataset diabetes</span><span class="font1">.</span></p>
<h2><a name="bookmark10"></a><span class="font1" style="font-weight:bold;"><a name="bookmark11"></a>Daftar Pustaka</span></h2>
<ul style="list-style:none;"><li>
<p><span class="font1">[1] &nbsp;&nbsp;&nbsp;R. Das, “A Comparison Of Multiple Classification Methods For Diagnosis Of Parkinson</span></p></li></ul>
<p><span class="font1">Disease,” </span><span class="font1" style="font-style:italic;">Expert Systems with Applications</span><span class="font1">, vol. 37, no 2, pp.1568-1572, 2010.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1">[2] &nbsp;&nbsp;&nbsp;C. J. Tsai, C. I. Lee, And W. P. Yang, “A Discretization Algorithm Based On Class</span></p></li></ul>
<p><span class="font1">Attribute Contingency Coefficient,” </span><span class="font1" style="font-style:italic;">Information Sciences,</span><span class="font1"> vol. 178, no. 3, pp.714-731, 2008.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1">[3] &nbsp;&nbsp;&nbsp;R. A. Muzakir, A., &amp;&nbsp;Wulandari, “Model Data Mining Sebagai Prediksi Penyakit</span></p></li></ul>
<p><span class="font1">Hipertensi Kehamilan Dengan Teknik Decision Tree,” </span><span class="font1" style="font-style:italic;">Scientific Journal of Informatics</span><span class="font1">, vol. 3, no. 1, pp. 19–26, 2016.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1">[4] &nbsp;&nbsp;&nbsp;&nbsp;S. M. Nuwangi, C. R. Oruthotaarachchi, J. M. P. P. Tilakaratna, And H. A. Caldera,</span></p></li></ul>
<p><span class="font1">“Utilization Of Data Mining Techniques In Knowledge Extraction For Diminution Of Diabetes,” In </span><span class="font1" style="font-style:italic;">Proceedings - 2nd Vaagdevi International Conference On Information Technology For Real World Problems, VCON</span><span class="font1">, pp.3-8, 2010.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1">[5] &nbsp;&nbsp;&nbsp;A. Al-Ibrahim, “Discretization Of Continuous Attributes In Supervised Learning</span></p></li></ul>
<p><span class="font1">Algorithms,” </span><span class="font1" style="font-style:italic;">Res. Bull. Jordan Acm</span><span class="font1">, 2011.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1">[6] &nbsp;&nbsp;&nbsp;&nbsp;R. Kerber, “Chimerge: Discretization Of Numeric Attributes,” </span><span class="font1" style="font-style:italic;">. In Proceedings of the tenth</span></p></li></ul>
<p><span class="font1" style="font-style:italic;">national conference on Artificial intelligence. Aaai Press</span><span class="font1">, 1992.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1">[7] &nbsp;&nbsp;&nbsp;Dash, R., Paramguru, R. L., &amp;&nbsp;Dash, R, “Comparative Analysis Of Supervised And</span></p></li></ul>
<p><span class="font1">Unsupervised Discretization Techniques,” </span><span class="font1" style="font-style:italic;">International Journal of Advances in Science and Technology</span><span class="font1">, Vol. 2, No. 3, Pp. 29–37, 2011.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1">[8] &nbsp;&nbsp;&nbsp;A. A. Nurcahyani And R. Saptono, “Identifikasi Kualitas Beras Dengan Citra Digital,”</span></p></li></ul>
<p><span class="font1" style="font-style:italic;">Scientific Journal of Informatics,</span><span class="font1"> vol. 2, no.1, pp.63-72, 2016.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1">[9] &nbsp;&nbsp;&nbsp;K. Tan, Pang, N., Michael, S. &amp;&nbsp;Vipin, </span><span class="font1" style="font-style:italic;">Introduction To Datamining</span><span class="font1">. Boston: Pearson</span></p></li></ul>
<p><span class="font1">Addison Wesley, 2006.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1">[10] &nbsp;&nbsp;O. Somantri, G. W. Sasmito, M. S. Sungkar, And Erwadi, “Optimalisasi Neural Network</span></p></li></ul>
<p><span class="font1">Dengan Bootstrap Aggregating (Bagging) Untuk Penentuan Prediksi Harga Listrik,” </span><span class="font1" style="font-style:italic;">Scientific Journal of Informatics,</span><span class="font1"> vol. 1, no.2, pp.185-192, 2014.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1">[11] &nbsp;&nbsp;&nbsp;F. Gorunescu, </span><span class="font1" style="font-style:italic;">Data Mining: Concepts And Techniques</span><span class="font1">, 1st Ed. Verlag Berlin Heidelberg: Springer, 2011.</span></p></li>
<li>
<p><span class="font1">[12] &nbsp;&nbsp;&nbsp;Prasetyo, “Data Mining Mengolah Data Menjadi Informasi Menggunakan Matlab,” CV. </span><span class="font1" style="font-style:italic;">Andi Offset</span><span class="font1">, 2014.</span></p></li>
<li>
<p><span class="font1">[13] &nbsp;&nbsp;&nbsp;J. Han, M. Kamber, and J. Pei, </span><span class="font1" style="font-style:italic;">Data Mining: Concepts and Techniques</span><span class="font1">, Waltham, MA: Elsevier/Morgan Kaufmann, 2012.</span></p></li></ul>
<p><span class="font1">143</span></p>