---
layout: full_article
title: "Epileptic Seizure Classification using Deep Batch Normalization Neural Network"
author: "Adenuar Purnomo, Handayani Tjandrasa"
categories: lontar
canonical_url: https://jurnal.harianregional.com/lontar/full-66155 
citation_abstract_html_url: "https://jurnal.harianregional.com/lontar/id-66155"
citation_pdf_url: "https://jurnal.harianregional.com/lontar/full-66155"  
comments: true
---

<p><span class="font0" style="font-weight:bold;">LONTAR KOMPUTER VOL. 11, NO. 3 DECEMBER 2020</span></p>
<p><span class="font0" style="font-weight:bold;">DOI : 10.24843/LKJITI.2020.v11.i03.p01</span></p>
<p><span class="font0" style="font-weight:bold;">Accredited B by RISTEKDIKTI Decree No. 51/E/KPT/2017</span></p>
<p><span class="font0" style="font-weight:bold;">p-ISSN 2088-1541</span></p>
<p><span class="font0" style="font-weight:bold;">e-ISSN 2541-5832</span></p><a name="caption1"></a>
<h1><a name="bookmark0"></a><span class="font1" style="font-weight:bold;"><a name="bookmark1"></a>Epileptic Seizure Classification using Deep Batch Normalization Neural Network</span></h1>
<p><span class="font0">Adenuar Purnomo<sup>a1</sup></span><span class="font0" style="font-weight:bold;">, </span><span class="font0">Handayani Tjandrasa<sup>a2</sup></span></p>
<p><span class="font0"><sup>a</sup>Department of Informatics, Institut Teknologi Sepuluh Nopember Jalan Raya ITS, Surabaya, Indonesia </span><a href="mailto:1Adenuar.19051@mhs.its.ac.id"><span class="font0"><sup>1</sup>Adenuar.19051@mhs.its.ac.id</span></a></p>
<p><a href="mailto:2handatj@its.ac.id"><span class="font0"><sup>2</sup>handatj@its.ac.id</span></a></p>
<p><span class="font0" style="font-weight:bold;font-style:italic;">Abstract</span></p>
<p><span class="font0" style="font-style:italic;">Epilepsy is a chronic noncommunicable brain disease. Manual inspection of long-term Electroencephalogram (EEG) records for detecting epileptic seizures or other diseases that lasted several days or weeks is a time-consuming task. Therefore, this research proposes a novel epileptic seizure classification architecture called the Deep Batch Normalization Neural Network (Deep BN<sup>3</sup>), a BN<sup>3</sup> architecture with a deeper layer to classify big epileptic seizure data accurately. The raw EEG signals are first to cut into pieces and passed through the bandpass filter. The dataset is very imbalanced, so an undersampling technique was used to produce a balanced sample of data for the training and testing dataset. Furthermore, the balanced data is used to train the Deep BN<sup>3</sup> architecture. The resulting model classifies the EEG signal as an epileptic seizure or non-seizure. The classification of epileptic seizures using Deep BN<sup>3</sup> obtained pretty good results compared to other architectures used in this research, with an accuracy of 53.61%.</span></p>
<p><span class="font0" style="font-weight:bold;font-style:italic;">Keywords: </span><span class="font0" style="font-style:italic;">Deep BN<sup>3</sup>, Seizure, Epilepsy, Deep Learning, Neural Network.</span></p>
<p><span class="font0">architecture is suited to a smaller dataset [15]. Since epilepsy EEG data is a big dataset, a deeper architecture may be better suited to classify big data.</span></p>
<p><span class="font0">Therefore, this research proposes a novel epileptic seizure classification architecture called the Deep Batch Normalization Neural Network (Deep BN<sup>3</sup>). The Deep BN<sup>3</sup> architecture is a BN<sup>3 </sup>architecture with a deeper layer inspired by deep CNN architecture to classify big epileptic seizures data accurately. The Deep BN<sup>3</sup> architecture is deep CNN architecture added with Batch Normalization layer, an essential layer in BN<sup>3</sup> architecture. This research’s contribution is to design deeper BN<sup>3</sup> networks, which was done by stacking uniform convolutions. The raw EEG signal is first cut into pieces and passed through the bandpass filter. The dataset is very imbalanced. The imbalanced dataset can result in a severe bias towards the majority class, reducing the classification performance and increasing the number of false negatives. So an undersampling technique was used to produce a balanced sample of data for the training and testing dataset. Undersampling is a technique to delete data in the majority class. Furthermore, Deep BN<sup>3</sup> architecture is trained using balanced data. The resulting model is then used to classify whether the tested EEG signal is an epileptic seizure or non-seizure. The testing data results are compared with the existing ground-truth to compute the confusion matrix’s sensitivity, specificity, and accuracy. Deep BN<sup>3</sup> will be concluded as a good architecture if it can compete with another architecture.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark2"></a><span class="font0" style="font-weight:bold;"><a name="bookmark3"></a>2. &nbsp;&nbsp;&nbsp;Research Methods</span></h2></li></ul>
<p><span class="font0">An overview of this research can be seen in Figure 1, starting from the dataset used, preprocessing, then classification using Deep BN<sup>3</sup> architecture.</span></p><img src="https://jurnal.harianregional.com/media/66155-1.jpg" alt="" style="width:423pt;height:286pt;">
<p><span class="font0" style="font-weight:bold;">Figure 1. </span><span class="font0">Overview of the process for Epileptic Seizure Classification</span></p><img src="https://jurnal.harianregional.com/media/66155-2.jpg" alt="" style="width:307pt;height:275pt;">
<p><span class="font0" style="font-weight:bold;">Figure 2. </span><span class="font0">The International 10–20 Electrode System Featuring Modified Combinatorial Nomenclature (MCN).</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark4"></a><span class="font0" style="font-weight:bold;"><a name="bookmark5"></a>2.1. &nbsp;&nbsp;&nbsp;Dataset</span></h2></li></ul>
<p><span class="font0">The data used in this research is a dataset belonging to TUH (Temple University Hospital), The TUH EEG Seizure Corpus version 1.5. This dataset is recorded based on the International 10-20 Electrode System featuring Modified Combinatorial Nomenclature (MCN), shown in Figure 2, with a sampling rate of 250 Hz. The training set consists of 1185 sessions taken from 592 patients, of which 343 sessions were seizure sessions, while the testing set consists of 238 sessions taken from 50 patients with 108 sessions being seizure sessions. Both the training and testing set used in this research is only limited to sessions with seizures.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark6"></a><span class="font0" style="font-weight:bold;"><a name="bookmark7"></a>2.2. &nbsp;&nbsp;&nbsp;Preprocessing</span></h2></li></ul>
<p><span class="font0">There are 26 channels used in both training and testing sets. The raw EEG signal seen in Figure 3 will initially be truncated every 2 seconds and then labeled according to the provided groundtruth. The EEG signal is then passed through a bandpass filter with a cut-off frequency of 0.5-44 Hz.</span></p>
<p><span class="font0">The undersampling technique will be carried out to produce balanced data for the training and testing sets. We balanced both training and testing sets because both sets are enormous and very unbalanced, with a non-seizure class around 20-25 times than seizure class. Therefore we must balance those data such that it can be appropriately classified. Otherwise, it will tend to classify closer to the class with more massive amounts of data. The details of class balancing for both training and testing sets are shown in Table 1 and Table 2.</span></p>
<p><span class="font0" style="font-weight:bold;">Table 1. Amount of Training data</span></p>
<table border="1">
<tr><td style="vertical-align:bottom;">
<p><span class="font0">Class</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">Before undersampling</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">After undersampling</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0">Seizure</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">28640</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">28640</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font0">Non-seizure</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">308112</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">28640</span></p></td></tr>
</table>
<p><span class="font0" style="font-weight:bold;text-decoration:underline;">Table 2. Amount of Testing data</span></p>
<table border="1">
<tr><td style="vertical-align:bottom;">
<p><span class="font0">Class</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">Before undersampling</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">After undersampling</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0">Seizure</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">16998</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">16998</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font0">Non-seizure</span></p></td><td style="vertical-align:top;">
<p><span class="font0">108373</span></p></td><td style="vertical-align:top;">
<p><span class="font0">16998</span></p></td></tr>
</table>
<div><img src="https://jurnal.harianregional.com/media/66155-3.jpg" alt="" style="width:438pt;height:241pt;">
<p><span class="font0" style="font-weight:bold;">Figure 3. </span><span class="font0">Raw EEG from The TUH EEG Seizure Corpus version 1.5</span></p>
</div><br clear="all">
<ul style="list-style:none;"><li>
<h2><a name="bookmark8"></a><span class="font0" style="font-weight:bold;"><a name="bookmark9"></a>2.3. &nbsp;&nbsp;&nbsp;Deep BN<sup>3</sup> Architecture</span></h2></li></ul>
<p><span class="font0">Deep BN<sup>3</sup> architecture used in this research can be seen in Figure 4. The first layer is the input layer. The inputs are the preprocessed signals that converted into a 2-dimensional image graphic, as shown in Figure 5. Then the batch normalization layer, continued by the convolutional layer with the filter size of </span><span class="font4">4 × 4, </span><span class="font0">and the number of filters is 16. The next layer is the convolutional layer, the batch normalization layer, and the max-pooling layer, repeated four times. Each convolutional layer has a filter size of </span><span class="font4">4 × 4, </span><span class="font0">and the number of filters is 16. Then the last max-pooling layer is followed by the fully connected layer. The dropout layer repeated twice with the fully connected layer’s configuration output size is 32 for the first fully connected layer and 16 for the second and with both dropout value 0.5. Finally, the last layer is the fully connected layer with the softmax function to classify the input. The training configuration used in this research are maximum training epoch 200 epoch, initial learning rate 10<sup>-3,</sup> and after 100 iterations the learning rate become 10<sup>-4</sup>. The training option used in this research is Adam optimizer. Adam weight update equation can be seen in (1), where </span><span class="font4" style="font-style:italic;">w<sub>t</sub></span><span class="font0"> is model weights, </span><span class="font4" style="font-style:italic;">η</span><span class="font0"> is the learning rate, </span><span class="font4" style="font-style:italic;">e</span><span class="font0"> is the epsilon and </span><span class="font4" style="font-style:italic;">m<sub>t</sub></span><span class="font0">, </span><span class="font4">v<sub>t</sub></span><span class="font0">are bias-corrected estimators for the first and second moments. After the training model is obtained, then the testing set will be classified using the training model.</span></p>
<p><span class="font3" style="font-style:italic;">m</span><span class="font2" style="font-style:italic;">t</span></p>
<div>
<p><span class="font0">(1)</span></p>
</div><br clear="all">
<p><span class="font3" style="font-style:italic;"><sup>w</sup>t </span><span class="font4" style="font-style:italic;">= </span><span class="font3" style="font-style:italic;"><sup>w</sup>t-ι<sup>-η</sup>√^</span></p><img src="https://jurnal.harianregional.com/media/66155-4.jpg" alt="" style="width:468pt;height:182pt;">
<p><span class="font0" style="font-weight:bold;">Figure 4. </span><span class="font0">Deep BN<sup>3</sup> Architecture</span></p><img src="https://jurnal.harianregional.com/media/66155-5.jpg" alt="" style="width:422pt;height:222pt;">
<p><span class="font0" style="font-weight:bold;">Figure 5. </span><span class="font0">An input image of the 26 channel signal</span></p><img src="https://jurnal.harianregional.com/media/66155-6.jpg" alt="" style="width:447pt;height:145pt;">
<p><span class="font0" style="font-weight:bold;">Figure 6. </span><span class="font0">CNN Architecture</span></p><img src="https://jurnal.harianregional.com/media/66155-7.jpg" alt="" style="width:445pt;height:122pt;">
<p><span class="font0" style="font-weight:bold;">Figure 7. </span><span class="font0">BN<sup>3</sup> Architecture</span></p>
<p><span class="font0" style="font-weight:bold;">Table 3. </span><span class="font0">Accuracy, Sensitivity, and Specificity results of each architecture for the testing set</span></p>
<table border="1">
<tr><td style="vertical-align:bottom;">
<p><span class="font0">Architecture</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">Accuracy (%)</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">Sensitivity (%)</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">Specificity (%)</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font0">Deep BN<sup>3</sup></span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">53.61</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">46.60</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">60.62</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font0">CNN</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">49.99</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">46.54</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">53.44</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font0">BN<sup>3</sup></span></p></td><td style="vertical-align:middle;">
<p><span class="font0">52.95</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">42.54</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">63.35</span></p></td></tr>
</table>
<p><span class="font0">An overview of the CNN and BN<sup>3</sup> architecture can be seen in Figures 6 and 7. The results of each architecture are shown in Table 3. Deep BN<sup>3</sup> has the highest testing set accuracy, with 53.61% accuracy, and has the highest sensitivity with 46.6%. However, for specificity, the BN<sup>3</sup> architecture got the highest, at 63.35%. As we can see, the testing accuracy results of each architecture are only 50-55%. One of the key factors is that the subject in the testing set different from the training set. Suppose the signal between the training set and the testing set is different. In that case, the training set signal may have different extracted fundamental feature values than the testing set. The other factor, in this research’s dropout value is high so it makes the training accuracy is not too high. The low accuracy in the training model causing low testing accuracy. The preprocessing step is also a factor that influences the low metric results of the three architectures. The different cutting processes can affect whether the spike from the seizure can be captured intact or only a piece of it within the cut’s range. If the seizure spike in the data is only partly captured, it will affect the results. The undersampling technique used in this research is also one factor of why the accuracy is low. A better undersampling technique used may increase the accuracy results. The other factor in this research used a time-domain signal, so the key features can’t be shown clearly, compared to the frequency domain used in research [3]. In research [3], the FFT and power spectrum usage used to have better results when there are 20 features extracted, which can be used in the future.</span></p>
<p><span class="font0">Tables 4, 5, and 6 is the confusion matrix of the testing set for each architecture. The deep BN3 architecture has better accuracy, shown by the sum of truly predicted seizure and true predicted</span></p>
<p><span class="font0">non-seizure. Figure 9 is an example of a misclassified seizure signal. The signal has seizure spikes, but the Deep BN<sup>3</sup> and the CNN architecture classified it as a non-seizure signal. Meanwhile, only BN<sup>3</sup> architecture classified it as a seizure signal.</span></p>
<p><span class="font0" style="font-weight:bold;">T</span><span class="font0" style="font-weight:bold;text-decoration:underline;">able 4. </span><span class="font0" style="text-decoration:underline;">Confusion M</span><span class="font0">atrix of Deep BN<sup>3</sup> Architecture</span></p>
<table border="1">
<tr><td style="vertical-align:top;"></td><td style="vertical-align:bottom;">
<p><span class="font0">Predicted Seizure</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">Predicted Non-Seizure</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font0">True Seizure</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">7921</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">9077</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0">True Non-seizure</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">6694</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">10304</span></p></td></tr>
<tr><td colspan="3" style="vertical-align:bottom;">
<p><span class="font0" style="font-weight:bold;">Table 5. </span><span class="font0">Confusion Matrix of CNN Architecture</span></p></td></tr>
<tr><td style="vertical-align:top;"></td><td style="vertical-align:bottom;">
<p><span class="font0">Predicted Seizure</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">Predicted Non-Seizure</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font0">True Seizure</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">7911</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">9087</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font0">True Non-seizure</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">7915</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">9083</span></p></td></tr>
<tr><td colspan="3" style="vertical-align:bottom;">
<p><span class="font0" style="font-weight:bold;">Table 6. </span><span class="font0">Confusion Matrix of BN<sup>3</sup> Architecture</span></p></td></tr>
<tr><td style="vertical-align:top;"></td><td style="vertical-align:bottom;">
<p><span class="font0">Predicted Seizure</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">Predicted Non-Seizure</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font0">True Seizure</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">7231</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">9767</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font0">True Non-seizure</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">6229</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">10769</span></p></td></tr>
</table><img src="https://jurnal.harianregional.com/media/66155-8.jpg" alt="" style="width:427pt;height:221pt;">
<p><span class="font0" style="font-weight:bold;">Figure 8. </span><span class="font0">The image of signal misclassified by the models of Deep BN3, and CNN Architecture</span></p>
<h2><a name="bookmark10"></a><span class="font0" style="font-weight:bold;"><a name="bookmark11"></a>References</span></h2>
<ul style="list-style:none;"><li>
<p><span class="font0">[1] &nbsp;&nbsp;&nbsp;WHO, “WHO Epilepsy Fact Sheet,” 2019. [Online]. Available: </span><a href="https://www.who.int/news-room/fact-sheets/detail/epilepsy"><span class="font0">https://www.who.int/news-room/fact-sheets/detail/epilepsy</span></a><span class="font0">. [Accessed: 11-Feb-2020].</span></p></li>
<li>
<p><span class="font0">[2] &nbsp;&nbsp;&nbsp;S. Roy, U. Asif, J. Tang, and S. Harrer, “Machine Learning for Seizure Type Classification: Setting the benchmark,” pp. 2–6, 2019.</span></p></li>
<li>
<p><span class="font0">[3] &nbsp;&nbsp;&nbsp;H. Tjandrasa, S. Djanali, and F. X. Arunanto, “Feature extraction using combination of intrinsic mode functions and power spectrum for EEG signal classification,” </span><span class="font0" style="font-style:italic;">Proc. - 2016 9th International Congress on Image and Signal Processing, Biomedical Engineering and Informatics, CISP-BMEI 2016</span><span class="font0">, pp. 1498–1502, 2017.</span></p></li>
<li>
<p><span class="font0">[4] &nbsp;&nbsp;&nbsp;H. Tjandrasa and S. Djanali, “Classification of EEG signals using single channel independent component analysis, power spectrum, and linear discriminant analysis,” in </span><span class="font0" style="font-style:italic;">Lecture Notes in Electrical Engineering</span><span class="font0">, 2016, vol. 387, pp. 259–268.</span></p></li>
<li>
<p><span class="font0">[5] &nbsp;&nbsp;&nbsp;U. R. Acharya, S. Lih, Y. Hagiwara, J. Hong, and H. Adeli, “Deep convolutional neural network for the automated detection and diagnosis of seizure using EEG signals,” </span><span class="font0" style="font-style:italic;">Computer in Biology and Medicine</span><span class="font0">, vol. 100, no. July 2017, pp. 270–278, 2018.</span></p></li>
<li>
<p><span class="font0">[6] &nbsp;&nbsp;&nbsp;S. Raghu, N. Sriraam, Y. Temel, S. V. Rao, and P. L. Kubben, “EEG based multi-class seizure type classification using convolutional neural network and transfer learning,” </span><span class="font0" style="font-style:italic;">Neural Networks</span><span class="font0">, vol. 124, pp. 202–212, 2020.</span></p></li>
<li>
<p><span class="font0">[7] &nbsp;&nbsp;&nbsp;J. Birjandtalab, M. Heydarzadeh, M. Nourani, and A. Background, “Automated EEG-Based Epileptic Seizure Detection Using Deep Neural Networks,” no. 1, pp. 2–5, 2017.</span></p></li>
<li>
<p><span class="font0">[8] &nbsp;&nbsp;&nbsp;I. Ullah, M. Hussain, E. Qazi, and H. Aboalsamh, “An automated system for epilepsy detection using EEG brain signals based on deep learning approach,” </span><span class="font0" style="font-style:italic;">Expert Systems with Applications</span><span class="font0">, vol. 107, pp. 61–71, 2018.</span></p></li>
<li>
<p><span class="font0">[9] &nbsp;&nbsp;&nbsp;F. Achilles, F. Tombari, V. Belagiannis, A. M. Loesch, S. Noachtar, and N. Navab, “Convolutional neural networks for real-time epileptic seizure detection,” </span><span class="font0" style="font-style:italic;">Computer Methods Biomechanics and Biomedical Engineering Imaging and Visualisations</span><span class="font0">, vol. 6, no. 3, pp. 264–269, 2018.</span></p></li>
<li>
<p><span class="font0">[10] &nbsp;&nbsp;&nbsp;N. D. Truong </span><span class="font0" style="font-style:italic;">et al.</span><span class="font0">, “Convolutional neural networks for seizure prediction using intracranial and scalp electroencephalogram,” </span><span class="font0" style="font-style:italic;">Neural Networks</span><span class="font0">, vol. 105, pp. 104–111, 2018.</span></p></li>
<li>
<p><span class="font0">[11] &nbsp;&nbsp;&nbsp;M. Hosseini, D. Pompili, K. Elisevich, and H. Soltanian-Zadeh, “Optimized Deep Learning for EEG Big Data and Seizure Prediction BCI via Internet of Things,” </span><span class="font0" style="font-style:italic;">IEEE Transactions Big Data</span><span class="font0">, vol. 3, no. 4, pp. 392–404, Dec. 2017.</span></p></li>
<li>
<p><span class="font0">[12] &nbsp;&nbsp;&nbsp;M. Liu, W. Wu, Z. Gu, Z. Yu, F. F. Qi, and Y. Li, “Deep learning based on Batch Normalization for P300 signal detection,” </span><span class="font0" style="font-style:italic;">Neurocomputing</span><span class="font0">, vol. 275, pp. 288–297, 2018.</span></p></li>
<li>
<p><span class="font0">[13] &nbsp;&nbsp;&nbsp;Y. Chen </span><span class="font0" style="font-style:italic;">et al.</span><span class="font0">, “Texts With Deep Learning Approaches,” </span><span class="font0" style="font-style:italic;">IEEE Transactions and Intelligent Transportation Systems</span><span class="font0">, vol. PP, no. 8, pp. 1–10, 2018.</span></p></li>
<li>
<p><span class="font0">[14] &nbsp;&nbsp;&nbsp;D. Macêdo, C. Zanchettin, A. L. I. Oliveira, and T. Ludermir, “Enhancing batch normalized convolutional networks using displaced rectifier linear units: A systematic comparative study,” </span><span class="font0" style="font-style:italic;">Expert Systems with Applications</span><span class="font0">, vol. 124, pp. 271–281, 2019.</span></p></li>
<li>
<p><span class="font0">[15] &nbsp;&nbsp;&nbsp;A. Schindler, T. Lidy, and A. Rauber, “Comparing shallow versus deep neural network architectures for automatic music genre classification,” </span><span class="font0" style="font-style:italic;">CEUR Workshop Proceedings</span><span class="font0">, vol. 1734, pp. 17–21, 2016.</span></p></li></ul>
<p><span class="font0">131</span></p>