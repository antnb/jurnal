---
layout: full_article
title: "Kombinasi Metode MFCC dan KNN dalam Pengenalan Emosi Manusia Melalui Ucapan"
author: "Putu Widya Eka Safitri, Anak Agung Istri Ngurah Eka Karyawati"
categories: jnatia
canonical_url: https://jurnal.harianregional.com/jnatia/full-92655 
citation_abstract_html_url: "https://jurnal.harianregional.com/jnatia/id-92655"
citation_pdf_url: "https://jurnal.harianregional.com/jnatia/full-92655"  
comments: true
---

<p><span class="font0">JNATIA Volume 1, Nomor 1, November 2022</span></p>
<p><span class="font0">Jurnal Nasional Teknologi Informasi dan Aplikasinya</span></p><a name="caption1"></a>
<h1><a name="bookmark0"></a><span class="font1" style="font-weight:bold;"><a name="bookmark1"></a>Kombinasi Metode MFCC dan KNN dalam Pengenalan Emosi Manusia Melalui Ucapan</span></h1>
<p><span class="font0">Putu Widya Eka Safitri<sup>1</sup></span><span class="font0" style="font-weight:bold;">, </span><span class="font0">AAIN Eka Karyawati <sup>a2</sup></span></p>
<p><span class="font0"><sup>a</sup> Program Studi Informatika, Universitas Udayana Kuta Selatan, Badung, Bali, Indonesia </span><a href="mailto:1widyaekasafitri79@gmail.com"><span class="font0"><sup>1</sup>widyaekasafitri79@gmail.com</span></a><span class="font0"> </span><a href="mailto:2eka.karyawati@unud.ac.id"><span class="font0"><sup>2</sup>eka.karyawati@unud.ac.id</span></a></p>
<p><span class="font0" style="font-weight:bold;font-style:italic;">Abstract</span></p>
<p><span class="font0" style="font-style:italic;">Emotions are expressions that humans have in responding or responding to things that happen to themselves or in the environment around them, with these emotions humans are more able to express what they feel about a situation or event, these emotions can also be a means of communication other than language, because with emotions Of course, humans can know what happens to other humans around them. One of the human expressions to be able to communicate is by voice, sound can also be used to find out the type of emotion that is being experienced by the speaker. Mel-Frequency Cepstrum Coefficient (MFCC) is one of the feature extractions that is often used in the field of speech technology where in this feature extraction the human voice recording will be converted into a convolution matrix, namely a spectrogram or voice signal. K-Nearest Neighbor (K-NN) is a method that works by grouping new data based on the distance (neighborhood) from one data to the other. In the study of classical human emotions with speech using the K-Nearest Neighbor (K-NN) method, it is not appropriate to use this method because it only gets 50% accuracy.</span></p>
<p><span class="font0" style="font-weight:bold;font-style:italic;">Keywords: </span><span class="font0" style="font-style:italic;">Emotion, Voice, K-Nearest Neighbor, MFCC, Music Information Retrieval</span></p>
<ul style="list-style:none;"><li>
<h3><a name="bookmark2"></a><span class="font0" style="font-weight:bold;"><a name="bookmark3"></a>1. &nbsp;&nbsp;&nbsp;Pendahuluan</span></h3></li></ul>
<p><span class="font0">Emosi merupakan bagian dari manusia yang diekspresikan secara nyata (Gumelar et al., 2019). Emosi adalah ekspresi manusia dalam menunjukan reaksi terhadap suatu kejadian yang juga dapat digunakan sebagai alat komunikasi. Emosi banyak jenisnya, untuk jenis emosi yang biasa dilakukan seperti senang, takut, sedih, netral, marah dan jijik, sebenarnya banyak cara dalam mengekspresikan emosi seperti raut wajah, menulis, ucapan dan lain-lain.</span></p>
<p><span class="font0">Ucapan adalah cara manusia berkomunikasi dengan sesama manusia, dengan ucapan ini manusia lebih mudah dalam mengekspresikan emosinya (Helmiah et al., 2019). Ucapan merupakan sinyal kompleks yang berisi informasi. Manusia dapat berdialog untuk menyampaikan sesuatu dengan berbagai emosi yang dirasakan,</span></p>
<p><span class="font0">Pada penelitian ini akan dilakukan Klasifikasi emosi manusia dengan ucapan dengan metode </span><span class="font0" style="font-style:italic;">K-Nearest Neighbor (</span><span class="font0">K-NN) menggunakan ekstraksi fitur </span><span class="font0" style="font-style:italic;">Mel-Frequency Cepstrum Coefficient </span><span class="font0">(MFCC). </span><span class="font0" style="font-style:italic;">Mel-Frequency Cepstrum Coefficient (</span><span class="font0">MFCC) merupakan salah satu ekstraksi fitur yang sering digunakan dalam bidang </span><span class="font0" style="font-style:italic;">speech technologi</span><span class="font0"> yang dimana pada ekstraksi fitur ini rekaman suara manusia akan diubah menjadi convolution matriks yaitu spectrogram atau sinyal suara dan nantinya akan diklasifikasi berdasarkan jenis emosinya.</span></p>
<p><span class="font0" style="font-style:italic;">K-Nearest Neighbor</span><span class="font0"> (KNN) dipilih karena bisa menyederhanakan perhitungan algoritma dan dapat mengefisiensikan waktu. </span><span class="font0" style="font-style:italic;">K-Nearest Neighbor</span><span class="font0"> (KNN) adalah metode yang bekerja dengan cara mengelompokan data baru didasarkan pada jarak (bertetangga) dari satu data ke data yang</span></p>
<p><span class="font0">satunya (Fajar et al., 2019) Klasifikasi jenis emosi ini akan dilakukan dengan menggunakan algoritma </span><span class="font0" style="font-style:italic;">K-Nearest Neighbor</span><span class="font0"> (KNN).</span></p>
<ul style="list-style:none;"><li>
<h3><a name="bookmark4"></a><span class="font0" style="font-weight:bold;"><a name="bookmark5"></a>2. &nbsp;&nbsp;&nbsp;Metode Penelitian</span></h3></li></ul>
<p><span class="font0">Penelitian ini dilakukan untuk mengetahui jenis emosi manusia menggunakan </span><span class="font0" style="font-style:italic;">K-Nearest Neighbor</span><span class="font0"> (K-NN), tahapan yang dilakukan pada penelitian ini yaitu pengumpulan data, preprocessing, ekstraksi fitur dan proses klasifikasi, dibawah ini merupakan alur dari penelitian</span></p><img src="https://jurnal.harianregional.com/media/92655-1.jpg" alt="" style="width:93pt;height:245pt;">
<p><span class="font0">Gambar 1. Diagram Alir Pemodelan K-NN</span></p>
<p><span class="font0">Pada alur penelitian diatas, dimulai dengan pengumpulan data, yang dimana dataset pada tahap pengumpulan data tersebut bersumber dari Kaggle, lalu pada tahap Preprocessing akan dilakukan untuk membersihkan data, terdapat empat preprocessing yang diimplementasikan pada data adalah pengurangan noise, stretch data suara, shifting dan penyesuaian pitch, lalu pada ekstraksi fitur yang digunakan ekstraksi fitur </span><span class="font0" style="font-style:italic;">Mel-Frequency Cepstrum Coefficient (</span><span class="font0">MFCC) dan data suara akan diubah menjadi sinyal suara, dan yang terakhir pada tahap pemodelan </span><span class="font0" style="font-style:italic;">K-Nearest Neighbor</span><span class="font0"> (K-NN) akan dicari akurasinya.</span></p>
<ul style="list-style:none;"><li>
<h3><a name="bookmark6"></a><span class="font0" style="font-weight:bold;"><a name="bookmark7"></a>2.1 &nbsp;&nbsp;&nbsp;Tahap Pengumpulan Data</span></h3></li></ul>
<p><span class="font0">Dataset yang digunakan berjumlah 7.244 data yang dimana data yang diperankan oleh 91 aktor dengan pembagian 48 suara pria dan 43 suara wanita, yang rentang usianya 20 sampai 74 tahun dari berbagai etnis dan ras yang berbeda, didalam terdapat beberapa jenis emosi yaitu seperti marah, jijik, takut, senang, netral, dan sedih yang berbahasa Inggris.</span></p>
<ul style="list-style:none;"><li>
<h3><a name="bookmark8"></a><span class="font0" style="font-weight:bold;"><a name="bookmark9"></a>2.2 &nbsp;&nbsp;&nbsp;Tahap Preprocessing Ucapan</span></h3></li></ul>
<p><span class="font0">Pada proses ini, data yang dimiliki akan melalui tahap pembersihan data yang dimana akan dilakukan, untuk memaksimalkan data dan mengurangi kemungkinan error, dilakukan preprocessing pada data suara yang dibantu menggunakan library librosa dan numpy, beberapa </span><span class="font0" style="font-style:italic;">preprocessing</span><span class="font0"> yang diimplementasikan pada data adalah pengurangan </span><span class="font0" style="font-style:italic;">noise</span><span class="font0">, </span><span class="font0" style="font-style:italic;">stretch</span><span class="font0"> data suara,</span></p>
<p><span class="font0" style="font-style:italic;">shifting</span><span class="font0"> dan penyesuaian </span><span class="font0" style="font-style:italic;">pitch</span><span class="font0">. Sesuai penjelasan diatas, terdapat empat tahapan </span><span class="font0" style="font-style:italic;">noise reduction</span><span class="font0"> untuk pengurangan noise, stretch untuk menghilangkan jeda pada data suara, shift yaitu menggeser waktu audio kami ke kiri atau ke kanan secara acak dengan persentase kecil, atau mengubah pitch atau kecepatan audio dengan jumlah kecil, pitch yaitu untuk menyesuaikan suara agar tidak terlalu rendah atau terlalu tinggi. Berikut merupakan hasil sinyal suara yang diuji coba pada penelitian ini setelah melalui tahap preprocessing:</span></p>
<div>
<h3><a name="bookmark10"></a><span class="font0" style="font-weight:bold;"><a name="bookmark11"></a>a.</span></h3>
</div><br clear="all">
<div>
<p><span class="font0">Emosi Fear (Takut)</span></p>
</div><br clear="all">
<div>
<p><span class="font0">1.</span></p>
</div><br clear="all">
<div><img src="https://jurnal.harianregional.com/media/92655-2.jpg" alt="" style="width:339pt;height:146pt;">
<p><span class="font0">Gambar 2. Sinyal Suara Emosi Fear (Takut)</span></p>
</div><br clear="all">
<p><span class="font0">Emosi takut dirasakan apabila seseorang merasa terancam akan suatu hal yang sedang terjadi, hatinya akan merasa gelisah dan suara biasanya akan gemetar, suara meninggi tetapi memelan.</span></p>
<div>
<h3><a name="bookmark12"></a><span class="font0" style="font-weight:bold;"><a name="bookmark13"></a>b.</span></h3>
</div><br clear="all">
<div>
<p><span class="font0">2.</span></p>
</div><br clear="all">
<div>
<p><span class="font0">Emosi Angry (Marah)</span></p><img src="https://jurnal.harianregional.com/media/92655-3.jpg" alt="" style="width:339pt;height:143pt;">
<p><span class="font0">Gambar 3. Sinyal Suara Emosi Angry (Marah)</span></p>
</div><br clear="all">
<p><span class="font0">Emosi marah ini akan terjadi ketika seseorang merasa harapan atau kehendaknya tidak terpenuhi dan tidak sesuai dengan harapannya</span></p>
<div>
<p><span class="font0" style="font-weight:bold;">c.</span></p><img src="https://jurnal.harianregional.com/media/92655-4.jpg" alt="" style="width:358pt;height:173pt;">
</div><br clear="all">
<p><span class="font0">Emosi senang ini muncul ketika ketika harapannya atau kehendaknya terpenuhi atau sesuatu yang menyenangkan hatinya terjadi</span></p>
<div>
<h3><a name="bookmark14"></a><span class="font0" style="font-weight:bold;"><a name="bookmark15"></a>d.</span></h3>
</div><br clear="all">
<div>
<p><span class="font0">4.</span></p>
</div><br clear="all">
<div>
<p><span class="font0">Emosi Sad (Sedih)</span></p><img src="https://jurnal.harianregional.com/media/92655-5.jpg" alt="" style="width:340pt;height:152pt;">
<p><span class="font0">Gambar 5. Sinyal Suara Emosi Sad (Sedih)</span></p>
</div><br clear="all">
<p><span class="font0">Emosi sedih ini terjadi ketika manusia merasa frustasi dan kecewa terhadap suatu hal atau seseorang, hatinya akan merasa kosong dan tidak puas akan sesuatu atau seseorang.</span></p>
<div>
<p><span class="font0" style="font-weight:bold;">e. </span><span class="font0">Emosi Disgust (Jijik)</span></p>
</div><br clear="all">
<div><img src="https://jurnal.harianregional.com/media/92655-6.jpg" alt="" style="width:321pt;height:106pt;">
</div><br clear="all">
<ul style="list-style:none;"><li>
<p><span class="font0">5. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Time</span></p></li></ul>
<p><span class="font0">Gambar 6. Sinyal Suara Emosi Disgust (Jijik)</span></p>
<p><span class="font0">Emosi ini terjadi apa bila manusia merasakan bahwa hal itu tidak seharusnya terjadi, dan timbul perasaan tidak ingin melihat, mendengar atau merasakan hal tersebut</span></p>
<div>
<p><span class="font0" style="font-weight:bold;">f. </span><span class="font0">Emosi Neutral (Netral)</span></p>
<p><span class="font0" style="font-weight:bold;">6.</span></p><img src="https://jurnal.harianregional.com/media/92655-7.jpg" alt="" style="width:341pt;height:119pt;">
<p><span class="font0">Gambar 7. Sinyal Suara Emosi Neutral (Netral)</span></p>
</div><br clear="all">
<p><span class="font0">Emosi ini terjadi apabila tidak merasakan emosi-emosi diatas, tetapi hal ini juga dapat terjadi pada emosi baru yang tidak bisa dijelaskan.</span></p>
<ul style="list-style:none;"><li>
<h3><a name="bookmark16"></a><span class="font0" style="font-weight:bold;"><a name="bookmark17"></a>2.3 &nbsp;&nbsp;&nbsp;Ekstraksi Fitur dengan MFCC</span></h3></li></ul>
<p><span class="font0">Pada penelitian dilakukan ekstraksi fitur </span><span class="font0" style="font-style:italic;">Mel-Frequency Cepstrum Coefficient (</span><span class="font0">MFCC) menggunakan library librosa, yang selanjutnya disimpan kedalam dataset. Pada ekstraksi fitur </span><span class="font0" style="font-style:italic;">Mel-Frequency Cepstrum Coefficient</span><span class="font0"> (MFCC) menghasilkan 20 set data yang nantinya akan digunakan sebagai fiture untuk metode KNN.</span></p><img src="https://jurnal.harianregional.com/media/92655-8.jpg" alt="" style="width:112pt;height:367pt;">
<p><span class="font0">Gambar 8. Alur MFCC</span></p>
<p><span class="font0">Pada proses alur MFCC tersebut, dari inputan data yang telah melalui preprocessing yaitu data ucapan yang telah menjadi data numerik, lalu akan melalui tahapan Pre – emphasis Filtering yang merupakan salah satu jenis filter yang sering digunakan sebelum sebuah sinyal diproses lebih lanjut, lalu pada tahap framing yang bertujuan untuk memotong agar sinyal suara menjadi durasi yang lebih kecil dan stabil, lalu pada tahap windowing bertujuan mencegah terjadinya kebocoran spektral aliasing, pada tahap Fast Fourier Transform ini bertujuan untuk merubah sinyal dari domain waktu ke frekuensi agar sinyal dapat di proses dalam spectral substraksi, selanjutnya pada tahap Mel Scale Filterbank bertujuan untuk menyesuaikan sistem dengan pendengaran manusia, pada tahap Discrete Cosine Transform ini akan mengkompres sinyal yang akan dimasukkan ke frekuensi, dan setelah sinyal diubah ke frekuensi maka pada MFCC akan dilakukan penangkapan karakteristik dari suatu sinyal suara.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font0" style="font-weight:bold;">2.4 &nbsp;&nbsp;&nbsp;Pemodelan </span><span class="font0" style="font-weight:bold;font-style:italic;">K-Nearest Neighbor (</span><span class="font0" style="font-weight:bold;">K-NN)</span></p></li></ul>
<p><span class="font0">Pada penelitian Kombinasi Metode MFCC dan KNN dalam Pengenalan Emosi Manusia Melalui Ucapan, berikut ditampilkan pada gambar Flowchart alur penelitian ini.</span></p><img src="https://jurnal.harianregional.com/media/92655-9.jpg" alt="" style="width:168pt;height:447pt;">
<p><span class="font0">Gambar 9. Flowchart Pemodelan K-NN</span></p>
<p><span class="font0">Pada Flowchart diatas alur dimulai dengan inputnya yaitu hasil dari MFCC, yang dimana akan dicari nilai k nya, lalu akan dihitung jarak dari data ke data yang sudah tersebar, setelah itu </span><span class="font0" style="font-style:italic;">sorting </span><span class="font0">semua jarak data, selanjutnya pilih data dengan jarak terkecil dan ambil emosi berdasarkan kategori mayoritas yang muncul. Setelah itu akan kembali ke tahap tanya apakah semua nilai k sudah diklasifikasi, jika sudah maka akan berakhir jika tidak akan diulangi proses tersebut sampai nilai k selesai di cari. Untuk mendapatkan tetangga terdekat didapatkan dari jarak terkecil antara data </span><span class="font0" style="font-style:italic;">input</span><span class="font0"> dengan seluruh data </span><span class="font0" style="font-style:italic;">training</span><span class="font0"> sebanyak nilai k</span></p>
<ul style="list-style:none;"><li>
<p><span class="font0">2.5 &nbsp;&nbsp;&nbsp;Tahap Evaluasi</span></p></li></ul>
<p><span class="font0">Pada tahap evaluasi sistem, akan dicari akurasi dari penggunaan ekstraksi fitur MFCC dan metode KNN pada penelitian emosi manusia melalui ucapan.</span></p>
<p><span class="font0">Untuk perhitungan akurasi dilakukan menggunakan persamaan:</span></p>
<div>
<h2><a name="bookmark18"></a><span class="font4" style="font-style:italic;"><a name="bookmark19"></a>Akurasi</span><span class="font4"> =</span></h2>
</div><br clear="all">
<div>
<p><span class="font0">(1)</span></p>
</div><br clear="all">
<div>
<p><span class="font2" style="font-style:italic;text-decoration:underline;">(TP+TN) </span><span class="font2" style="font-style:italic;">(TP+TN+FP+FN)</span></p>
</div><br clear="all">
<p><span class="font0">Keterangan :</span></p>
<p><span class="font3" style="font-style:italic;">TP</span><span class="font0"> = true positive </span><span class="font3" style="font-style:italic;">TN</span><span class="font0"> = true negative </span><span class="font3" style="font-style:italic;">FP</span><span class="font0"> = false positive </span><span class="font3" style="font-style:italic;">FN</span><span class="font0"> = false negative</span></p>
<ul style="list-style:none;"><li>
<h3><a name="bookmark20"></a><span class="font0" style="font-weight:bold;"><a name="bookmark21"></a>3. &nbsp;&nbsp;&nbsp;Hasil dan Pembahasan</span></h3></li></ul>
<p><span class="font0">Tabel 1. Hasil Akurasi</span></p>
<table border="1">
<tr><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;font-style:italic;">k</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">Akurasi</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font0">3</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">50%</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font0">5</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">46,66%</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font0">7</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">45%</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font0">9</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">49,16%</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font0">11</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">49,16%</span></p></td></tr>
</table>
<p><span class="font0">Tabel diatas merupakan jumlah k yang diuji, yaitu ditampilkan 6 model terbaik, akhirnya didapatkan bahwa dengan k yaitu 3 didapatkan nilai akurasi paling besar dari semua k yang diujikan yaitu 50%.</span></p>
<ul style="list-style:none;"><li>
<h3><a name="bookmark22"></a><span class="font0" style="font-weight:bold;"><a name="bookmark23"></a>4. &nbsp;&nbsp;&nbsp;Kesimpulan</span></h3></li></ul>
<p><span class="font0">Berdasarkan penelitian yang telah ditulis dari pemodelan emosi melalui ucapan yang dibuat, dengan menggunakan ekstraksi fitur </span><span class="font0" style="font-style:italic;">Mel-Frequency Cepstrum Coefficient (</span><span class="font0">MFCC) yang dimana pada ekstraksi fitur </span><span class="font0" style="font-style:italic;">Mel-Frequency Cepstrum Coefficient</span><span class="font0"> (MFCC) data numeric yang diambil yaitu berjumlah 20 set data dan dibuatkan grafik, dimasukan data baru yang tersebar acak dan data tersebut akan dikelompokkan dengan menggunakan metode </span><span class="font0" style="font-style:italic;">K-Nearest Neighbor</span><span class="font0"> (K-NN) dengan</span></p>
<p><span class="font0">nilai k yaitu 3 sampai 101, yang dimana nilai k haruslah ganjil, setelah iterasi sebanyak 48, didapatkan bahwa dengan nilai k yaitu 3 dan 13 didapatkan akurasi terbaik yaitu 50%. Jadi dapat disimpulkan bahwa Pemodelan Emosi Manusia Melalui Ucapan Menggunakan Metode K-Nearest Neighbor (K-NN), kurang baik sehingga penelitian ini akan dilanjutkan di Tugas Akhir dengan metode yang berbeda untuk mendapatkan akurasi yang lebih tinggi.</span></p>
<h3><a name="bookmark24"></a><span class="font0" style="font-weight:bold;"><a name="bookmark25"></a>Referensi</span></h3>
<ul style="list-style:none;"><li>
<p><span class="font0">[1] &nbsp;&nbsp;&nbsp;Fajar Septria, Jangkung Raharjo, Nur Ibrahim, S.T.,M.T, “ KLASIFIKASI EMOSI</span></p></li></ul>
<p><span class="font0">BERDASARKAN SINYAL SUARA MANUSIA MENGGUNAKAN METODE K-NEAREST NEIGHBOR (K-NN) ” e-Proceeding of Engineering, Vol.6, No.2. Page 4130, 2019.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font0">[2] &nbsp;&nbsp;&nbsp;Siti Helmiyah, Imam Riadi, Rusydi Umar, Abdullah Hanif, Anton Yudhana, Abdul Fadlil, “IDENTIFIKASI EMOSI MANUSIA BERDASARKAN UCAPAN MENGGUNAKAN METODE EKSTRAKSI CIRI LPC DAN METODE EUCLIDEAN DISTANCE ” Jurnal Teknologi Informasi dan Ilmu Komputer (JTIIK), Vol. 7, No. 6. Page 1177-1186, 2020.</span></p></li>
<li>
<p><span class="font0">[3] &nbsp;&nbsp;&nbsp;Yulistia Aini, Tri Budi Santoso, Titon Dutono. “ Pemodelan CNN Untuk Deteksi Emosi Berbasis Speech Bahasa Indonesia “ Jurnal Politeknik Caltex Riau, Vol.7, No.1. Page 143 – 152, 2021.</span></p></li>
<li>
<p><span class="font0">[4] &nbsp;&nbsp;&nbsp;GUMELAR, A. B. et al. </span><span class="font0" style="font-style:italic;">“Human Voice Emotion Identification Using Prosodic and Spectral Feature Extraction Based on Deep Neural Networks”, International Conference on Serious Games and Applications for Health (SeGAH). IEEE, Page 1– 8. 2019</span></p></li>
<li>
<p><span class="font0">[5] &nbsp;&nbsp;&nbsp;Anjani Reddy J, Dr. Shiva G. “</span><span class="font0" style="font-style:italic;">Emotion Recognition from Speech Using MLP AND KNN</span><span class="font0"> ”, RESEARCH ARTICLE. Vol. 11, (Series-II) Page 34-38. 2021</span></p></li>
<li>
<p><span class="font0">[6] &nbsp;&nbsp;&nbsp;Steven R. Livingstone, Frank A. Russo, “The Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS): A dynamic, multimodal set of facial and vocal expressions in North American English”, PLoS ONE 13(5): e0196391. 2018.</span></p></li></ul>
<p><span class="font3">140</span></p>