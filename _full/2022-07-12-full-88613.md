---
layout: full_article
title: "Pengaruh Kombinasi dan Urutan Pre-Processing pada Tweets Bahasa Indonesia"
author: "Sheila Shevira, I Made Agus Dwi Suarjaya, Putu Wira Buana"
categories: jitter
canonical_url: https://jurnal.harianregional.com/jitter/full-88613 
citation_abstract_html_url: "https://jurnal.harianregional.com/jitter/id-88613"
citation_pdf_url: "https://jurnal.harianregional.com/jitter/full-88613"  
comments: true
---

<p><span class="font0">JITTER- Jurnal Ilmiah Teknologi dan Komputer Vol. 3, No. 2 Agustus 2022</span></p><a name="caption1"></a>
<h1><a name="bookmark0"></a><span class="font2" style="font-weight:bold;"><a name="bookmark1"></a>Pengaruh Kombinasi dan Urutan </span><span class="font2" style="font-weight:bold;font-style:italic;">Pre-Processing</span><span class="font2" style="font-weight:bold;"> pada </span><span class="font2" style="font-weight:bold;font-style:italic;">Tweets</span><span class="font2" style="font-weight:bold;"> Bahasa Indonesia</span></h1>
<h2><a name="bookmark2"></a><span class="font0" style="font-weight:bold;"><a name="bookmark3"></a>Sheila Shevira<sup>a1</sup>, I Made Agus Dwi Suarjaya<sup>a2</sup>, Putu Wira Buana <sup>b3</sup></span></h2>
<ul style="list-style:none;"><li>
<p><span class="font0"><sup>1,2,3</sup> Program Studi Teknologi Informasi, Fakultas Teknik, Universitas Udayana e-mail:</span><a href="mailto:1shevira@student.unud.ac.id"><span class="font0"> <sup>1</sup>shevira@student.unud.ac.id</span></a><span class="font0">,</span><a href="mailto:2Author2@email.com"><span class="font0"> <sup>2</sup>agussuarjaya@it.unud.ac.id</span></a><span class="font0">, </span><a href="mailto:3wbhuana@it.unud.ac.id"><span class="font0"><sup>3</sup>wbhuana@it.unud.ac.id</span></a></p></li></ul>
<p><span class="font0" style="font-weight:bold;font-style:italic;">Abstrak</span></p>
<p><span class="font0" style="font-style:italic;">Twitter merupakan jaringan microblog online yang dijadikan gaya hidup baru di kalangan masyarakat sebagai wadah pengganti untuk mencari dan menyebarkan informasi, sebagai tempat mencurahkan perasaan, ataupun menjalankan bisnis, dengan cara menuliskan tweet. Permasalahannya adalah tweet yang dituliskan mayoritas oleh remaja berumur 18-24 tahun, sehingga kata-kata yang dituliskan masih banyak mengandung karakter pengganggu, ejaan, kata gaul, atau kata yang bersifat non-baku. Data yang tidak bersih dan akurat akan berdampak buruk bagi hasil analisis. Pre-processing data dalam hal ini berperan penting untuk memperbaiki data agar menjadi lebih bersih dan akurat sebelum diproses. Penelitian ini fokus membahas mengenai beberapa skenario kombinasi pre-processing, serta dengan mengubah urutan proses cleaning, normalisasi, stemming, dan stop-word, untuk mendapatkan akurasi paling baik dan meningkatkan performa dalam klasifikasi. Hasil testing pada tweet menunjukkan akurasi tertinggi ada pada data yang melewati tahapan penuh pre-processing data dengan urutan kombinasi pre-processing adalah menaruh proses normalisasi sebelum melakukan proses stemming, yaitu sebesar 89.2%.</span></p>
<p><span class="font0" style="font-weight:bold;font-style:italic;">Kata kunci: </span><span class="font0" style="font-style:italic;">Normalisasi, Pre-Processing Data, Stemming, Stop-word, Twitter</span></p>
<p><span class="font0" style="font-weight:bold;font-style:italic;">Abstract</span></p>
<p><span class="font0" style="font-style:italic;">Twitter is an online microblog network that is used as a new lifestyle among the community as a substitute for finding and sharing information, as a place to express feelings, or doing a business, by writing tweets. The problem is that the majority of tweets are written by teenagers aged 18-24 years, so the words written still contain a lot of distracting characters, spelling, slang, or non-standard words. Data that is not clean and accurate will have a bad impact on the results of the analysis. Pre-processing data in this case plays an important role in improving the data to be cleaner and more accurate before being analyzed. This study focuses on discussing several scenarios of pre-processing combinations, and changing the order of the cleaning, normalizing, stemming, and stop-word processes, to get the best accuracy and improve performance in classification. The results of testing on tweets show that the highest accuracy is in data that has passed the full stages of pre-processing data with the preprocessing combination order placing the normalization process before carrying out the stemming process, which is 89.2%.</span></p>
<p><span class="font0" style="font-weight:bold;font-style:italic;">Keywords: </span><span class="font0" style="font-style:italic;">Normalization, Pre-Processing Data, Stemming, Stop-word, Twitter</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark4"></a><span class="font0" style="font-weight:bold;"><a name="bookmark5"></a>1. &nbsp;&nbsp;&nbsp;Pendahuluan</span></h2></li></ul>
<p><span class="font0">Twitter merupakan jaringan </span><span class="font0" style="font-style:italic;">microblog online</span><span class="font0"> yang sering dimanfaatkan masyarakat untuk menuliskan segala sesuatu yang berkaitan dengan pemikiran, suasana hati, aktivitas, komunikasi, kehidupan sosial, ataupun berbagi informasi berita, karena penggunanya dapat menuliskan pesan secara singkat, padat, dan jelas dibawah 280 karakter [1]. Banyak masyarakat saat ini menuliskan </span><span class="font0" style="font-style:italic;">tweet</span><span class="font0"> di Twitter untuk menunjukkan perasaannya secara </span><span class="font0" style="font-style:italic;">realtime</span><span class="font0">, baik berupa </span><span class="font0" style="font-style:italic;">tweet</span><span class="font0"> yang bersifat positif maupun negatif. </span><span class="font0" style="font-style:italic;">Tweet</span><span class="font0"> yang tersebar di internet ini dapat digunakan sebagai data dalam melakukan analisis terhadap berbagai hal.</span></p>
<p><span class="font0">Data merupakan aspek penting bagi setiap individu, organisasi, maupun perusahaan, karena berperan dalam banyak hal, seperti pengambilan keputusan, sebagai dasar</span></p>
<p><span class="font0">perencanaan, ataupun sebagai bahan evaluasi [2]. Kualitas data dalam </span><span class="font0" style="font-style:italic;">data mining </span><span class="font0">berpengaruh signifikan pada tingginya kinerja model dan juga hasil analisis. Kualitas data yang buruk dapat berdampak negatif bagi produktivitas individu/organisasi/perusahaan sehingga capaian hasil yang diinginkan menjadi tidak maksimal.</span></p>
<p><span class="font0" style="font-style:italic;">Tweet</span><span class="font0"> yang dituliskan setiap orang pada media sosial Twitter, dapat dikatakan sebagai salah satu data yang bersifat kurang baik, karena mayoritas pengguna Twitter adalah di kalangan masyarakat remaja, yakni berumur 18-24 tahun [3]. Hal ini membuat </span><span class="font0" style="font-style:italic;">tweet</span><span class="font0"> yang tersebar di dunia maya lebih banyak menggunakan kata yang memiliki ejaan/singkatan ataupun kata-kata gaul. Tahap </span><span class="font0" style="font-style:italic;">pre-processing</span><span class="font0"> dalam hal ini penting dilakukan untuk membersihkan dan memperbaiki struktur pada </span><span class="font0" style="font-style:italic;">tweet</span><span class="font0"> agar data menjadi lebih seragam dan akurat ketika dianalisis.</span></p>
<p><span class="font0" style="font-style:italic;">Pre-processing</span><span class="font0"> adalah tahap untuk melakukan transformasi data agar sesuai dengan format seharusnya dan dapat diproses. Tahapan </span><span class="font0" style="font-style:italic;">pre-processing</span><span class="font0"> ada beragam tergantung pada kebutuhan, namun secara umum diantaranya, yaitu </span><span class="font0" style="font-style:italic;">cleaning tweet</span><span class="font0">, </span><span class="font0" style="font-style:italic;">lowering case</span><span class="font0">, normalisasi, </span><span class="font0" style="font-style:italic;">stop-word</span><span class="font0">, </span><span class="font0" style="font-style:italic;">stemming</span><span class="font0">, dan </span><span class="font0" style="font-style:italic;">tokenizing</span><span class="font0">. </span><span class="font0" style="font-style:italic;">Cleaning tweet</span><span class="font0"> dilakukan agar karakter yang bersifat </span><span class="font0" style="font-style:italic;">noise</span><span class="font0"> dapat dihilangkan [4]. </span><span class="font0" style="font-style:italic;">Lowering case</span><span class="font0"> merupakan proses untuk mengubah bentuk data menjadi huruf kecil seluruhnya [5]. Normalisasi </span><span class="font0" style="font-style:italic;">tweet</span><span class="font0"> merupakan proses untuk mengubah </span><span class="font0" style="font-style:italic;">tweet </span><span class="font0">yang mengandung ejaan dan kata </span><span class="font0" style="font-style:italic;">slang</span><span class="font0"> untuk mempermudah proses analisis [6]. Kata </span><span class="font0" style="font-style:italic;">slang </span><span class="font0">yang dimaksudkan adalah kata yang sulit dimengerti, kata yang memiliki makna beda dari makna aslinya, kata yang bersifat non-baku, ataupun kata gaul yang digunakan remaja modern [7]. Proses normalisasi bertujuan agar pembaca dapat memahami arti kata yang dimaksudkan secara jelas, begitu juga dengan sistem ketika melakukan analisis klasifikasi. </span><span class="font0" style="font-style:italic;">Stemming </span><span class="font0">merupakan proses dalam mentransformasi kata menjadi kata dasar dengan menghilangkan imbuhannya, sehingga bisa meminimalkan dimensi kata yang berbeda bentuk namun dengan makna yang sama [8]. </span><span class="font0" style="font-style:italic;">Stop-word</span><span class="font0"> dilakukan untuk meminimalkan jumlah kata dengan nilai informasi rendah sehingga proses klasifikasi lebih cepat dan akurat [9]. </span><span class="font0" style="font-style:italic;">Tokenizing</span><span class="font0"> adalah proses memecah kalimat per-kata/token [10].</span></p>
<p><span class="font0">Penelitian terdahulu yang sejenis oleh Danny Sebastian dan Kristian Adi Nugraha tahun 2019 adalah melakukan pengembangan dataset kata-kata singkatan bahasa Indonesia, yang kemudian dapat digunakan untuk menormalkan kata-kata menggunakan </span><span class="font0" style="font-style:italic;">Crowdsourcing</span><span class="font0">. Akurasi yang didapatkan dari penelitian ini sekitar 90,85%.[11]</span></p>
<p><span class="font0">Dwi Wahyudi, dkk melakukan penelitian di tahun 2017 untuk membandingkan 2 algoritma </span><span class="font0" style="font-style:italic;">stemming</span><span class="font0"> pada </span><span class="font0" style="font-style:italic;">task</span><span class="font0"> bahasa Indonesia. Fokus penelitian yaitu ada pada proses </span><span class="font0" style="font-style:italic;">stemming</span><span class="font0"> yang membandingkan algoritma Nazief &amp;&nbsp;Adriani dengan algoritma Porter untuk menentukan algoritma yang lebih akurat. Hasil menunjukkan bahwa algoritma Nazief &amp;&nbsp;Adriani lebih unggul daripada algoritma Porter, yaitu dengan akurasi 95,26% dan 79,13%. [12]</span></p>
<p><span class="font0">Penelitian terkait </span><span class="font0" style="font-style:italic;">pre-processing</span><span class="font0"> telah dilakukan oleh Siti Khomsah &amp;&nbsp;Agus Sasmito Aribowo tahun 2020. Berbagai macam model </span><span class="font0" style="font-style:italic;">pre-processing</span><span class="font0"> dilakukan pada data komentar YouTube, lalu dibandingkan untuk mendapatkan akurasi terbaiknya. Hasil menunjukkan bahwa </span><span class="font0" style="font-style:italic;">pre-processing</span><span class="font0"> dengan melakukan </span><span class="font0" style="font-style:italic;">cleaning</span><span class="font0"> data, </span><span class="font0" style="font-style:italic;">stop-words</span><span class="font0">, dan konversi kata gaul berdasarkan kamus bahasa Indonesia menaikkan akurasi sebanayk 3,5% pada kata </span><span class="font0" style="font-style:italic;">unigram </span><span class="font0">[13].</span></p>
<p><span class="font0">Penelitian lain telah dilakukan juga oleh Riri Riyaddulloh dan Ade Romadhony tahun 2021. Penelitian ini melakukan normalisasi pada </span><span class="font0" style="font-style:italic;">tweet</span><span class="font0"> yang dituliskan akun resmi beberapa </span><span class="font0" style="font-style:italic;">merk gadget</span><span class="font0"> menggunakan model </span><span class="font0" style="font-style:italic;">word2vec</span><span class="font0">. Hasil pengujian yang didapatkan, yaitu adanya peningkatan akurasi untuk </span><span class="font0" style="font-style:italic;">tweet</span><span class="font0"> yang mengalami normalisasi dibandingkan dengan </span><span class="font0" style="font-style:italic;">tweet</span><span class="font0"> yang tidak mengalami normalisasi, yaitu 91% berbanding 88%. [7]</span></p>
<p><span class="font0">Penelitian kali ini memfokuskan pada </span><span class="font0" style="font-style:italic;">pre-processing</span><span class="font0"> data dengan mencoba beberapa skenario urutan </span><span class="font0" style="font-style:italic;">pre-processing</span><span class="font0"> pada proses normalisasi, </span><span class="font0" style="font-style:italic;">stop-word</span><span class="font0">, dan </span><span class="font0" style="font-style:italic;">stemming</span><span class="font0">. Dilakukannya penelitian ini bertujuan agar dapat melihat pengaruh yang dihasilkan dari urutan </span><span class="font0" style="font-style:italic;">pre-processing</span><span class="font0"> data dan juga kombinasi proses di dalamnya sebelum diekstraksi fitur dan melakukan analisis.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark6"></a><span class="font0" style="font-weight:bold;"><a name="bookmark7"></a>2. &nbsp;&nbsp;&nbsp;Metode Penelitian</span></h2></li></ul>
<p><span class="font0">Analisis pengaruh kombinasi dan urutan tahap </span><span class="font0" style="font-style:italic;">pre-processing</span><span class="font0"> pada </span><span class="font0" style="font-style:italic;">tweet</span><span class="font0"> bahasa Indonesia memiliki metode penelitian yang dipaparkan ke dalam alur sebagai berikut.</span></p><img src="https://jurnal.harianregional.com/media/88613-1.jpg" alt="" style="width:79pt;height:261pt;">
<p><span class="font0">Gambar 1. Alur penelitian</span></p>
<p><span class="font0">Alur yang digunakan dari penelitian ini terbagi dalam beberapa tahapan. Pengumpulan data dilakukan pada Twitter menggunakan Twitter API, dan diberi label secara manual. Tahap </span><span class="font0" style="font-style:italic;">pre-processing</span><span class="font0"> data dilakukan beberapa kali, yaitu dengan kombinasi dan urutan proses </span><span class="font0" style="font-style:italic;">cleaning</span><span class="font0">, normalisasi, </span><span class="font0" style="font-style:italic;">stop-word</span><span class="font0">, dan </span><span class="font0" style="font-style:italic;">stemming</span><span class="font0"> yang berbeda-beda. </span><span class="font0" style="font-style:italic;">Dataset</span><span class="font0"> yang sudah di</span><span class="font0" style="font-style:italic;">cleansing</span><span class="font0"> diekstrak dengan menggunakan TF-IDF untuk mentransformasikan tulisan ke bentuk angka, sebelum diuji performa modelnya menggunakan Naïve Bayes, sehingga didapatkan hasil akurasi terbaik.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark8"></a><span class="font0" style="font-weight:bold;"><a name="bookmark9"></a>3. &nbsp;&nbsp;&nbsp;Kajian Pustaka</span></h2></li></ul>
<p><span class="font0">Penelitian ini dilakukan berdasarkan beberapa teori penunjang yang dijabarkan dalam kajian pustaka sebagai berikut.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark10"></a><span class="font0" style="font-weight:bold;"><a name="bookmark11"></a>3.1. &nbsp;&nbsp;&nbsp;Twitter dan Twitter API</span></h2></li></ul>
<p><span class="font0">Twitter adalah jaringan microblog </span><span class="font0" style="font-style:italic;">online</span><span class="font0"> yang mengizinkan penggunanya untuk menulis cuitan atau pesan singkat di bawah 280 karakter [1]. Manfaat Twitter sangat beragam mulai dari bertukar indormasi, melatih kreativitas menulis, hingga menjalankan bisnis [14]. Twitter memiliki API tersendiri yang dibangun untuk mempermudah </span><span class="font0" style="font-style:italic;">developer</span><span class="font0"> dalam mengambil data untuk diolah, dengan cara </span><span class="font0" style="font-style:italic;">login</span><span class="font0"> melalui akun </span><span class="font0" style="font-style:italic;">developer</span><span class="font0"> hingga mendapatkan akses API berupa </span><span class="font3">api_key, api_secret_key</span><span class="font0">, </span><span class="font3">access_token</span><span class="font0">, dan </span><span class="font3">access_token_secret</span><span class="font0">.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark12"></a><span class="font0" style="font-weight:bold;"><a name="bookmark13"></a>3.2. &nbsp;&nbsp;&nbsp;Python</span></h2></li></ul>
<p><span class="font0">Python merupakan bahasa pemrograman yang memiliki banyak </span><span class="font0" style="font-style:italic;">library</span><span class="font0"> dan digunakan oleh </span><span class="font0" style="font-style:italic;">data scientists</span><span class="font0"> dan </span><span class="font0" style="font-style:italic;">machine learning engineers</span><span class="font0"> untuk mengembangkan model serta aplikasi yang berhubungan dengan </span><span class="font0" style="font-style:italic;">data science</span><span class="font0">. </span><span class="font0" style="font-style:italic;">Library</span><span class="font0"> Python yang digunakan dijabarkan sebagai berikut.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font0">a. &nbsp;&nbsp;&nbsp;Snscrape, untuk mengumpulkan data Twitter dengan Twitter API</span></p></li>
<li>
<p><span class="font0">b. &nbsp;&nbsp;&nbsp;Regex, untuk proses </span><span class="font0" style="font-style:italic;">cleaning</span><span class="font0">, dan normalisasi.</span></p></li>
<li>
<p><span class="font0">c. &nbsp;&nbsp;&nbsp;NLTK, untuk proses </span><span class="font0" style="font-style:italic;">stop-word</span><span class="font0">.</span></p></li>
<li>
<p><span class="font0">d. &nbsp;&nbsp;&nbsp;Sastrawi, untuk membantu proses </span><span class="font0" style="font-style:italic;">stemming</span></p></li>
<li>
<p><span class="font0">e. &nbsp;&nbsp;&nbsp;Sklearn, untuk klasifikasi</span></p></li></ul>
<ul style="list-style:none;"><li>
<h2><a name="bookmark14"></a><span class="font0" style="font-weight:bold;"><a name="bookmark15"></a>3.3. &nbsp;&nbsp;&nbsp;Text Pre-Processing</span></h2></li></ul>
<p><span class="font0">Text </span><span class="font0" style="font-style:italic;">pre-processing</span><span class="font0"> terdiri dari beberapa proses di dalamnya yang terbagi sebagai berikut.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font0">a.</span><span class="font0" style="font-style:italic;"> &nbsp;&nbsp;&nbsp;Cleaning Text</span><span class="font0">, untuk membersihkan </span><span class="font0" style="font-style:italic;">tweet</span><span class="font0"> dari simbol, angka, URL, </span><span class="font0" style="font-style:italic;">hashtag</span><span class="font0">. Contohnya menghilangkan tanda koma (,) pada kalimat “Pengen menyerah, capek dgn smuanya” sehingga menjadi “Pengen menyerah capek dgn smuanya”.</span></p></li>
<li>
<p><span class="font0">b.</span><span class="font0" style="font-style:italic;"> &nbsp;&nbsp;&nbsp;Lowering Case</span><span class="font0">, untuk menyeragamkan ke dalam huruf kecil. Contohnya kata “Pengen” menjadi “pengen”.</span></p></li>
<li>
<p><span class="font0">c. &nbsp;&nbsp;&nbsp;Normalisasi, untuk mengubah kata non-baku menjadi baku. Contohnya kata “pengen” menjadi “ingin”, kata “dgn” menjadi “dengan”, kata “smuanya” menjadi “semuanya”.</span></p></li>
<li>
<p><span class="font0">d.</span><span class="font0" style="font-style:italic;"> &nbsp;&nbsp;&nbsp;Stop-word removal</span><span class="font0">, untuk menghilangkan kata yang nilai informasinya rendah. Contohnya kata “ada”, “di”, “dan”, “dengan”.</span></p></li>
<li>
<p><span class="font0">e.</span><span class="font0" style="font-style:italic;"> &nbsp;&nbsp;&nbsp;Stemming</span><span class="font0">, untuk mengubah kata menjadi bentuk dasarnya. Contohnya kata “semuanya” menjadi “semua”, kata “perasaan” menjadi “rasa”.</span></p></li>
<li>
<p><span class="font0">f.</span><span class="font0" style="font-style:italic;"> &nbsp;&nbsp;&nbsp;Tokenization</span><span class="font0">, untuk memecah kalimat per-</span><span class="font0" style="font-style:italic;">token</span><span class="font0"> atau kata.</span></p></li></ul>
<p><span class="font0">Penelitian ini menggunakan 20 skenario kombinasi dan urutan </span><span class="font0" style="font-style:italic;">pre-processing</span><span class="font0">, yaitu: melakukan </span><span class="font0" style="font-style:italic;">cleaning text</span><span class="font0"> saja, normalisasi saja, </span><span class="font0" style="font-style:italic;">stopword</span><span class="font0"> saja, </span><span class="font0" style="font-style:italic;">stemming</span><span class="font0"> saja, </span><span class="font0" style="font-style:italic;">cleaning text</span><span class="font0"> dan normalisasi, </span><span class="font0" style="font-style:italic;">cleaning text</span><span class="font0"> dan </span><span class="font0" style="font-style:italic;">stopword</span><span class="font0">, </span><span class="font0" style="font-style:italic;">cleaning text</span><span class="font0"> dan </span><span class="font0" style="font-style:italic;">stemming</span><span class="font0">, normalisasi dan </span><span class="font0" style="font-style:italic;">stopword</span><span class="font0">,</span></p>
<p><span class="font0">normalisasi dan </span><span class="font0" style="font-style:italic;">stemming</span><span class="font0">, </span><span class="font0" style="font-style:italic;">stopword</span><span class="font0"> dan </span><span class="font0" style="font-style:italic;">stemming</span><span class="font0">, </span><span class="font0" style="font-style:italic;">cleaning text</span><span class="font0">-normalisasi-</span><span class="font0" style="font-style:italic;">stopword</span><span class="font0">,</span></p>
<p><span class="font0" style="font-style:italic;">cleaning text</span><span class="font0">-normalisasi-</span><span class="font0" style="font-style:italic;">stemming</span><span class="font0">, normalisasi-</span><span class="font0" style="font-style:italic;">stopword</span><span class="font0">-</span><span class="font0" style="font-style:italic;">stemming</span><span class="font0">, </span><span class="font0" style="font-style:italic;">full pre-processing</span><span class="font0"> 1</span></p>
<p><span class="font0">dengan urutan (</span><span class="font0" style="font-style:italic;">cleaning text</span><span class="font0">-</span><span class="font0" style="font-style:italic;">lowercase</span><span class="font0">-normalisasi-</span><span class="font0" style="font-style:italic;">stopword-stemming-tokenizing</span><span class="font0">), </span><span class="font0" style="font-style:italic;">full processing</span><span class="font0"> 2 (</span><span class="font0" style="font-style:italic;">cleaning text</span><span class="font0">-</span><span class="font0" style="font-style:italic;">lowercase</span><span class="font0">-normalisasi-</span><span class="font0" style="font-style:italic;">stemming</span><span class="font0">-</span><span class="font0" style="font-style:italic;">stopword</span><span class="font0">-</span><span class="font0" style="font-style:italic;">tokenizing</span><span class="font0">), </span><span class="font0" style="font-style:italic;">full processing</span><span class="font0"> 3 (</span><span class="font0" style="font-style:italic;">cleaning text</span><span class="font0">-</span><span class="font0" style="font-style:italic;">lowercase-stopword-stemming</span><span class="font0">-normalisasi-</span><span class="font0" style="font-style:italic;">tokenizing</span><span class="font0">), </span><span class="font0" style="font-style:italic;">full processing</span><span class="font0"> 4 (</span><span class="font0" style="font-style:italic;">cleaning text-lowercase</span><span class="font0">-</span><span class="font0" style="font-style:italic;">stopword</span><span class="font0">-normalisasi-</span><span class="font0" style="font-style:italic;">stemming</span><span class="font0">-</span><span class="font0" style="font-style:italic;">tokenizing</span><span class="font0">), </span><span class="font0" style="font-style:italic;">full processing</span><span class="font0"> 5 (</span><span class="font0" style="font-style:italic;">cleaning text</span><span class="font0">-</span><span class="font0" style="font-style:italic;">lowercase</span><span class="font0">-</span><span class="font0" style="font-style:italic;">stemming</span><span class="font0">-normalisasi-</span><span class="font0" style="font-style:italic;">stopword</span><span class="font0">-</span><span class="font0" style="font-style:italic;">tokenizing</span><span class="font0">), </span><span class="font0" style="font-style:italic;">full processing</span><span class="font0"> 6 (</span><span class="font0" style="font-style:italic;">cleaning text</span><span class="font0">-</span><span class="font0" style="font-style:italic;">lowercase</span><span class="font0">-</span><span class="font0" style="font-style:italic;">stemming-stopword-</span><span class="font0">normalisasi-</span><span class="font0" style="font-style:italic;">tokenizing</span><span class="font0">).</span></p>
<div>
<p><span class="font0" style="font-style:italic;">pre-pre-pre-pre-pre-</span></p>
</div><br clear="all">
<ul style="list-style:none;"><li>
<h2><a name="bookmark16"></a><span class="font0" style="font-weight:bold;"><a name="bookmark17"></a>3.4. &nbsp;&nbsp;&nbsp;TF-IDF</span></h2></li></ul>
<p><span class="font0" style="font-style:italic;">Dataset</span><span class="font0"> yang masih berbentuk tulisan, sebelum melewati pemrosesan harus diekstrak terlebih dahulu dengan TF-IDF. TF-IDF digunakan sebagai salah satu bagian </span><span class="font0" style="font-style:italic;">information retrieval system</span><span class="font0"> dalam mengubah data non-terstruktur menjadi bentuk yang dapat memenuhi kebutuhan informasi. Tujuannya agar tulisan dapat direpresentasikan ke dalam bentuk angka sebelum diolah dengan Naïve Bayes. Ekstraksi tulisan dapat dikalkulasikan menggunakan rumus berikut.</span></p>
<div>
<p><span class="font5">w<sub>1</sub>√ = </span><span class="font4" style="font-weight:bold;font-style:italic;">tfij X</span><span class="font5"> log </span><span class="font4" style="font-weight:bold;font-style:italic;">(P∕df<sub>j</sub>}</span></p>
</div><br clear="all">
<div>
<p><span class="font0">(1)</span></p>
</div><br clear="all">
<p><span class="font0">Menentukan bobot setiap kata </span><span class="font0" style="font-style:italic;">(w)</span><span class="font0"> dilakukan dengan mengalikan banyaknya kata i dalam suatu dokumen j (</span><span class="font0" style="font-style:italic;">tf</span><span class="font0">) dan </span><span class="font0" style="font-style:italic;">idf</span><span class="font0">, yang mana (</span><span class="font0" style="font-style:italic;">idf</span><span class="font0">) didapat dari logaritma pembagian jumlah seluruh dokumen (</span><span class="font0" style="font-style:italic;">D</span><span class="font0">) dengan banyaknya dokumen yang mengandung kata j (</span><span class="font0" style="font-style:italic;">df</span><span class="font0">).</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark18"></a><span class="font0" style="font-weight:bold;"><a name="bookmark19"></a>3.5. &nbsp;&nbsp;&nbsp;Evaluasi Performa</span></h2></li></ul>
<p><span class="font0">Pengukuran </span><span class="font0" style="font-style:italic;">performance</span><span class="font0"> kinerja dari beberapa kombinasi dan urutan </span><span class="font0" style="font-style:italic;">pre-processing </span><span class="font0">dilakukan dengan menghitung keakuratan dengan rumus berikut.</span></p>
<p><span class="font0" style="font-weight:bold;font-style:italic;">Total Benar</span></p>
<div>
<p><span class="font0">(2)</span></p>
</div><br clear="all">
<p><span class="font0" style="font-weight:bold;font-style:italic;">Akurasi =---—-----;---;--x</span><span class="font5" style="font-weight:bold;"> 100%</span></p>
<p><span class="font0" style="font-weight:bold;font-style:italic;">Jumlah Keseluruhan</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark20"></a><span class="font0" style="font-weight:bold;"><a name="bookmark21"></a>4. &nbsp;&nbsp;&nbsp;Hasil dan Pembahasan</span></h2></li></ul>
<p><span class="font0">Hasil yang didapat dari penelitian ini akan dibahas dengan pemaparan berdasarkan gambaran umum sistem yang ada.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark22"></a><span class="font0" style="font-weight:bold;"><a name="bookmark23"></a>4.1. &nbsp;&nbsp;&nbsp;Dataset</span></h2></li></ul>
<p><span class="font0" style="font-style:italic;">Dataset</span><span class="font0"> didapat dengan mengumpulkan data Twitter menggunakan </span><span class="font0" style="font-style:italic;">library</span><span class="font0"> Snscrape dan disimpan ke Mongo </span><span class="font0" style="font-style:italic;">database</span><span class="font0">. </span><span class="font0" style="font-style:italic;">Keyword</span><span class="font0"> yang digunakan berkaitan dengan kata-kata yang mengindikasikan gangguan mental, yaitu &quot;capek&quot;, &quot;stres&quot;, &quot;depresi&quot;, &quot;mau mati&quot;, dan &quot;tidak ada</span></p>
<p><span class="font0">yang peduli&quot;. Data </span><span class="font0" style="font-style:italic;">tweet</span><span class="font0"> yang sudah dikumpulkan selanjutnya diberi label secara manual sesuai kebutuhan penelitian. Beberapa </span><span class="font0" style="font-style:italic;">tweet</span><span class="font0"> yang diambil dari Twitter ada pada Tabel 1.</span></p>
<p><span class="font0">Tabel 1. </span><span class="font0" style="font-style:italic;">Dataset</span><span class="font0"> Twitter</span></p>
<table border="1">
<tr><td style="vertical-align:bottom;">
<p><span class="font0" style="font-weight:bold;">Full Tweet</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0" style="font-weight:bold;">Label</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0">Maaf mngecewakan km, udh cape bgt..</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">0</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0">@dyonisuss2_ Yallah capek ketawa</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">1</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0">Rasanya mau mati</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">0</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0">hadiah paling susah menurutku itu doa yg tulus jadi bersyukur sekali bisa dapat teman2 yang tidak ada hentinya doakan yg baik2. terima kasih jg untuk mama papa yg ajar caca untuk peduli sekitar dengan hal paling simple : selalu doakan sesama manusia sebaik mungkin.</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">1</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0">@bertanyarl Jujur aku kalau lagi capek emang kepikiran itu cuma kalau entar aku udah mati gimana perasaan orang tua aku? :) Mereka pasti kecewa banget, anak yang mereka besarkan sepenuh hati bukannya berjuang untuk hidup malah lebih milih nyerah. Kena dosa juga karena belum waktunya dipanggil</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">0</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0">Cinta sejati akan dibawa sampai mati.</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">1</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0">SUMPAH GUE SENENG BANGET GILA HAHAHAA</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">1</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0">Ini hari paling buruk bikin hilang minat dan lelah nangis :)))</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">0</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0">gue jadi manusia bodoh bgt ! jadi paling bego.tolol.banget. gue mending gak lahir kykny</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">1</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0">Guee bersyukur bgt ada Bangtan yang jadi sumber kebahagiaan, penerang, dan semangat untuk gue...</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">0</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0">Ini jg ngikut jd cowok mamba, &nbsp;&nbsp;&nbsp;&nbsp;</span><span class="font1">gila ga kuat gua knp ganteng</span></p>
<p><span class="font1">banget sih</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">1</span></p></td></tr>
</table>
<p><span class="font0">Data </span><span class="font0" style="font-style:italic;">tweet</span><span class="font0"> yang dikumpulkan berjumlah 2.400 data dan dilabelkan secara manual. </span><span class="font0" style="font-style:italic;">Dataset</span><span class="font0"> sebanyak 2.400 terbagi atas 1.151 (48%) diberi label “0” untuk merepresentasikan </span><span class="font0" style="font-style:italic;">tweet</span><span class="font0"> negatif dan 1.249 (52%) diberi label “1” untuk merepresentasian </span><span class="font0" style="font-style:italic;">tweet</span><span class="font0"> positif.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark24"></a><span class="font0" style="font-weight:bold;"><a name="bookmark25"></a>4.2. &nbsp;&nbsp;&nbsp;Pre-Processing Data</span></h2></li></ul>
<p><span class="font0">Tahap ini dilakukan untuk membersihkan data </span><span class="font0" style="font-style:italic;">tweet</span><span class="font0"> sebelum dilakukan analisis agar data menjadi lebih akurat. Berikut pada Tabel 2. adalah contoh hasil tahap </span><span class="font0" style="font-style:italic;">pre-processing</span><span class="font0"> data.</span></p>
<p><span class="font0">Tabel 2. Hasil </span><span class="font0" style="font-style:italic;">pre-processing</span><span class="font0"> data</span></p>
<table border="1">
<tr><td style="vertical-align:bottom;">
<p><span class="font0" style="font-weight:bold;">Proses</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0" style="font-weight:bold;">Tweet Sebelum Proses</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0" style="font-weight:bold;">Tweet Setelah Proses</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font0" style="font-style:italic;">Cleaning Text</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">Maaf mngecewakan km, udh cape bgt..</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">Maaf mngecewakan km udh cape bgt</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font0" style="font-style:italic;">Lowering Case</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">Maaf mngecewakan km udh cape bgt</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">maaf mngecewakan km udh cape bgt</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font0">Normalisasi</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">maaf mngecewakan km udh cape bgt</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">maaf &nbsp;&nbsp;&nbsp;mengecewakan</span></p>
<p><span class="font0">kamu sudah capek banget</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font0" style="font-style:italic;">Stopword Removal</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">maaf mengecewakan kamu sudah capek banget</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">maaf &nbsp;&nbsp;&nbsp;mengecewakan</span></p>
<p><span class="font0">capek banget</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font0" style="font-style:italic;">Stemming</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">maaf mengecewakan capek banget</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">maaf kecewa capek banget</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font0" style="font-style:italic;">Tokenizing</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">maaf kecewa capek banget</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">“maaf”, “kecewa”, “capek”, “banget”</span></p></td></tr>
</table>
<p><span class="font0">Data </span><span class="font0" style="font-style:italic;">tweet</span><span class="font0"> melewati tahap </span><span class="font0" style="font-style:italic;">cleaning text</span><span class="font0"> untuk menghilangkan karakter </span><span class="font0" style="font-style:italic;">noise</span><span class="font0"> dengan menghapus angka, simbol, URL, </span><span class="font0" style="font-style:italic;">hashtag</span><span class="font0">, lalu diseragamkan seluruhnya ke dalam huruf kecil pada tahap </span><span class="font0" style="font-style:italic;">lowering case</span><span class="font0">. </span><span class="font0" style="font-style:italic;">Tweet</span><span class="font0"> yang sudah bersih melewati tahap normalisasi dengan mengubah kata gaul, ejaan, ataupun kata non-baku menjadi bentuk sebenarnya. Tahap normalisasi dilakukan berdasarkan kamus </span><span class="font0" style="font-style:italic;">slang</span><span class="font0"> yang dibuat manual yang terdiri dari 250 kata. Berdasarkan Tabel 2. dapat diketahui bahwa normalisasi dilakukan pada pada “mngecewakan”</span></p>
<p><span class="font0">menjadi “mengecewakan”, “km” menjadi “kamu”, “udh” menjadi “sudah”, “cape” menjadi “capek”, dan “bgt” menjadi “banget”. </span><span class="font0" style="font-style:italic;">Tweet</span><span class="font0"> yang sudah melewati tahap normalisasi, selanjutnya dipilih kata-kata yang memiliki nilai informasi rendah untuk dihilangkan. Tahap </span><span class="font0" style="font-style:italic;">stop-word removal</span><span class="font0"> dilakukan berdasarkan kamus </span><span class="font0" style="font-style:italic;">stop-word</span><span class="font0"> yang didapat dari jurnal Fadillah Z Tala, yang terdiri dari 750 kata [15]. Contohnya, yaitu menghapuskan kata ganti orang “kamu”, dan kata hubung “sudah”. Data </span><span class="font0" style="font-style:italic;">tweet</span><span class="font0"> yang sudah disaring kemudian melewati tahap </span><span class="font0" style="font-style:italic;">stemming</span><span class="font0"> untuk mengubah kata demi kata menjadi ke bentuk dasar, yaitu kata “mengecewakan” yang dihilangkan </span><span class="font0" style="font-style:italic;">prefix</span><span class="font0">, </span><span class="font0" style="font-style:italic;">infix</span><span class="font0">, serta </span><span class="font0" style="font-style:italic;">suffix-nya</span><span class="font0"> sehingga menjadi “kecewa”. Terakhir yaitu memecah kalimat menjadi </span><span class="font0" style="font-style:italic;">token</span><span class="font0"> pada tahap </span><span class="font0" style="font-style:italic;">tokenizing</span><span class="font0">.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark26"></a><span class="font0" style="font-weight:bold;"><a name="bookmark27"></a>4.3. &nbsp;&nbsp;&nbsp;Pembobotan TF-IDF</span></h2></li></ul>
<p><span class="font0" style="font-style:italic;">Dataset</span><span class="font0"> hasil </span><span class="font0" style="font-style:italic;">cleansing</span><span class="font0"> didapatkan berupa atribut tulisan, sehingga perlu dilakukan pembobotan agar </span><span class="font0" style="font-style:italic;">dataset</span><span class="font0"> dapat diproses dengan algoritma Naïve Bayes. Hasil pembobotan adalah berupa matriks numerik. Contoh kalkulasi TF-IDF pada 3 buah dokumen (D) sebagai berikut.</span></p>
<p><span class="font0" style="font-style:italic;">Tweet Clean:</span></p>
<p><span class="font0">maaf kecewa capek banget (negatif)</span></p>
<p><span class="font0">yallah capek ketawa (positif)</span></p>
<p><span class="font0">rasa mau mati (negatif)</span></p>
<p><span class="font0">Tabel 3. Matriks Kalkulasi TF-IDF</span></p>
<table border="1">
<tr><td rowspan="2" style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">Kata</span></p></td><td colspan="3" style="vertical-align:bottom;">
<p><span class="font0" style="font-weight:bold;">tf</span></p></td><td rowspan="2" style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">df</span></p></td><td rowspan="2" style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">D/df</span></p></td><td rowspan="2" style="vertical-align:bottom;">
<p><span class="font0" style="font-weight:bold;">IDF (log D/df)</span></p></td><td colspan="3" style="vertical-align:bottom;">
<p><span class="font0" style="font-weight:bold;">W (TF-IDF)</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0" style="font-weight:bold;">D1</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0" style="font-weight:bold;">D2</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0" style="font-weight:bold;">D3</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0" style="font-weight:bold;">D1</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0" style="font-weight:bold;">D2</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0" style="font-weight:bold;">D3</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0">maaf</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">1</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">0</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">0</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">1</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">3</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">0,477121</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">0,477121</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">0</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">0</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0">kecewa</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">1</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">0</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">0</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">1</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">3</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">0,477121</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">0,477121</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">0</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">0</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0">capek</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">1</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">1</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">0</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">2</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">1,5</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">0,176091</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">0,176091</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">0,176091</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">0</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0">banget</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">1</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">0</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">0</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">1</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">3</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">0,477121</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">0,477121</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">0</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">0</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0">yallah</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">0</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">1</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">0</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">1</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">3</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">0,477121</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">0</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">0,477121</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">0</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0">ketawa</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">0</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">1</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">0</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">1</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">3</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">0,477121</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">0</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">0,477121</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">0</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0">rasa</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">0</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">0</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">1</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">1</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">3</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">0,477121</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">0</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">0</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">0,477121</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0">mau</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">0</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">0</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">1</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">1</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">3</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">0,477121</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">0</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">0</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">0,477121</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0">mati</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">0</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">0</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">1</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">1</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">3</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">0,477121</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">0</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">0</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">0,477121</span></p></td></tr>
</table>
<ul style="list-style:none;"><li>
<h2><a name="bookmark28"></a><span class="font0" style="font-weight:bold;"><a name="bookmark29"></a>4.4. &nbsp;&nbsp;&nbsp;Evaluasi</span></h2></li></ul>
<p><span class="font0">Evaluasi performa dari kombinasi dan urutan </span><span class="font0" style="font-style:italic;">pre-processing</span><span class="font0"> dilakukan dengan algoritma Naïve Bayes. Pembagian </span><span class="font0" style="font-style:italic;">dataset</span><span class="font0"> pada data hasil klasifikasi diakukan dengan menggunakan perbandingan persentase data uji berbanding data latih, yaitu 90:10.</span></p>
<p><span class="font0">Tabel 4. Evaluasi performa </span><span class="font0" style="font-style:italic;">pre-processing</span><span class="font0"> data</span></p>
<table border="1">
<tr><td style="vertical-align:bottom;">
<p><span class="font0" style="font-weight:bold;">Skn</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0" style="font-weight:bold;">Urutan</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0" style="font-weight:bold;">Akurasi</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0">1</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0" style="font-style:italic;">Cleaning text</span><span class="font0"> saja</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">77.1%</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0">2</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">Normalisasi saja</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">79.6%</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0">3</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0" style="font-style:italic;">Stop-word removal</span><span class="font0"> saja</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">78.3%</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0">4</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0" style="font-style:italic;">Stemming</span><span class="font0"> saja</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">78.7%</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0">5</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0" style="font-style:italic;">Cleaning text</span><span class="font0"> dan Normalisasi</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">80.7%</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0">6</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0" style="font-style:italic;">Cleaning text</span><span class="font0"> dan </span><span class="font0" style="font-style:italic;">Stop-word removal</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">79.6%</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0">7</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0" style="font-style:italic;">Cleaning text</span><span class="font0"> dan </span><span class="font0" style="font-style:italic;">Stemming</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">79.6%</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0">8</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">Normalisasi dan </span><span class="font0" style="font-style:italic;">Stop-word removal</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">84.1%</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0">9</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">Normalisasi dan </span><span class="font0" style="font-style:italic;">Stemming</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">85.7%</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0">10</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0" style="font-style:italic;">Stop-word removal</span><span class="font0"> dan </span><span class="font0" style="font-style:italic;">Stemming</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">82.6%</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0">11</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0" style="font-style:italic;">Cleaning text</span><span class="font0">, Normalisasi, dan </span><span class="font0" style="font-style:italic;">Stop-word removal</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">85.5%</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0">12</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0" style="font-style:italic;">Cleaning text,</span><span class="font0"> Normalisasi, dan </span><span class="font0" style="font-style:italic;">Stemming</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">85.7%</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0">13</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0" style="font-style:italic;">Cleaning text, Stop-word removal</span><span class="font0">, dan </span><span class="font0" style="font-style:italic;">Stemming</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">79.7%</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0">14</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">Normalisasi, </span><span class="font0" style="font-style:italic;">Stop-word removal</span><span class="font0">, dan </span><span class="font0" style="font-style:italic;">Stemming</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">85.7%</span></p></td></tr>
</table>
<table border="1">
<tr><td style="vertical-align:bottom;">
<p><span class="font0" style="font-weight:bold;">Skn</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0" style="font-weight:bold;">Urutan</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0" style="font-weight:bold;">Akurasi</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0">15</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0" style="font-style:italic;">Full 1(Cleaning-Lowercase-</span><span class="font0">Normalisasi</span><span class="font0" style="font-style:italic;">-Stopword-Stemming-Tokenizing)</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">89.2%</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0">16</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0" style="font-style:italic;">Full 2(Cleaning-Lowercase-</span><span class="font0">Normalisasi</span><span class="font0" style="font-style:italic;">-Stemming-Stopword-Tokenizing)</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">89.2%</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0">17</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0" style="font-style:italic;">Full 3(Cleaning-Lowercase-Stopword-Stemming-</span><span class="font0">Normalisasi</span><span class="font0" style="font-style:italic;">-Tokenizing)</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">86.8%</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0">18</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0" style="font-style:italic;">Full 4(Cleaning-Lowercase-Stopword-</span><span class="font0">Normalisasi</span><span class="font0" style="font-style:italic;">-Stemming-Tokenizing)</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">88.5%</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0">19</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0" style="font-style:italic;">Full 5(Cleaning-Lowercase-Stemming-</span><span class="font0">Normalisasi</span><span class="font0" style="font-style:italic;">-Stopword-Tokenizing)</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">87.1%</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0">20</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0" style="font-style:italic;">Full 6(Cleaning-Lowercase-Stemming-Stopword-</span><span class="font0">Normalisasi</span><span class="font0" style="font-style:italic;">-Tokenizing)</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">87.3%</span></p></td></tr>
</table>
<p><span class="font0">Hasil akurasi dengan kinerja sistem tertinggi diperoleh oleh skenarip 15, dan 16 yang melakukan </span><span class="font0" style="font-style:italic;">pre-processing</span><span class="font0"> secara keseluruhan, yaitu sebesar 89,2%. Urutan tertinggi dalam tahap </span><span class="font0" style="font-style:italic;">full pre-processing</span><span class="font0"> ini didapatkan oleh urutan yang melakukan proses normalisasi lebih dulu sebelum melakukan </span><span class="font0" style="font-style:italic;">stemming</span><span class="font0">, sedangkan akurasi tertinggi pada tahap </span><span class="font0" style="font-style:italic;">full pre-processing </span><span class="font0">dengan urutan normalisasi setelah </span><span class="font0" style="font-style:italic;">stemming</span><span class="font0"> adalah 87,3%. Hal ini dikarenakan ketika proses normalisasi dilakukan sebelum </span><span class="font0" style="font-style:italic;">stemming</span><span class="font0">, maka kata non-baku sudah menjadi baku sebelum diubah ke bentuk dasar, namun apabila normalisasi dilakukan setelah </span><span class="font0" style="font-style:italic;">stemming</span><span class="font0">, maka akan ada beberapa kata yang tidak terdeteksi di proses </span><span class="font0" style="font-style:italic;">stemming</span><span class="font0"> karena belum menjadi ke bentuk sebenarnya dalam kamus bahasa Indonesia, sehingga imbuhan tidak dapat dihilangkan, dan data yang dihasilkan menjadi kurang akurat serta tidak dapat dianalisis secara maksimal dalam tahap </span><span class="font0" style="font-style:italic;">processing</span><span class="font0">. Hasil ini juga menunjukkan bahwa urutan proses pada tahap </span><span class="font0" style="font-style:italic;">pre-processing </span><span class="font0">data berpengaruh pada akurasi dan kinerja model dalam analisis klasifikasi, terutama dalam mengatur tata letak dilakukannya proses normalisasi dan </span><span class="font0" style="font-style:italic;">stemming</span><span class="font0">.</span></p>
<p><span class="font0">Lima (5) urutan tertinggi berikutnya untuk tahapan </span><span class="font0" style="font-style:italic;">pre-processing</span><span class="font0"> secara tidak lengkap, secara berurutan dijuarai oleh: skenario 9 (akurasi sebesar 85,7%) dengan kombinasi hanya melakukan normalisasi dan </span><span class="font0" style="font-style:italic;">stemming</span><span class="font0">; skenario 12 (akurasi sebesar 85,7%) dengan kombinasi </span><span class="font0" style="font-style:italic;">cleaning text,</span><span class="font0"> normalisasi, dan </span><span class="font0" style="font-style:italic;">stemming</span><span class="font0">; skenario 14 (akurasi sebesar 85,7%) dengan kombinasi normalisasi, </span><span class="font0" style="font-style:italic;">stop-word removal</span><span class="font0">, dan </span><span class="font0" style="font-style:italic;">stemming</span><span class="font0">; skenario 11 (akurasi sebesar 85,5%) dengan kombinasi </span><span class="font0" style="font-style:italic;">cleaning text</span><span class="font0">, normalisasi, dan </span><span class="font0" style="font-style:italic;">stop-word removal</span><span class="font0">; skenario 8 (akurasi sebesar 84,1%) dengan kominasi hanya melakukan normalisasi dan </span><span class="font0" style="font-style:italic;">stop-word removal</span><span class="font0">. Urutan kombinasi </span><span class="font0" style="font-style:italic;">pre-processing</span><span class="font0"> dengan akurasi terendah ada pada proses yang melakukan </span><span class="font0" style="font-style:italic;">cleaning text</span><span class="font0"> saja, yaitu sebesar 77,1%. Berdasarkan hasil ini, kelima kombinasi </span><span class="font0" style="font-style:italic;">pre-processing</span><span class="font0"> dengan urutan teratas diantaranya adalah sama-sama melakukan proses normalisasi, sedangkan untuk urutan dengan akurasi terendah tidak melakukan proses normalisasi. Melihat dari percobaan pada skenario 2 dengan hanya melakukan normalisasi saja, akurasi yang didapat juga sudah cukup tinggi dibandingkan dengan tanpa melakukan normalisasi, yaitu sebesar 79,6%. Berdasarkan hasil ini juga, hal terbesar yang mungkin menyebabkan tinggi dan rendahnya akurasi adalah karena adanya pengaruh dari proses normalisasi. Dalam proses normalisasi, kata-kata yang disingkat pada data, ejaan, bahasa gaul, atau kata apapun yang berbentuk nonbaku, seperti kata “km”, “udah”, “utk”, “onlen”, “cpt”, “smg”, dan lain sebagainya, akan diubah menjadi bentuk yang asli yang memiliki makna sama. Hasil normalisasi akan berdampak pada data </span><span class="font0" style="font-style:italic;">tweet</span><span class="font0"> yang menjadi mudah dipahami dan dapat diklasifikasikan dengan sesuai oleh sistem. Lain halnya dengan data yang tidak mengalami proses normalisasi, maka sistem akan kebingungan dalam mengecek kata demi kata sehingga hasil klasifikasi menyatakan </span><span class="font0" style="font-style:italic;">false</span><span class="font0">.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark30"></a><span class="font0" style="font-weight:bold;"><a name="bookmark31"></a>5. &nbsp;&nbsp;&nbsp;Kesimpulan</span></h2></li></ul>
<p><span class="font0">Kesimpulan yang bisa diperoleh dari analisa tahap </span><span class="font0" style="font-style:italic;">pre-processing</span><span class="font0"> pada </span><span class="font0" style="font-style:italic;">tweet</span><span class="font0"> bahasa Indonesia adalah kombinasi dan urutan proses pada tahap </span><span class="font0" style="font-style:italic;">pre-processing</span><span class="font0">, dalam hal ini mempengaruhi akurasi dan kinerja model yang digunakan dalam analisis klasifikasi. Berdasarkan 20 skenario </span><span class="font0" style="font-style:italic;">pre-processing</span><span class="font0"> data dengan mengubah kombinasi dan urutan proses </span><span class="font0" style="font-style:italic;">cleaning text</span><span class="font0">, normalisasi, </span><span class="font0" style="font-style:italic;">stemming</span><span class="font0">, dan </span><span class="font0" style="font-style:italic;">stop-word</span><span class="font0">, didapat akurasi lebih tinggi pada </span><span class="font0" style="font-style:italic;">preprocessing</span><span class="font0"> yang dilakukan secara keseluruhan (</span><span class="font0" style="font-style:italic;">full pre-processing</span><span class="font0">) dengan urutan melakukan normalisasi terlebih dahulu sebelum melakukan </span><span class="font0" style="font-style:italic;">stemming</span><span class="font0">, yaitu sebesar 89,2%. Pengaruh terbesar dari tingginya akurasi yang didapat, ada pada proses normalisasi sebagai kunci utamanya, karena apabila kata tidak dinormalisasikan terlebih dahulu, maka sistem akan sulit mendeteksi kata dan mengakibatkan adanya klasifikasi yang salah. Namun, hal ini tidak berarti bahwa proses </span><span class="font0" style="font-style:italic;">cleaning</span><span class="font0">, </span><span class="font0" style="font-style:italic;">stemming</span><span class="font0">, dan </span><span class="font0" style="font-style:italic;">stop-word</span><span class="font0"> tidak berpengaruh pada kinerja analisis, meskipun akurasi yang didapat dari kombinasi tersebut lebih rendah. Ketiga proses tersebut cukup untuk menaikkan beberapa persen akurasi dari kinerja sistem. Hal ini dibuktikan dengan hasil akurasi tertinggi ada pada tahap </span><span class="font0" style="font-style:italic;">pre-processing</span><span class="font0"> yang dilakukan dengan menggunakan</span></p>
<p><span class="font0">seluruh proses didalamnya, meskipun harus dengan urutan dimana normalisasi dilakukan lebih dulu daripada </span><span class="font0" style="font-style:italic;">stemming</span><span class="font0">.</span></p>
<h2><a name="bookmark32"></a><span class="font0" style="font-weight:bold;"><a name="bookmark33"></a>Referensi</span></h2>
<ul style="list-style:none;"><li>
<p><span class="font0">[1] &nbsp;&nbsp;&nbsp;S. Bhatt, “Apa itu Twitter?,” 2022. </span><a href="https://www.experthoot.com/id/cara-dm-di-twitter/"><span class="font0">https://www.experthoot.com/id/cara-dm-di-twitter/</span></a><span class="font0">.</span></p></li>
<li>
<p><span class="font0">[2] &nbsp;&nbsp;&nbsp;L. N. Azizah, “Pengertian Data: Fungsi, Manfaat, Jenis, dan Contohnya,” </span><span class="font0" style="font-style:italic;">Gramedia Blog</span><span class="font0">, 2022. </span><a href="https://www.gramedia.com/literasi/pengertian-data/%23:~:text=a.,-Sebagai"><span class="font0">https://www.gramedia.com/literasi/pengertian-data/#:~:text=a.,-Sebagai</span></a><span class="font0"> Suatu Acuan&amp;text=Manfaat dan juga fungsi data,kegiatan tertentu yang kita inginkan.</span></p></li>
<li>
<p><span class="font0">[3] &nbsp;&nbsp;&nbsp;Adam, “Demografi Pengguna Twitter di Indonesia Paling Banyak Pria daripada Perempuan,” </span><span class="font0" style="font-style:italic;">itworks.id</span><span class="font0">, 2019. </span><a href="https://www.itworks.id/19408/demografi-pengguna-twitter-di-indonesia-paling-banyak-pria-daripada-perempuan.html"><span class="font0">https://www.itworks.id/19408/demografi-pengguna-twitter-di-indonesia-paling-banyak-pria-daripada-perempuan.html</span></a><span class="font0">.</span></p></li>
<li>
<p><span class="font0">[4] &nbsp;&nbsp;&nbsp;D. Sebastian, “Implementasi Algoritma K-Nearest Neighbor untuk Melakukan Klasifikasi Produk dari beberapa E-marketplace,” </span><span class="font0" style="font-style:italic;">J. Tek. Inform. dan Sist. Inf.</span><span class="font0">, vol. 5, no. 1, pp. 51– 61, 2019, doi: 10.28932/jutisi.v5i1.1581.</span></p></li>
<li>
<p><span class="font0">[5] &nbsp;&nbsp;&nbsp;P. A. Sumitro, Rasiban, D. I. Mulyana, and W. Saputro, “Analisis Sentimen Terhadap Vaksin Covid-19 di Indonesia pada Twitter Menggunakan Metode Lexicon Based,” </span><span class="font0" style="font-style:italic;">J-ICOM - J. Inform. dan Teknol. Komput.</span><span class="font0">, vol. 2, no. 2, pp. 50–56, 2021, doi: 10.33059/j-icom.v2i2.4009.</span></p></li>
<li>
<p><span class="font0">[6] &nbsp;&nbsp;&nbsp;D. Darwis, E. S. Pratiwi, and A. F. O. Pasaribu, “Penerapan Algoritma Svm Untuk Analisis Sentimen Pada Data Twitter Komisi Pemberantasan Korupsi Republik Indonesia,” </span><span class="font0" style="font-style:italic;">Edutic - Sci. J. Informatics Educ.</span><span class="font0">, vol. 7, no. 1, pp. 1–11, 2020, doi: 10.21107/edutic.v7i1.8779.</span></p></li>
<li>
<p><span class="font0">[7] &nbsp;&nbsp;&nbsp;R. Riyaddulloh and A. Romadhony, “Normalisasi Teks Bahasa Indonesia Berbasis Kamus Slang Studi Kasus: Tweet Produk Gadget Pada Twitter,” </span><span class="font0" style="font-style:italic;">eProceedings Eng.</span><span class="font0">, vol. 8, no. 4, pp. 4216–4228, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2021, [Online]. Available:</span></p></li></ul>
<p><a href="https://openlibrarypublications.telkomuniversity.ac.id/index.php/engineering/article/view/"><span class="font0">https://openlibrarypublications.telkomuniversity.ac.id/index.php/engineering/article/view/</span></a><span class="font0"> 15246/14969.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font0">[8] &nbsp;&nbsp;&nbsp;Arifin Kurniawan, Indriati Indriati, and Sigit Adinugroho, “Analisis Sentimen Opini Film Menggunakan Metode Naïve Bayes dan Lexicon Based Features,” </span><span class="font0" style="font-style:italic;">J. Pengemb. Teknol. Inf. dan Ilmu Komput.</span><span class="font0">, vol. 3, no. 9, pp. 8335–8342, 2019.</span></p></li>
<li>
<p><span class="font0">[9] &nbsp;&nbsp;&nbsp;S. Almouzini, M. Khemakhem, and A. Alageel, “Detecting Arabic Depressed Users from Twitter Data,” </span><span class="font0" style="font-style:italic;">Procedia Comput. Sci.</span><span class="font0">, vol. 163, pp. 257–265, 2019, doi: 10.1016/j.procs.2019.12.107.</span></p></li>
<li>
<p><span class="font0">[10] &nbsp;&nbsp;&nbsp;B. Nurfadhila, “Analisis Sentimen Untuk Mengukur Tingkat Indikasi Depresi Pada Twitter Menggunakan Text Mining,” no. 1, 2018.</span></p></li>
<li>
<p><span class="font0">[11] &nbsp;&nbsp;&nbsp;D. Sebastian and K. A. Nugraha, “Text normalization for Indonesian abbreviated word using crowdsourcing method,” </span><span class="font0" style="font-style:italic;">2019 Int. Conf. Inf. Commun. Technol. ICOIACT 2019</span><span class="font0">, pp. 529–532, 2019, doi: 10.1109/ICOIACT46704.2019.8938463.</span></p></li>
<li>
<p><span class="font0">[12] &nbsp;&nbsp;&nbsp;D. Wahyudi, T. Susyanto, and D. Nugroho, “Implementasi Dan Analisis Algoritma Stemming Nazief &amp;&nbsp;Adriani Dan Porter Pada Dokumen Berbahasa Indonesia,” </span><span class="font0" style="font-style:italic;">J. Ilm. SINUS</span><span class="font0">, vol. 15, no. 2, pp. 49–56, 2017, doi: 10.30646/sinus.v15i2.305.</span></p></li>
<li>
<p><span class="font0">[13] &nbsp;&nbsp;&nbsp;S. Khomsah and Agus Sasmito Aribowo, “Model Text-Preprocessing Komentar Youtube Dalam Bahasa Indonesia,” </span><span class="font0" style="font-style:italic;">J. RESTI (Rekayasa Sist. dan Teknol. Informasi)</span><span class="font0">, vol. 4, no. 4, pp. 648–654, 2020, doi: 10.13140/RG.2.2.32319.74403.</span></p></li>
<li>
<p><span class="font0">[14] &nbsp;&nbsp;&nbsp;R. D. Arifin, “Pengertian Twitter | Sejarah, Fitur, Manfaat,” </span><span class="font0" style="font-style:italic;">dianisa.com</span><span class="font0">, 2020. </span><a href="https://dianisa.com/pengertian-twitter/"><span class="font0">https://dianisa.com/pengertian-twitter/</span></a><span class="font0"> (accessed Nov. 23, 2021).</span></p></li>
<li>
<p><span class="font0">[15] &nbsp;&nbsp;&nbsp;F. Z. Tala, “A Study of Stemming Effects on Information Retrieval in Bahasa Indonesia,” </span><span class="font0" style="font-style:italic;">M.Sc. Thesis, Append. D</span><span class="font0">, vol. pp, pp. 39–46, 2003.</span></p></li></ul>