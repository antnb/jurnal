---
layout: full_article
title: "Identifikasi Komentar Spam Pada Instagram"
author: "Antonius Rachmat Chrismanto, Yuan Lukito"
categories: lontar
canonical_url: https://jurnal.harianregional.com/lontar/full-34994 
citation_abstract_html_url: "https://jurnal.harianregional.com/lontar/id-34994"
citation_pdf_url: "https://jurnal.harianregional.com/lontar/full-34994"  
comments: true
---

<p><span class="font3" style="font-weight:bold;">LONTAR KOMPUTER VOL. 8, NO. 3, DESEMBER 2017</span></p>
<p><span class="font3" style="font-weight:bold;">DOI : 10.24843/LKJITI.2017.v08.i03.p08</span></p>
<p><span class="font3" style="font-weight:bold;">p-ISSN 2088-1541</span></p>
<p><span class="font3" style="font-weight:bold;">e-ISSN 2541-5832</span></p><a name="caption1"></a>
<h2><a name="bookmark0"></a><span class="font5" style="font-weight:bold;"><a name="bookmark1"></a>Identifikasi Komentar Spam Pada Instagram</span></h2>
<p><span class="font3">Antonius Rachmat Chrismanto<sup>1</sup></span><span class="font3" style="font-weight:bold;">, </span><span class="font3">Yuan Lukito<sup>2</sup></span></p>
<p><span class="font3">Program Studi Informatika, Fakultas Teknologi Informasi, Universitas Kristen Duta Wacana Jl. Dr. Wahidin Sudirohusodo 5-25, Yogyakarta, Indonesia </span><a href="mailto:1anton@ti.ukdw.ac.id"><span class="font3"><sup>1</sup>anton@ti.ukdw.ac.id</span></a></p>
<p><a href="mailto:2yuanlukito@ti.ukdw.ac.id"><span class="font3"><sup>2</sup>yuanlukito@ti.ukdw.ac.id</span></a></p>
<p><span class="font3" style="font-weight:bold;font-style:italic;">Abstrak</span></p>
<p><span class="font3" style="font-style:italic;">Spam pada Instagram (IG) umumnya berupa komentar yang dianggap mengganggu karena tidak berhubungan dengan foto atau video yang dikomentari. Spam pada komentar dapat menyebabkan beberapa dampak negatif seperti menyulitkan untuk mengikuti diskusi pada komentar yang dipenuhi oleh komentar spam dan menyebabkan seseorang tampak populer karena jumlah komentarnya banyak walaupun pada kenyataannya lebih banyak komentar yang berupa spam. Penelitian ini mencoba untuk membangun model yang dapat melakukan identifikasi komentar spam pada IG. Komentar pada IG berbentuk teks, sehingga pada penelitian ini digunakan metode-metode pengolahan teks. Untuk identifikasi digunakan metode Support Vector Machine (SVM). Data komentar yang digunakan pada penelitian ini dikumpulkan dari komentar-komentar pada foto atau video yang dibagikan oleh aktor dan artis Indonesia yang memiliki pengikut (follower) paling banyak di IG. Dari hasil penelitian didapatkan model identifikasi komentar spam dengan metode SVM menghasilkan tingkat akurasi 78,49% yang lebih baik jika dibandingkan dengan model pembanding yang menggunakan metode NB (77,25%). Penelitian ini juga menguji beberapa proporsi data pelatihan yang berbeda-beda dan hasilnya metode SVM tetap lebih baik dibandingkan dengan metode NB. Hasil lain dari penelitian ini adalah tahap pre-processing dan stemming yang harus disesuaikan terutama untuk dukungan terhadap pengolahan karakter-karakter unicode dan simbol-simbol khusus yang banyak ditemukan pada komentar-komentar di IG.</span></p>
<p><span class="font3" style="font-weight:bold;font-style:italic;">Kata kunci: </span><span class="font3" style="font-style:italic;">Identifikasi Spam, Komentar Spam, Instagram, Naive Bayes (NB), Support Vector Machine (SVM).</span></p>
<p><span class="font3" style="font-weight:bold;font-style:italic;">Abstract</span></p>
<p><span class="font3" style="font-style:italic;">Spam on Instagram (IG) is generally a comment that is considered as irritating because it does not relate to the photos or videos which were commented. Spam on comment section can cause some negative impacts such as making it difficult to follow the discussion on the posted status and making someone’s photo or video looks very popular, commented by a lot of followers despite the fact that most of the comments are actually spam. This research tries to build a model that can identify spam comments on IG. The comment on IG is in text format, so in this research, we use text processing methods. We use Support Vector Machine (SVM) for spam identification. The comment data used in this study were collected from Indonesian actors and artists who are the most followed accounts in IG. We have tested the spam identification model using SVM method resulted in 78.49% of accuracy. This result is better than the baseline model using NB method (77.25%). This research also tested some of the different training data proportions and SVM remains better than NB. Another result of this research are some adaptations needed for preprocessing and stemming stages that must be customized to support Unicode characters and unique symbols that commonly found in IG comments section.</span></p>
<p><span class="font3" style="font-weight:bold;font-style:italic;">Keywords: </span><span class="font3" style="font-style:italic;">Spam Identification, Spam Comment, Instagram, Naive Bayes (NB), Support Vector Machine (SVM).</span></p>
<ul style="list-style:none;"><li>
<h3><a name="bookmark2"></a><span class="font3" style="font-weight:bold;"><a name="bookmark3"></a>1. &nbsp;&nbsp;&nbsp;Pendahuluan</span></h3></li></ul>
<p><span class="font3">Instagram (IG) merupakan media sosial berbasis foto/gambar terpopuler di dunia nomor 1, dan di urutan ke-6 untuk media sosial secara umum. Instagram dapat digunakan oleh siapapun tidak terkecuali oleh publik figur. Publik figur, terutama artis dan aktor banyak sekali yang menggunakan IG untuk berbagai keperluan terutama untuk berbagi mengenai aktivitas mereka, promosi, menjalin dan menjaga relasi dengan para penggemarnya. Dengan jumlah pengguna mencapai 500 juta serta 95 juta gambar &amp;&nbsp;video yang diunggah setiap harinya, tentu hal ini sangat bermanfaat bagi para publik figur sebagai sarana promosi mereka.</span></p>
<p><span class="font3">Para artis/aktor Indonesia juga tidak ketinggalan dengan menggunakan IG agar memperoleh banyak </span><span class="font3" style="font-style:italic;">follower</span><span class="font3">. Beberapa artis bahkan memiliki </span><span class="font3" style="font-style:italic;">follower</span><span class="font3"> lebih dari 10 juta akun [1]. Para penggemar yang mem-</span><span class="font3" style="font-style:italic;">follow</span><span class="font3"> artis idola tentu dapat memberikan </span><span class="font3" style="font-style:italic;">like</span><span class="font3"> dan komentar pada setiap status terbaru yang dibuat oleh artis tersebut. Sayangnya tidak semua komentar pada status adalah komentar yang berkaitan dengan status yang dibagikan, banyak sekali komentar-komentar yang disebut komentar spam yang dibuat oleh para </span><span class="font3" style="font-style:italic;">spammer</span><span class="font3"> yang jelas-jelas tidak berkaitan dengan status yang dibagikan. Para </span><span class="font3" style="font-style:italic;">spammer</span><span class="font3"> menuliskan berbagai komentar tentang bisnis mereka (promo/berjualan), atau link spam, dan berbagai hal lain yang tentu sangat mengganggu.</span></p>
<p><span class="font3">Berdasarkan latar belakang di atas, ternyata IG sendiri belum memiliki fitur deteksi atau penghapus komentar spam otomatis. Fitur yang sudah disediakan adalah fitur laporan suatu komentar adalah spam atau melalui aplikasi mobile untuk melakukan ”</span><span class="font3" style="font-style:italic;">hide inappropriate comments</span><span class="font3">” terhadap komentar berbahasa Inggris berbasiskan kata-kata kunci yang sudah disediakan oleh IG, atau yang terakhir menonaktifkan komentar pada setiap status. Proses melaporkan komentar secara manual tentu sangat merepotkan karena harus dilakukan satu persatu. Cara lain yang dapat dilakukan untuk meminimalisasi komentar spam adalah dengan membuat profil IG menjadi privat. Hal ini tentu tidak mungkin dilakukan oleh para artis, karena jika dibuat privat maka tentu </span><span class="font3" style="font-style:italic;">follower</span><span class="font3"> akan semakin sedikit.</span></p>
<p><span class="font3">Pada penelitian ini masalah yang dibahas adalah bagaimana membangun model identifikasi komentar spam untuk bahasa Indonesia menggunakan algoritma Naive Bayes (NB) dan Support Vector Machine (SVM). Penelitian ini merupakan kelanjutan dari penelitian sebelumnya yang telah menghasilkan hasil bahwa algoritma NB mampu mencapai akurasi tertinggi 77,25 % untuk deteksi komentar spam di IG [2]. Penelitian mengenai penggunaan metode NB dan SVM yang digunakan dalam klasifikasi atau deteksi spam juga telah banyak dilakukan. Naive Bayes telah digunakan untuk mendeteksi klasifikasi teks karena mudah digunakan, performa baik, dan fleksibel, dan banyak pula yang melakukan berbagai peningkatan algoritma ini, seperti misalnya penggunaan informasi </span><span class="font3" style="font-style:italic;">class</span><span class="font3"> negatif yang diterapkan pada NewsGroup dataset untuk meningkatkan performa NB, dan terbukti memiliki hasil yang meningkat [3]. Naïve Bayes juga telah digunakan pada klasifikasi email spam pada dataset CERT yang memiliki hasil yang mirip dengan metode Auxiliary Features Method [4]. Pada penelitian analisis sentimen, Naïve Bayes juga telah digunakan dalam mendeteksi sentimen komentar pada Facebook Page Calon Presiden RI 2014 dan menghasilkan akurasi mencapai 82% [5]. SVM terbukti memiliki akurasi yang tinggi mencapai 96,3 % untuk mendeteksi email spam, dan meningkat menjadi 98,01 % ketika dikombinasikan dengan algoritma k-Means Clustering [6]. Ada pula penelitian yang menggabungkan SVM dan Naive Bayes guna mengklasifikasi teks ke folder secara otomatis dengan dataset sebesar 20000 (20 kategori) mampu menghasilkan akurasi rata-rata 80% dibandingkan dengan satu metode saja [7]. Hal ini membuktikan bahwa kedua metode tersebut juga memang dapat dan tepat diterapkan dalam klasifikasi komentar spam pada IG.</span></p>
<p><span class="font3">Penelitian ini memiliki tujuan jangka pendek untuk membangun </span><span class="font3" style="font-style:italic;">dataset</span><span class="font3"> komentar IG berbahasa Indonesia untuk artis ber-</span><span class="font3" style="font-style:italic;">follower</span><span class="font3"> lebih dari 10 juta terpopuler guna mendapatkan dataset training untuk sistem </span><span class="font3" style="font-style:italic;">supervised learning</span><span class="font3">. Batasan masalah dari penelitian ini adalah (1) menggunakan data dari 10 artis Indonesia yang memiliki </span><span class="font3" style="font-style:italic;">follower</span><span class="font3"> lebih dari 10 juta berdasarkan referensi dari [1], di mana setiap artis diambil 50 status terbaru dengan 50 komentar terbaru, (2) proses </span><span class="font3" style="font-style:italic;">stemming</span><span class="font3"> menggunakan library Sastrawi </span><span class="font3" style="font-style:italic;">Stemming</span><span class="font3"> dari Andi Librian, (3) hanya digunakan untuk deteksi komentar spam dalam bahasa Indonesia, (4) </span><span class="font3" style="font-style:italic;">tool</span><span class="font3"> yang digunakan untuk analisis adalah RapidMiner 7.x</span><span class="font4">.</span></p>
<ul style="list-style:none;"><li>
<h3><a name="bookmark4"></a><span class="font3" style="font-weight:bold;"><a name="bookmark5"></a>2. &nbsp;&nbsp;&nbsp;Metode Penelitian</span></h3></li></ul>
<p><span class="font3">Pada bagian ini akan dituliskan metode penelitian yang digunakan pada sub bab-sub bab berikutnya. Tahap secara keseluruhan dapat dilihat pada Gambar 1</span></p>
<div><img src="https://jurnal.harianregional.com/media/34994-1.jpg" alt="" style="width:391pt;height:150pt;">
<p><span class="font3" style="font-weight:bold;">Gambar 1</span><span class="font3">. </span><span class="font3" style="font-style:italic;">Flowchart</span><span class="font3"> dan Metode Penelitian</span></p>
</div><br clear="all">
<ul style="list-style:none;"><li>
<h3><a name="bookmark6"></a><span class="font3" style="font-weight:bold;"><a name="bookmark7"></a>2.1. &nbsp;&nbsp;&nbsp;Tahap Pengumpulan Data</span></h3></li></ul>
<p><span class="font3">Pada tahap ini dikumpulkan data status IG dan komentar dari 10 artis terpopuler dengan jumlah </span><span class="font3" style="font-style:italic;">follower</span><span class="font3"> lebih besar sama dengan 10 juta. Setiap satu artis diambil 50 post terbaru dan dari setiap post diambil 50 komentar terbaru. Data 10 artis diambil dari sumber [1] sebagai berikut: @ayutingting92, @princessyahrini, @raffinagita1717, @laudyacynthiabella, @prillylatuconsina96, @juliaperrezz: @chelseaoliviaa, @raisa6690, @lunamaya, @agnezmo.</span></p>
<p><span class="font3">Terkumpul data sejumlah 10 artis x 50 status x 50 komentar = 25000 data [2]. Data diambil dengan menggunakan tool </span><span class="font3" style="font-style:italic;">Instagram Tool Grabber</span><span class="font3"> yang dikembangkan penulis berdasarkan pengembangan dan modifikasi dari tool PHP Instagram Grabber yang dapat diunduh secara gratis. Setelah tahap pengumpulan data tahap pemrosesan selanjutnya dilakukan seperti pada tahap pemrosesan text mining, yaitu: tokenisasi, </span><span class="font3" style="font-style:italic;">stopwords removal</span><span class="font3">, </span><span class="font3" style="font-style:italic;">stemming</span><span class="font3">, </span><span class="font3" style="font-style:italic;">features selection</span><span class="font3">, klasifikasi, dan evaluasi [8].</span></p>
<ul style="list-style:none;"><li>
<h3><a name="bookmark8"></a><span class="font3" style="font-weight:bold;"><a name="bookmark9"></a>2.2. &nbsp;&nbsp;&nbsp;Tahap Pemrosesan Data (</span><span class="font3" style="font-weight:bold;font-style:italic;">Data Cleaning</span><span class="font3" style="font-weight:bold;">)</span></h3></li></ul>
<p><span class="font3">Pada bagian ini akan dilakukan pemrosesan data berupa data </span><span class="font3" style="font-style:italic;">cleaning</span><span class="font3">. Data </span><span class="font3" style="font-style:italic;">cleaning</span><span class="font3"> yang dilakukan adalah menghapus karakter-karakter khusus, menghapus angka, menghapus URL, dan data-data kosong. Hal ini penting dilakukan karena proses pengambilan data otomatis dari IG tidak selalu berhasil dengan sempurna. Setelah dilakukan data </span><span class="font3" style="font-style:italic;">cleaning</span><span class="font3"> kemudian dilanjutkan proses pada tahap berikutnya. Dari data yang terkumpul setelah dilakukan data </span><span class="font3" style="font-style:italic;">cleaning</span><span class="font3"> dihasilkan sejumlah 17.007 dengan data dapat dilihat pada Tabel 1 sebagai berikut [2]:</span></p>
<p><span class="font3" style="font-weight:bold;">Tabel 1. </span><span class="font3">Data Hasil </span><span class="font3" style="font-style:italic;">Cleaning</span></p>
<table border="1">
<tr><td style="vertical-align:middle;">
<p><span class="font2" style="font-weight:bold;">No.</span></p></td><td style="vertical-align:middle;">
<p><span class="font2" style="font-weight:bold;">Artis</span></p></td><td style="vertical-align:middle;">
<p><span class="font2" style="font-weight:bold;">Nama Kelas dan Jumlah</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2">1.</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">Ayu Ting-Ting</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">Spam (1262), Bukan Spam (584)</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font2">2.</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Julia Perez</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Spam (1362), Bukan Spam (739)</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font2">3.</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Nagita Slavina</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Spam (1435), Bukan Spam (610)</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font2">4.</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Syahrini</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Spam (922), Bukan Spam (448)</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font2">5.</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Laudya Cinthia Bella</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Spam (902), Bukan Spam (688)</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font2">6.</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Prili Ratuconsina</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Spam (437), Bukan Spam (1091)</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font2">7.</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Chelsea Olivia</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Spam (1625), Bukan Spam (293)</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font2">8.</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Luna Maya</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Spam (965), Bukan Spam (275)</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font2">9.</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Raisa</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Spam (666), Bukan Spam (621)</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font2">10.</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Agnes Monica</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Spam (1143), Bukan Spam (940)</span></p></td></tr>
<tr><td colspan="2" style="vertical-align:top;">
<p><span class="font2" style="font-weight:bold;">JUMLAH SPAM 10.719</span></p></td><td style="vertical-align:top;">
<p><span class="font2" style="font-weight:bold;">JUMLAH BUKAN SPAM 6.288</span></p></td></tr>
<tr><td colspan="2" style="vertical-align:middle;">
<p><span class="font2" style="font-weight:bold;">TOTAL KESELURUHAN 17.007</span></p></td><td style="vertical-align:top;"></td></tr>
</table>
<ul style="list-style:none;"><li>
<p><span class="font3" style="font-weight:bold;">2.3. &nbsp;&nbsp;&nbsp;Tahap </span><span class="font3" style="font-weight:bold;font-style:italic;">Pre-processing</span></p></li></ul>
<p><span class="font3">Tahap </span><span class="font3" style="font-style:italic;">pre-processing</span><span class="font3"> dilakukan sebagai berikut:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font3" style="font-style:italic;">a. &nbsp;&nbsp;&nbsp;Tokenisasi.</span><span class="font3"> Tokenisasi dilakukan untuk menghaslkan token-token data. Jumlah token yang dihasilkan adalah 35154 token unik dan 7728 token unik.</span></p></li>
<li>
<p><span class="font3" style="font-style:italic;">b. &nbsp;&nbsp;&nbsp;Stopwords Removal. Stopwords removal</span><span class="font3"> menggunakan data dari file txt yang diinputkan. Setelah dilakukan </span><span class="font3" style="font-style:italic;">stopwords removal</span><span class="font3">, dihasilkan data token sejumlah 31226 token. Tujuan dari tahap ini adalah mengurangi jumlah token.</span></p></li>
<li>
<p><span class="font3" style="font-style:italic;">c. &nbsp;Stemming. Stemming</span><span class="font3"> pada penelitian ini menggunakan library Sastrawi Stemming,</span></p></li></ul>
<p><span class="font3" style="font-style:italic;">library stemming</span><span class="font3"> bahasa Indonesia yang berbasis C, Java, Go, Ruby, PHP dan Python yang berbasis algoritma Nazief dan Adriani. Tujuan dari tahap ini juga mengurangi jumlah token.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font3" style="font-style:italic;">d. &nbsp;&nbsp;&nbsp;Cleansing and Symbol Handling.</span><span class="font3"> Tahap ini terdiri dari c</span><span class="font3" style="font-style:italic;">leansing</span><span class="font3"> yaitu menghapus karakter-karakter seperti: ~, ', !, $, %, ^, &amp;, *, (, ), _, -, +, =, :, “, ‘, &lt;, &gt;, koma, titik, ?, /, \, dan |. Kemudian dilanjutkan dengan membuang semua spasi yang berjumlah lebih dari satu dan menggabungkannya menjadi satu spasi saja. Membuang semua spasi di awal dan akhir kalimat (</span><span class="font3" style="font-style:italic;">trim</span><span class="font3">), dan menghapus semua baris yang kosong. Terakhir adalah membuang semua angka, string dengan format URL, dan email. Simbol-simbol pada IG perlu dikonversikan ke dalam bentuk teks. Data hasil cleansing menghasilkan Spam berjumlah 10399 dan Non Spam berjumlah 6062 data.</span></p></li></ul>
<ul style="list-style:none;"><li>
<p><span class="font3" style="font-weight:bold;">2.4. &nbsp;&nbsp;&nbsp;Tahap </span><span class="font3" style="font-weight:bold;font-style:italic;">Text Transformation</span></p></li></ul>
<p><span class="font3">Pada tahap ini dilakukan proses pengubahan data dari token teks menjadi </span><span class="font3" style="font-style:italic;">vector</span><span class="font3"> data yang memiliki nilai berupa bobot yang dapat digunakan untuk perhitungan data / </span><span class="font3" style="font-style:italic;">text mining</span><span class="font3">. Proses </span><span class="font3" style="font-style:italic;">text transformation</span><span class="font3"> dilakukan dengan menggunakan pembobotan Term Frequency - Inverse Document Frequency (TF-IDF). Dalam TF-IDF semakin banyak suatu token muncul berkali-kali di banyak dokumen maka berarti token tersebut tidak memiliki bobot yang besar sebab bobot token tersebut tidak penting dan memiliki ciri khas yang membedakannya dengan token-token lain. Sebaliknya token tertentu akan memiliki bobot tinggi jika token tersebut muncul banyak namun hanya di satu atau beberapa dokumen saja, yang artinya semakin penting dan memberikan ciri atau pengaruh kuat tentang suatu dokumen.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font3" style="font-weight:bold;">2.5. &nbsp;&nbsp;&nbsp;Tahap </span><span class="font3" style="font-weight:bold;font-style:italic;">Features Selection</span></p></li></ul>
<p><span class="font3">Pada tahap ini dilakukan pemilihan fitur-fitur dari keseluruhan token yang telah ditransformasi dan memiliki bobot TF-IDF seperti pada langkah sebelumnya. Berdasarkan [9] dan [10], tahap ini penting dilakukan dengan tujuan mengurangi jumlah fitur dan memilih fitur token-token tertentu yang memiliki bobot tertinggi sehingga dapat mewakili keunikan setiap data dokumen. Proses ini dilakukan dengan menggunakan metode </span><span class="font3" style="font-style:italic;">pruning</span><span class="font3"> di bawah 0.1 dan di atas 0.98.</span></p>
<ul style="list-style:none;"><li>
<h3><a name="bookmark10"></a><span class="font3" style="font-weight:bold;"><a name="bookmark11"></a>2.6. &nbsp;&nbsp;&nbsp;Tahap Klasifikasi</span></h3></li></ul>
<p><span class="font3">Tahap klasifikasi dilakukan dengan menggunakan algoritma SVM yang diimplementasikan pada RapidMiner 7.5 dengan pengaturan operator seperti pada Gambar 2. Algoritma NB digunakan sebagai pembanding berdasarkan penelitian sebelumnya. Sedangkan parameter-paramater yang digunakan adalah seperti pada Tabel 2 berikut.</span></p>
<p><span class="font3" style="font-weight:bold;">Tabel 2. </span><span class="font3">Parameter Klasifikasi</span></p>
<table border="1">
<tr><td style="vertical-align:bottom;">
<p><span class="font2" style="font-weight:bold;">Algoritma</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2" style="font-weight:bold;">Parameter</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2" style="font-weight:bold;">Nilai</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2">Support Vector Machine</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">Kernel Function</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">RBF</span></p></td></tr>
<tr><td style="vertical-align:top;"></td><td style="vertical-align:bottom;">
<p><span class="font2">C</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">1</span></p></td></tr>
<tr><td style="vertical-align:top;"></td><td style="vertical-align:bottom;">
<p><span class="font2">Gamma</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">1</span></p></td></tr>
<tr><td style="vertical-align:top;"></td><td style="vertical-align:bottom;">
<p><span class="font2">Epsilon</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">0.001</span></p></td></tr>
<tr><td style="vertical-align:top;"></td><td style="vertical-align:top;">
<p><span class="font2">Max iteration</span></p></td><td style="vertical-align:top;">
<p><span class="font2">100000</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2">Naive Bayes</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">Laplace Correction</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">Yes</span></p></td></tr>
<tr><td style="vertical-align:top;"></td><td style="vertical-align:bottom;">
<p><span class="font2">Estimation mode</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">Greedy</span></p></td></tr>
<tr><td style="vertical-align:top;"></td><td style="vertical-align:top;">
<p><span class="font2">Minimum Width</span></p></td><td style="vertical-align:top;">
<p><span class="font2">0.1</span></p></td></tr>
<tr><td style="vertical-align:top;"></td><td style="vertical-align:middle;">
<p><span class="font2">No of kernels</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">10</span></p></td></tr>
</table>
<ul style="list-style:none;"><li>
<h3><a name="bookmark12"></a><span class="font3" style="font-weight:bold;"><a name="bookmark13"></a>2.7. &nbsp;&nbsp;&nbsp;Tahap Evaluasi</span></h3></li></ul>
<p><span class="font3">Tahap evaluasi dilakukan dengan menggunakan pengujian k-fold </span><span class="font3" style="font-style:italic;">validation</span><span class="font3"> pada RapidMiner 7.5 sesuai pengaturan pada Tabel 3 berikut.</span></p>
<p><span class="font3" style="font-weight:bold;">Tabel 3. </span><span class="font3">Parameter Evaluasi Penelitian</span></p>
<table border="1">
<tr><td style="vertical-align:bottom;">
<p><span class="font2" style="font-weight:bold;">Algoritma</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2" style="font-weight:bold;">Parameter</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2" style="font-weight:bold;">Nilai</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2">Support Vector</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">Metode validasi</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2" style="font-style:italic;">k-Fold Validation</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font2">Machine</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">Metrik pengujian</span></p>
<p><span class="font2">Jumlah data</span></p>
<p><span class="font2">Tool</span></p>
<p><span class="font2">Kriteria output yang dihasilkan</span></p>
<p><span class="font2" style="font-style:italic;">Sampling type</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2" style="font-style:italic;">Confusion Matrix</span></p>
<p><span class="font2">15000 data</span></p>
<p><span class="font2">RapidMiner 7.5</span></p>
<p><span class="font2" style="font-style:italic;">Accuracy</span><span class="font2"> dan </span><span class="font2" style="font-style:italic;">Classification</span></p>
<p><span class="font2" style="font-style:italic;">Shuffled sampling</span></p></td></tr>
</table>
<ul style="list-style:none;"><li>
<h3><a name="bookmark14"></a><span class="font3" style="font-weight:bold;"><a name="bookmark15"></a>3. &nbsp;&nbsp;&nbsp;Kajian Pustaka</span><br><br><span class="font3" style="font-weight:bold;"><a name="bookmark16"></a>3.1. &nbsp;&nbsp;&nbsp;Tinjauan Pustaka</span></h3></li></ul>
<p><span class="font3">Pada era modern dan berkembangnya media sosial, para pengguna Internet secara </span><span class="font3" style="font-style:italic;">usercentric</span><span class="font3"> bebas dapat melakukan dua hal yaitu proses </span><span class="font3" style="font-style:italic;">read</span><span class="font3">, yaitu membaca konten yang disediakan oleh orang lain di Internet dan yang kedua adalah proses </span><span class="font3" style="font-style:italic;">write</span><span class="font3">, yaitu mengisi konten di Internet dengan berbagai cara seperti mengunggah tulisan, dokumen, gambar, ataupun video terutama melalui situs media sosial. Era Internet seperti ini disebut sebagai era Web 2.0, di mana Internet sudah menjadi platform online yang bersifat dua arah, </span><span class="font3" style="font-style:italic;">read</span><span class="font3"> dan </span><span class="font3" style="font-style:italic;">write</span><span class="font3"> [11]. Dengan teknologi berbasis Web 2.0 terdapat banyak aplikasi yang akan memungkinkan akses terintegrasi terhadap berbagai layanan, konten, dan segala sesuatu di Internet. Hal ini juga menyebabkan pengguna Web 2.0 tidak hanya bersifat pasif (konsumer), sekaligus aktif (sebagai produser), yang disebut prosumer [12]. Proses </span><span class="font3" style="font-style:italic;">write</span><span class="font3">, yaitu menuliskan sesuatu di Internet dapat dilakukan di berbagai hal, salah satunya melalui menulis status dan komentar pada media sosial. Hal ini memiliki resiko buruk yaitu dapat menulis dengan sembarangan, termasuk munculnya tulisan </span><span class="font3" style="font-style:italic;">spam</span><span class="font3">.</span></p>
<p><span class="font3">Spam diterjemahkan sebagai suatu tulisan/pesan yang tidak sesuai/tidak berhubungan dengan topik tertentu sehingga menyebabkan ketidaknyamanan atau bahkan ketidaktepatan informasi yang diperoleh pengguna. Spam pada komentar ditemukan dalam bentuk yaitu tautan spam yang ditulis pada </span><span class="font3" style="font-style:italic;">web</span><span class="font3"> seperti </span><span class="font3" style="font-style:italic;">blog</span><span class="font3"> dan </span><span class="font3" style="font-style:italic;">wiki</span><span class="font3">. Beberapa diantaranya sering ditemukan dalam bentuk komentar, </span><span class="font3" style="font-style:italic;">trackback</span><span class="font3">, dan </span><span class="font3" style="font-style:italic;">pingback</span><span class="font3"> spam pada artikel blog yang di-posting seseorang. Namun baru-baru ini komentar spam juga berupa tulisan seperti jualan barang dagangan maupun promosi sesuatu yang tidak berhubungan dengan status yang dikomentari, seperti yang banyak ditemukan pada </span><span class="font3" style="font-style:italic;">blog</span><span class="font3"> dan IG.</span></p>
<p><span class="font3">Beberapa cara manual yang dapat digunakan untuk mendeteksi komentar spam adalah: (1) deteksi komentar dobel/duplikasi, (2) menggunakan </span><span class="font3" style="font-style:italic;">plugin</span><span class="font3"> untuk blog, (3) menonaktifkan komentar tanpa login, (4) menggunakan CAPTCHA, (5) moderasi komentar secara manual, (6) tidak memperbolehkan </span><span class="font3" style="font-style:italic;">hyperlink</span><span class="font3">, (6) deteksi kata-kata aneh, kesalahan gramatikal, tidak rasional, tidak relevan dengan yang diberi komentar, dan biasanya bersifat sangat umum.</span></p>
<p><span class="font3">Pada penelitian ini digunakan sistem </span><span class="font3" style="font-style:italic;">supervised learning</span><span class="font3"> di mana sistem berusaha mendeteksi secara otomatis menggunakan algoritma Naïve Bayes (NB) dan Support Vector Machine (SVM). Berdasarkan penelitian sebelumnya diperoleh bahwa algoritma NB mencapai akurasi tertinggi 77,25 %. Penelitian tersebut telah menghasilkan dataset komentar IG dari 10 artis ber-</span><span class="font3" style="font-style:italic;">follower</span><span class="font3"> terbanyak dengan jumlah data sebanyak 17007 data (10719 spam, 6288 bukan spam) [2]. Penelitian ini membandingkan NB dan SVM karena SVM memiliki kelebihan dengan jumlah kelas kecil (biasanya 2 kelas) dan buruk untuk kelas yang sangat banyak [13], serta merupakan klasifier yang sangat baik karena memiliki tingkat akurasi yang tinggi bahkan mencapai di atas 95%, walaupun waktu komputasinya lebih lama daripada Naïve Bayes [14] [15]. SVM dipilih dalam penelitian ini karena beberapa alasan: 1). SVM mampu melakukan generalisasi dengan error yang lebih kecil, 2). SVM mampu bekerja untuk dimensi yang besar, dan 3). SVM memiliki </span><span class="font3" style="font-style:italic;">feasibility</span><span class="font3"> yang jelas, artinya termasuk bisa diimplementasikan dan memiliki banyak </span><span class="font3" style="font-style:italic;">library </span><span class="font3">pendukung.</span></p>
<ul style="list-style:none;"><li>
<h3><a name="bookmark17"></a><span class="font3" style="font-weight:bold;"><a name="bookmark18"></a>3.2. &nbsp;&nbsp;&nbsp;Algoritma Naïve Bayes</span></h3></li></ul>
<p><span class="font3">Algoritma Naive Bayes (NB) adalah algoritma klasifier yang menggunakan teori kemungkinan dalam bidang statistik yang digagas pertama kali oleh Thomas Bayes untuk memprediksi peluang di masa yang akan datang berdasarkan peluang dari masa sebelumnya. Metode ini kemudian digabungkan dengan kondisi natif yaitu kondisi dimana kondisi antar atribut dalam universe saling bebas dan tidak berhubungan satu sama lain. Dalam kaitannya dengan data latih, setiap data latih memiliki atribut-atribut dan satu buah label kelas, maka kemungkinan suatu data baru masuk ke dalam suatu kelas dapat didefinisikan dengan Persamaan (1) berikut [16]:</span></p>
<p><span class="font3"><sub>p</sub> (</span><span class="font13">c⅛</span><span class="font11">∣</span><span class="font13">χ)= </span><span class="font12">PtffcgiKfc) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="font3">(1)</span></p>
<p><span class="font3">Dalam kasus klasifikasi spam, dapat dijelaskan bahwa probabilitas suatu dokumen x masuk dalam kelas Ck jika diketahui sesuatu adalah sama dengan probabilitas keseluruhan bahwa suatu data masuk dalam kelas Ck, dikali probabilitas x ada pada kelas Ck, kemudian dibagi dengan </span><span class="font3" style="font-style:italic;">evidence</span><span class="font3"> probabilitas x. Jika dalam bentuk klasifikasi spam adalah sebagaimana pada Persamaan (2) berikut:</span></p>
<p><span class="font12" style="font-style:italic;text-decoration:underline;">(s).p (d</span><span class="font7" style="font-style:italic;text-decoration:underline;">∖</span><span class="font12" style="font-style:italic;text-decoration:underline;">s')</span></p>
<p><span class="font12">P^ <sup>1</sup> &nbsp;&nbsp;&nbsp;</span><span class="font13">= </span><span class="font12">p(d</span><span class="font10">∣</span><span class="font12">S).p(S)+p(d</span><span class="font10">∣</span><span class="font12">WS).p(WS) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="font3"><sup>(</sup> )</span></p>
<p><span class="font3">Dengan keterangan:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font3">• &nbsp;&nbsp;&nbsp;p(S|d) adalah probabilitas dokumen d masuk dalam kategori Spam (S)</span></p></li>
<li>
<p><span class="font3">• &nbsp;&nbsp;&nbsp;p(S) adalah probabilitas keseluruhan kategori Spam (S)</span></p></li>
<li>
<p><span class="font3">• &nbsp;&nbsp;&nbsp;p(d|S) adalah probabilitas kategori Spam (S) pada dokumen d</span></p></li>
<li>
<p><span class="font3">• &nbsp;p(d|NS) adalah probabilitas kategori Not Spam (NS) pada dokumen d</span></p></li>
<li>
<p><span class="font3">• &nbsp;p(NS) adalah probabilitas keseluruhan kategori Not Spam (NS)</span></p></li></ul>
<ul style="list-style:none;"><li>
<h3><a name="bookmark19"></a><span class="font3" style="font-weight:bold;"><a name="bookmark20"></a>3.3. &nbsp;&nbsp;&nbsp;Algoritma Support Vector Machine</span></h3></li></ul>
<p><span class="font3">Algoritma Support Vector Machine (SVM) merupakan salah satu algoritma klasifier yang berbasiskan model </span><span class="font3" style="font-style:italic;">supervised learning</span><span class="font3"> dan diperkenalkan oleh Vapnik pada tahun 1992. Pada sejumlah data pelatihan yang memiliki sejumlah x atribut (vektornya memiliki ukuran x dimensi), metode SVM akan mencari dan menemukan sebuah </span><span class="font3" style="font-style:italic;">hyperplane</span><span class="font3"> berukuran x-1 dimensi guna memisahkan data pelatihan berbasiskan kategori atau kelasnya. Proses menemukan </span><span class="font3" style="font-style:italic;">hyperplane</span><span class="font3"> dilakukan dengan memaksimalkan jarak antar kelas (margin). Dengan cara ini SVM dapat menjamin kemampuan generalisasi yang tinggi untuk data-data yang akan datang [17].</span></p>
<p><span class="font3">Apabila diketahui data </span><span class="font3" style="font-style:italic;">training</span><span class="font3"> merupakan data yang telah diberi label dan memiliki sejumlah x atribut (atau biasa dinamakan sebagai </span><span class="font3" style="font-style:italic;">tuple</span><span class="font3">), (x</span><span class="font0">i</span><span class="font3">, y</span><span class="font0">i</span><span class="font3">) dengan i = 1, 2, …, n, di mana n adalah jumlah data </span><span class="font3" style="font-style:italic;">training</span><span class="font3">, sedangkan x</span><span class="font0">i </span><span class="font3">adalah kumpulan atribut pada data </span><span class="font3" style="font-style:italic;">training</span><span class="font3"> ke-i dan y</span><span class="font0">i </span><span class="font3">adalah kelas dari data </span><span class="font3" style="font-style:italic;">training</span><span class="font3"> ke-i tersebut, maka SVM akan menghitung masalah optimisasi seperti dilihat pada Persamaan (3) [16].</span></p>
<p><span class="font13">min</span><span class="font9"><sub>w</sub></span><span class="font12">, </span><span class="font13" style="font-style:italic;">b,ξ ^w<sup>r</sup>W</span><span class="font13"> + </span><span class="font13" style="font-style:italic;">C</span><span class="font13"> ∑^ </span><span class="font12">ι</span><span class="font13">ξ</span></p>
<p><span class="font3">(3)</span></p>
<p><span class="font3">dengan ketentuan seperti pada Persamaan (4) berikut:</span></p>
<p><span class="font13" style="font-style:italic;">y<sub>i</sub>(w<sup>r</sup> φ(x<sub>i</sub>) + b ≥ 1 — ξ<sub>l</sub> ,dan</span><span class="font13"> ξ</span><span class="font9"><sub>i</sub> </span><span class="font13">&gt;&nbsp;0. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="font3">(4)</span></p>
<p><span class="font3">Metode SVM mempunyai kelemahan pada proses perhitungan yang relatif lama dan sulit diaplikasikan pada jumlah sampel dan dimensi yang besar dibandingkan dengan metode-metode klasifikasi lainnya, namun mempunyai kelebihan dalam mengklasifikasikan data untuk kategori/kelas dengan jumlah sedikit (direkomendasikan untuk 2 kelas) sehingga sangat cocok untuk klasifikasi spam (spam dan </span><span class="font3" style="font-style:italic;">not spam</span><span class="font3">) [17].</span></p>
<ul style="list-style:none;"><li>
<h3><a name="bookmark21"></a><span class="font3" style="font-weight:bold;"><a name="bookmark22"></a>3.4. &nbsp;&nbsp;&nbsp;Confusion Matrix</span></h3></li></ul>
<p><span class="font3">Confusion Matrix merupakan sebuah tabel atau matriks yang menggambarkan “kebingungan” dari hasil klasifikasi yang dilakukan oleh system dibandingkan dengan yang sebenarnya. Tabel </span><span class="font3" style="font-style:italic;">confusion matrix</span><span class="font3"> dapat dilihat pada Tabel 4 berikut [18]:</span></p>
<table border="1">
<tr><td colspan="3" style="vertical-align:top;">
<p><span class="font3" style="font-weight:bold;">Tabel 4</span><span class="font3">. Confusion Matrix</span></p></td></tr>
<tr><td rowspan="2" style="vertical-align:top;"></td><td colspan="2" style="vertical-align:top;">
<p><span class="font2" style="font-weight:bold;font-style:italic;">Class</span><span class="font2" style="font-weight:bold;"> Hasil Prediksi</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2">Negatif</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">Positif</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font2" style="font-weight:bold;font-style:italic;">Class</span><span class="font2" style="font-weight:bold;"> sebenarnya &nbsp;&nbsp;</span><span class="font2">Negatif</span></p></td><td style="vertical-align:middle;">
<p><span class="font2" style="font-style:italic;">True</span><span class="font2"> Negatif (TN)</span></p></td><td style="vertical-align:middle;">
<p><span class="font2" style="font-style:italic;">False</span><span class="font2"> Negatif (FN)</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font2">Positif</span></p></td><td style="vertical-align:top;">
<p><span class="font2" style="font-style:italic;">False</span><span class="font2"> Positif (FP)</span></p></td><td style="vertical-align:top;">
<p><span class="font2" style="font-style:italic;">True</span><span class="font2"> Positif (TP)</span></p></td></tr>
</table>
<p><span class="font3">Dari </span><span class="font3" style="font-style:italic;">confusion matrix</span><span class="font3"> pada Tabel 5 dapat dilakukan perhitungan lebih lanjut untuk mendapatkan tingkat akurasi (</span><span class="font3" style="font-style:italic;">accuracy</span><span class="font3">), </span><span class="font3" style="font-style:italic;">recall</span><span class="font3">, </span><span class="font3" style="font-style:italic;">precision</span><span class="font3"> dan </span><span class="font3" style="font-style:italic;">f-measure</span><span class="font3"> dengan Persamaan (5-10).</span></p>
<ul style="list-style:none;"><li>
<p><a href="#bookmark23"><span class="font3">• &nbsp;</span><span class="font3" style="font-style:italic;">Accuracy</span><span class="font3"> = (TN + TP) / (TN + FP + FN + TP)(5)</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark24"><span class="font3">• &nbsp;&nbsp;</span><span class="font3" style="font-style:italic;">Recall / True Positive Rate</span><span class="font3"> = TP / (FP + TP)(6)</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark25"><span class="font3">• &nbsp;&nbsp;</span><span class="font3" style="font-style:italic;">False Positive Rate</span><span class="font3"> = FN / (TN + FN)(7)</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark26"><span class="font3">• &nbsp;&nbsp;</span><span class="font3" style="font-style:italic;">Specificity / True Negative</span><span class="font3"> = FP / (FP + TP)(8)</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark27"><span class="font3">• &nbsp;&nbsp;</span><span class="font3" style="font-style:italic;">Precision</span><span class="font3"> = TP / (FN + TP)(9)</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark28"><span class="font3">• &nbsp;</span><span class="font3" style="font-style:italic;">F-Measure</span><span class="font3"> = 2 * TP / (2 * TP + FP + FN(10)</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<h3><a name="bookmark29"></a><span class="font3" style="font-weight:bold;"><a name="bookmark30"></a>4. &nbsp;&nbsp;&nbsp;Hasil dan Pembahasan</span></h3></li></ul>
<p><span class="font3">Pada bagian ini dibahas dua hal, yaitu konfigurasi pembelajaran sistem berbasis </span><span class="font3" style="font-style:italic;">supervised learning</span><span class="font3"> dan evaluasi pengujian sistem. Hasil konfigurasi RapidMiner dapat dilihat pada Gambar 2 berikut.</span></p><img src="https://jurnal.harianregional.com/media/34994-2.jpg" alt="" style="width:396pt;height:134pt;">
<p><span class="font3" style="font-weight:bold;">Gambar 2</span><span class="font3">. Konfigurasi Sistem </span><span class="font3" style="font-style:italic;">Supervised Learning</span></p>
<p><span class="font3">Pada konfigurasi Gambar 2 di atas, dapat dijelaskan bahwa tahapan pertama adalah pengambilan data dari basis data, kemudian dilakukan normalisasi, </span><span class="font3" style="font-style:italic;">pre-processing</span><span class="font3"> dokumen, kemudian langkah terakhir adalah tahap klasifikasi dan validadasi.</span></p>
<p><span class="font3">Langkah evaluasi dilakukan dengan pengujian sistem yang terdiri dari skenario berikut:</span></p>
<ul style="list-style:none;"><li>
<h3><a name="bookmark31"></a><span class="font3" style="font-weight:bold;"><a name="bookmark32"></a>4.1. &nbsp;&nbsp;&nbsp;Skenario I Tanpa </span><span class="font3" style="font-weight:bold;font-style:italic;">Stemming</span></h3></li></ul>
<p><span class="font3">Skenario I tanpa </span><span class="font3" style="font-style:italic;">stemming</span><span class="font3"> adalah pengujian di mana data yang digunakan untuk </span><span class="font3" style="font-style:italic;">training </span><span class="font3">berjumlah 10.399 untuk data spam dan 6062 untuk data </span><span class="font3" style="font-style:italic;">not spam</span><span class="font3"> tanpa dilakukan </span><span class="font3" style="font-style:italic;">stemming </span><span class="font3">terlebih dahulu. Dari data tersebut dilakukan pengujian menggunakan teknik k-fold </span><span class="font3" style="font-style:italic;">validation </span><span class="font3">dengan k=10, artinya data uji untuk masing-masing pengujian berjumlah 1646 (10%) dan hasilnya akan dirata-rata serta ditampilkan dalam kurva ROC (</span><span class="font3" style="font-style:italic;">Receiver Operating Characteristic</span><span class="font3">). Gambar data profil skenario I dapat dilihat di Gambar 3 (a) berikut.</span></p><img src="https://jurnal.harianregional.com/media/34994-3.jpg" alt="" style="width:312pt;height:119pt;">
<p><span class="font3" style="font-weight:bold;">Gambar 3. </span><span class="font3">(a) Data Profil I dan (b) Data Profil II</span></p>
<ul style="list-style:none;"><li>
<h3><a name="bookmark33"></a><span class="font3" style="font-weight:bold;"><a name="bookmark34"></a>4.1.1. &nbsp;&nbsp;&nbsp;Hasil Naïve Bayes (NB)</span></h3></li></ul>
<p><span class="font3">Hasil </span><span class="font3" style="font-style:italic;">confusion matrix</span><span class="font3"> untuk NB pada Skenario I tanpa </span><span class="font3" style="font-style:italic;">stemming</span><span class="font3"> dapat dilihat pada Tabel 5. Dari hasil tersebut dapat dibuat kurva ROC untuk kemampuan algoritma NB pada data tidak seimbang pada Gambar 4 (a). Dari kurva tersebut dapat dilihat kinerja algoritma NB dalam melakukan klasifikasi. Pada sumbu X dapat dilihat hasil </span><span class="font3" style="font-style:italic;">False Positive Rate</span><span class="font3"> (</span><span class="font3" style="font-style:italic;">fallout</span><span class="font3">) dan sumbu Y adalah </span><span class="font3" style="font-style:italic;">True Positive Rate</span><span class="font3"> (</span><span class="font3" style="font-style:italic;">sensitivity</span><span class="font3">). Dari Gambar 4 (a) dapat diketahui bahwa grafik NB sudah cukup baik karena grafik NB memiliki luasan yang besar dan tidak mendekati titik 0,0, justru makin mendekati titik 1,0.</span></p>
<p><span class="font3" style="font-weight:bold;">Tabel 5</span><span class="font3">. </span><span class="font3" style="font-style:italic;">Confusion Matrix</span><span class="font3"> Skenario I NB Tanpa </span><span class="font3" style="font-style:italic;">Stemming</span></p>
<table border="1">
<tr><td style="vertical-align:top;"></td><td style="vertical-align:middle;">
<p><span class="font2" style="font-weight:bold;">True Spam</span></p></td><td style="vertical-align:middle;">
<p><span class="font2" style="font-weight:bold;">True Not Spam</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">Class Precission</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font2" style="font-weight:bold;">Predicted Spam</span></p></td><td style="vertical-align:top;">
<p><span class="font2">6388 (TP)</span></p></td><td style="vertical-align:top;">
<p><span class="font2">217 (FP)</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2" style="font-weight:bold;">96,71% (precision)</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font2" style="font-weight:bold;">Predicted Not Spam</span></p>
<p><span class="font2">Class Recall</span></p></td><td style="vertical-align:top;">
<p><span class="font2">4011 (FN)</span></p>
<p><span class="font2" style="font-weight:bold;">61,43% (recall)</span></p></td><td style="vertical-align:top;">
<p><span class="font2">5845 (TN)</span></p>
<p><span class="font2" style="font-weight:bold;">96,42% (specificity)</span></p></td><td style="vertical-align:top;">
<p><span class="font2" style="font-weight:bold;">59,30% (fallout)</span></p></td></tr>
</table>
<p><span class="font3">Dari Tabel 5 diperoleh </span><span class="font3" style="font-style:italic;">accuracy</span><span class="font3"> 74,31 %, </span><span class="font3" style="font-style:italic;">classification error</span><span class="font3"> 25,69 %, dan </span><span class="font3" style="font-style:italic;">f-measure</span><span class="font3"> 75, 13 %.</span></p>
<ul style="list-style:none;"><li>
<h3><a name="bookmark35"></a><span class="font3" style="font-weight:bold;"><a name="bookmark36"></a>4.1.2. &nbsp;&nbsp;&nbsp;Hasil Support Vector Machine (SVM)</span></h3></li></ul>
<p><span class="font3">Hasil confusion matrix untuk SVM pada Skenario I tanpa </span><span class="font3" style="font-style:italic;">stemming</span><span class="font3"> dapat dilihat pada Tabel 6. Dari hasil tersebut SVM lebih baik 4.18% daripada Naïve Bayes. Pada kurva ROC untuk algoritma SVM pada data tidak seimbang dapat dilihat pada Gambar 4 (b). Dari kurva tersebut dapat dilihat kinerja algoritma SVM dalam melakukan klasifikasi. Dari gambar tersebut dapat diketahui bahwa garis merah pada grafik SVM cukup mirip dengan grafik NB yang ada pada Gambar 4 (a).</span></p>
<p><span class="font3" style="font-weight:bold;">Tabel 6. </span><span class="font3">Confusion Matrix Skenario I SVM Tanpa </span><span class="font3" style="font-style:italic;">Stemming</span></p>
<table border="1">
<tr><td style="vertical-align:top;"></td><td style="vertical-align:bottom;">
<p><span class="font2" style="font-weight:bold;">True Spam</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2" style="font-weight:bold;">True Not Spam</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">Class Precission</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2" style="font-weight:bold;">Predicted Spam</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">8933 (TP)</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">2074 (FP)</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2" style="font-weight:bold;">81.16% (precision)</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font2" style="font-weight:bold;">Predicted Not Spam</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">1466 (FN)</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">3988 (TN)</span></p></td><td style="vertical-align:middle;">
<p><span class="font2" style="font-weight:bold;">73.12% (fallout)</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font2">Class Recall</span></p></td><td style="vertical-align:top;">
<p><span class="font2" style="font-weight:bold;">85.90% (recall)</span></p></td><td style="vertical-align:top;">
<p><span class="font2" style="font-weight:bold;">65.79% (specificity)</span></p></td><td style="vertical-align:top;"></td></tr>
</table>
<p><span class="font3">Dari Tabel 6 diperoleh </span><span class="font3" style="font-style:italic;">accuracy</span><span class="font3"> 78.49 %, </span><span class="font3" style="font-style:italic;">classification error</span><span class="font3"> 21.51 %, dan </span><span class="font3" style="font-style:italic;">f-measure</span><span class="font3"> 83.46 %.</span></p><img src="https://jurnal.harianregional.com/media/34994-4.jpg" alt="" style="width:345pt;height:94pt;">
<p><span class="font3" style="font-weight:bold;">Gambar 4. </span><span class="font3">(a) ROC </span><span class="font3" style="font-style:italic;">Curve</span><span class="font3"> NB Skenario I, (b) ROC </span><span class="font3" style="font-style:italic;">Curve</span><span class="font3"> SVM Skenario I (Tanpa </span><span class="font3" style="font-style:italic;">Stemming)</span></p>
<ul style="list-style:none;"><li>
<h3><a name="bookmark37"></a><span class="font3" style="font-weight:bold;"><a name="bookmark38"></a>4.2. &nbsp;&nbsp;&nbsp;Skenario II Tanpa </span><span class="font3" style="font-weight:bold;font-style:italic;">Stemming</span></h3></li></ul>
<p><span class="font3">Skenario II tanpa </span><span class="font3" style="font-style:italic;">stemming</span><span class="font3"> adalah pengujian di mana data spam dan </span><span class="font3" style="font-style:italic;">not spam</span><span class="font3"> dibuat menjadi seimbang, sehingga yang digunakan untuk </span><span class="font3" style="font-style:italic;">training</span><span class="font3"> berjumlah 6062 untuk data spam dan 6062 untuk data </span><span class="font3" style="font-style:italic;">not spam</span><span class="font3"> tanpa dilakukan </span><span class="font3" style="font-style:italic;">stemming</span><span class="font3"> terlebih dahulu. Dari data tersebut dilakukan pengujian menggunakan teknik k-fold </span><span class="font3" style="font-style:italic;">validation</span><span class="font3"> dengan k=10, artinya data uji untuk masing-masing pengujian berjumlah 606 (10%) dan hasilnya akan dirata-rata serta ditampilkan dalam kurva ROC. Gambar data profil skenario II dapat dilihat pada Gambar 3 (b).</span></p>
<ul style="list-style:none;"><li>
<h3><a name="bookmark39"></a><span class="font3" style="font-weight:bold;"><a name="bookmark40"></a>4.2.1. &nbsp;&nbsp;&nbsp;Hasil Naïve Bayes (NB)</span></h3></li></ul>
<p><span class="font3">Hasil </span><span class="font3" style="font-style:italic;">confusion matrix</span><span class="font3"> untuk NB pada Skenario II tanpa </span><span class="font3" style="font-style:italic;">stemming</span><span class="font3"> dapat dilihat pada Tabel 7. Dari hasil tersebut terlihat ada peningkatan 2,75 % dari Skenario I ke Skenario II pada NB. Kurva ROC untuk melihat kemampuan algoritma NB pada data seimbang dapat dilihat pada Gambar 5 (a). Terlihat bahwa ROC NB pada Skenario I dan II sangat mirip seperti pada Gambar 4 (a) dan 5 (a).</span></p>
<p><span class="font3" style="font-weight:bold;">Tabel 7</span><span class="font3">. Confusion Matrix NB Skenario II Tanpa </span><span class="font3" style="font-style:italic;">Stemming</span></p>
<table border="1">
<tr><td style="vertical-align:top;"></td><td style="vertical-align:middle;">
<p><span class="font2" style="font-weight:bold;">True Spam</span></p></td><td style="vertical-align:middle;">
<p><span class="font2" style="font-weight:bold;">True Not Spam</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">Class Precission</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font2" style="font-weight:bold;">Predicted Spam</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">3468 (TP)</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">164 (FP)</span></p></td><td style="vertical-align:middle;">
<p><span class="font2" style="font-weight:bold;">95.48% (precision)</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font2" style="font-weight:bold;">Predicted Not Spam</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">2594 (FN)</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">5898 (TN)</span></p></td><td style="vertical-align:middle;">
<p><span class="font2" style="font-weight:bold;">69.45% (fallout)</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font2">Class Recall</span></p></td><td style="vertical-align:middle;">
<p><span class="font2" style="font-weight:bold;">57.21% (recall)</span></p></td><td style="vertical-align:middle;">
<p><span class="font2" style="font-weight:bold;">97.29% (specificity)</span></p></td><td style="vertical-align:top;"></td></tr>
</table>
<p><span class="font3">Dari Tabel 7 diperoleh </span><span class="font3" style="font-style:italic;">accuracy</span><span class="font3"> 77,25 %, </span><span class="font3" style="font-style:italic;">classification error</span><span class="font3"> 22,75 %, dan </span><span class="font3" style="font-style:italic;">f-measure</span><span class="font3"> 71,5 %.</span></p>
<ul style="list-style:none;"><li>
<h3><a name="bookmark41"></a><span class="font3" style="font-weight:bold;"><a name="bookmark42"></a>4.2.2. &nbsp;&nbsp;&nbsp;Hasil Support Vector Machine (SVM)</span></h3></li></ul>
<p><span class="font3">Hasil Confusion Matrix untuk SVM pada Skenario II tanpa </span><span class="font3" style="font-style:italic;">stemming</span><span class="font3"> dapat dilihat pada Tabel 8. Berbeda dengan hasil SVM menggunakan data tidak seimbang (skenario I), dari hasil perbandingan akurasi antara SVM skenario I dan II terjadi penurunan kecil, yaitu sebesar 2.71 %. Kurva ROC untuk SVM data seimbang (skenario II) juga mengalami penurunan luasan seperti pada Gambar 5 (b). Dari Gambar 5 (b) dapat diketahui bahwa grafik SVM untuk data seimbang mirip sekali dengan SVM data tidak seimbang (Gambar 4 (b), yang berarti tidak lebih baik kinerjanya daripada metode NB, karena grafik SVM memiliki luasan yang lebih kecil daripada NB.</span></p>
<p><span class="font3" style="font-weight:bold;">Tabel 8. </span><span class="font3">Confusion Matrix SVM Skenario II Tanpa </span><span class="font3" style="font-style:italic;">Stemming</span></p>
<table border="1">
<tr><td style="vertical-align:top;"></td><td style="vertical-align:middle;">
<p><span class="font2" style="font-weight:bold;">True Spam</span></p></td><td style="vertical-align:middle;">
<p><span class="font2" style="font-weight:bold;">True Not Spam</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">Class Precission</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font2" style="font-weight:bold;">Predicted Spam</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">3224 (TP)</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">98 (FP)</span></p></td><td style="vertical-align:middle;">
<p><span class="font2" style="font-weight:bold;">97.05% (precision)</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2" style="font-weight:bold;">Predicted Not Spam</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">2838 (FN)</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">5964 (TN)</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2" style="font-weight:bold;">67.76% (fallout)</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2">Class Recall</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2" style="font-weight:bold;">53.18% (recall)</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2" style="font-weight:bold;">98.38% (specificity)</span></p></td><td style="vertical-align:top;"></td></tr>
</table>
<p><span class="font3">Dari Tabel 8 diperoleh </span><span class="font3" style="font-style:italic;">accuracy</span><span class="font3"> 75.78 %, </span><span class="font3" style="font-style:italic;">classification error</span><span class="font3"> 24.22 %, dan </span><span class="font3" style="font-style:italic;">f-measure</span><span class="font3"> 68.71 %.</span></p><img src="https://jurnal.harianregional.com/media/34994-5.jpg" alt="" style="width:312pt;height:90pt;">
<p><span class="font3" style="font-weight:bold;">Gambar 5. </span><span class="font2">(a) ROC </span><span class="font2" style="font-style:italic;">Curve</span><span class="font2"> Naïve Bayes Skenario II, (b) ROC </span><span class="font2" style="font-style:italic;">Curve</span><span class="font2"> SVM Skenario II (Tanpa </span><span class="font2" style="font-style:italic;">Stemming)</span></p>
<ul style="list-style:none;"><li>
<h3><a name="bookmark43"></a><span class="font3" style="font-weight:bold;"><a name="bookmark44"></a>4.3. &nbsp;&nbsp;&nbsp;Pembahasan Perbandingan Skenario I dan II Tanpa </span><span class="font3" style="font-weight:bold;font-style:italic;">Stemming</span></h3></li></ul>
<p><span class="font3">Dilihat dari kedua pengujian menggunakan skenario I dan II (tanpa </span><span class="font3" style="font-style:italic;">stemming</span><span class="font3">) diperoleh peningkatan akurasi sebesar 2,94 % untuk algoritma NB namun justru terjadi penurunan akurasi kecil sebesar 2.71 % untuk algoritma SVM, namun pada prinsipnya penurunan tersebut tidak signifikan. Jika dilihat dari kurva ROC, kinerja NB antara data seimbang dan tidak seimbang hampir sama dan untuk ROC SVM lebih baik daripada NB walaupun peningkatan</span></p>
<p><span class="font3">sangat kecil. Kurva ROC juga menunjukkan bahwa kinerja algoritma SVM lebih baik daripada NB dan keduanya memiliki akurasi dalam kisaran 74% – 79%. Perbandingan akhir kedua metode untuk skenario I dan II diperoleh bahwa algoritma SVM dan algoritma NB sebenarnya memiliki kemampuan yang hampir sama (terjadi perbedaan namun tidak signifikan) untuk kasus Instagram bahasa Indonesia tanpa </span><span class="font3" style="font-style:italic;">stemming</span><span class="font3">.</span></p>
<ul style="list-style:none;"><li>
<h3><a name="bookmark45"></a><span class="font3" style="font-weight:bold;"><a name="bookmark46"></a>4.4. &nbsp;&nbsp;&nbsp;Skenario I dengan </span><span class="font3" style="font-weight:bold;font-style:italic;">Stemming</span></h3></li></ul>
<p><span class="font3">Skenario I dengan </span><span class="font3" style="font-style:italic;">stemming</span><span class="font3"> adalah pengujian di mana data yang digunakan untuk </span><span class="font3" style="font-style:italic;">training </span><span class="font3">berjumlah 10.399 untuk data spam dan 6062 untuk data </span><span class="font3" style="font-style:italic;">not spam</span><span class="font3"> denga terlebih dahulu dilakukan pemrosesan </span><span class="font3" style="font-style:italic;">stemming</span><span class="font3">. Dari data tersebut dilakukan pengujian menggunakan teknik k-fold </span><span class="font3" style="font-style:italic;">validation</span><span class="font3"> dengan k=10, artinya data uji untuk masing-masing pengujian berjumlah 1646 (10%) dan hasilnya dirata-rata serta ditampilkan dalam kurva ROC.</span></p>
<ul style="list-style:none;"><li>
<h3><a name="bookmark47"></a><span class="font3" style="font-weight:bold;"><a name="bookmark48"></a>4.4.1. &nbsp;&nbsp;&nbsp;Hasil Naïve Bayes (NB)</span></h3></li></ul>
<p><span class="font3">Hasil </span><span class="font3" style="font-style:italic;">confusion matrix</span><span class="font3"> untuk NB pada Skenario I dengan </span><span class="font3" style="font-style:italic;">stemming</span><span class="font3"> dapat dilihat pada Tabel 9. Dilihat dari data pada tabel tersebut, tingkat akurasi menurun dibandingkan dengan data yang tidak dilakukan </span><span class="font3" style="font-style:italic;">stemming</span><span class="font3">. Hal ini terjadi karena data-data teks menggunakan Unicode namun </span><span class="font3" style="font-style:italic;">library stemming</span><span class="font3"> yang digunakan tidak mendukung Unicode dengan baik. Grafik ROC NB untuk data seimbang untuk </span><span class="font3" style="font-style:italic;">stemming</span><span class="font3"> dapat dilihat pada Gambar 6 (a). Pada Gambar 6 (a) kinerja algoritma NB masih cukup baik dan hampir mirip dengan kinerja NB pada Gambar 4 (a) dan 5(a).</span></p>
<div><img src="https://jurnal.harianregional.com/media/34994-6.jpg" alt="" style="width:183pt;height:98pt;">
</div><br clear="all">
<div><img src="https://jurnal.harianregional.com/media/34994-7.jpg" alt="" style="width:179pt;height:99pt;">
</div><br clear="all">
<p><span class="font3" style="font-weight:bold;">Tabel 9. </span><span class="font3">Confusion Matrix Skenario I NB Dengan </span><span class="font3" style="font-style:italic;">Stemming</span></p>
<table border="1">
<tr><td style="vertical-align:top;"></td><td style="vertical-align:bottom;">
<p><span class="font2" style="font-weight:bold;">True Spam</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2" style="font-weight:bold;">True Not Spam</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">Class Precission</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font2" style="font-weight:bold;">Predicted Spam</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">10176 (TP)</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">4722 (FP)</span></p></td><td style="vertical-align:middle;">
<p><span class="font2" style="font-weight:bold;">68.30% (precision)</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font2" style="font-weight:bold;">Predicted Not Spam</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">223 (FN)</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">1340 (TN)</span></p></td><td style="vertical-align:middle;">
<p><span class="font2" style="font-weight:bold;">85.73% (fallout)</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font2">Class Recall</span></p></td><td style="vertical-align:middle;">
<p><span class="font2" style="font-weight:bold;">97.86% (recall)</span></p></td><td style="vertical-align:middle;">
<p><span class="font2" style="font-weight:bold;">22.10% (specificity)</span></p></td><td style="vertical-align:top;"></td></tr>
</table>
<p><span class="font3">Dari Tabel 9 diperoleh </span><span class="font3" style="font-style:italic;">accuracy</span><span class="font3"> 69,96 %, </span><span class="font3" style="font-style:italic;">classification error</span><span class="font3"> 30.04 %, dan </span><span class="font3" style="font-style:italic;">f-measure</span><span class="font3"> 80.4 %.</span></p>
<p><span class="font3" style="font-weight:bold;">Gambar 6. </span><span class="font3">(a) ROC </span><span class="font3" style="font-style:italic;">Curve</span><span class="font3"> NB Skenario I dan (b) ROC </span><span class="font3" style="font-style:italic;">Curve</span><span class="font3"> Skenario I SVM (</span><span class="font3" style="font-style:italic;">Stemming)</span></p>
<ul style="list-style:none;"><li>
<h3><a name="bookmark49"></a><span class="font3" style="font-weight:bold;"><a name="bookmark50"></a>4.4.2. &nbsp;&nbsp;&nbsp;Hasil Support Vector Machine (SVM)</span></h3></li></ul>
<p><span class="font3">Hasil confusion matrix untuk SVM pada Skenario I dengan </span><span class="font3" style="font-style:italic;">stemming</span><span class="font3"> dapat dilihat pada Tabel 10. Dilihat dari data tersebut, tingkat akurasi dengan </span><span class="font3" style="font-style:italic;">stemming</span><span class="font3"> sama saja dibandingkan dengan data yang tidak dilakukan </span><span class="font3" style="font-style:italic;">stemming</span><span class="font3">. Dalam hal ini </span><span class="font3" style="font-style:italic;">stemming</span><span class="font3"> tidak membawa perubahan apapun. Gambar grafik ROC dapat dilihat pada Gambar 6 (b). Dari grafik ROC SVM sangat mirip seperti pada SVM tidak seimbang maupun seimbang tanpa </span><span class="font3" style="font-style:italic;">stemming</span><span class="font3">, alias tidak terjadi perubahan. Dari hasil pengujian yang sudah dilakukan untuk skenario I (data tidak seimbang) baik tanpa </span><span class="font3" style="font-style:italic;">stemming</span><span class="font3"> ataupun dengan </span><span class="font3" style="font-style:italic;">stemming</span><span class="font3"> ternyata algoritma SVM lebih baik daripada NB dengan selisih keakuratan antara 4 – 9 % lebih tinggi.</span></p>
<p><span class="font3" style="font-weight:bold;">Tabel 10. </span><span class="font3">Confusion Matrix Skenario I SVM Dengan </span><span class="font3" style="font-style:italic;">Stemming</span></p>
<table border="1">
<tr><td style="vertical-align:top;"></td><td style="vertical-align:middle;">
<p><span class="font2" style="font-weight:bold;">True Spam</span></p></td><td style="vertical-align:middle;">
<p><span class="font2" style="font-weight:bold;">True Not Spam</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">Class Precission</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font2" style="font-weight:bold;">Predicted Spam</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">6958 (TP)</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">131 (FP)</span></p></td><td style="vertical-align:middle;">
<p><span class="font2" style="font-weight:bold;">98.15 % (precision)</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2" style="font-weight:bold;">Predicted Not Spam</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">3441 (FN)</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">5931 (TN)</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2" style="font-weight:bold;">63.28 % (fallout)</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font2">Class Recall</span></p></td><td style="vertical-align:middle;">
<p><span class="font2" style="font-weight:bold;">66.91 % (recall)</span></p></td><td style="vertical-align:middle;">
<p><span class="font2" style="font-weight:bold;">97.84 % (specificity)</span></p></td><td style="vertical-align:top;"></td></tr>
</table>
<p><span class="font3">Dari Tabel 10 diperoleh </span><span class="font3" style="font-style:italic;">accuracy</span><span class="font3"> 78.3 %, </span><span class="font3" style="font-style:italic;">classification error</span><span class="font3"> 21.7 %, dan </span><span class="font3" style="font-style:italic;">f-measure</span><span class="font3"> 79.57 %.</span></p>
<ul style="list-style:none;"><li>
<h3><a name="bookmark51"></a><span class="font3" style="font-weight:bold;"><a name="bookmark52"></a>4.5. &nbsp;&nbsp;&nbsp;Skenario II dengan </span><span class="font3" style="font-weight:bold;font-style:italic;">Stemming</span></h3></li></ul>
<p><span class="font3">Skenario II dengan </span><span class="font3" style="font-style:italic;">stemming</span><span class="font3"> adalah pengujian di mana data spam dan </span><span class="font3" style="font-style:italic;">not spam</span><span class="font3"> dibuat menjadi seimbang, sehingga yang digunakan untuk </span><span class="font3" style="font-style:italic;">training</span><span class="font3"> berjumlah 6062 untuk data spam dan 6062 untuk data </span><span class="font3" style="font-style:italic;">not spam</span><span class="font3"> dengan terlebih dahulu dilakukan pemrosesan </span><span class="font3" style="font-style:italic;">stemming</span><span class="font3">. Dari data tersebut dilakukan pengujian menggunakan teknik k-fold </span><span class="font3" style="font-style:italic;">validation</span><span class="font3"> dengan k=10, artinya data uji untuk masing-masing pengujian berjumlah 606 (10%) dan hasilnya dirata-rata serta ditampilkan dalam kurva ROC.</span></p>
<ul style="list-style:none;"><li>
<h3><a name="bookmark53"></a><span class="font3" style="font-weight:bold;"><a name="bookmark54"></a>4.5.1. &nbsp;&nbsp;&nbsp;Hasil Naïve Bayes (NB)</span></h3></li></ul>
<p><span class="font3">Hasil confusion matrix untuk NB pada Skenario II dengan </span><span class="font3" style="font-style:italic;">stemming</span><span class="font3"> dapat dilihat pada Tabel 11. Pada Gambar 7 (a) dapat dilihat grafik ROC dari NB skenario II dengan </span><span class="font3" style="font-style:italic;">stemming</span><span class="font3">. Dari gambar tersebut dapat diketahui bahwa kinerja algoritma NB masih cukup baik, walaupun tetap lebih baik pada Skenario I dengan </span><span class="font3" style="font-style:italic;">stemming</span><span class="font3">.</span></p>
<p><span class="font3" style="font-weight:bold;">Tabel 11</span><span class="font3">. Confusion Matrix Skenario II NB Dengan </span><span class="font3" style="font-style:italic;">Stemming</span></p>
<table border="1">
<tr><td style="vertical-align:top;"></td><td style="vertical-align:top;">
<p><span class="font2" style="font-weight:bold;">True Spam</span></p></td><td style="vertical-align:top;">
<p><span class="font2" style="font-weight:bold;">True Not Spam</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Class Precission</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font2" style="font-weight:bold;">Predicted Spam</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">5969 (TP)</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">5072 (FP)</span></p></td><td style="vertical-align:middle;">
<p><span class="font2" style="font-weight:bold;">54.06 % (precision)</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font2" style="font-weight:bold;">Predicted Not Spam</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">93 (FN)</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">990 (TN)</span></p></td><td style="vertical-align:middle;">
<p><span class="font2" style="font-weight:bold;">91.41 % (fallout)</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font2">Class Recall</span></p></td><td style="vertical-align:top;">
<p><span class="font2" style="font-weight:bold;">98.47 % (recall)</span></p></td><td style="vertical-align:top;">
<p><span class="font2" style="font-weight:bold;">16.33 % (specificity)</span></p></td><td style="vertical-align:top;"></td></tr>
</table>
<p><span class="font3">Dari Tabel 11 diperoleh </span><span class="font3" style="font-style:italic;">accuracy</span><span class="font3"> 78.30 %, </span><span class="font3" style="font-style:italic;">classification error</span><span class="font3"> 21.70 %, dan </span><span class="font3" style="font-style:italic;">f-measure</span><span class="font3"> 79.57 %.</span></p>
<table border="1">
<tr><td style="vertical-align:middle;">
<p><span class="font1"><sup>1</sup>I i &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*</span></p></td><td style="vertical-align:top;"></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font14">L</span></p></td><td style="vertical-align:top;"></td></tr>
</table>
<p><span class="font3" style="font-weight:bold;">Gambar 7</span><span class="font3">. (a) ROC </span><span class="font3" style="font-style:italic;">Curve</span><span class="font3"> Skenario II NB, (b) ROC Curve Skenario II SVM (Dengan </span><span class="font3" style="font-style:italic;">Stemming)</span></p>
<ul style="list-style:none;"><li>
<h3><a name="bookmark55"></a><span class="font3" style="font-weight:bold;"><a name="bookmark56"></a>4.5.2. &nbsp;&nbsp;&nbsp;Hasil Support Vector Machine (SVM)</span></h3></li></ul>
<p><span class="font3">Hasil confusion matrix untuk SVM pada Skenario II dengan </span><span class="font3" style="font-style:italic;">stemming</span><span class="font3"> dapat dilihat pada Tabel 12. Gambar 7 (b) merupakan grafik ROC algoritma SVM untuk skenario II dengan </span><span class="font3" style="font-style:italic;">stemming </span><span class="font3">yang jelas lebih baik daripada NB.</span></p>
<p><span class="font3" style="font-weight:bold;">Tabel 12. </span><span class="font3">Confusion Matrix Skenario II SVM Dengan </span><span class="font3" style="font-style:italic;">Stemming</span></p>
<table border="1">
<tr><td style="vertical-align:top;"></td><td style="vertical-align:top;">
<p><span class="font2" style="font-weight:bold;">True Spam</span></p></td><td style="vertical-align:top;">
<p><span class="font2" style="font-weight:bold;">True Not Spam</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Class Precission</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font2" style="font-weight:bold;">Predicted Spam</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">3253 (TP)</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">89 (FP)</span></p></td><td style="vertical-align:middle;">
<p><span class="font2" style="font-weight:bold;">97.34 % (precision)</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font2" style="font-weight:bold;">Predicted Not Spam</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">2809 (FN)</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">5973 (TN)</span></p></td><td style="vertical-align:middle;">
<p><span class="font2" style="font-weight:bold;">68.01 % (fallout)</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font2">Class Recall</span></p></td><td style="vertical-align:middle;">
<p><span class="font2" style="font-weight:bold;">53.66 % (recall)</span></p></td><td style="vertical-align:middle;">
<p><span class="font2" style="font-weight:bold;">98.53 % (specificity)</span></p></td><td style="vertical-align:top;"></td></tr>
</table>
<p><span class="font3">Dari Tabel 13 diperoleh </span><span class="font3" style="font-style:italic;">accuracy</span><span class="font3"> 76.10 %, </span><span class="font3" style="font-style:italic;">classification error</span><span class="font3"> 23.90 %, dan </span><span class="font3" style="font-style:italic;">f-measure</span><span class="font3"> 69.2 %.</span></p>
<ul style="list-style:none;"><li>
<h3><a name="bookmark57"></a><span class="font3" style="font-weight:bold;"><a name="bookmark58"></a>4.6. &nbsp;&nbsp;&nbsp;Pembahasan Perbandingan Algoritma NB dan SVM dengan Stemming</span></h3></li></ul>
<p><span class="font3">Dari hasil akurasi algoritma SVM lebih tinggi daripada algoritma Nb untuk data dengan </span><span class="font3" style="font-style:italic;">stemming</span><span class="font3">, walaupun akurasi dan F-Measure-nya lebih kecil / turun daripada yang tanpa </span><span class="font3" style="font-style:italic;">stemming</span><span class="font3">. Hal ini terjadi karena pemrosesan karakter </span><span class="font3" style="font-style:italic;">Unicode</span><span class="font3"> yang tidak terproses dengan baik. Dari Gambar 11 dan Gambar 12 juga dapat diketahui bahwa grafik kinerja SVM baik karena grafik SVM memiliki luasan yang lebih besar daripada NB pada skenario II menggunakan </span><span class="font3" style="font-style:italic;">stemming</span><span class="font3">. SVM unggul dari NB baik untuk tanpa </span><span class="font3" style="font-style:italic;">stemming</span><span class="font3"> maupun dengan </span><span class="font3" style="font-style:italic;">stemming</span><span class="font3">.</span></p>
<ul style="list-style:none;"><li>
<h3><a name="bookmark59"></a><span class="font3" style="font-weight:bold;"><a name="bookmark60"></a>4.7. &nbsp;&nbsp;&nbsp;Pembahasan Perbandingan Algoritma NB dan SVM Secara Keseluruhan</span></h3></li></ul>
<p><span class="font3">Hasil akurasi dan F-measure dari Algoritma NB dan SVM dapat dilihat pada Tabel 13 dan Gambar 13 berikut. Dari Tabel dan gambar tersebut dapat dilihat bahwa akurasi dan </span><span class="font3" style="font-style:italic;">f-measure </span><span class="font3">terbaik diperoleh SVM S1 NS dengan nilai 78.49 % dan 83.46.</span></p>
<p><span class="font3" style="font-weight:bold;">Tabel 13. </span><span class="font3" style="text-decoration:underline;">Perbandingan Akurasi Dan F-Measure Naïve Bayes</span><span class="font3"> Dan SVM</span></p>
<p><span class="font2" style="font-weight:bold;">Akurasi &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;F-Measure</span></p>
<table border="1">
<tr><td style="vertical-align:middle;">
<p><span class="font2">NB S1 NS</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">74.31 %</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">75.13</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font2">NB S1 S</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">69.96 %</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">80.4</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font2">NB S2 NS</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">77.75 %</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">71.5</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font2">NB S2 S</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">78.3 %</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">79.57</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font2">SVM S1 NS</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">78.49 %</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">83.46</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font2">SVM S1 S</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">78.3 %</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">79.57</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font2">SVM S2 NS</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">75.78 %</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">68.71</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font2">SVM S2 S</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">76.1 %</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">69.2</span></p></td></tr>
</table>
<p><span class="font13" style="font-weight:bold;">Perbandingan Hasil Akurasi dan F-1 Naive Bayes dan Support Vector Machine</span></p>
<p><span class="font8">100</span></p>
<div>
<p><span class="font8">80</span></p>
<p><span class="font8">60</span></p>
<p><span class="font8">40</span></p>
<p><span class="font8">20</span></p>
<p><span class="font8">0</span></p>
</div><br clear="all">
<div><a name="caption2"></a>
<h1><a name="bookmark61"></a><span class="font6" style="font-variant:small-caps;"><a name="bookmark62"></a>Iiiiiiiiiiii</span></h1>
</div><br clear="all">
<p><span class="font8">NB S1 NB S1 NB S2 NB S2 SVM SVM SVM SVM</span></p>
<p><span class="font8">NS &nbsp;&nbsp;&nbsp;S &nbsp;&nbsp;&nbsp;&nbsp;NS &nbsp;&nbsp;&nbsp;S S1 NS S1 S S2 NS S2 S</span></p>
<p><span class="font8">□ Akurasi </span><span class="font1">■</span><span class="font8"> F-Measure</span></p>
<p><span class="font3" style="font-weight:bold;">Gambar 8. </span><span class="font3">Grafik Perbandingan Akurasi &amp;&nbsp;F-Measure Naïve Bayes - Support Vector Machine</span></p>
<ul style="list-style:none;"><li>
<h3><a name="bookmark63"></a><span class="font3" style="font-weight:bold;"><a name="bookmark64"></a>5. &nbsp;&nbsp;&nbsp;Kesimpulan</span></h3></li></ul>
<p><span class="font3">Kesimpulan yang diperoleh dari penelitian ini adalah SVM memiliki kinerja yang lebih baik daripada NB namun tidak terlalu signifikan peningkatannya. Tingkat akurasi antara NB dan SVM berkisar antara 70 – 79 % di mana kemampuan deteksi keduanya termasuk dalam kategori baik. Akurasi untuk klasifikasi menggunakan NB adalah 74,31 % untuk skenario I (data tidak seimbang) dan sebesar 77,25% untuk skenario II (data seimbang). Terjadi peningkatan sebesar 2,94 % untuk data seimbang. Akurasi untuk klasifikasi menggunakan SVM adalah sebesar 78,49 % untuk skenario I (data tidak seimbang) dan sebesar 75,78% untuk skenario II (data seimbang). Terjadi penurunan sebesar 2,71 % untuk data seimbang. Proses </span><span class="font3" style="font-style:italic;">stemming </span><span class="font3">yang digunakan pada data skenario I dan II tidak menghasilkan akurasi yang lebih baik pada algoritma NB maupun SVM karena adanya karakter </span><span class="font3" style="font-style:italic;">Unicode</span><span class="font3"> dan simbol yang belum dapat ditangani sepenuhnya. Penggunaan </span><span class="font3" style="font-style:italic;">stemming</span><span class="font3"> juga tidak meningkatkan akurasi baik pada NB (tingkat akurasi 69.96 % untuk skenario I dan 76.1 % untuk skenario II</span><span class="font3" style="font-style:italic;">)</span><span class="font3"> maupun SVM (tingkat akurasi 78.30 % untuk skenario I dan 76.1 % untuk skenario II</span><span class="font3" style="font-style:italic;">)</span><span class="font3">. Tahapan </span><span class="font3" style="font-style:italic;">pre-processing</span><span class="font3"> data Instagram bahasa Indonesia yang perlu dilakukan untuk pemrosesan data deteksi komentar spam dari Instagram adalah: </span><span class="font3" style="font-style:italic;">setting encoding</span><span class="font3"> teks ke </span><span class="font3" style="font-style:italic;">encoding</span><span class="font3"> Unicode (UTF-8), tokenisasi, </span><span class="font3" style="font-style:italic;">case folding</span><span class="font3">, </span><span class="font3" style="font-style:italic;">stop words removal, stemming</span><span class="font3">, dan konversi simbol-simbol, serta </span><span class="font3" style="font-style:italic;">emoticon</span><span class="font3">.</span></p>
<h3><a name="bookmark65"></a><span class="font3" style="font-weight:bold;"><a name="bookmark66"></a>Daftar Pustaka</span></h3>
<ul style="list-style:none;"><li>
<p><span class="font3">[1] &nbsp;&nbsp;&nbsp;M. Deoranje, “10+ Akun Instagram Dengan Followers Terbanyak di Indonesia,”</span></p></li></ul>
<p><span class="font3">Musdeoranje.net, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;August &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2016. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[Online]. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Available:</span></p>
<p><a href="http://www.musdeoranje.net/2016/08/akun-instagram-dengan-followers-terbanyak-di-indonesia.html"><span class="font3">http://www.musdeoranje.net/2016/08/akun-instagram-dengan-followers-terbanyak-di-indonesia.html</span></a><span class="font3">. [Acessed on 9 August 2017].</span></p>
<ul style="list-style:none;"><li>
<p><span class="font3">[2] &nbsp;&nbsp;&nbsp;A. Rachmat and Y. Lukito, “Deteksi Komentar Spam Bahasa Indonesia Pada Instagram Menggunakan Naive Bayes,” </span><span class="font3" style="font-style:italic;">Ultimatics - Jurnal Informatika,</span><span class="font3"> vol. 9, no. 1, pp. 50-58, 1 June 2017.</span></p></li>
<li>
<p><span class="font3">[3] &nbsp;&nbsp;&nbsp;Y. Ko, “How to use negative class information for Naive Bayes classification,” </span><span class="font3" style="font-style:italic;">Information Processing &amp;&nbsp;Management,</span><span class="font3"> vol. 53, no. 6, pp. 1255-1268, 2017.</span></p></li>
<li>
<p><span class="font3">[4] &nbsp;&nbsp;&nbsp;F. G. Wei Zhang, “An Improvement to Naive Bayes for Text Classification,” </span><span class="font3" style="font-style:italic;">Procedia Engineering,</span><span class="font3"> vol. 15, no. 15, pp. 2160-2164, 2011.</span></p></li>
<li>
<p><span class="font3">[5] &nbsp;&nbsp;&nbsp;A. Rachmat C e Y. Lukito, “Klasifikasi Sentimen Komentar Politik dari Facebook,” </span><span class="font3" style="font-style:italic;">JUISI, </span><span class="font3">vol. 02, no. 02, 2016.</span></p></li>
<li>
<p><span class="font3">[6] &nbsp;N. O. F. Elssied, O. Ibrahim and A. H. Osman, “Enhancement of spam detection</span></p></li></ul>
<p><span class="font3">mechanism based on hybrid kk,” </span><span class="font3" style="font-style:italic;">Soft Computing,</span><span class="font3"> vol. 19, no. 11, p. 3237–3248, 2015.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font3">[7] &nbsp;L. H. Lee, R. Rajkumar and D. Isa, “Automatic folder allocation system using Bayesian-</span></p></li></ul>
<p><span class="font3">support vector,” </span><span class="font3" style="font-style:italic;">Applied Intelligence,</span><span class="font3"> vol. 36, no. 2, pp. 295-307, March 2012.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font3">[8] &nbsp;&nbsp;&nbsp;S. M. Weiss, N. Indurkhya and T. Zhang, Fundamentals of Predictive Text Mining, 1st ed., London: Springer, 2010, pp. XIV, 226.</span></p></li>
<li>
<p><span class="font3">[9] &nbsp;&nbsp;&nbsp;G. Forman, “An extensive empirical study of feature selection metrics for text classification,” </span><span class="font3" style="font-style:italic;">Journal of machine learning research,</span><span class="font3"> vol. 3, no. March, pp. 1289-1305, 2003.</span></p></li>
<li>
<p><span class="font3">[10] &nbsp;&nbsp;&nbsp;W. Zhang, T. Yoshida and X. Tang, “A comparative study of TF-IDF, LSI, and multi-words for text classification,” </span><span class="font3" style="font-style:italic;">Expert Systems with Application,</span><span class="font3"> vol. 38, no. 2011, pp. 2758-2765, 2010.</span></p></li>
<li>
<p><span class="font3">[11] &nbsp;&nbsp;&nbsp;R. Hail, “Towards a Fusion of Formal and Informal Learning Environments: The Impact of the Read/Write Web,” </span><span class="font3" style="font-style:italic;">Electronic Journal of e-Learning,</span><span class="font3"> vol. 7, no. 1, pp. 29-40, 2009.</span></p></li>
<li>
<p><span class="font3">[12] &nbsp;&nbsp;&nbsp;J. A. Lara, D. Lizcano, M. A. Martínez and J. Pazos, “Developing front-end Web 2.0 technologies to access services, content and things in the future Internet,” </span><span class="font3" style="font-style:italic;">Future Generation Computer Systems,</span><span class="font3"> vol. 29, no. 5, pp. 1184-1195, 2013.</span></p></li>
<li>
<p><span class="font3">[13] &nbsp;&nbsp;&nbsp;Y. Lukito and A. R. Chrismanto, “Perbandingan Metode-Metode Klasifikasi untuk Indoor Positioning System,” </span><span class="font3" style="font-style:italic;">Jutisi (Jurnal Teknik Informatika dan Sistem Informasi),</span><span class="font3"> vol. 1, no. 2, pp. 123-131, 2015.</span></p></li>
<li>
<p><span class="font3">[14] &nbsp;&nbsp;&nbsp;D. Ariadi and K. Fithriasari, “Klasifikasi Berita Indonesia Menggunakan Metode Naive Bayesian Classification dan Support Vector Machine dengan Confix Stripping Stemmer,” </span><span class="font3" style="font-style:italic;">JURNAL SAINS DAN SENI ITS,</span><span class="font3"> vol. 4, no. 2, pp. D248-D253, 2015.</span></p></li>
<li>
<p><span class="font3">[15] &nbsp;&nbsp;&nbsp;S. N. D. Pratiwi and B. S. S. Ulama, “Klasifikasi Email Spam dengan Menggunakan Metode Support Vector Machine dan k-Nearest Neighbor,” </span><span class="font3" style="font-style:italic;">JURNAL SAINS DAN SENI ITS,</span><span class="font3"> vol. 5, no. 2, pp. D-344 - D-349, 2016.</span></p></li>
<li>
<p><span class="font3">[16] &nbsp;&nbsp;&nbsp;H. Jiawei, K. Micheline and P. Jian, Classification: basic concepts. In Data mining Concepts and techniques (3rd ed.), Amsterdam: Elsevier, 2011.</span></p></li>
<li>
<p><span class="font3">[17] &nbsp;&nbsp;&nbsp;S. M. Dr. Suyatno, Data Mining untuk Klasifikasi dan Klasterisasi Data, Bandung:</span></p></li></ul>
<p><span class="font3">Informatika, 2017.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font3">[18] &nbsp;&nbsp;&nbsp;X. Deng, Q. Liu, Y. Deng e S. Mahadevan, “An improved method to construct basic probability assignment based on the confusion matrix for classification problem,” </span><span class="font3" style="font-style:italic;">Information Sciences,</span><span class="font3"> vol. 340–341, no. 1 May 2016, pp. 250-261, 2016.</span></p></li></ul>
<p><span class="font3">231</span></p>