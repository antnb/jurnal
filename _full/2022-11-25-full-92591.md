---
layout: full_article
title: "Deteksi Sarkasme dan Ironi pada Twitter dengan Mengunakan Metode CNN"
author: "Arvanchrist Charlie Wijaya, I Gede Arta Wibawa"
categories: jnatia
canonical_url: https://jurnal.harianregional.com/jnatia/full-92591 
citation_abstract_html_url: "https://jurnal.harianregional.com/jnatia/id-92591"
citation_pdf_url: "https://jurnal.harianregional.com/jnatia/full-92591"  
comments: true
---

<p><span class="font0">JNATIA Volume 1, Nomor 1, November 2022</span></p>
<p><span class="font0">Jurnal Nasional Teknologi Informasi dan Aplikasinya</span></p><a name="caption1"></a>
<h1><a name="bookmark0"></a><span class="font1" style="font-weight:bold;"><a name="bookmark1"></a>Deteksi Sarkasme dan Ironi pada Twitter dengan Mengunakan Metode CNN</span></h1>
<p><span class="font0">Arvanchrist Charlie Wijaya<sup>1</sup></span><span class="font0" style="font-weight:bold;">, </span><span class="font0">I Gede Arta Wibawa<sup>2</sup></span></p>
<ul style="list-style:none;"><li>
<p><span class="font0"><sup>1,2</sup>Informatika, Universitas Udayana</span></p></li></ul>
<p><span class="font0">Kampus Bukit, Jl. Raya Kampus Unud Jimbaran, Kec. Kuta Sel., Kabupaten Badung, Bali, Indonesia</span></p>
<p><a href="mailto:1arvanwijaya01@gmail.com"><span class="font0"><sup>1</sup>arvanwijaya01@gmail.com</span></a><span class="font0"> </span><a href="mailto:2gede.arta@unud.ac.id"><span class="font0"><sup>2</sup>gede.arta@unud.ac.id</span></a></p>
<p><span class="font0" style="font-weight:bold;font-style:italic;">Abstract</span></p>
<p><span class="font0" style="font-style:italic;">Sarcasm refers to the use of words with meaning opposite of what is written or said. With this ambiguity, it could be difficult to tell if the message is sarcastic or not. This paper aim to give some method to detect sarcasm in message, especially in a tweets from Twitter. In this paper we will use a convolutional neural network method to classify the tweets. In this paper we got the accuracy of 73,8% training and 74,6% for validation.</span></p>
<p><span class="font0" style="font-weight:bold;font-style:italic;">Keywords: </span><span class="font0" style="font-style:italic;">Classification, Sentiment Analysis, Sarcasm Detection, Convolutional Neural Network, Natural Language Processing</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark2"></a><span class="font0" style="font-weight:bold;"><a name="bookmark3"></a>1. &nbsp;&nbsp;&nbsp;Pendahuluan</span></h2></li></ul>
<p><span class="font0">Dalam kalimat yang mengandung sarkasme dan ironi umumnya memiliki makna yang berkebalikan dari kata-kata yang digunakan. Apa yang dimaksud dari sarkasme adalah penggunaan kata yang memiliki arti yang berlawanan dengan apa yang ingin disampaikan yang biasanya digunakan dalam menghina atau mengejek orang. Ironi juga menyerupai sarkasme dimana ironi adalah penggunaan kata yang berlainan dengan apa yang terjadi. Tetapi, terdapat pula perbedaan utama dari sarkasme dan ironi, dimana sarkasme memiliki konotasi negatif sedangkan ironi tidak.</span></p>
<p><span class="font0">Kalimat yang mengandung sarkasme dan ironi seringkali sulit untuk dibedakan dengan kalimat biasa[1]. Permasalahan tersebut seringkali menyebabkan salah komunikasi. Oleh karena itulah digunakan teknik-teknik tertentu dalam membedakan kalimat tersebut. Deteksi sarkasme dalam ilmu komputer adalah termasuk dalam bagian analisis sentiment dimana dalam pemrosesan bahasa alami masuk ke dalam jenis permasalahan klasifikasi[2]. Dalam deteksi sarkasme umumnya data tekstual akan diklasifikasikan apakah termasuk sarkasme atau bukan.</span></p>
<p><span class="font0">Pada tulisan ini akan dilakukan deteksi sarkasme pada tweet dari media sosial Twitter. Pesan-pesan tweet dari Twitter ini akan dipisahkan menjadi empat buah kelas yaitu untuk pesan yang mengandung sarkasme, pesan yang mengandung ironi, pesan yang mengandung sarkasme dan ironi, dan pesan yang tidak mengandung sarkasme maupun ironi. Metode klasifikasi yang akan digunakan adalah metode </span><span class="font0" style="font-style:italic;">convolutional neural network</span><span class="font0"> atau CNN. CNN umumnya digunakan dalam proses klasifikasi untuk data citra, namun penggunaan metode CNN tidak terbatas hanya untuk data citra saja[3].</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark4"></a><span class="font0" style="font-weight:bold;"><a name="bookmark5"></a>2. &nbsp;&nbsp;&nbsp;Metodologi</span></h2></li></ul>
<p><span class="font0">Deteksi sarkasme adalah salah satu bagian dari sentimen analisis dari itu dapat menggunakan metode yang serupa[4]. Dalam membangun model untuk melakukan deteksi sarkasme dan ironi akan dilakan dalam beberapa tahapan.</span></p><img src="https://jurnal.harianregional.com/media/92591-1.jpg" alt="" style="width:335pt;height:93pt;">
<p><span class="font0" style="font-weight:bold;">Figure 1. </span><span class="font0">Metodologi Deteksi Sarkasme</span></p>
<p><span class="font0">Dalam tulisan ini akan dilakukan dalam beberapa tahapan dimana pertama-tama adalah dalam pengumpulan data. Ketika sudah ditemukan kemudian dataset akan dipreprocessing dimana data akan diolah untuk dapat digunakan dalam model. Data yang telah dipreprocessing akan dilakukan tokenisasi. Selanjutnya dataset yang telah ditokenisasi akan digunakan untuk melatih model </span><span class="font0" style="font-style:italic;">convolutional neural network</span><span class="font0">. Selanjutnya akan dilakukan evaluasi dan analisis daripada model yang dibuat.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark6"></a><span class="font0" style="font-weight:bold;"><a name="bookmark7"></a>2.1. &nbsp;&nbsp;&nbsp;Pengumpulan Data</span></h2></li></ul>
<p><span class="font0">Dalam pemrosesan bahasa alami banyak sekali sumber data yang dapat digunakan untuk penelitian dari menggunakan artikel-artikel sampai menggunakan data dari sosial media. Dalam penelitian ini digunakan data yang berasal dari sosial media twitter. Alasan diambilnya data dari media sosial Twitter sebab banyaknya ketersediaan data di media sosial.</span></p>
<p><span class="font0">Selain itu, kini juga mudah dan banyak metode yang dapat digunakan untuk mendapatkan data dari sosial media dari menggunakan API</span><span class="font0" style="font-style:italic;">,</span><span class="font0"> melalui </span><span class="font0" style="font-style:italic;">web scraping</span><span class="font0">, dan lain sebagainya[5]. Twitter sendiri memiliki API tersendiri yang banyak dipakai di bebagai penelitian[6]. Selain metode pengumpulan data tersebut terdapat pula data - data dari sumber lain seperti dari repositori -repositori publik. Dalam penelitian ini akan dicari data dari repositori tersebut, sebab pengumpulan data melalui </span><span class="font0" style="font-style:italic;">web scraping</span><span class="font0"> dan API akan menghabiskan waktu yang cukup banyak terutama dalam pelabelan data.</span></p>
<p><span class="font0">Apabila dataset telah ditemukan selanjutnya akan digunakan sebagai data latih serta data validasi. Sebelum data digunakan dalam melatih model akan dilakukan preprocessing data serta tokenisasi.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark8"></a><span class="font0" style="font-weight:bold;"><a name="bookmark9"></a>2.2. &nbsp;&nbsp;&nbsp;Preprocessing Data</span></h2></li></ul>
<p><span class="font0">Preprocessing data bertujuan dalam mempersiapkan data sebelum dilakukan pelatihan pada model[7]. Dalam tahapan ini terdapat berbagai pemrosesan terhadap dataset yang didapatkan diantaranya yaitu menghapus mention, menghapus URL, menghapus hashtag, menghapus angka, menghapus emoticon, </span><span class="font0" style="font-style:italic;">case folding,</span><span class="font0"> menghapus tanda baca, dan tokenisasi.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font0">a. &nbsp;&nbsp;&nbsp;Tweet Cleaning</span></p></li></ul>
<p><span class="font0">Tahapan preprocessing ini bertujuan untuk membersihkan data pada tweet terlebih dahulu. Pada tweet twitter biasanya terdiri atas banyak komponen yang kurang bermanfaat dalam proses deteksi sarkasme seperti diantaranya angka, </span><span class="font0" style="font-style:italic;">emoticon</span><span class="font0">, </span><span class="font0" style="font-style:italic;">hashtag, mention</span><span class="font0">, dan url.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font0">b. &nbsp;&nbsp;&nbsp;Lowercasing</span></p></li></ul>
<p><span class="font0">Tahapan ini adalah salah satu tahapan preprocessing yang ternilai sederhana dimana huruf kapital akan diubah ke dalam huruf kecil. Tahapan ini meski sederhana namun memiliki dampak yang penting. Dengan menggunakan lowercasing maka kata yang semulanya terpisah menjadi kata berbeda karena perbedaan huruf kapital maka kini dapat dihitung sebagai kata yang sama.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font0">c. &nbsp;&nbsp;&nbsp;Punctuation Removal</span></p></li></ul>
<p><span class="font0">Dalam </span><span class="font0" style="font-style:italic;">punctuation removal</span><span class="font0"> dilakukan penghapusan tanda baca serta angka dalam tweet. Hal tersebut dilakukan sebab angka dan tanda baca dianggap tidak memiliki peran dalam menunjukkan apakah kalimat tersebut termasuk dalam sarkasme dan ironi atau bukan.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font0">d. &nbsp;&nbsp;&nbsp;Tokenization</span></p></li></ul>
<p><span class="font0">Tokenisasi adalah proses untuk membagi teks ke dalam token - token[8]. Tiap token terdiri dari satu kata. Pada tokenisasi tiap kata akan direpresentasikan dengan angka bilangan bulat yang unik. Data teks yang telah ditokenisasi adalah data yang baru dapat untuk digunakan untuk melatih model </span><span class="font0" style="font-style:italic;">neural network</span><span class="font0">.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark10"></a><span class="font0" style="font-weight:bold;"><a name="bookmark11"></a>2.3. &nbsp;&nbsp;&nbsp;Perancangan Model</span></h2></li></ul>
<p><span class="font0">Dalam penelitian ini akan digunakan convolutional neural network dalam mendeteksi sarkasme dan ironi. </span><span class="font0" style="font-style:italic;">Convolutional neural network</span><span class="font0"> adalah salah satu jenis </span><span class="font0" style="font-style:italic;">neural network</span><span class="font0"> yang sering digunakan dalam klasifikasi citra.Terdapat pula berbagai jenis </span><span class="font0" style="font-style:italic;">convolutional neural network</span><span class="font0"> atau CNN, seperti yang digunakan dalam klasifikasi citra yaitu CNN dua dimensi. Untuk CNN satu dimensi dapat digunakan untuk berbagai aplikasi seperti </span><span class="font0" style="font-style:italic;">speech recognition, electrocardiogram monitoring,</span><span class="font0"> dan lain sebagainya[9]. Dalam perancangannya berdasarkan data yang digunakan model akan menggunakan konvolusi satu dimensi. Hal itu dikarenakan data teks akan terepresentasikan sebagai kumpulan kata.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark12"></a><span class="font0" style="font-weight:bold;"><a name="bookmark13"></a>3. &nbsp;&nbsp;&nbsp;Hasil dan Pembahasan</span></h2></li></ul>
<p><span class="font0">Pada bagian ini akan diberikan gambaran daripada hasil model yang dibuat. Model diimplementasikan pada Google Colab dengan menggunakan Tensorflow. Terdapat beberapa tahapan pokok dalam implementasi ini yaitu pengambilan data, </span><span class="font0" style="font-style:italic;">preprocessing</span><span class="font0">, pemodelan, dan diakhiri dengan evaluasi.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark14"></a><span class="font0" style="font-weight:bold;"><a name="bookmark15"></a>3.1. &nbsp;&nbsp;&nbsp;Pengambilan Data</span></h2></li></ul>
<p><span class="font0">Pada tahapan ini dilakukan pengambilan data dari Kaggle. Dataset yang digunakan adalah dataset “Tweets with Sarcasm and Irony” yang diupload oleh Nikhil John. Dataset terdiri atas file train.csv dan test.csv. File train.csv terdiri atas 67.997 buah data sedangkan file test.csv terdiri atas 7.994 buah data yang terbagi menjadi empat buah kelas yaitu </span><span class="font0" style="font-style:italic;">regular, sarcasm, irony,</span><span class="font0"> dan </span><span class="font0" style="font-style:italic;">figurative</span><span class="font0">.</span></p>
<p><span class="font0" style="font-weight:bold;">Table 1. </span><span class="font0">Dataset Tweet Sarkasme dan Ironi</span></p>
<table border="1">
<tr><td style="vertical-align:bottom;">
<p><span class="font0">Nama file</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">Jumlah data</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0">train.csv</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">67.997</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font0">test.csv</span></p></td><td style="vertical-align:top;">
<p><span class="font0">7.994</span></p></td></tr>
</table>
<p><span class="font0">Dalam kedua file tersebut terdapat atas dua kolom yaitu </span><span class="font0" style="font-style:italic;">tweet</span><span class="font0"> dan </span><span class="font0" style="font-style:italic;">class</span><span class="font0">. Kolom </span><span class="font0" style="font-style:italic;">tweet</span><span class="font0"> berisikan dengan teks tweet dari Twitter, sedangkan kolom </span><span class="font0" style="font-style:italic;">class</span><span class="font0"> berisikan kelas daripada tweet tersebut. Pada dataset ini terdapat empat buah kelas yaitu </span><span class="font0" style="font-style:italic;">irony</span><span class="font0">, </span><span class="font0" style="font-style:italic;">sarcasm</span><span class="font0">, </span><span class="font0" style="font-style:italic;">figurative</span><span class="font0">, dan </span><span class="font0" style="font-style:italic;">regular</span><span class="font0">. Kelas </span><span class="font0" style="font-style:italic;">irony</span><span class="font0"> yaitu tweet yang mengandung ironi. Kelas </span><span class="font0" style="font-style:italic;">sarcasm</span><span class="font0"> yaitu tweet yang mengandung sarkasme. Kelas </span><span class="font0" style="font-style:italic;">figurative</span><span class="font0"> yaitu tweet yang mengandung ironi dan sarkasme. Kelas </span><span class="font0" style="font-style:italic;">regular</span><span class="font0"> yaitu tweet yang tidak mengandung ironi maupun sarkasme.</span></p><img src="https://jurnal.harianregional.com/media/92591-2.jpg" alt="" style="width:271pt;height:188pt;">
<p><span class="font0" style="font-weight:bold;">Figure 2. </span><span class="font0">Distribusi Kelas Dataset</span></p>
<p><span class="font0">Diagram diatas menggambarkan distribusi kelas daripada dataset yang digunakan dimana yang berwarna biru adalah data dalam file train.csv yang akan digunakan sebagai data latih dan yang berwarna oranye adalah data dalam file test.csv yang akan digunakan sebagai data validasi.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark16"></a><span class="font0" style="font-weight:bold;"><a name="bookmark17"></a>3.2. &nbsp;&nbsp;&nbsp;Preprocessing</span></h2></li></ul>
<p><span class="font0">Data yang diambil selanjutnya akan melalui proses </span><span class="font0" style="font-style:italic;">preprocessing.</span><span class="font0"> Terdapat beberapa tahapan dalam preprocessing yaitu </span><span class="font0" style="font-style:italic;">tweet cleaning</span><span class="font0">, </span><span class="font0" style="font-style:italic;">lowercasing, punctuation removal,</span><span class="font0"> dan </span><span class="font0" style="font-style:italic;">tokenization</span><span class="font0">.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font0">a. &nbsp;&nbsp;&nbsp;Tweet Cleaning</span></p></li></ul>
<p><span class="font0">Berikut adalah tahapan </span><span class="font0" style="font-style:italic;">tweet cleaning</span><span class="font0"> pada salah satu tweet dalam dataset.</span></p>
<p><span class="font0" style="font-weight:bold;">Table 2. </span><span class="font0">Tweet Cleaning</span></p>
<table border="1">
<tr><td style="vertical-align:top;">
<p><span class="font0">Before</span></p></td><td style="vertical-align:top;">
<p><span class="font0">After</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font0">My jobs great because I love what I do (operate rides for kids) and sometimes if the weather's right, I get a shower too!! #rain #sarcasm</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">My jobs great because I love what I do (operate rides for kids) and sometimes if the weather's right, I get a shower too!!</span></p></td></tr>
</table>
<ul style="list-style:none;"><li>
<p><span class="font0">b. &nbsp;&nbsp;&nbsp;Lowercasing</span></p></li></ul>
<p><span class="font0">Berikut adalah tahapan </span><span class="font0" style="font-style:italic;">lowercasing</span><span class="font0"> pada salah satu tweet dalam dataset.</span></p>
<p><span class="font0" style="font-weight:bold;">Table 3. </span><span class="font0">Lowercasing</span></p>
<table border="1">
<tr><td style="vertical-align:top;">
<p><span class="font0">Before</span></p></td><td style="vertical-align:top;">
<p><span class="font0">After</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0">My jobs great because I love what I do (operate rides for kids) and sometimes if the weather's right, I get a shower too!!</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">my jobs great because i love what i do (operate rides for kids) and sometimes if the weather's right, i get a shower too!!</span></p></td></tr>
</table>
<ul style="list-style:none;"><li>
<p><span class="font0">c. &nbsp;&nbsp;&nbsp;Punctuation Removal</span></p></li></ul>
<p><span class="font0">Berikut adalah tahapan </span><span class="font0" style="font-style:italic;">punctuation removal</span><span class="font0"> pada salah satu tweet dalam dataset.</span></p>
<p><span class="font0" style="font-weight:bold;">Table 4. </span><span class="font0">Punctuation Removal</span></p>
<p><span class="font0">Before &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;After</span></p>
<p><span class="font0">my jobs great because i love my jobs great because i love what i do (operate rides for kids) what i do operate rides for kids and sometimes if the weather's and sometimes if the weather's</span></p>
<p><span class="font0">right, i get a shower too!! &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;right i get a shower too</span></p>
<ul style="list-style:none;"><li>
<p><span class="font0">d. &nbsp;&nbsp;&nbsp;Tokenization</span></p></li></ul>
<p><span class="font0">Dalam proses ini digunakan </span><span class="font0" style="font-style:italic;">Tokenizer</span><span class="font0"> dari Tensorflow Keras. Dalam proses tokenisasi data teks dipisahkan menjadi kata - kata serta memiliki representasi bilangan bulat sehingga dapat digunakan sebagai input dari model </span><span class="font0" style="font-style:italic;">neural network.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark18"></a><span class="font0" style="font-weight:bold;"><a name="bookmark19"></a>3.3. &nbsp;&nbsp;&nbsp;Pemodelan</span></h2></li></ul>
<p><span class="font0">Untuk data berupa teks digunakan </span><span class="font0" style="font-style:italic;">convolution neural network</span><span class="font0"> satu dimensi. Terdapat pula berbagai </span><span class="font0" style="font-style:italic;">layers</span><span class="font0"> yang akan digunakan dalam model yaitu </span><span class="font0" style="font-style:italic;">embedding, conv1d, global max pooling 1d,</span><span class="font0"> dan </span><span class="font0" style="font-style:italic;">dense.</span><span class="font0"> Berikut adalah rincian daripada model yang dibuat.</span></p>
<p><span class="font0" style="font-weight:bold;">Table 2. </span><span class="font0">Model Neural Network</span></p>
<table border="1">
<tr><td style="vertical-align:bottom;">
<p><span class="font0">Layer (type)</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">Output Shape</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">Param</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font0">embedding (Embedding)</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">(None, 120, 16)</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">16000</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font0">conv1d (Conv1D)</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">(None, 118, 64)</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">3136</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font0">conv1d_1 (Conv1D)</span></p></td><td style="vertical-align:top;">
<p><span class="font0">(None, 116, 64)</span></p></td><td style="vertical-align:top;">
<p><span class="font0">12352</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0">global_max_pooling1d</span></p>
<p><span class="font0">(GlobalMaxPooling1D)</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">(None, 64)</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">0</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font0">dense (Dense)</span></p></td><td style="vertical-align:top;">
<p><span class="font0">(None, 32)</span></p></td><td style="vertical-align:top;">
<p><span class="font0">2080</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font0">dense_1 (Dense)</span></p></td><td style="vertical-align:top;">
<p><span class="font0">(None, 4)</span></p></td><td style="vertical-align:top;">
<p><span class="font0">132</span></p></td></tr>
</table>
<p><span class="font0">Layer </span><span class="font0" style="font-style:italic;">Embedding</span><span class="font0"> biasanya digunakan dalam data berupa teks. </span><span class="font0" style="font-style:italic;">Layer</span><span class="font0"> ini menerima inputan dari data yang telah ditokenisasi. Setelah masuk </span><span class="font0" style="font-style:italic;">embedding</span><span class="font0"> selanjutnya akan masuk ke layer konvolusi dimana untuk data teks digunakan konvolusi satu dimensi. Pada layer konvolusi data akan dibagi menjadi bagian - bagian yang lebih kecil. Pada layer </span><span class="font0" style="font-style:italic;">max pooling</span><span class="font0"> bagian-bagian dari konvolusi akan digabungkan kembali. Pada layer </span><span class="font0" style="font-style:italic;">dense</span><span class="font0"> terakhir akan ditentukan apakah termasuk sarkasme, ironi, atau tidak.</span></p><img src="https://jurnal.harianregional.com/media/92591-3.jpg" alt="" style="width:425pt;height:127pt;">
<p><span class="font0" style="font-weight:bold;">Figure 3. </span><span class="font0">Neural Network Model</span></p>
<p><span class="font0">Pada model </span><span class="font0" style="font-style:italic;">neural network</span><span class="font0"> yang dibangun digunakan layer </span><span class="font0" style="font-style:italic;">embedding</span><span class="font0"> sebagai layer input. Untuk </span><span class="font0" style="font-style:italic;">hidden layer</span><span class="font0"> dari model yang dibangun terdiri atas layer konvolusi, </span><span class="font0" style="font-style:italic;">max pooling</span><span class="font0">, dan layer </span><span class="font0" style="font-style:italic;">dense</span><span class="font0">. Untuk layer </span><span class="font0" style="font-style:italic;">output</span><span class="font0"> digunakan layer </span><span class="font0" style="font-style:italic;">dense</span><span class="font0"> dengan aktivasi </span><span class="font0" style="font-style:italic;">softmax</span><span class="font0">.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark20"></a><span class="font0" style="font-weight:bold;"><a name="bookmark21"></a>3.4. &nbsp;&nbsp;&nbsp;Hasil</span></h2></li></ul>
<p><span class="font0">Data kemudian dilatih sebanyak 10 epoch. Setelah data dilatih didapatkan nilai akurasi 73,8% untuk data latih dan 74,6% untuk data validasi. Sedangkan, nilai loss yang didapatkan yaitu 0,5</span></p>
<p><span class="font0">untuk data latih dan 0,49 untuk data validasi. Berikut adalah tabel akurasi dan loss dari model yang dibuat.</span></p>
<p><span class="font0" style="font-weight:bold;">Table 3. </span><span class="font0">Akurasi dan Loss Data Latih dan Validasi</span></p>
<table border="1">
<tr><td style="vertical-align:bottom;">
<p><span class="font0">Data</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">Akurasi</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">Loss</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font0">Data Latih</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">73,8%</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">0,5</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font0">Data Validasi</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">74,6%</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">0,49</span></p></td></tr>
</table><img src="https://jurnal.harianregional.com/media/92591-4.jpg" alt="" style="width:233pt;height:159pt;">
<p><span class="font0" style="font-weight:bold;">Figure 4. </span><span class="font0">Grafik Akurasi Model</span></p>
<p><span class="font0">Diatas adalah grafik dari akurasi yang dicapai model. Dari grafik diatas didapatkan bahwa model mencapai puncak akurasi dengan cukup cepat dimana model telah mencapai puncak akurasi pada </span><span class="font0" style="font-style:italic;">epoch</span><span class="font0"> awal.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark22"></a><span class="font0" style="font-weight:bold;"><a name="bookmark23"></a>4. &nbsp;&nbsp;&nbsp;Kesimpulan</span></h2></li></ul>
<p><span class="font0">Berdasarkan penelitian ini ditemukan bahwa metode </span><span class="font0" style="font-style:italic;">convolutional neural network</span><span class="font0"> dapat digunakan dalam pemrosesan bahasa alami yakni dalam hal deteksi sarkasme. Dari hasil latih model didapatkan akurasi 73,8% untuk data latih dan 74,6% untuk data validasi.</span></p>
<h2><a name="bookmark24"></a><span class="font0" style="font-weight:bold;"><a name="bookmark25"></a>References</span></h2>
<ul style="list-style:none;"><li>
<p><span class="font0">[1] &nbsp;&nbsp;&nbsp;S. M. Sarsam, H. Al-Samarraie, A. I. Alzahrani, and B. Wright. “Sarcasm detection using machine learning algorithms in Twitter: A systematic review” </span><span class="font0" style="font-style:italic;">International Journal of Market Research</span><span class="font0">, vol.62, no.5, p. 578-598</span></p></li>
<li>
<p><span class="font0">[2] &nbsp;&nbsp;&nbsp;P. M. Nadkarni, L. Ohno-Machado and W. W. Chapman. “Natural language processing: an introduction” </span><span class="font0" style="font-style:italic;">Journal of the American Medical Informatics Association</span><span class="font0">, vol.18, no.5, p. 544551, 2011</span></p></li>
<li>
<p><span class="font0">[3] &nbsp;&nbsp;&nbsp;W. Yin, K. Kann, M. Yu, and H. Schutze. “Comparative study of CNN and RNN for natural language processing”. 2017</span></p></li>
<li>
<p><span class="font0">[4] &nbsp;&nbsp;&nbsp;A. Kedia and M. Rasu. “Hands-on Python natural language processing: explore tools and techniques to analyze and process text with a view to building real-world NLP applications”. Packt Publishing Ltd. 2020</span></p></li>
<li>
<p><span class="font0">[5] H. Liang and J. J. Zhu. “Big data, collection of (social media, harvesting)” </span><span class="font0" style="font-style:italic;">The international</span></p></li></ul>
<p><span class="font0" style="font-style:italic;">encyclopedia of communication research methods,</span><span class="font0"> p. 1-18. 2017</span></p>
<ul style="list-style:none;"><li>
<p><span class="font0">[6] &nbsp;&nbsp;&nbsp;A. Karami, M. Lundy, F. Webb, and Y. K. Dwivedi. “Twitter and research: A systematic literature review through text mining” </span><span class="font0" style="font-style:italic;">IEEE Access</span><span class="font0">, vol. 8, p. 67698-67717. 2020</span></p></li>
<li>
<p><span class="font0">[7] &nbsp;&nbsp;&nbsp;J. Camacho-Collados and M. T. Pilehvar. “On the role of text preprocessing in neural network architectures: An evaluation study on text categorization and sentiment analysis”. 2017</span></p></li>
<li>
<p><span class="font0">[8] &nbsp;&nbsp;&nbsp;T. Jo. “Text mining: Concepts, implementation, and big data challenge”, vol. 45. Springer. 2018</span></p></li>
<li>
<p><span class="font0">[9] &nbsp;&nbsp;&nbsp;S. Kiranyaz, O. Avci, O. Abdeljabel, T. Ince, M. Gabbouj, and D. J. Inman. “1 D convolutional neural networks and applications: A survey” </span><span class="font0" style="font-style:italic;">Mechanical systems and signal processing, 151, 107398</span></p></li></ul>
<p><span class="font0">Halaman ini sengaja dibiarkan kosong</span></p>
<p><span class="font2">360</span></p>