---
layout: full_article
title: "Analisis Sentimen pada Teks Berbahasa Bali Menggunakan Metode Multinomial Naive Bayes dengan TF-IDF dan BoW"
author: "Putu Widyantara Artanta Wibawa, Cokorda Rai Adi Pramartha"
categories: jnatia
canonical_url: https://jurnal.harianregional.com/jnatia/full-102412 
citation_abstract_html_url: "https://jurnal.harianregional.com/jnatia/id-102412"
citation_pdf_url: "https://jurnal.harianregional.com/jnatia/full-102412"  
comments: true
---

<p><span class="font2">JNATIA Volume 2, Nomor 1, November 2023</span></p>
<p><span class="font2">Jurnal Nasional Teknologi Informasi dan Aplikasinya</span></p>
<p><span class="font2">p-ISSN: 2986-3929</span></p>
<p><span class="font3" style="font-weight:bold;">Analisis Sentimen pada Teks Berbahasa Bali Menggunakan Metode Multinomial Naive Bayes dengan TF-IDF dan BoW</span></p>
<p><span class="font2">Putu Widyantara Artanta Wibawa<sup>a1</sup></span><span class="font2" style="font-weight:bold;">, </span><span class="font2">Cokorda Pramartha<sup>a2</sup></span></p>
<p><span class="font2"><sup>a</sup>Program Studi Informatika, Fakultas Matematika dan Ilmu Pengetahuan Alam Universitas Udayana, Bali</span></p>
<p><span class="font2">Jln. Raya Kampus UNUD, Bukit Jimbaran, Kuta Selatan, Badung, 08261, Bali, Indonesia </span><a href="mailto:1putuwaw973@gmail.com"><span class="font2"><sup>1</sup>putuwaw973@gmail.com</span></a><span class="font2"> </span><a href="mailto:2cokorda@unud.ac.id"><span class="font2"><sup>2</sup>cokorda@unud.ac.id</span></a></p>
<p><span class="font2" style="font-weight:bold;font-style:italic;">Abstract</span></p>
<p><span class="font2" style="font-style:italic;">Currently, digital technology is developing rapidly thus increasing the availability of textual data in the digital form. Many of the digital texts are available in Balinese. From the existing Balinese language texts, an analysis can be carried out to determine the emotional level or sentiment contained in them. Through this analysis, information will be obtained regarding sentiment towards a product or service so that it can be used as information for consideration in making decisions. To determine sentiment in textual data, more specifically unstructured data, several stages are required, one of which is feature extraction such as TF-IDF and BoW. This study will analyze the effect of TF-IDF and BoW feature extraction on the Multinomial Naive Bayes method. The test results show that the TF-IDF feature extraction provides precision, recall, accuracy, and F1-score values respectively 92.3%, 91.13%, 91.5%, and 91.38% higher than with BoW feature extraction.</span></p>
<p><span class="font2" style="font-weight:bold;font-style:italic;">Keywords: </span><span class="font2" style="font-style:italic;">Sentiment Analysis, Balinese Language, Multinomial Naive Bayes, TF-IDF, BoW</span></p>
<ul style="list-style:none;"><li><a name="caption1"></a>
<h1><a name="bookmark0"></a><span class="font2" style="font-weight:bold;"><a name="bookmark1"></a>1. &nbsp;&nbsp;&nbsp;Pendahuluan</span></h1></li></ul>
<p><span class="font2">Dewasa ini teknologi telah mengalami perkembangan yang sangat pesat. Pesatnya perkembangan teknologi telah menyebabkan pertumbungan yang signifikan terhadap ketersediaan data, salah satunya adalah data tekstual [1]. Dari banyaknya data tekstual yang ada, beberapa diantaranya menggunakan bahasa Bali. Bahasa Bali merupakan bahasa daerah yang masih eksis dituturkan oleh penduduk Bali hingga saat ini [2]. Beberapa inisiasi pelestarian dan pemajuan Bahasa dan Aksara Bali dalam bentuk digital telah dilakukan oleh komunitas dan peneliti. Dari teks berbahasa Bali yang ada dapat dilakukan analisis untuk menentukan tingkat emosional atau sentimen yang terdapat didalamnya.</span></p>
<p><span class="font2">Banyaknya jumlah teks yang ada menyulitkan proses untuk melakukan analisis atau sentimen dari suatu teks. Terlebih lagi jika analisis tersebut dilakukan secara manual. Oleh karena itu, diperlukan sebuah sebuah sistem yang mampu untuk melakukan analisis sentimen dari suatu teks secara otomatis. Analisis sentimen sendiri adalah proses untuk mendapatkan informasi tentang sentimen baik sentimen positif, negatif, maupun netral dari suatu teks. Analisis sentimen termasuk ke dalam permasalahan klasifikasi, yaitu bagian dari </span><span class="font2" style="font-style:italic;">supervised maching learning</span><span class="font2"> yang memungkinkan model untuk memberikan prediksi dari masukan baru yang diberikan setelah dilatih dengan menggunakan data berlabel [3].</span></p>
<p><span class="font2">Saat ini, analisis sentimen merupakan salah satu bidang dalam NLP yang memiliki banyak manfaat di berbagai sektor kehidupan. Pada sektor ekonomi atau bisnis, analisis sentimen dapat digunakan untuk mengukur tingkat kepuasan pengguna terhadap produk atau jasa yang diberikan oleh perusahan. Sentimen analisis juga dapat digunakan pada sektor pendidikan untuk mengetahui tingkat kepuasan siswa terhadap materi pembelajaran yang diberikan. Selain itu,</span></p>
<p><span class="font2">pada sektor pemerintahan analisis sentimen juga dapat digunakan untuk melihat respon masyarakat terhadap kebijakan yang diberlakukan.</span></p>
<p><span class="font2">Terdapat cukup banyak penelitian tedahulu yang telah melakukan analisis sentimen. Beberapa diataranya menggunakan metode Mutlinomial Naive Bayes karena metode ini memiliki kecepatan dan akurasi yang tinggi ketika digunakan data yang besar dan beragam [4]. Selain itu, jika dibandingkan dari segi kompleksitas, metode Multinomial Naive Bayes lebih sederhana dibandingkan dengan algoritma lainnya, sehingga akan memiliki waktu komputasi yang lebih singkat untuk melakukan proses klasifikasi [5].</span></p>
<p><span class="font2">Dalam melakukan analisis sentimen, khususnya dari data tekstual yang tidak terstruktur, diperlukan proses untuk mengekstraksi fitur yang ada dari data tersebut. Setelah ekstraksi fitur akan dilakukan seleksi fitur dan kemudian mengaplikasikan metode untuk melakukan klasifikasi [6]. Terdapat beberapa teknik ekstraksi fitur yang ada, diantaranya seperti TF-IDF, Bag of Words, dan Word Embedding. Penggunaan ekstraksi fitur yang tepat akan mampu untuk meningkatkan performa dari model. Oleh karena itu, pada penelitian ini akan membandingkan pengaruh ekstraksi fitur TF-IDF dengan Bag of Words (BoW) terhadap performa dari metode Multinomial Naive Bayes. Diharapkan dengan dilakukannya penelitian ini dapat membantu dalam melakukan analisis atau klasifikasi terhadap sentimen pada teks berbahasa Bali.</span></p>
<ul style="list-style:none;"><li>
<h1><a name="bookmark2"></a><span class="font2" style="font-weight:bold;"><a name="bookmark3"></a>2. &nbsp;&nbsp;&nbsp;Metode Penelitian</span></h1>
<ul style="list-style:none;">
<li>
<h1><a name="bookmark4"></a><span class="font2" style="font-weight:bold;"><a name="bookmark5"></a>2.1. &nbsp;&nbsp;&nbsp;Desain Penelitian</span></h1><img src="https://jurnal.harianregional.com/media/102412-1.jpg" alt="" style="width:178pt;height:247pt;"></li></ul></li></ul>
<p><span class="font2" style="font-weight:bold;">Gambar 1. </span><span class="font2">Bagan Alur Penelitian</span></p>
<p><span class="font2">Penelitian ini diawali dengan pengumpulan data terhadap teks berbahasa Bali yang nantinya akan dilakukan proses analisis sentimen. Setelah data terkumpul, tahapan selanjutnya adalah melakukan proses </span><span class="font2" style="font-style:italic;">text preprocessing</span><span class="font2">. Kemudian, akan dilakukan perhitungan ekstraksi fitur menggunakan Term Frequency-Inverse Document Frequency (TF-IDF) dan Bag of Words (BoW). Setelah ekstraksi fitur, selanjutnya adalah melakukan pelatihan model Multinomial Naive Bayes dengan kedua jenis ekstraksi fitur tersebut. Tahap terakhir adalah melakukan evaluasi terhadap model untuk menentukan model dengan ekstraksi fitur yang menghasilkan performa terbaik.</span></p>
<ul style="list-style:none;"><li>
<h1><a name="bookmark6"></a><span class="font2" style="font-weight:bold;"><a name="bookmark7"></a>2.2. &nbsp;&nbsp;&nbsp;Pengumpulan Data</span></h1></li></ul>
<p><span class="font2">Data yang digunakan pada penelitian ini adalah data sekunder yang berasal dari NusaX-Senti, yaitu dataset sentimen analisis untuk 10 bahasa daerah di Indonesia [7]. Dataset yang digunakan adalah dataset sentimen bahasa Bali yang terdiri atas 1000 data yang tersebar ke dalam 3 kelas, yaitu sentimen positif sebanyak 378 data, netral sebanyak 239 data, dan sentimen negatif sebanyak 383 data. Pada penelitian ini, hanya akan digunakan dua kelas, yaitu kelas atau label positif dan label negatif. Gambaran data yang akan digunakan pada penelitian ini ditunjukkan pada Tabel 1.</span></p>
<p><span class="font2" style="font-weight:bold;">Tabel 1. </span><span class="font2">Gambaran Dataset</span></p>
<table border="1">
<tr><td style="vertical-align:middle;">
<p><span class="font2" style="font-weight:bold;">id</span></p></td><td style="vertical-align:middle;">
<p><span class="font2" style="font-weight:bold;">text</span></p></td><td style="vertical-align:middle;">
<p><span class="font2" style="font-weight:bold;">label</span></p></td></tr>
<tr><td colspan="2" style="vertical-align:bottom;">
<p><span class="font2">592 Pelayanan bus DAMRI luung pesan.</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">positive</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font2">317</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">Dot ngae postingan sane isine mengedukasi customers gojek.</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">neutral</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font2">352</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">Satusan umah ring medan merendem banjir</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">neutral</span></p></td></tr>
</table>
<ul style="list-style:none;"><li>
<h1><a name="bookmark8"></a><span class="font2" style="font-weight:bold;"><a name="bookmark9"></a>2.3. &nbsp;&nbsp;&nbsp;Text Preprocessing</span></h1></li></ul>
<p><span class="font2">Text preprocessing adalah tahap pertama dalam klasifikasi teks yang mengubah data teks asli yang tidak terstruktur menjadi data yang terstruktur sekaligus juga untuk mengidentifikasi fitur dari teks yang paling signifikan untuk membedakan antara kategori teks [8]. Tahap ini akan menghasilkan data teks yang siap digunakan untuk proses selanjutnya. Adapun tahapan dalam text preprocessing ini ditunjukkan pada Gambar 2.</span></p><img src="https://jurnal.harianregional.com/media/102412-2.jpg" alt="" style="width:384pt;height:106pt;">
<p><span class="font2" style="font-weight:bold;">Gambar 2. </span><span class="font2">Tahapan Text Preprocessing</span></p>
<p><span class="font2">Tahapan pertama dalam </span><span class="font2" style="font-style:italic;">text preprocessing</span><span class="font2"> adalah melakukan </span><span class="font2" style="font-style:italic;">case folding</span><span class="font2">, yaitu mengubah semua huruf menjadi huruf kecil atau </span><span class="font2" style="font-style:italic;">lowercase.</span><span class="font2"> Setelah dilakukan </span><span class="font2" style="font-style:italic;">case folding</span><span class="font2">, tahapan selanjutnya adalah menghilangkan karakter selain alfabet seperti tanda baca dan angka. Kemudian, data teks akan dilakukan proses </span><span class="font2" style="font-style:italic;">filtering</span><span class="font2"> untuk menghilangkan kata-kata yang bukan berasal dari bahasa Bali. Tahapan terakhir setelah </span><span class="font2" style="font-style:italic;">filtering</span><span class="font2"> adalah tokenisasi, yaitu memecah data teks menjadi token-token.</span></p>
<ul style="list-style:none;"><li>
<h1><a name="bookmark10"></a><span class="font2" style="font-weight:bold;"><a name="bookmark11"></a>2.4. &nbsp;&nbsp;&nbsp;Ekstraksi Fitur</span></h1></li></ul>
<p><span class="font2">Dalam penelitian ini, terdapat dua metode ekstraksi fitur yang akan digunakan yaitu Term Frequency-Invers Document Frequency (TF-IDF) dan Bag of Words (BoW).</span></p>
<ul style="list-style:none;"><li>
<h1><a name="bookmark12"></a><span class="font2" style="font-weight:bold;"><a name="bookmark13"></a>2.4.1. &nbsp;&nbsp;&nbsp;TF-IDF (Term Frequency-Invers Document Frequency)</span></h1></li></ul>
<p><span class="font2">TF-IDF adalah algoritma yang dapat digunakan untuk melakukan ekstraksi fitur pada dokumen. Algoritma ini menunjukkan informasi mengenai pentingnya suatu kata pada dokumen. Prinsipnya adalah jika suatu kata atau frasa sering muncul di suatu kelas dokumen namun tidak muncul di kelas dokumen yang lain, maka kata atau frasa tersebut dianggap memiliki pembeda yang baik untuk klasifikasi [9]. Nilai TF-IDF didapatkan dengan menghitung TF (</span><span class="font2" style="font-style:italic;">term frequency</span><span class="font2">) yang</span></p>
<p><span class="font2">dikalikan dengan IDF </span><span class="font2" style="font-style:italic;">(invers document frequency</span><span class="font2">). Representasi matematis dari bobot term </span><span class="font6">d </span><span class="font2">dalam dokumen </span><span class="font6">t </span><span class="font2">oleh TF-IDF diberikan dalam Persamaan 1 [10].</span></p>
<p><span class="font10" style="font-style:italic;">Nx</span></p>
<p><span class="font10" style="font-style:italic;">W(d,t)=TF(d,t)×</span><span class="font6"> log (—</span><span class="font13">) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="font2">(1)</span></p>
<p><span class="font2">Dimana </span><span class="font6">TF</span><span class="font13">(</span><span class="font6">d</span><span class="font13">,</span><span class="font6">t</span><span class="font13">) </span><span class="font2">adalah </span><span class="font2" style="font-style:italic;">term frequency</span><span class="font2"> atau jumlah kemunculan term </span><span class="font6">d </span><span class="font2">dalam dokumen </span><span class="font6">t</span><span class="font2">, </span><span class="font6">N </span><span class="font2">adalah jumlah dokumen, </span><span class="font6">df</span><span class="font13">(</span><span class="font6">t</span><span class="font13">) </span><span class="font2">adalah jumlah dokumen yang mengantung term t.</span></p>
<ul style="list-style:none;"><li>
<h1><a name="bookmark14"></a><span class="font2" style="font-weight:bold;"><a name="bookmark15"></a>2.4.2. &nbsp;&nbsp;&nbsp;BoW (Bag of Words)</span></h1></li></ul>
<p><span class="font2">Bag of Words (BoW) adalah sebuah teknik ekstraksi fitur untuk merepresentasikan dokumen teks ke dalam bentuk matriks. Teknik ini bekerja dengan cara mempelajari seluruh kosakata dari dokumen, lalu memodelkan tiap dokumen dengan menghitung jumlah kemunculan tiap katanya [11]. Dalam Bag of Words, matriks yang dihasilkan akan tidak akan mampu untuk menangkap baik struktur dari kalimat maupun hubungan semantik yang ada pada kalimat [10].</span></p>
<ul style="list-style:none;"><li>
<h1><a name="bookmark16"></a><span class="font2" style="font-weight:bold;"><a name="bookmark17"></a>2.5. &nbsp;&nbsp;&nbsp;Multinomial Naive Bayes</span></h1></li></ul>
<p><span class="font2">Multinomial Naive Bayes adalah salah satu bagian dari Naive Bayes yang termasuk ke dalam supervised learning. Algoritma ini bekerja dengan prinsip distribusi multinomial dan dapat diterapkan pada kasus teks dengan mengkonversi ke bentuk nominal yang dapat dihitung dengan nilai bilangan bulat [12]. Algoritma ini akan menghitung probabilitas sebuah dokumen </span><span class="font6">d </span><span class="font2">terhadap kelas </span><span class="font6">C </span><span class="font2">yang ditunjukkan pada Persamaan 2 [13].</span></p>
<p><span class="font10" style="font-style:italic;">N<sub>c</sub></span></p>
<p><span class="font10" style="font-style:italic;">P(C)</span><span class="font13"> = ^ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="font4"><sup>(2)</sup></span></p>
<p><span class="font2">Dimana </span><span class="font6">N<sub>c</sub> </span><span class="font2">adalah jumlah kelas </span><span class="font6">C </span><span class="font2">pada seluruh dokumen dan </span><span class="font6">N </span><span class="font2">adalah jumlah seluruh dokumen. Untuk probabilitas dari kata ke-n ditentukan dengan menggunakan persamaan berikut:</span></p>
<p><span class="font10" style="font-style:italic;">N<sub>r</sub> + + ot</span></p>
<p><span class="font13"><sup>w</sup>) = N≡τV &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="font4"><sup>(3)</sup></span></p>
<p><span class="font2">Dimana </span><span class="font6">N</span><span class="font5">x<sub>n</sub> ,</span><span class="font6"><sub>c</sub> </span><span class="font2">adalah jumlah term </span><span class="font6">X<sub>n</sub> </span><span class="font2">yang ditemukan di seluruh data training pada kelas </span><span class="font6">C </span><span class="font2">dan </span><span class="font6">N</span><span class="font13">(</span><span class="font6">C</span><span class="font13">) </span><span class="font2">adalah jumlah term di seluruh data training pada kelas </span><span class="font6">C</span><span class="font2">, dan </span><span class="font6">α </span><span class="font2">adalah parameter laplace smoothing, </span><span class="font6">V </span><span class="font2">adalah jumlah seluruh kata pada data training. Sementara rumus Multinomial yang digunakan dalam pembobotan TF-IDF adalah sebagai berikut:</span></p>
<p><span class="font13">p'χ ■■■■ &nbsp;&nbsp;∑</span><span class="font14"><sup>t</sup>√,<sup>,d</sup> </span><span class="font13">(C''</span><span class="font14"><sup>o</sup> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="font2">(4)</span></p>
<p><span class="font10" style="font-style:italic;">L<sup>N</sup></span><span class="font7" style="font-style:italic;">dec</span><span class="font14"> <sup>+ v</sup></span></p>
<p><span class="font2">Dimana </span><span class="font13">∑ </span><span class="font6">tf</span><span class="font13">(</span><span class="font6">X<sub>n</sub></span><span class="font13">,</span><span class="font6">d </span><span class="font12">∈</span><span class="font13"> </span><span class="font6">C</span><span class="font13">) </span><span class="font2">adalah jumlah pembobotan kata </span><span class="font6">X</span><span class="font5">n</span><span class="font2">dari seluruh data training pada kelas C dan </span><span class="font13">∑ </span><span class="font6">N<sub>d</sub></span><span class="font11">∈</span><span class="font5">C </span><span class="font2">adalah jumlah bobot seluruh term pada data training pada kelas C.</span></p>
<p><span class="font2">Dalam penelitian ini, dataset yang telah melalui </span><span class="font2" style="font-style:italic;">text preprocessing</span><span class="font2"> akan dibagi menjadi 80% untuk </span><span class="font2" style="font-style:italic;">training</span><span class="font2"> dan 20% untuk </span><span class="font2" style="font-style:italic;">testing</span><span class="font2">. Tahapan ekstraksi fitur akan menggunakan ekstraksi fitur Bag of Words dan TF-IDF. Kedua ekstraksi fitur akan dicoba dengan menggunakan jumlah NGram 1 sampai 2 (unigram dan bigram) dengan jumlah maksimal 4000 fitur. Dari skenario tersebut, akan dicari model Multinomial Naive Bayes dengan ekstraksi fitur yang memiliki performa terbaik. Performa yang ditinjau dalam penelitian ini adalah tingkat </span><span class="font2" style="font-style:italic;">accuracy, recall, precision</span><span class="font2">, dan F1-</span><span class="font2" style="font-style:italic;">score</span><span class="font2">. Adapun skema dari pelatihan model Multinomial Naive Bayes ditunjukkan oleh Gambar 3.</span></p>
<div><img src="https://jurnal.harianregional.com/media/102412-3.jpg" alt="" style="width:199pt;height:243pt;">
</div><br clear="all">
<p><span class="font2" style="font-weight:bold;">Gambar 3</span><span class="font2">. Skema Pelatihan Model Multinomial Naive Bayes</span></p>
<ul style="list-style:none;"><li>
<h1><a name="bookmark18"></a><span class="font2" style="font-weight:bold;"><a name="bookmark19"></a>2.6. &nbsp;&nbsp;&nbsp;Evaluasi</span></h1></li></ul>
<p><span class="font2">Evaluasi akan dilakukan dengan menggunaan data </span><span class="font2" style="font-style:italic;">testing</span><span class="font2"> yang telah dibagi sebelumnya. Pada tahap evaluasi akan dihitung performa dari tiap model untuk mencari model dengan performa tertinggi yang diukur dari akurasi, presisi, recall, dan F1-score. Perhitungan akurasi didapatkan pada </span><span class="font2" style="font-style:italic;">confusion matrix</span><span class="font2">. </span><span class="font2" style="font-style:italic;">Confusion matrix</span><span class="font2"> sendiri adalah sebuah matriks dua dimensi yang menunjukkan hasil prediksi dari model dan hasil sebenarnya [4]. Untuk menghitung performa dari model melalui akurasi, presisi, recall, dan F1-score dapat digunakan rumus sebagai berikut [4]:</span></p>
<div>
<p><span class="font10" style="font-style:italic;">TP</span></p>
<p><span class="font10" style="font-style:italic;">Precision = </span><span class="font9" style="font-style:italic;text-decoration:line-through;"><sub>τp</sub> </span><span class="font8" style="font-style:italic;text-decoration:line-through;">+ </span><span class="font9" style="font-style:italic;text-decoration:line-through;"><sub>Fp</sub></span></p>
</div><br clear="all">
<div>
<p><span class="font10" style="font-style:italic;">Recall =</span></p>
</div><br clear="all">
<div>
<p><span class="font10" style="font-style:italic;">TP</span></p>
<p><span class="font10" style="font-style:italic;">TP+ FN</span></p>
</div><br clear="all">
<div>
<p><span class="font10" style="font-style:italic;">TP + TN Accuracy =</span></p>
<p><span class="font10" style="font-style:italic;">TP + TN + FP + FN</span></p>
</div><br clear="all">
<div>
<p><span class="font10" style="font-style:italic;">F</span><span class="font6" style="font-style:italic;">1</span></p>
</div><br clear="all">
<div>
<p><span class="font10" style="font-style:italic;">— Score = </span><span class="font6" style="font-style:italic;">2</span><span class="font13"> ×</span></p>
</div><br clear="all">
<div>
<p><span class="font10" style="font-style:italic;">Precision × Recall</span></p>
<p><span class="font10" style="font-style:italic;">Precision + Recall</span></p>
</div><br clear="all">
<div>
<p><span class="font2">(5)</span></p>
<p><span class="font2">(6)</span></p>
<p><span class="font2">(7)</span></p>
<p><span class="font2">(8)</span></p>
</div><br clear="all">
<ul style="list-style:none;"><li>
<h1><a name="bookmark20"></a><span class="font2" style="font-weight:bold;"><a name="bookmark21"></a>3. &nbsp;&nbsp;&nbsp;Hasil dan Pembahasan</span></h1>
<ul style="list-style:none;">
<li>
<h1><a name="bookmark22"></a><span class="font2" style="font-weight:bold;"><a name="bookmark23"></a>3.1 . &nbsp;Preprocessing Data</span></h1></li></ul></li></ul>
<p><span class="font2">Dari data yang berjumlah 383 data dengan label positif dan 378 data dengan label negatif terlebih dahulu dilakukan proses </span><span class="font2" style="font-style:italic;">preprocessing</span><span class="font2"> untuk keseragaman dan meningkatkan performa dari model. Hasil dari text preprocessing ditampilkan pada Tabel 2.</span></p>
<p><span class="font2" style="font-weight:bold;">Tabel 2. </span><span class="font2">Tabel Hasil Text Preprocessing</span></p>
<table border="1">
<tr><td style="vertical-align:middle;">
<p><span class="font2" style="font-weight:bold;">No. Proses</span></p></td><td style="vertical-align:middle;">
<p><span class="font2" style="font-weight:bold;">Hasil</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font2">1 &nbsp;&nbsp;&nbsp;&nbsp;Initial Data</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">Iraga saling megedegan ajak sane lianan uli 4 warsa sane lintang.</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2">2 &nbsp;&nbsp;Case Folding</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">iraga saling megedegan ajak sane lianan uli 4 warsa sane lintang.</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font2">3 &nbsp;&nbsp;Number removal</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">iraga saling megedegan ajak sane lianan uli warsa sane lintang.</span></p></td></tr>
</table>
<table border="1">
<tr><td style="vertical-align:middle;">
<p><span class="font2">4</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">Punctutation removal</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">iraga saling megedegan ajak sane lianan uli warsa sane lintang</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font2">5</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">Tokenization</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">['iraga', 'saling', 'megedegan', 'ajak', 'sane', 'lianan', 'uli', 'warsa', 'sane', 'lintang']</span></p></td></tr>
</table>
<p><span class="font2">Selain itu, label dari data akan dilakukan proses </span><span class="font2" style="font-style:italic;">mapping</span><span class="font2"> untuk mengubahnya menjadi data nominal, dimana label negatif akan diubah menjadi -1 dan label positif akan diubah menjadi 1.</span></p>
<p><span class="font2">Adapun hasil akhir dari </span><span class="font2" style="font-style:italic;">text preprocessing</span><span class="font2"> dan label </span><span class="font2" style="font-style:italic;">mapping</span><span class="font2"> ditampilkan pada Tabel 3.</span></p>
<p><span class="font2" style="font-weight:bold;">Tabel 3. </span><span class="font2">Tabel Hasil Akhir </span><span class="font2" style="font-style:italic;">Text Preprocessing</span><span class="font2"> dan Label </span><span class="font2" style="font-style:italic;">Mapping</span></p>
<table border="1">
<tr><td style="vertical-align:middle;">
<p><span class="font2" style="font-weight:bold;">text</span></p></td><td style="vertical-align:middle;">
<p><span class="font2" style="font-weight:bold;">label</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2">['jajejaje', 'ne', 'sane', 'kasajiang', 'ngaenang', 'tiang', 'bernostalgia', 'makejang', 'sakadi', 'jaje', 'jaman', 'ipidan', 'uli', 'penampilanne', 'tur', 'rasa', 'ne', 'jajene', 'jaan', 'lan', 'ajine', 'mudah']</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">1</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2">['paling', 'demen', 'sajan', 'ngajeng', 'siang', 'driki', 'be', 'siap', 'lan', 'sambelne', 'jaen', 'sajan', 'ajine', 'jeg', 'mudah', 'sajan', 'rasan', 'be', 'siap', 'ne', 'ngresep', 'kanti', 'ke', 'tulang', 'ne', 'ngrasa', 'lebih', 'jaen', 'ke', 'waduk']</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">1</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font2">['pelayanan', 'bus', 'damri', 'luung', 'pesan']</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">1</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2">['barange', 'lumayan', 'nanging', 'sane', 'tiang', 'heran', 'xiaomi', 'redmi', 'note', 'niki', 'tombol', 'onne', 'mula', 'agak', 'usak', 'terus', 'batre', 'mula', 'enggal', 'low', 'bat', 'bos']</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">-1</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font2">['keweh', 'sajan', 'ngugu', 'anak', 'ane', 'suba', 'taen', 'berkhianat']</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">-1</span></p></td></tr>
</table>
<ul style="list-style:none;"><li>
<h1><a name="bookmark24"></a><span class="font2" style="font-weight:bold;"><a name="bookmark25"></a>3.2 &nbsp;&nbsp;&nbsp;Perhitungan Ekstraksi Fitur</span></h1></li></ul>
<p><span class="font2">Setelah data setelesai melalui tahap </span><span class="font2" style="font-style:italic;">preprocessing</span><span class="font2">, kemudian akan dilakukan ekstraksi fitur dengan TF-IDF dan Bag of Words (BoW). Dalam melakukan proses ekstraksi fitur, digunakan bantuan dari modul CountVectorizer dan TfidfVectorizer dari library scikit-learn dengan menggunakan bahasa pemrograman Python. Jumlah maksimal fitur yang digunakan adalah 4000 dan ngram yang digunakan adalah unigram dan bigram.</span></p>
<p><span class="font0">tfidf = TfidfVectorizer(max_features=4000<sub>s</sub> ngram_range=( 1, 2))</span></p>
<p><span class="font0">bow = CountVectorizer(max_features=4ΘΘΘ, ngram range=(l, 2))</span></p>
<p><span class="font0">X_train_tfidf = tfidf.fit tra∏5form(X_train)</span></p>
<p><span class="font0">X_test„tfidf = tfidf.transformX test)</span></p>
<p><span class="font0">X_train_bow = bow.fit<sub>-</sub>transform(X_train)</span></p>
<p><span class="font0">X_test_bow ≡ bow.transform(X_test)</span></p>
<p><span class="font2" style="font-weight:bold;">Gambar 4. </span><span class="font2">Implementasi Ekstraksi Fitur</span></p>
<ul style="list-style:none;"><li>
<h1><a name="bookmark26"></a><span class="font2" style="font-weight:bold;"><a name="bookmark27"></a>3.3 &nbsp;&nbsp;&nbsp;Pemodelan Multinomial Naive Bayes</span></h1></li></ul>
<p><span class="font2">Model Multinomial Naive Bayes dibangun dengan menggunakan bantuan library scikit-learn dalam bahasa pemrograman Python. Salah satu </span><span class="font2" style="font-style:italic;">hyperparameter</span><span class="font2"> yang digunakan adalah </span><span class="font2" style="font-style:italic;">alpha </span><span class="font2">atau </span><span class="font2" style="font-style:italic;">laplace smoothing</span><span class="font2"> sebesar 0,1. Setelah itu model akan dilatih dengan data </span><span class="font2" style="font-style:italic;">training</span><span class="font2"> yang telah dilakukan ekstraksi fitur TF-IDF dan Bag of Words untuk kemudian dilakukan evaluasi menggunakan data </span><span class="font2" style="font-style:italic;">testing</span><span class="font2">.</span></p>
<p><span class="font1">mnbtfidf = MultinomialNB(alpha=.1)</span></p>
<p><span class="font1">mnb_tfidf.fit(X_train_tfidf, y_train)</span></p>
<p><span class="font1">mnb_bow = MultinomialNB(alpha=.1)</span></p>
<p><span class="font1">m∏b bow.ftt(X_train_bow, ytrain)</span></p>
<p><span class="font2" style="font-weight:bold;">Gambar 5. </span><span class="font2">Implementasi Multinomial Naive Bayes</span></p>
<p><span class="font2">Selanjutnya, setiap model akan diuji menggunakan data </span><span class="font2" style="font-style:italic;">testing</span><span class="font2">. Hasil dari pengujian dari model Multinomial Naive Bayes dengan ekstraksi fitur TF-IDF ditunjukkan oleh </span><span class="font2" style="font-style:italic;">confusion matrix</span><span class="font2"> pada Gambar 6.</span></p><img src="https://jurnal.harianregional.com/media/102412-4.jpg" alt="" style="width:192pt;height:156pt;">
<p><span class="font2" style="font-weight:bold;">Gambar 6. </span><span class="font2">Confusion Matrix dengan Ekstrasi Fitur TF-IDF</span></p>
<p><span class="font2">Pada Gambar 6. ditunjukkan bahwa dari model berhasil memprediksi secara benar sebanyak 61 data dengan label positif dan sebanyak 79 data dengan label negatif. Adapun sebanyak 11 data yang seharusnya memiliki label positif diprediksi negatif oleh model dan sebanyak 2 data yang seharusnya memiliki label negatif diprediksi positif oleh model. Sementara hasil dari pengujian model Multinomial Naive Bayes dengan ekstraksi fitur Bag of Words (BoW) ditunjukkan oleh </span><span class="font2" style="font-style:italic;">confusion matrix</span><span class="font2"> pada Gambar 7.</span></p>
<div><img src="https://jurnal.harianregional.com/media/102412-5.jpg" alt="" style="width:197pt;height:160pt;">
</div><br clear="all">
<p><span class="font2" style="font-weight:bold;">Gambar 7. </span><span class="font2">Confusion Matrix dengan Ekstraksi Fitur BoW</span></p>
<p><span class="font2">Pada Gambar 7. ditunjukkan bahwa dari model berhasil memprediksi secara benar sebanyak 61 data dengan label positif dan sebanyak 78 data dengan label negatif. Adapun sebanyak 11 data yang seharusnya memiliki label positif diprediksi negatif oleh model dan sebanyak 3 data yang seharusnya memiliki label negatif diprediksi positif oleh model.</span></p>
<p><span class="font2">Berdasarkan </span><span class="font2" style="font-style:italic;">confusion matrix</span><span class="font2"> tersebut, didapatkan perbandingan nilai </span><span class="font2" style="font-style:italic;">accuracy, precision, recall, </span><span class="font2">dan F1-</span><span class="font2" style="font-style:italic;">score</span><span class="font2"> dari model Multinomial Naive Bayes dengan menggunakan ekstraksi fitur TF-IDF dan BoW yang ditunjukkan pada Tabel 4.</span></p>
<p><span class="font2" style="font-weight:bold;">Tabel 4. </span><span class="font2">Perbandingan Performa Ekstraksi Fitur TF-IDF dan BoW</span></p>
<p><span class="font2" style="font-weight:bold;text-decoration:underline;">Precision</span><span class="font2" style="font-weight:bold;"> Recall &nbsp;Accuracy F1-Score</span></p>
<p><span class="font2" style="font-weight:bold;">BoW &nbsp;</span><span class="font2" style="text-decoration:underline;">91,48%</span><span class="font2"> &nbsp;&nbsp;90,51% 90,85% &nbsp;&nbsp;90,74%</span></p>
<p><span class="font2" style="font-weight:bold;">TF-IDF </span><span class="font2">92,3% &nbsp;&nbsp;&nbsp;91,13% 91,5% &nbsp;&nbsp;&nbsp;91,38%</span></p>
<p><span class="font2">Berdasarkan Tabel 4, nilai dari </span><span class="font2" style="font-style:italic;">precision, recall, accuracy</span><span class="font2">, dan F1-</span><span class="font2" style="font-style:italic;">score</span><span class="font2"> dari TF-IDF secara berturut-turut adalah 92,3%, 91,13%, 91,5%, dan 91,38%. Nilai tersebut lebih tinggi dibandingkan BoW dengan nilai </span><span class="font2" style="font-style:italic;">precision, recall, accuracy</span><span class="font2">, dan F1-</span><span class="font2" style="font-style:italic;">score</span><span class="font2"> secara berturut-turut 91,48%, 90,51%, 90,85%, dan 90,74%. Terlihat bahwa nilai </span><span class="font2" style="font-style:italic;">precision, recall, accuracy, dan</span><span class="font2"> F1</span><span class="font2" style="font-style:italic;">-score</span><span class="font2"> dari model Multinomial Naive Bayes dengan ekstraksi fitur TF-IDF lebih tinggi dibandingkan dengan ekstraksi fitur Bag of Words (BoW).</span></p>
<ul style="list-style:none;"><li>
<h1><a name="bookmark28"></a><span class="font2" style="font-weight:bold;"><a name="bookmark29"></a>4. &nbsp;&nbsp;&nbsp;Kesimpulan</span></h1></li></ul>
<p><span class="font2">Berdasarkan penelitian yang telah dilakukan, dapat ditarik kesimpulan bahwa dari perbandingan ekstraksi fitur antara TF-IDF dan Bag of Words (BoW) yang memberikan performa lebih baik pada metode Multinomial Naive Bayes adalah TF-IDF. Ekstraksi fitur TF-IDF memberikan nilai </span><span class="font2" style="font-style:italic;">precision, recall, accuracy</span><span class="font2">, dan F1-</span><span class="font2" style="font-style:italic;">score</span><span class="font2"> dari TF-IDF secara berturut-turut adalah 92,3%, 91,13%, 91,5%, dan 91,38%. Sementara ekstraksi fitur BoW memberikan nilai nilai </span><span class="font2" style="font-style:italic;">precision, recall, accuracy</span><span class="font2">, dan F1-</span><span class="font2" style="font-style:italic;">score</span><span class="font2"> secara berturut-turut 91,48%, 90,51%, 90,85%, dan 90,74%. Selain melalui pemilihan ekstrasi fitur, untuk meningkatkan performa dari model juga dapat dilakukan dengan teknik seleksi fitur serta melakukan </span><span class="font2" style="font-style:italic;">tuning</span><span class="font2"> terhadap </span><span class="font2" style="font-style:italic;">hyperparameter</span><span class="font2"> pada model yang digunakan.</span></p>
<p><span class="font2" style="font-weight:bold;">Daftar Pustaka</span></p>
<ul style="list-style:none;"><li>
<p><span class="font2">[1] &nbsp;&nbsp;&nbsp;Saputra A, Firdaus MI, Wahyudi R, Mohdo L, Gunawan ME, Encep M, and Khaira M, “Big Data”, </span><span class="font2" style="font-style:italic;">KARIMAH TAUHID</span><span class="font2">, vol. 1, no. 6, pp. 880-889, 2022, doi: 10.30997/karimahtauhid. v1i6.7664</span></p></li>
<li>
<p><span class="font2">[2] &nbsp;&nbsp;&nbsp;Suwija I, “Tingkat-Tingkatan Bicara Bahasa Bali (Dampak Anggah-Ungguh Kruna)”, </span><span class="font2" style="font-style:italic;">Sosiohumaniora,</span><span class="font2"> vol. 21, no. 1, pp. 90-97, 2019, doi: 10.24198/sosiohumaniora.</span></p></li></ul>
<p><span class="font2">v21i1.19507</span></p>
<ul style="list-style:none;"><li>
<p><span class="font2">[3] &nbsp;&nbsp;&nbsp;P. C. Sen, M. Hajra, and M. Ghosh, “Supervised Classification Algorithms in Machine</span></p></li></ul>
<p><span class="font2">Learning: A Survey and Review,” Advances in Intelligent Systems and Computing, pp. 99– 111, Jul. 2019, doi: 10.1007/978-981-13-7403-6_11.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font2">[4] &nbsp;&nbsp;&nbsp;Mas'udah E, Wahyuni ED, and Anjani A, “Analisis sentimen: Pemindahan ibu kota</span></p></li></ul>
<p><span class="font2">Indonesia pada twitter</span><span class="font2" style="font-style:italic;">”, Jurnal Informatika dan Sistem Informasi</span><span class="font2">, vol. 1, no. 2, pp. 397401, 2020.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font2">[5] &nbsp;&nbsp;&nbsp;Naf'an MZ, Bimantara AA, Larasati A, Risondang EM, and Nugraha NA, “Sentiment</span></p></li></ul>
<p><span class="font2">Analysis of Cyberbullying on Instagram User Comments”. </span><span class="font2" style="font-style:italic;">Journal of Data Science and Its Applications</span><span class="font2">, vol. 2, no. 1, pp. 38-48, 2019, doi: 10.21108/jdsa.2019.2.20</span></p>
<ul style="list-style:none;"><li>
<p><span class="font2">[6] &nbsp;&nbsp;&nbsp;R. Ahuja, A. Chug, S. Kohli, S. Gupta, and P. Ahuja, “The Impact of Features Extraction</span></p></li></ul>
<p><span class="font2">on the Sentiment Analysis,” </span><span class="font2" style="font-style:italic;">Procedia Computer Science</span><span class="font2">, vol. 152, pp. 341–348, 2019, doi: 10.1016/j.procs.2019.05.008.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font2">[7] &nbsp;&nbsp;&nbsp;Genta Indra Winata et al., “NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local Languages,” May 2022, doi: 10.48550/arxiv.2205.15960.</span></p></li>
<li>
<p><span class="font2">[8] &nbsp;&nbsp;&nbsp;Kadhim AI, “An evaluation of preprocessing techniques for text classification”, </span><span class="font2" style="font-style:italic;">International</span></p></li></ul>
<p><span class="font2" style="font-style:italic;">Journal of Computer Science and Information Security (IJCSIS),</span><span class="font2"> vol. 16, no. 6, pp. 22-32, 2018</span></p>
<ul style="list-style:none;"><li>
<p><span class="font2">[9] &nbsp;&nbsp;&nbsp;C. Liu, Y. Sheng, Z. Wei, and Y. Yang, “Research of Text Classification Based on Improved TF-IDF Algorithm,” </span><span class="font2" style="font-style:italic;">IEEE Xplore</span><span class="font2">, Aug. 01, 2018.</span></p></li></ul>
<p><a href="https://ieeexplore.ieee.org/abstract/document/8492945"><span class="font2">https://ieeexplore.ieee.org/abstract/document/8492945</span></a></p>
<ul style="list-style:none;"><li>
<p><span class="font2">[10] &nbsp;&nbsp;&nbsp;K. Kowsari, K. Jafari Meimandi, M. Heidarysafa, S. Mendu, L. Barnes, and D. Brown, “Text Classification Algorithms: A Survey,” </span><span class="font2" style="font-style:italic;">Information</span><span class="font2">, vol. 10, no. 4, p. 150, Apr. 2019, doi: 10.3390/info10040150.</span></p></li>
<li>
<p><span class="font2">[11] &nbsp;&nbsp;&nbsp;Wahyuningdiah Trisari Harsanti Putri and Retno Hendrowati, “PENGGALIAN TEKS DENGAN MODEL BAG OF WORDS TERHADAP DATA TWITTER,” vol. 2, no. 1, pp. 129– 138, Sep. 2018, doi: 10.24912/jmstkik. v2i1.1560.</span></p></li>
<li>
<p><span class="font2">[12] &nbsp;&nbsp;&nbsp;A. A. Farisi, Y. Sibaroni, and S. A. Faraby, “Sentiment analysis on hotel reviews using Multinomial Naïve Bayes classifier,” </span><span class="font2" style="font-style:italic;">Journal of Physics: Conference Series</span><span class="font2">, vol. 1192, p. 012024, Mar. 2019, doi: 10.1088/1742-6596/1192/1/012024.</span></p></li>
<li>
<p><span class="font2">[13] &nbsp;&nbsp;&nbsp;Harjito, B., Aini, K.N. and Murtiyasa, B., “Klasifikasi Dokumen berkonten Serangan jaringan menggunakan Multinomial Naive Bayes”, </span><span class="font2" style="font-style:italic;">In Seminar Nasional Teknologi Informasi dan Komunikasi (SEMNASTIK)</span><span class="font2">, vol. 1, no. 1, pp. 112-118, 2018</span></p></li>
<li>
<p><span class="font2">[14] &nbsp;&nbsp;&nbsp;M. Grandini, Enrico Bagli, and Giorgio Visani, “Metrics for Multi-Class Classification: An Overview,” arXiv (Cornell University), Aug. 2020, doi: 10.48550/arxiv.2008.05756.</span></p></li></ul>
<p><span class="font2">Halaman ini sengaja dibiarkan kosong</span></p>
<p><span class="font2">46</span></p>