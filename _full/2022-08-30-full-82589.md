---
layout: full_article
title: "Batik’s Pattern Recognition and Generation: Review and Challenges"
author: "Dewa Made Sri Arsa, Anak Agung Ngurah Hary Susila, Desak Ayu Sista Dewi, Ni Putu Sutramiani, I Wayan Agus Surya Darma"
categories: merpati
canonical_url: https://jurnal.harianregional.com/merpati/full-82589 
citation_abstract_html_url: "https://jurnal.harianregional.com/merpati/id-82589"
citation_pdf_url: "https://jurnal.harianregional.com/merpati/full-82589"  
comments: true
---

<p><span class="font0">JURNAL ILMIAH MERPATI VOL. 10, NO. 2 AUGUST 2022</span></p>
<p><span class="font0">p-ISSN: 2252-3006</span></p>
<p><span class="font0">e-ISSN: 2685-2411</span></p><a name="caption1"></a>
<h1><a name="bookmark0"></a><span class="font1" style="font-weight:bold;"><a name="bookmark1"></a>Batik’s Pattern Recognition and Generation: Review and Challenges</span></h1>
<h2><a name="bookmark2"></a><span class="font0" style="font-weight:bold;"><a name="bookmark3"></a>Dewa Made Sri Arsa<sup>a1</sup>, Anak Agung Ngurah Hary Susila<sup>a2</sup>, Desak Ayu Sista Dewi<sup>b3</sup>, Ni Putu Sutramiani<sup>a4</sup>, I Wayan Agus Surya Darma<sup>c5</sup></span></h2>
<p><span class="font0"><sup>a</sup>Department of Information Technology, Universitas Udayana, Indonesia <sup>b</sup>Department of Industrial Engineering, Universitas Udayana, Indonesia <sup>c</sup> Informatics Engineering, STMIK STIKOM Indonesia, Indonesia e-mail: <sup>1</sup></span><a href="mailto:dewamsa@unud.ac.id"><span class="font0" style="text-decoration:underline;">dewamsa@unud.ac.id</span></a><span class="font0">, <sup>2</sup></span><a href="mailto:harysusila@unud.ac.id"><span class="font0" style="text-decoration:underline;">harysusila@unud.ac.id</span></a><span class="font0">, <sup>3</sup></span><a href="mailto:sistadasd@unud.ac.id"><span class="font0" style="text-decoration:underline;">sistadasd@unud.ac.id</span></a><span class="font0">, <sup>4</sup></span><a href="mailto:sutramiani@unud.ac.id"><span class="font0" style="text-decoration:underline;">sutramiani@unud.ac.id</span></a><span class="font0">, </span><a href="mailto:5surya@stiki-indonesia.ac.id"><span class="font0" style="text-decoration:underline;"><sup>5</sup>surya@stiki-indonesia.ac.id</span></a></p>
<p><span class="font0" style="font-weight:bold;font-style:italic;">Abstrak</span></p>
<p><span class="font0" style="font-style:italic;">Batik adalah salah satu warisan budaya yang diakui oleh UNESCO. Sistem cerdas datang sebagai salah satu solusi untuk mendukung program pelestarian dari warisan budaya ini. Studi ini mengeksplorasi capaian saat ini pada aplikasi kecerdasan tiruan pada gambar batik. Penelitian ini memberikan investigasi sistematik dan mempresentasikan progres saat ini dan topik-topik hangat pada bidang pengenalan dan pembangkitan untuk gambar Batik. Penelitian ini juga merangkum beberapa data Batik beserta state-of-the-art dari data tersebut dan memproyeksikan beberapa topik yang dapat dilakukan pada bagian diskusi.</span></p>
<p><span class="font0" style="font-weight:bold;font-style:italic;">Kata kunci: </span><span class="font0" style="font-style:italic;">kecerdasan tiruan, pengenalan batik, pembangkitan batik, pengolahan citra</span></p>
<p><span class="font0" style="font-weight:bold;font-style:italic;">Abstract</span></p>
<p><span class="font0" style="font-style:italic;">Batik is one of cultural heritage acknowledged by UNESCO. Intelligence system comes as one of solution to take parts on preservation programs of this heritage. This study explores the current state of the art in application of artificial intelligence on Batik images. This research provides a systematic investigation and present the current progress and hot issues in recognition and generation area for Batik images. Furthermore, this research also presents several Batik data sets and their state of the art and projecting several future works in the discussion.</span></p>
<p><span class="font0" style="font-weight:bold;font-style:italic;">Keywords: </span><span class="font0" style="font-style:italic;">artificial intelligence, batik recognition, batik generation, image processing</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark4"></a><span class="font0" style="font-weight:bold;"><a name="bookmark5"></a>1. &nbsp;&nbsp;&nbsp;Introduction</span></h2></li></ul>
<p><span class="font0">Batik is an Indonesian cultural heritage which philosophically possesses visceral meaning and high value. United Nations Educational Scientific and Culture Organization (UNESCO) has also acknowledged it as one of the worlds cultural heritages [1]. Batik can be found in various Indonesia’s regions, but the pattern might be different. The Batik’s pattern might be different in various Indonesia’s regions because of each pattern representing tradition and culture in such a region.</span></p>
<p><span class="font0">Generally, Batik has two types of patterns [2]. The first pattern is geometric. The examples of this pattern are Ceplok, Banji, Parang, Kawung, and Mega Mendung. The second pattern is a non-geometric pattern like Semen, Cuwiri, Lunglungan, and Buketan. The craftsmen usually arrange such kind of pattern frequently on the material [3]. The variety of batik patterns becomes challenging for the Indonesian government to preserve this cultural heritage. However, the details of information are harder to collect because only particular people learn it.</span></p>
<p><span class="font0">The information communication technologies bring new options to provide and share cultural heritage, and these options are suitable as preservation tools. Cantoni et al. [4] mention five areas where the information communication technologies useful in cultural heritage, such as easy access, better experience, connecting locals and visitor, dis-intermediate to improve business activities, and support the training and education activities. To overcome the preservation issue, particularly Batik, worldwide researchers in computer sciences try to address it by proposing an automatic system that provides details of specific batik patterns.</span></p>
<p><span class="font0">Beside, various research also have been tried to create a various kind of system and using artificial intelligence [5]–[7]</span></p>
<p><span class="font0">In this study, we summarise previous approaches which have been proposed to analyse batik pattern. We collect var- ious literature from 2015 to present from various sources. Then, we arrange them into several groups by approach similarity. In advance, this paper has several contributions which can be divided into four parts as follows.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font0">1. &nbsp;&nbsp;&nbsp;Categorise all approach which has been done to analyse the pattern of Batik.</span></p></li>
<li>
<p><span class="font0">2. &nbsp;&nbsp;&nbsp;Summarise all batik dataset which can be accessed publicly. We also provide the challenge for each dataset and current state of the art.</span></p></li>
<li>
<p><span class="font0">3. &nbsp;&nbsp;&nbsp;We are presenting the current benchmark method for each Batik’s dataset.</span></p></li>
<li>
<p><span class="font0">4. &nbsp;&nbsp;&nbsp;Present future research direction related to Batik</span></p></li></ul>
<p><span class="font0">The rest of this study is written as follows. Section II analyses various batik pattern recognition approach. Section III presents the batik pattern synthesis method. Section IV provides several batik datasets which publicly available and its state of the art. Section V concludes our findings with future directions.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark6"></a><span class="font0" style="font-weight:bold;"><a name="bookmark7"></a>2. &nbsp;&nbsp;&nbsp;&nbsp;Research Method</span></h2></li></ul>
<p><span class="font0">This review is following the systematic review guidelines used in [8]. Firstly, we gather the literatures from various sources such as IEEE Explorer, ScienceDirect, and ACM Digital Library. Since the literatures are limited due to a specific object, we further explored secondary indexer through Google Scholar and Researchgate. Then the collected literatures are filtered by their quality in terms of their quality. Secondly, we identified the problem and mapping the proposed method for each refined literature. Thirdly, we analyze the open problem and providing the future direction for the future research.</span></p>
<p><span class="font0">After collecting and refining the gathered literature, we got 22 papers. Then, we create a state-of-the-art matrix and found that there are two main tasks related to Batik, such as recognizing the Batik’s motif and synthesizing Batik’s pattern, which will be further explained in section 3 and 4.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark8"></a><span class="font0" style="font-weight:bold;"><a name="bookmark9"></a>3. &nbsp;&nbsp;&nbsp;&nbsp;Batik’s Pattern Recognition Approach</span><br><br><span class="font0" style="font-weight:bold;"><a name="bookmark10"></a>3.1. &nbsp;&nbsp;Image Retrieval-based Approach</span></h2></li></ul>
<p><span class="font0">Table 1 present several research which is developed based on the image retrievalbased approach. Majorly, the texture feature-based was preferred here. Fahmi et al. [9] combining four methods that produce a high data dimension, reducing and filtering those features using sequential forward floating selection [10] or principal component analysis [11] through a performance comparison. They report that principal component analysis has better precision than sequential forward floating selection but slower in the retrieval execution time. However, the difference is not significant. Similar approaches use in [12], [13] . Nurhaida et al. [12] compare several feature combinations experimentally, like Gabor features, log-Gabor features, grey level co-occurrence matrices, and local binary pattern features. The results show that all combination provide high precisions but low recalls. Moreover, Prasetyo et al. [13] combine ordered dither block truncation coding with a particle swarm optimization to find the optimal value for similarity weighting constants to enhance the retrieval performance. In ordered dither block truncation coding, they extract colour feature and texture feature.</span></p>
<p><span class="font0">The method for matching the test image with the database also affects retrieval performance. Prasetyo et al. [13] demonstrate the trend for </span><span class="font2">L</span><span class="font0">1, </span><span class="font0" style="font-style:italic;">L2, x2,</span><span class="font0"> and Canberra distance in precision and recall value. From the four scenarios, the canberra distance outperformed other methods in three scenarios where the block sizes are 4×4, 8×8, and 32×32. In block size 16 × 16, the canberra distance is in the second position. In advance, Prasetyo et al. [13] optimize the canberra distance performance using particle swarm optimization. The particle swarm optimization is used to optimize the value of </span><span class="font2">«</span><span class="font0">1, </span><span class="font2">«</span><span class="font0">2, and </span><span class="font2">«</span><span class="font0">3. The particle swarm optimization is able to improve the performance of canberra distance 0.5% of accuracy.</span></p>
<p><span class="font0">Table 1 Content based image retrieval-based approach</span></p>
<table border="1">
<tr><td style="vertical-align:top;">
<p><span class="font0">Authors</span></p></td><td style="vertical-align:top;">
<p><span class="font0">Feature extraction method</span></p></td><td style="vertical-align:top;">
<p><span class="font0">Retrieval method</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font0">[9]</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">Features: Gabor filter, log-gabor filter, GLCM, LBP. Feature selection is done by using SFFS and PCA</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">euclidean distance</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font0">[33]</span></p></td><td style="vertical-align:top;">
<p><span class="font0">Scaled invariant feature transform with hough transform</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">euclidean distance</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0">[12]</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">Feature fusion (Gabor, Log-gabor, GLCM, LBP)</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">euclidean distance</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font0">[13]</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">Ordered dither block tuncation coding (ODBTC)</span></p></td><td style="vertical-align:top;">
<p><span class="font0">L1, L2, X2, and modified canberra distance</span></p></td></tr>
</table>
<p><span class="font0">Table 2 Batik’s pattern classification using various feature extractor and classification methods</span></p>
<table border="1">
<tr><td style="vertical-align:top;">
<p><span class="font0">Authors</span></p></td><td style="vertical-align:top;">
<p><span class="font0">Feature extraction method</span></p></td><td style="vertical-align:top;">
<p><span class="font0">Classification</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0">[2]</span></p></td><td style="vertical-align:top;">
<p><span class="font0">Various pretrained-convolutional neural networks</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">Softmax</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0">[14]</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">Fast Discrete Curvelet Transform + hue saturation value</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">K-Nearest Neighbour</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0">[15]</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">Gabor filter, log Gabor filter, gray level co-occurence matrix, and LBP followed by a principal component analysis</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">deep neural network</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0">[16]</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">Gray level co-occurence matrix, deep belief network, convolutional neural network</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">SVM, Softmax, Fully-connected layers+Softmax</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0">[20]</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">Pretrained VGG-16</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">Random forest and SVM</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0">[34]</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">Gray level co-occurence matrix + statistical color channel RGB</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">backprogagation neural network</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0">[35]</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">Gray level co-occurence matrix + shape features</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">three layers neural network</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0">[36]</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">Gray level co-occurence matrix and shape features + feature selection using information gain</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">three layers neural network</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0">[37]</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">Gray level co-occurence matrix + SURF</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">K-Nearest Neighbour</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font0">[38]</span></p></td><td style="vertical-align:top;">
<p><span class="font0">IncRes</span></p></td><td style="vertical-align:top;">
<p><span class="font0">Fully-connected layers + Softmax</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font0">[39]</span></p></td><td style="vertical-align:top;">
<p><span class="font0">Geometric invariant moment</span></p></td><td style="vertical-align:top;">
<p><span class="font0">K-Nearest Neighbour</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font0">[32]</span></p></td><td style="vertical-align:top;">
<p><span class="font0">Pretrained VGG-16 and VGG-19</span></p></td><td style="vertical-align:top;">
<p><span class="font0">Fully-conencted layers + Softmax</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0">[40]</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">Gray level co-occurence matrix</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">three layers neural network backpropagation</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font0">[28]</span></p></td><td style="vertical-align:top;">
<p><span class="font0">Pretrained VGG-16</span></p></td><td style="vertical-align:top;">
<p><span class="font0">Various classifiers</span></p></td></tr>
<tr><td colspan="2" style="vertical-align:top;">
<p><span class="font0" style="font-weight:bold;">3.2.</span><span class="font0">[28] </span><span class="font0" style="font-weight:bold;">Clas</span><span class="font0">M</span><span class="font0" style="font-weight:bold;">s</span><span class="font0">u</span><span class="font0" style="font-weight:bold;">if</span><span class="font0">l</span><span class="font0" style="font-weight:bold;">i</span><span class="font0">t</span><span class="font0" style="font-weight:bold;">c</span><span class="font0">i t</span><span class="font0" style="font-weight:bold;">a</span><span class="font0">e</span><span class="font0" style="font-weight:bold;">t</span><span class="font0">x</span><span class="font0" style="font-weight:bold;">io</span><span class="font0">to</span><span class="font0" style="font-weight:bold;">n</span><span class="font0">n</span><span class="font0" style="font-weight:bold;">-b</span><span class="font0">c</span><span class="font0" style="font-weight:bold;">a</span><span class="font0">o</span><span class="font0" style="font-weight:bold;">s</span><span class="font0">-o</span><span class="font0" style="font-weight:bold;">e</span><span class="font0">c</span><span class="font0" style="font-weight:bold;">d</span><span class="font0">cu</span><span class="font0" style="font-weight:bold;">A</span><span class="font0">r</span><span class="font0" style="font-weight:bold;">p</span><span class="font0">en</span><span class="font0" style="font-weight:bold;">p</span><span class="font0">c</span><span class="font0" style="font-weight:bold;">r</span><span class="font0">e</span><span class="font0" style="font-weight:bold;">oa</span><span class="font0">d</span><span class="font0" style="font-weight:bold;">c</span><span class="font0">es</span><span class="font0" style="font-weight:bold;">h</span><span class="font0">criptor</span></p></td><td style="vertical-align:top;">
<p><span class="font0">SVM</span></p></td></tr>
</table>
<p><span class="font0">This method can be divided into two parts, as shown in Table 2. The first part is the feature extraction process. The purpose of this process is extracting a unique key representation from the given data to improve the classification performance in the second part.</span></p>
<p><span class="font0">A texture-based approach dominates the feature extraction method. Suciati et al. [14] combine a fast discrete curvelet transform and the hue saturation value then the k-nearest neighbour placed to classify the features. Moreover, the statistical features from the grey level co-occurrence matrix are dominating the texture-based method. The statistical fea tures were computed from the grey level co-occurrence matrix, for example, contrast, correlation, energy, homogeneity, and entropy [15]. Nurhaida et al. [15] combined those features with feature reduction using principal component analysis and followed by a deep neural network. They also show how the batch normalization takes effect on boosting the deep neural network performance. This approach shows a significant upgrade from the standard deep neural network.</span></p>
<p><span class="font0">Deep learning methods also take parts in recognizing Batik’s patterns. Handhayani et al. [16] found that VGG16 [17] and ResNet [18] were underperformed. The deep of the network is not continuously increase the accuracy of such a model on a particular problem. A simple</span></p>
<p><span class="font0">Table 3 Generation and synthesize Batik’s pattern method</span></p>
<table border="1">
<tr><td style="vertical-align:top;">
<p><span class="font0">Authors</span></p></td><td style="vertical-align:top;">
<p><span class="font0">Synthesize approach</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font0">[25]</span></p></td><td style="vertical-align:top;">
<p><span class="font0">GAN with captions</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0">[26]</span></p></td><td style="vertical-align:top;">
<p><span class="font0">deep convolutional generative adversarial networks with modification</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0">[27]</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">BatikGAN, BatikGAN with style, BatikGAN with style and local features</span></p></td></tr>
</table>
<p><span class="font0">Table 4 Publicly available of Batik dataset. Note: NoC refers to number of classes</span></p>
<table border="1">
<tr><td style="vertical-align:bottom;">
<p><span class="font0">No</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">Dataset name</span></p></td><td style="vertical-align:top;">
<p><span class="font0">Class number</span></p></td><td style="vertical-align:top;">
<p><span class="font0">Total images</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font0">1</span></p></td><td style="vertical-align:top;">
<p><span class="font0">Gultom dataset</span></p></td><td style="vertical-align:top;">
<p><span class="font0">5</span></p></td><td style="vertical-align:top;">
<p><span class="font0">2.092</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font0">2</span></p></td><td style="vertical-align:top;">
<p><span class="font0">Minarno dataset</span></p></td><td style="vertical-align:top;">
<p><span class="font0">50</span></p></td><td style="vertical-align:top;">
<p><span class="font0">300</span></p></td></tr>
</table><img src="https://jurnal.harianregional.com/media/82589-1.jpg" alt="" style="width:409pt;height:108pt;">
<p><span class="font0">Figure 1 Generative adversarial networks architecture proposed in [26], [27]</span></p>
<p><span class="font0">convolutional neural network consisting of three convolution layers can place in the third position of accuracy in [16].</span></p>
<p><span class="font0">Moreover, in contrast with Handhayani results in [16], Rasyidi et al. [2] recently show that pre-trained networks can be used to recognise the ornament on Batik images. Rasyidi et al. [2] compared the accuracy, precision, and recall of AlexNet and various type of DenseNet, ResNet, SqueezeNet, and VGG. Gultom [19] and Arsa [20] also produce similar results where the pre-trained networks have outstanding performance when used on other domains.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark11"></a><span class="font0" style="font-weight:bold;"><a name="bookmark12"></a>4. &nbsp;&nbsp;&nbsp;Automatic Batik’s Pattern Generation and Synthesis</span></h2></li></ul>
<p><span class="font0">Batik pattern synthesis has been a new challenge in processing batik images. This approach enabling the fusion of several ornaments or generate patterns with different style using artificial intelligence. As we can see in Table 3, all of the methods were built based on generative adversarial networks. This method has known its performance for generating images [21]–[27].</span></p>
<p><span class="font0">Figure 1 shows the general architecture used in [25]–[27]. Amalia et al. [25] and Abdurrahman et al. [26] use a standard generative adversarial network, as shown in Figure 1a. The difference is the construction of generator and discriminator. Then, Chu et al. [27] propose a different design of the generation method. Their method receives two patches of batik patterns as input to synthesis a new batik image.</span></p>
<p><span class="font0">BatikGAN [27] shows better performance compared with [25], [26]. The generated images present more details in the pattern where Amalia’s approach [25] and Abdurrahman’s approach [26] have more unstructured patterns if we scale the image. The three designed discriminators, such as pretrained VGG-19, global discriminator, and local discrimina tor, improve the quality of synthesis because each discriminator focuses on one task. For example, the global discriminator checks small local areas, and local discriminator determines the generated images’ details.</span></p>
<p><span class="font0">Table 5 Results of the previous research which was used Minarno dataset</span></p>
<table border="1">
<tr><td style="vertical-align:middle;">
<p><span class="font0">Authors</span></p></td><td colspan="2" style="vertical-align:middle;">
<p><span class="font0">Method</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">Performance</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0">[28]</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">Multi texton co-occurence descriptor</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">acc:</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">100%</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0">[20]</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">pretrained VGG16 + radom forest</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">acc:</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">97.50 +- 2.32%</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0">[29]</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">Multi texton histogram and probabilistic neural network</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">acc:</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">92%</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0">[30]</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">Multi texton histogram + k-nearest neighbours</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">acc:</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">82%</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0">[31]</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">Multi structure co-occurence descriptor</span></p></td><td colspan="2" style="vertical-align:bottom;">
<p><span class="font0">avg precision: 81.47%</span></p></td></tr>
</table>
<p><span class="font0">Table 6 Gultom dataset state of the art</span></p>
<table border="1">
<tr><td style="vertical-align:middle;">
<p><span class="font0">Authors</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">Method</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">Accuracy</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0">[32]</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">pretrained VGG19</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">89+-2.8%</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0">[19]</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">pretrained VGG16</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">89+-7%</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0">[15]</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">deep neural networks</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">85.57%</span></p></td></tr>
</table>
<ul style="list-style:none;"><li>
<h2><a name="bookmark13"></a><span class="font0" style="font-weight:bold;"><a name="bookmark14"></a>5. &nbsp;&nbsp;&nbsp;Batik Dataset and State of The Art</span></h2></li></ul>
<p><span class="font0">Previous research mostly built their dataset by crawling Batik images from search engines, for example, Google. We found that only two datasets are published freely. Table 4 shows some details of those datasets. Those datasets are varied in the number of classes and the total number of images. Gultom dataset provides more images per classes. The highest class number is provided in Minarno dataset with six images per class.</span></p>
<p><span class="font0">Table 5 shows the progress performance on developing classification method for Minarno dataset. The table presents that the Minarno dataset challenges have been solved since the current state of the art already on maximum performance [28]. Arsa et al. [20] use pretrained VGG16 here, combined with random forest and the result still competitive. For this pretrained network, we replace the Random Forest with Logistic Regression and produce 100% of accuracy consistently when the experiment is repeated.</span></p>
<p><span class="font0">Table 6 provides the current state of the art of Gultom dataset. Agastya et al. [32] approaches are the current best method. Even the accuracy is the same as Gultom [19], the standard deviation indicates that Agastya method [32] is stabler than Gultom method [19]. Moreover, a non-convolutional deep neural network can compete here, as shown by Nurhaida et al. [15] by incorporating the batch normalization process.</span></p>
<p><span class="font0">Table 6 provides the current state of the art of Gultom dataset. Agastya et al. [32] approaches is the current best method. Even the accuracy is the same as Gultom [19], the standard deviation indicates that Agastya method [32] is stabler than Gultom method [19]. Moreover, a non convolutional deep neural networks is able to compete here as shown by Nurhaida et al. [15] by incorporating the batch normalization process.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark15"></a><span class="font0" style="font-weight:bold;"><a name="bookmark16"></a>6. &nbsp;&nbsp;&nbsp;Conclusion</span></h2></li></ul>
<p><span class="font0">Various approaches have been applied to analyze Batik image using hand-crafted features or learned features like neural networks. The recognition task is still an open problem in Batik classification because tons of motifs are not yet compiled as a dataset. The batik motif generation is attractive because it is rarely done and in the early development of Batik patterns generation. This topic may enrich the Batik motif and can be used to learn unidentified pattern. The application of the batik motif generation and recognition through mobile devices can also be developed as an effort to preserve batik as a cultural heritage that is spread throughout Indonesia.</span></p>
<h2><a name="bookmark17"></a><span class="font0" style="font-weight:bold;"><a name="bookmark18"></a>Acknowlegdement</span></h2>
<p><span class="font0">This study was the results of the research project granted by Universitas Udayana entitled by &quot;Pelestarian Jenis-Jenis Batik melalui Sistem Klasifikasi berbasis Deep Learning&quot; on PUPS scheme.</span></p>
<h2><a name="bookmark19"></a><span class="font0" style="font-weight:bold;"><a name="bookmark20"></a>References</span></h2>
<ul style="list-style:none;"><li>
<p><span class="font2">[1] &nbsp;&nbsp;&nbsp;</span><span class="font0">UNESCO, “Indonesian batik,” </span><a href="https://ich.unesco.org/en/RL/indonesian-batik-00170"><span class="font0" style="font-style:italic;">https://ich.unesco.org/en/RL/indonesian-batik-00170</span></a><span class="font0">.</span></p></li>
<li>
<p><span class="font0">[2] &nbsp;&nbsp;&nbsp;M. A. Rasyidi and T. Bariyah, “Batik pattern recognition using convolutional neural network,” </span><span class="font0" style="font-style:italic;">Bulletin of Electrical Engineering and Informatics</span><span class="font0">, vol. 9, no. 4, pp. 1430–1437, Aug. 2020, doi: 10.11591/eei.v9i4.2385.</span></p></li>
<li>
<p><span class="font0">[3] &nbsp;&nbsp;&nbsp;A.HAAKE, “The Role of Symmetry in Javanese Batik Patterns,” </span><span class="font0" style="font-style:italic;">International Series in Modern Applied Mathematics and Computer Science</span><span class="font0">, vol. 17, pp. 815–826, 1989.</span></p></li>
<li>
<p><span class="font0">[4] &nbsp;&nbsp;&nbsp;L. Cantoni, S. de Ascaniis, and M. Gravari-Barbas, “Heritage and Sustainable Tourism,” </span><span class="font0" style="font-style:italic;">The Role and Challenge of Information and Communication Technologies</span><span class="font0">, 2018.</span></p></li>
<li>
<p><span class="font0">[5] &nbsp;&nbsp;&nbsp;D. A. Savita, I. K. G. D. Putra, and N. K. D. Rusjayanthi, “Public Sentiment Analysis of Online Transportation in Indonesia through Social Media Using Google Machine Learning,” </span><span class="font0" style="font-style:italic;">JURNAL ILMIAH MERPATI</span><span class="font0">, vol. 9, no. 2, pp. 153–164, 2021.</span></p></li>
<li>
<p><span class="font0">[6] &nbsp;&nbsp;&nbsp;I. P. Y. P. Yasa, I. K. G. D. Putra, and D. M. S. Arsa, “Augmented Reality Application</span></p></li></ul>
<p><span class="font0">with Real Object Marker of Tanah Lot Temple,” </span><span class="font0" style="font-style:italic;">JURNAL ILMIAH MERPATI</span><span class="font0">, vol. 9, no. 1, pp. 46–57, 2021.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font0">[7] &nbsp;&nbsp;&nbsp;A. A. Priyangka and I. M. S. Kumara, “ Classification Of Rice Plant Diseases Using the Convolutional Neural Network Method,” </span><span class="font0" style="font-style:italic;">Lontar Komputer: Jurnal Ilmiah Teknologi Informasi</span><span class="font0">, vol. 12, no. 2, pp. 123–129, 2021, doi: 10.24843/LKJITI.2021.v12.i02.p06.</span></p></li>
<li>
<p><span class="font0">[8] &nbsp;&nbsp;&nbsp;I. P. A. Dharmaadi, D. Made, and S. Arsa, “Studi Pustaka Sistem Pemantauan Jaringan</span></p></li></ul>
<p><span class="font0">Distribusi Air Publik berbasis Internet of Things (IoT),” </span><span class="font0" style="font-style:italic;">JURNAL ILMIAH MERPATI</span><span class="font0">, vol. 8, no. 1, pp. 54–60, 2020.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font0">[9] &nbsp;&nbsp;&nbsp;H. Fahmi, R. A. M. Zen, H. R. Sanabila, I. Nurhaida, and A. M. Arymurthy, “Feature selection and reduction for batik image retrieval,” in </span><span class="font0" style="font-style:italic;">ACM International Conference Proceeding Series</span><span class="font0">, Dec. 2016, pp. 47–52. doi: 10.1145/3033288.3033327.</span></p></li>
<li>
<p><span class="font0">[10] &nbsp;&nbsp;&nbsp;P. Pudil, J. Novovičová, and J. Kittler, “Floating search methods in feature selection,” </span><span class="font0" style="font-style:italic;">Pattern Recognit Lett</span><span class="font0">, vol. 15, no. 11, pp. 1119–1125, 1994.</span></p></li>
<li>
<p><span class="font0">[11] &nbsp;&nbsp;&nbsp;H. Abdi and L. J. Williams, “Principal component analysis,” </span><span class="font0" style="font-style:italic;">Wiley interdisciplinary reviews: computational statistics</span><span class="font0">, vol. 2, no. 4, pp. 433–459, 2010.</span></p></li>
<li>
<p><span class="font0">[12] &nbsp;&nbsp;&nbsp;I. Nurhaida, H. Wei, R. A. M. Zen, R. Manurung, and A. M. Arymurthy, “Texture fusion for batik motif retrieval system,” </span><span class="font0" style="font-style:italic;">International Journal of Electrical and Computer Engineering (IJECE)</span><span class="font0">, vol. 6, no. 6, pp. 3174–3187, 2016.</span></p></li>
<li>
<p><span class="font0">[13] &nbsp;&nbsp;&nbsp;H. Prasetyo, W. Wiranto, W. Winarno, U. Salamah, and B. Harjito, “Batik image retrieval using ODBTC feature and particle swarm optimization,” </span><span class="font0" style="font-style:italic;">Journal of Telecommunication, Electronic and Computer Engineering (JTEC)</span><span class="font0">, vol. 10, no. 2–4, pp. 71–74, 2018.</span></p></li>
<li>
<p><span class="font0">[14] &nbsp;&nbsp;&nbsp;N. Suciati, A. Kridanto, M. F. Naufal, M. Machmud, and A. Y. Wicaksono, “Fast discrete curvelet transform and HSV color features for batik image clansificotlon,” in </span><span class="font0" style="font-style:italic;">2015 International Conference on Information &amp;&nbsp;Communication Technology and Systems (ICTS)</span><span class="font0">, 2015, pp. 99–104.</span></p></li>
<li>
<p><span class="font0">[15] &nbsp;&nbsp;&nbsp;I. Nurhaida, V. Ayumi, D. Fitrianah, R. A. M. Zen, H. Noprisson, and H. Wei, “Implementation of deep neural networks (DNN) with batch normalization for batik pattern recognition.,” </span><span class="font0" style="font-style:italic;">International Journal of Electrical &amp;&nbsp;Computer Engineering (20888708)</span><span class="font0">, vol. 10, 2020.</span></p></li>
<li>
<p><span class="font0">[16] &nbsp;&nbsp;&nbsp;T. Handhayani, J. Hendryli, and L. Hiryanto, “Comparison of shallow and deep learning models for classification of Lasem batik patterns,” in </span><span class="font0" style="font-style:italic;">2017 1st International Conference on Informatics and Computational Sciences (ICICoS)</span><span class="font0">, 2017, pp. 11–16.</span></p></li>
<li>
<p><span class="font0">[17] &nbsp;&nbsp;&nbsp;K. Simonyan and A. Zisserman, “Very deep convolutional networks for large-scale image recognition,” </span><span class="font0" style="font-style:italic;">arXiv preprint arXiv:1409.1556</span><span class="font0">, 2014.</span></p></li>
<li>
<p><span class="font0">[18] &nbsp;&nbsp;&nbsp;K. He, X. Zhang, S. Ren, and J. Sun, “Deep residual learning for image recognition,” in </span><span class="font0" style="font-style:italic;">Proceedings of the IEEE conference on computer vision and pattern recognition</span><span class="font0">, 2016, pp. 770–778.</span></p></li>
<li>
<p><span class="font0">[19] &nbsp;&nbsp;&nbsp;Y. Gultom, A. M. Arymurthy, and R. J. Masikome, “Batik classification using deep convolutional network transfer learning,” </span><span class="font0" style="font-style:italic;">Jurnal Ilmu Komputer dan Informasi</span><span class="font0">, vol. 11, no. 2, pp. 59–66, 2018.</span></p></li>
<li>
<p><span class="font0">[20] &nbsp;&nbsp;&nbsp;D. M. S. Arsa and A. A. N. H. Susila, “VGG16 in Batik Classification based on Random Forest,” in </span><span class="font0" style="font-style:italic;">2019 International Conference on Information Management and Technology (ICIMTech)</span><span class="font0">, 2019, vol. 1, pp. 295–299.</span></p></li>
<li>
<p><span class="font0">[21] &nbsp;&nbsp;&nbsp;I. Goodfellow </span><span class="font0" style="font-style:italic;">et al.</span><span class="font0">, “Generative adversarial nets,” in </span><span class="font0" style="font-style:italic;">Advances in neural information processing systems</span><span class="font0">, 2014, pp. 2672–2680.</span></p></li>
<li>
<p><span class="font0">[22] &nbsp;&nbsp;&nbsp;A. Radford, L. Metz, and S. Chintala, “Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks,” in </span><span class="font0" style="font-style:italic;">4th International Conference on Learning Representations, ICLR 2016, San Juan, Puerto Rico, May 2-4, 2016, Conference Track Proceedings</span><span class="font0">, 2016. [Online]. Available: </span><a href="http://arxiv.org/abs/1511.06434"><span class="font0">http://arxiv.org/abs/1511.06434</span></a></p></li>
<li>
<p><span class="font0">[23] &nbsp;&nbsp;&nbsp;Q. Cheng and X. Gu, “Cross-modal Feature Alignment based Hybrid Attentional Generative Adversarial Networks for Text-to-image Synthesis,” </span><span class="font0" style="font-style:italic;">Digital Signal Processing</span><span class="font0">, p. 102866, 2020.</span></p></li>
<li>
<p><span class="font0">[24] &nbsp;&nbsp;&nbsp;Y. Chen </span><span class="font0" style="font-style:italic;">et al.</span><span class="font0">, “Person Image Synthesis through Siamese Generative Adversarial Network,” </span><span class="font0" style="font-style:italic;">Neurocomputing</span><span class="font0">, 2020.</span></p></li>
<li>
<p><span class="font0">[25] &nbsp;&nbsp;&nbsp;A. N. Amalia, A. F. Huda, D. R. Ramdania, and M. Irfan, “Making a Batik Dataset for Text to Image Synthesis Using Generative Adversarial Networks,” in </span><span class="font0" style="font-style:italic;">2019 IEEE 5th International Conference on Wireless and Telematics (ICWT)</span><span class="font0">, 2019, pp. 1–7.</span></p></li>
<li>
<p><span class="font0">[26] &nbsp;&nbsp;&nbsp;M. Abdurrahman, N. H. Shabrina, and D. K. Halim, “Generative Adversarial Network Implementation for Batik Motif Synthesis,” in </span><span class="font0" style="font-style:italic;">2019 5th International Conference on New Media Studies (CONMEDIA)</span><span class="font0">, 2019, pp. 63–67.</span></p></li>
<li>
<p><span class="font0">[27] &nbsp;&nbsp;&nbsp;W.-T. Chu and L.-Y. Ko, “BatikGAN: A Generative Adversarial Network for Batik Creation,” in </span><span class="font0" style="font-style:italic;">Proceedings of the 2020 Joint Workshop on Multimedia Artworks Analysis and Attractiveness Computing in Multimedia</span><span class="font0">, 2020, pp. 13–18.</span></p></li>
<li>
<p><span class="font0">[28] &nbsp;&nbsp;&nbsp;A. E. Minarno, Y. Azhar, F. D. S. Sumadi, and Y. Munarko, “A Robust Batik Image Classification using Multi Texton Co-Occurrence Descriptor and Support Vector Machine,” in </span><span class="font0" style="font-style:italic;">2020 3rd International Conference on Intelligent Autonomous Systems (ICoIAS)</span><span class="font0">, 2020, pp. 51–55.</span></p></li>
<li>
<p><span class="font0">[29] &nbsp;&nbsp;&nbsp;A. E. Minarno, Y. Munarko, A. Kurniawardhani, and F. Bimantoro, “Classification of Texture Using Multi Texton Histogram and Probabilistic Neural Network,” in </span><span class="font0" style="font-style:italic;">IOP Conf. Ser. Mater. Sci. Eng</span><span class="font0">, 2016, vol. 105, no. 1, p. 12022.</span></p></li>
<li>
<p><span class="font0">[30] &nbsp;&nbsp;&nbsp;A. E. Minarno, A. S. Maulani, A. Kurniawardhani, F. Bimantoro, and N. Suciati, “Comparison of methods for batik classification using multi texton histogram,” </span><span class="font0" style="font-style:italic;">Telkomnika</span><span class="font0">, vol. 16, no. 3, pp. 1358–1366, 2018.</span></p></li>
<li>
<p><span class="font0">[31] &nbsp;&nbsp;&nbsp;A. E. Minarno, A. Kurniawardhani, and F. Bimantoro, “Image retrieval based on multi structure co-occurrence descriptor,” </span><span class="font0" style="font-style:italic;">Telkomnika</span><span class="font0">, vol. 14, no. 3, pp. 1175–1182, 2016.</span></p></li>
<li>
<p><span class="font0">[32] &nbsp;&nbsp;&nbsp;I. M. A. Agastya and A. Setyanto, “Classification of Indonesian Batik Using Deep Learning Techniques and Data Augmentation,” in </span><span class="font0" style="font-style:italic;">2018 3rd International Conference on Information Technology, Information System and Electrical Engineering (ICITISEE)</span><span class="font0">, 2018, pp. 27–31.</span></p></li>
<li>
<p><span class="font0">[33] &nbsp;&nbsp;&nbsp;I. Nurhaida, A. Noviyanto, R. Manurung, and A. M. Arymurthy, “Automatic Indonesian’s batik pattern recognition using SIFT approach,” </span><span class="font0" style="font-style:italic;">Procedia Computer Science</span><span class="font0">, vol. 59, no. 5, pp. 567–576, 2015.</span></p></li>
<li>
<p><span class="font0">[34] &nbsp;&nbsp;&nbsp;C. S. K. Aditya, M. Hani’ah, R. R. Bintana, and N. Suciati, “Batik classification using neural network with gray level co-occurence matrix and statistical color feature extraction,” in </span><span class="font0" style="font-style:italic;">2015 International Conference on Information &amp;&nbsp;Communication Technology and Systems (ICTS)</span><span class="font0">, 2015, pp. 163–168.</span></p></li>
<li>
<p><span class="font0">[35] &nbsp;&nbsp;&nbsp;A. A. Kasim, R. Wardoyo, and A. Harjoko, “Batik classification with artificial neural network based on texture-shape feature of main ornament,” </span><span class="font0" style="font-style:italic;">International Journal of Intelligent Systems and Applications</span><span class="font0">, vol. 11, no. 6, p. 55, 2017.</span></p></li>
<li>
<p><span class="font0">[36] &nbsp;&nbsp;&nbsp;A. A. Kasim, R. Wardoyo, and A. Harjoko, “The selection feature for batik motif classification with information gain value,” in </span><span class="font0" style="font-style:italic;">International Conference on Soft Computing in Data Science</span><span class="font0">, 2017, pp. 106–115.</span></p></li>
<li>
<p><span class="font0">[37] &nbsp;&nbsp;&nbsp;F. U. Karimah and A. Harjoko, “Classification of batik kain besurek image using speed up robust features (SURF) and gray level co-occurrence matrix (GLCM),” in </span><span class="font0" style="font-style:italic;">International Conference on Soft Computing in Data Science</span><span class="font0">, 2017, pp. 81–91.</span></p></li>
<li>
<p><span class="font0">[38] &nbsp;&nbsp;&nbsp;A. Y. Wicaksono, N. Suciati, C. Fatichah, K. Uchimura, and G. Koutaki, “Modified convolutional neural network architecture for batik motif image classification,” </span><span class="font0" style="font-style:italic;">IPTEK Journal of Science</span><span class="font0">, vol. 2, no. 2, 2017.</span></p></li>
<li>
<p><span class="font0">[39] &nbsp;&nbsp;&nbsp;R. E. Caraka, T. W. Cenggoro, B. Pardamean, and others, “Batik parang rusak detection using geometric invariant moment,” in </span><span class="font0" style="font-style:italic;">2018 Indonesian Association for Pattern Recognition International Conference (INAPR)</span><span class="font0">, 2018, pp. 71–74.</span></p></li>
<li>
<p><span class="font0">[40] &nbsp;&nbsp;&nbsp;J. Kusanti and A. Suprapto, “Combination of Otsu and Canny Method to Identify the Characteristics of Solo Batik as Surakarta Traditional Batik,” in </span><span class="font0" style="font-style:italic;">2019 2nd International Conference of Computer and Informatics Engineering (IC2IE)</span><span class="font0">, 2019, pp. 63–68.</span></p></li></ul>
<p><span class="font0" style="font-style:italic;">Batik’s Pattern Recognition and Generation: Review and Challenges (Dewa Made Sri Arsa)</span><span class="font0"> 121</span></p>