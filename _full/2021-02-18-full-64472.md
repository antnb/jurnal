---
layout: full_article
title: "The Influence of Changes in ANN Hidden Layer Unit and Feature Selection on Classification"
author: "Sawendo Eko Wijana, I Gede Santi Astawa, AAIN Eka Karyawati"
categories: jik
canonical_url: https://jurnal.harianregional.com/jik/full-64472 
citation_abstract_html_url: "https://jurnal.harianregional.com/jik/id-64472"
citation_pdf_url: "https://jurnal.harianregional.com/jik/full-64472"  
comments: true
---

<p><span class="font2">p-ISSN: 2301-5373</span></p>
<p><span class="font2">e-ISSN: 2654-5101</span></p>
<p><span class="font2">Jurnal Elektronik Ilmu Komputer Udayana</span></p>
<p><span class="font2">Volume 9 No. 3, February 2021</span></p><a name="caption1"></a>
<h1><a name="bookmark0"></a><span class="font3" style="font-weight:bold;"><a name="bookmark1"></a>Effect of Feature Selection on Classification Liver Disease</span></h1>
<p><span class="font2">I Wayan Sawendo Eko Wijana<sup>a1</sup>, I Gede Santi Astawa<sup>a2</sup>, AAIN Eka Karyawati<sup>a3 a</sup>Informatics Department, Faculty of Math and Sciences, Udayana University Badung, Bali, Indonesia </span><a href="mailto:1ekosawendo@gmail.com"><span class="font2"><sup>1</sup>ekosawendo@gmail.com</span></a><span class="font2"> </span><a href="mailto:2santiastawa@gmail.com"><span class="font2"><sup>2</sup>santiastawa@gmail.com</span></a><span class="font2"> </span><a href="mailto:3eka.karyawati@unud.ac.id"><span class="font2"><sup>3</sup>eka.karyawati@unud.ac.id</span></a></p>
<p><span class="font2" style="font-weight:bold;font-style:italic;">Abstract</span></p>
<p><span class="font2" style="font-style:italic;">Classification is the process of differentiating a set of models into several data classes. There are many methods that can be used for the classification process, one of which is the Artificial Neural Network method. Neural networks are a computational method that mimics biological syafar networks. Artificial condition networks can be used to model complex relationships between input and output to recognize patterns in data [1]. In this study, a test was conducted to determine the effect of feature selection on the classification results. This research was carried out by eliminating uncorrelated data variables and correlated data to determine their effect on the classification results and the computation time obtained.In this study, the results show that the accuracy obtained from eliminating uncorrelated data does not really affect the accuracy results where it only has a decrease of 0.04049%, while the correlated features are more influential on the classification results obtained, where the accuracy increases by 1.64%. and 2.02%. For computation time, feature selection does not really affect the computation time obtained.</span></p>
<p><span class="font2" style="font-weight:bold;font-style:italic;">Keywords: </span><span class="font2" style="font-style:italic;">Classification, Artificial Neural Network, Liver Disease, Accuracy, Time</span><span class="font2">.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark2"></a><span class="font2" style="font-weight:bold;"><a name="bookmark3"></a>1. &nbsp;&nbsp;&nbsp;Introduction</span></h2></li></ul>
<p><span class="font2">Classification is the process of differentiating a set of models into several data classes. The classification process aims to predict the class label for data that does not yet have a class label. There are many methods that can be used for the classification process, one of which is the Artificial Neural Network method. Neural networks are a computational method that mimics biological safeguards. Artificial condition networks can be used to model complex relationships between input and output to recognize patterns in data [1]. In Artificial Neural Networks, there are several parameters which are initialized at the beginning and can be changed such as the number of units in the hidden layer. In 2017 a research was conducted on Implementation of Backpropagation Neural Networks to Diagnose Skin Diseases in Children, in this study they tested the number of hidden neurons in order to obtain the smallest MSE error value from each combination of the number of hidden neurons. The results obtained in this study are the optimal number of hidden neurons as many as 4 neurons [2].</span></p>
<p><span class="font2">In 2016 Nunik Purwaningsih conducted a research on the application of the multilayer perceptron for the classification of the tannest cowhide types. This study aims to apply the MLP method to classify the tanned cow hides. From the test results obtained classification accuracy level reached 87.83%. The most appropriate type of skin that can be identified is pull up skin with an accuracy rate of 98.75% [3]. In 2016, a study was conducted on the diagnosis of Parkinson's disease based on the combination of data mining algorithm and feature selection by Astuti and Ferinanto, which obtained the best accuracy value of 96.923% with a running time of 0.10 seconds for the classification results of data mining with the CFS feature selection. Meanwhile, the Naive Bayes algorithm gets an accuracy value of 76,923% [4]. Research with other objects in 2018 conducted by Amrin and Satriadi on the Implementation of Artificial Neural Networks with Multilayer Perceptron for Credit Lending Analysis obtained an accuracy of 96.1% with an area</span></p>
<p><span class="font2">under the curva (AUC) value of 0.999. From these results it can be said that the classification is done very well, this is because it has an AUC value between 0.90 - 1.00 [5].</span></p>
<p><span class="font2">In 2020, research on Influence Optimization Feature Against Liver Disorders Diagnostic Results Using Artificial Neural Network. This study found that data that did not perform feature selection resulted in an accuracy value that tended to be greater than data that did feature selection between 64% and 100%. However, the accuracy value obtained in the data that selected fetuses was more stable than the accuracy values for data that did not select fetuses, namely between 68.57% and 71.42% [6].</span></p>
<p><span class="font2">In this study, the Artificial Neural Network method will be used for the classification of liver disease. There are many types of liver disease such as hepatitis and liver cancer, but in this study only classified it into a general form, namely positive and negative. A new study by the British Liver Trust reveals that liver disease or liver disease is the leading cause of death in people aged 35-49 years, particularly in the UK. Apart from the liver, at the top of the list of biggest deaths are suicide, heart disease and breast cancer. As reported by netdoctor, this study analyzed data on mortality in England and Wales. The findings show that in 2017, 998 men and women aged between 35 and 49 died from liver disease.</span></p>
<p><span class="font2">The type of data used in this study is the Liver Disease Lab data obtained from the Kaggle Dataset. This liver disease data has a total of 483 data records. In the process of testing the data will use SPSS for the classification process. In this study, the effect of data attributes on the classification process will be examined, where in the classification process some data items will be removed and their effects on the classification process using the Perceptron Multilayer Neural Network method. In this study, before conducting research on the effect of feature selection, the optimal number of hidden neurons will be sought first so that they will get optimal accuracy.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark4"></a><span class="font2" style="font-weight:bold;"><a name="bookmark5"></a>2. &nbsp;&nbsp;&nbsp;Research Methods</span></h2></li></ul>
<p><span class="font2">In this research, the research method carried out starts from analyzing the problems to be done, collecting data to be tested, inputting the tested data into the IBM SPSS Statistic 25 tools, seeing the feature correlation to the classification results, creating scenarios from testing, performing the classification process in SPSS, then copy the test results from the classification and computation time. The following is a flow chart of the research to be carried out.</span></p><img src="https://jurnal.harianregional.com/media/64472-1.jpg" alt="" style="width:386pt;height:216pt;">
<p><span class="font2" style="font-weight:bold;">Picture 1. </span><span class="font2">Research Methodology Flow</span></p>
<p><span class="font2">From the picture above, it can be explained by the following steps:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font2" style="font-weight:bold;">2.1 &nbsp;&nbsp;&nbsp;Identification of problems</span></p></li></ul>
<p><span class="font2">The problem raised is about the selection of features from the most distant or uncorrelated variables to the dependent variable to determine the effect of accuracy and computation time. In addition, this study also examines the effect of changing the number of hidden layer units in Artificial Neural Networks on the results of liver disease classification.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark6"></a><span class="font2" style="font-weight:bold;"><a name="bookmark7"></a>2.2 &nbsp;&nbsp;&nbsp;Data collection</span></h2></li></ul>
<p><span class="font2">The type of data used in this study is the Liver Disease Lab data obtained from the Kaggle Dataset. This liver disease data has a total of 483 data records.</span></p>
<p><span class="font2" style="font-weight:bold;">Table 1. </span><span class="font2">Indian Liver Patient Dataset</span></p>
<table border="1">
<tr><td style="vertical-align:top;">
<p><span class="font2">Attribute</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Description</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font2">Age TB</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">Patient Age</span></p>
<p><span class="font2">Total Bilirubin</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font2">DB</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">Direct Bilirubin</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font2">Alkphos Really Sgot ALB</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">Alkaline Phosphotase Amartotransferse</span></p>
<p><span class="font2">Aspartate Albumin</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font2">A / G Ratio</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">Albumin and Globullin Ratio</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font2">Class</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">Dividing Data Into Two Classes 0 and 1</span></p></td></tr>
</table>
<ul style="list-style:none;"><li>
<h2><a name="bookmark8"></a><span class="font2" style="font-weight:bold;"><a name="bookmark9"></a>2.3 &nbsp;&nbsp;&nbsp;Data Normalization</span></h2></li></ul>
<p><span class="font2">Based on the data above, it can be seen that the domain of each feature can be said to be unbalanced, therefore data normalization is needed to equalize the data for each feature so that no feature that has a large value dominates the results of the classification. Here is the formula for data normalization:</span></p>
<p><span class="font6">y = &nbsp;</span><span class="font5"><sup>x-Dmin</sup> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="font2">(1)</span></p>
<p><span class="font4">D</span><span class="font5">max</span><span class="font4">-D</span><span class="font5">min</span></p>
<p><span class="font2">Information :</span></p>
<ul style="list-style:none;"><li>
<p><span class="font6">y &nbsp;&nbsp;&nbsp;&nbsp;</span><span class="font2">= &nbsp;Value of data after normalization</span></p></li>
<li>
<p><span class="font6">x &nbsp;&nbsp;&nbsp;&nbsp;</span><span class="font2">= &nbsp;Data values before normalization</span></p></li></ul>
<p><span class="font6">D</span><span class="font5"><sub>max</sub> &nbsp;&nbsp;</span><span class="font2">= &nbsp;The maximum value of all original data</span></p>
<p><span class="font6">D</span><span class="font5"><sub>min</sub> &nbsp;&nbsp;</span><span class="font2">= &nbsp;Minimum value of all original data</span></p>
<p><span class="font2">The dataset will be normalized using formula (1). The data normalization process is done using Microsoft Excel tools.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark10"></a><span class="font2" style="font-weight:bold;"><a name="bookmark11"></a>2.4 &nbsp;&nbsp;&nbsp;Perceptron Multilayer Artificial Neural Network</span></h2></li></ul>
<p><span class="font2">Artificial neural network is one of the artificial representations of the human brain which always tries to simulate the learning process in the human brain. The artificial term here is used because this neural network is implemented using a computer program that is able to complete a number of calculation processes during the learning process [1].</span></p>
<p><span class="font2">Neural network is a network of a group of small processing units modeled on the basis of human neural networks. Artificial neural networks are adaptive systems that can change their structure to solve based on external information flowing through the network. In simple terms, neural networks are a non-linear statistical data modeling tool. Artificial conditional networks can be used to model complex relationships between input and output to identify patterns in data. Network with multiple layers(multi layer network)It has certain characteristics, namely having 3 types of layers, namely the input layer, the output layer, and the hidden layer. Networks with many layers can solve more complex problems than a network with a single layer. However, the training process often takes a longer time [1].</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark12"></a><span class="font2" style="font-weight:bold;"><a name="bookmark13"></a>2.5 &nbsp;&nbsp;&nbsp;Feature Selection</span></h2></li></ul>
<p><span class="font2">Feature selection is a preprocessing stage that aims to find the value of the relevance of an attribute to the class label and ignore attributes that do not contribute anything to data classification [6]. This feature selection will analyze the significance value of each feature in the dataset used in the study. Where if the significance value of a feature is close to 0 then the feature has a strong influence on the output dataset. And if the feature significance value is close to 1, the feature will not have a significant effect on the dataset output. Before performing feature selection, a significant value search will be carried out for each feature to the output using the Bivariate Correlation feature on IBM SPSS. The results of the Correlation analysis can be seen in the following Figure:</span></p>
<p><span class="font5">Correlations</span></p>
<p><span class="font0" style="font-weight:bold;">Aspartate-Am &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Albumin_and</span></p>
<table border="1">
<tr><td style="vertical-align:top;"></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">Age</span></p></td><td style="vertical-align:top;">
<p><span class="font0" style="font-weight:bold;">TotaLBiItrubi DirecLBilirubt n &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;n</span></p></td><td style="vertical-align:top;">
<p><span class="font0" style="font-weight:bold;">Alkaline-Pho Sphotase</span></p></td><td style="vertical-align:top;">
<p><span class="font0" style="font-weight:bold;">AlatninO-Anii notransferase</span></p></td><td style="vertical-align:top;">
<p><span class="font0" style="font-weight:bold;">Inotransferas e</span></p></td><td style="vertical-align:top;">
<p><span class="font0" style="font-weight:bold;">TotaLProtien S</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">Albumin</span></p></td><td style="vertical-align:top;">
<p><span class="font0" style="font-weight:bold;">.Global I n_R a tie</span></p></td><td style="vertical-align:top;">
<p><span class="font0" style="font-weight:bold;">Liver_Diseas e</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font1" style="font-weight:bold;">LivecDisease &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;PearsonCiiireiation</span></p></td><td style="vertical-align:top;">
<p><span class="font1" style="font-weight:bold;">.137&quot;</span></p></td><td style="vertical-align:top;">
<p><span class="font1" style="font-weight:bold;">.219&quot; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;.249&quot;</span></p></td><td style="vertical-align:top;">
<p><span class="font1" style="font-weight:bold;">.210&quot;</span></p></td><td style="vertical-align:top;">
<p><span class="font1" style="font-weight:bold;">.174”</span></p></td><td style="vertical-align:top;">
<p><span class="font1" style="font-weight:bold;">,2tΓ</span></p></td><td style="vertical-align:top;">
<p><span class="font1" style="font-weight:bold;">-.029</span></p></td><td style="vertical-align:top;">
<p><span class="font1" style="font-weight:bold;">-.159&quot;</span></p></td><td style="vertical-align:top;">
<p><span class="font1" style="font-weight:bold;">■158&quot;</span></p></td><td style="vertical-align:top;">
<p><span class="font1" style="font-weight:bold;">1</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font1" style="font-weight:bold;">Sii(MaiIed)</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1" style="font-weight:bold;">.003</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1" style="font-weight:bold;">.000 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;.900</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1" style="font-weight:bold;">.000</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1" style="font-weight:bold;">.000</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1" style="font-weight:bold;">.000</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1" style="font-weight:bold;">.521</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1" style="font-weight:bold;">.000</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1" style="font-weight:bold;">.001</span></p></td><td style="vertical-align:top;"></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font1" style="font-weight:bold;">N</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1" style="font-weight:bold;">483</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1" style="font-weight:bold;">483 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;433</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1" style="font-weight:bold;">483</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1" style="font-weight:bold;">433</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1" style="font-weight:bold;">433</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1" style="font-weight:bold;">483</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1" style="font-weight:bold;">483</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1" style="font-weight:bold;">480</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1" style="font-weight:bold;">483</span></p></td></tr>
</table>
<p><span class="font1" style="font-weight:bold;">*. Conelalion is Signiftanf Kthe OOS level (Mailed).</span></p>
<p><span class="font1" style="font-weight:bold;">&quot; Correlation is Significantatltie 0.01 level (Mailed).</span></p>
<h2><a name="bookmark14"></a><span class="font2" style="font-weight:bold;"><a name="bookmark15"></a>Figure 2. Correlation Testing Results</span></h2>
<p><span class="font2">Where if the significance value of a feature is below or equal to 0.05, this feature has a strong influence on the output dataset. And if the feature significance value is more than 0.05, the feature will not have a significant effect on the dataset output. After checking the correlation (can be seen in Figure 2), the results show that the total protein has a correlation value above 0.05 and does not really have an effect on the output dataset, so that in later testing, the total protein will be removed to determine its effect on the test results. In addition to total protein, age as well as albumin will be removed because it has a correlation value below 0.05 and affects the output dataset.From these results in this study several scenarios for selecting features / attributes used in data processing will be determined as follows:</span></p>
<p><span class="font2" style="font-weight:bold;">Table 2. </span><span class="font2">Testing Scenarios</span></p>
<table border="1">
<tr><td style="vertical-align:bottom;">
<p><span class="font2">Scenario</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">Selected Features</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font2">1</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">All Data</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font2">2</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">Without total protein</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2">3</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">Without Age</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font2">4</span></p></td><td style="vertical-align:top;">
<p><span class="font2">Without Albumin</span></p></td></tr>
</table>
<p><span class="font2">Scenario 1 is done in order to find out how much accuracy will be obtained if all the data is used and also as a comparison to other scenarios. Scenario 2 is carried out in order to determine the effect of uncorrelated data variables on the classification results obtained. Scenarios 3 and 4 are carried out in order to determine the effect of correlated data on the classification results obtained.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark16"></a><span class="font2" style="font-weight:bold;"><a name="bookmark17"></a>2.6 &nbsp;&nbsp;&nbsp;Data Processing</span></h2></li></ul>
<p><span class="font2">The classification method used in this research is the Artificial Neural Network Multilayer Perceptron method. This is done by finding the optimal number of hidden layer neurons by comparing the number of hidden layers used. The maximum duration of training used is 15 minutes, the maximum epoch given is 1000 and the proportion of training data and test data used is 70:30. After obtaining the optimal number of hidden neurons, the effect of feature selection on the classification of liver disease will be carried out using the number of hidden neurons that have been obtained and using the maximum training time, maximum epoch, the same data proportion as when testing the number of hidden layer neurons.</span></p><img src="https://jurnal.harianregional.com/media/64472-2.jpg" alt="" style="width:342pt;height:475pt;">
<p><span class="font2" style="font-weight:bold;">Figure 3. Example of ANN Architecture</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark18"></a><span class="font2" style="font-weight:bold;"><a name="bookmark19"></a>2.7 &nbsp;&nbsp;&nbsp;Analysis of Data Processing Results</span></h2></li></ul>
<p><span class="font2">The things that will be analyzed in this study are the effect of reducing correlated and uncorrelated features of the target on the accuracy and computation time of the classification of liver disease using the Multilayer Perceptron method using SPSS.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark20"></a><span class="font2" style="font-weight:bold;"><a name="bookmark21"></a>3. &nbsp;&nbsp;&nbsp;Results and Discussion</span><br><br><span class="font2" style="font-weight:bold;"><a name="bookmark22"></a>3.1 &nbsp;&nbsp;&nbsp;Data Processing</span></h2></li></ul>
<p><span class="font2">At the data processing stage, a Perceptron Multilayer Neural Network will be implemented which will be carried out on the IBM SPSS tool. In IBM SPSS, there is a Neural Network feature that can be used to apply the Multilayer Perceptron method. The implementation used is the same as that described at the data sharing stage, namely 7: 3.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font2" style="font-weight:bold;">1. &nbsp;&nbsp;&nbsp;Testing the number of hidden neurons.</span></p></li></ul>
<p><span class="font2">In testing the number of hidden neurons, the aim is to obtain the optimal number of hidden neurons so as to increase the accuracy obtained. The results obtained can be seen in the table below:</span></p>
<p><span class="font2" style="font-weight:bold;">Table 3. </span><span class="font2">Hidden Layer Measurement Results</span></p>
<table border="1">
<tr><td style="vertical-align:bottom;">
<p><span class="font2" style="font-weight:bold;">Number of Units on Hidden Layer</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2" style="font-weight:bold;">Accuracy</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2" style="font-weight:bold;">Time</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font2">2</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">71.2</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">0.09</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font2">4</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">72.5</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">0.1</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font2">6</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">71.8</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">0.08</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font2">8</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">72.7</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">0.1</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font2">10</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">73.8</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">0.11</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font2">12</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">73.1</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">0.12</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font2">14</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">72.9</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">0.1</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font2">16</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">73.9</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">0.1</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font2">18</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">73.8</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">0.11</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font2">20</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">74.2</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">0.12</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font2">22</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">74.12</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">0.1</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font2">24</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">74.05</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">0.13</span></p></td></tr>
</table>
<p><span class="font2">From the experiments that have been carried out, the optimal number of hidden neurons is as many as 20 with an accuracy obtained of 74.2%, but the number of hidden neuron units is also used to find the effect of feature selection</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark23"></a><span class="font2" style="font-weight:bold;"><a name="bookmark24"></a>2. &nbsp;&nbsp;&nbsp;The effect of feature selection</span></h2></li></ul>
<p><span class="font2">The effect of feature selection to determine the accuracy and computation time of the classification will use the number of hidden neurons that have been obtained, namely as many as 20 with a maximum training time of 15 minutes. The results of accuracy and computation time can be seen as follows:</span></p>
<p><span class="font2" style="font-weight:bold;">Table 4. </span><span class="font2">Feature Selection Results</span></p>
<table border="1">
<tr><td rowspan="2" style="vertical-align:middle;">
<p><span class="font2" style="font-weight:bold;">Trial</span></p></td><td colspan="2" style="vertical-align:middle;">
<p><span class="font2" style="font-weight:bold;">All Data</span></p></td><td colspan="2" style="vertical-align:bottom;">
<p><span class="font2" style="font-weight:bold;">Without total protein</span></p></td><td colspan="2" style="vertical-align:bottom;">
<p><span class="font2" style="font-weight:bold;">No Age</span></p></td><td colspan="2" style="vertical-align:bottom;">
<p><span class="font2" style="font-weight:bold;">Without Albumin</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2" style="font-weight:bold;">Accurac y</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2" style="font-weight:bold;">Time</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2" style="font-weight:bold;">Accurac y</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2" style="font-weight:bold;">Time</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2" style="font-weight:bold;">Accurac y</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2" style="font-weight:bold;">Time</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2" style="font-weight:bold;">Accurac y</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2" style="font-weight:bold;">Time</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font2">1</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">72.1</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">0.12</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">72.5</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">0.15</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">76.7</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">12</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">75.9</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">0.11</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font2">2</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">74.5</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">0.14</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">73.4</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">0.1</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">76.6</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">0.16</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">74.2</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">0.14</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font2">3</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">73.7</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">0.17</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">72.9</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">0.13</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">77.6</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">0.19</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">74.7</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">0.13</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font2">4</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">74.7</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">0.11</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">78.6</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">0.1</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">75.3</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">0.12</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">76.6</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">0.1</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font2">5</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">74.8</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">0.16</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">74.6</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">0.15</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">75.3</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">0.11</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">75.7</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">0.14</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font2">6</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">74.5</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">0.14</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">73.9</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">0.13</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">72.5</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">0.16</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">75.5</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">0.14</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font2">7</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">75.3</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">0.14</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">74.7</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">0.13</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">75.6</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">0.13</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">76.6</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">0.13</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2">8</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">75.3</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">0.11</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">73.5</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">0.13</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">76</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">0.18</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">76.2</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2">0.12</span></p></td></tr>
</table>
<table border="1">
<tr><td style="vertical-align:top;">
<p><span class="font2">9</span></p></td><td style="vertical-align:top;">
<p><span class="font2">73.7</span></p></td><td style="vertical-align:top;">
<p><span class="font2">0.14</span></p></td><td style="vertical-align:top;">
<p><span class="font2">72.1</span></p></td><td style="vertical-align:top;">
<p><span class="font2">0.14</span></p></td><td style="vertical-align:top;">
<p><span class="font2">74.5</span></p></td><td style="vertical-align:top;">
<p><span class="font2">0.17</span></p></td><td style="vertical-align:top;">
<p><span class="font2">75.9</span></p></td><td style="vertical-align:top;">
<p><span class="font2">0.11</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font2">10</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">72.2</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">0.17</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">74.3</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">0.13</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">72.9</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">0.14</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">74.5</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">0.12</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font2" style="font-weight:bold;">Average</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2" style="font-weight:bold;">74.08</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2" style="font-weight:bold;">0.14</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2" style="font-weight:bold;">74.05</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2" style="font-weight:bold;">0.129</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2" style="font-weight:bold;">75.3</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2" style="font-weight:bold;">1,336</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2" style="font-weight:bold;">75.58</span></p></td><td style="vertical-align:bottom;">
<p><span class="font2" style="font-weight:bold;">0.124</span></p></td></tr>
</table>
<ul style="list-style:none;"><li>
<h2><a name="bookmark25"></a><span class="font2" style="font-weight:bold;"><a name="bookmark26"></a>3.2 &nbsp;&nbsp;&nbsp;Results Analysis</span></h2></li></ul>
<p><span class="font2">The results of the Multilayer Perceptron implementation which aims to determine the effect of feature selection on the classification results shown in Table 4 show that the feature selection results do not really affect the computation time. For the accuracy results obtained, uncorrelated data does not really affect the results of accuracy (has a small difference when compared to scenario 1), where the accuracy obtained decreases by 0.04% and correlated data has more influence on the classification results, which can be where the accuracy increased by 1.64% and 2.02%, it can be seen from the following table:</span></p>
<p><span class="font2" style="font-weight:bold;">Table 5. </span><span class="font2">Percentage Decreased Computing Time</span></p>
<table border="1">
<tr><td style="vertical-align:middle;">
<p><span class="font2">Scenario</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">Average Accuracy</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">Difference (with scenario 1 accuracy)</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font2">1</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">74.08</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">0%</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font2">2</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">74.05</span></p></td><td style="vertical-align:middle;">
<p><span class="font2">0.04049% decrease</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font2">3</span></p></td><td style="vertical-align:top;">
<p><span class="font2">75.3</span></p></td><td style="vertical-align:top;">
<p><span class="font2">1.64% increase</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font2">4</span></p></td><td style="vertical-align:top;">
<p><span class="font2">75.58</span></p></td><td style="vertical-align:top;">
<p><span class="font2">2.02% increase</span></p></td></tr>
</table>
<ul style="list-style:none;"><li>
<h2><a name="bookmark27"></a><span class="font2" style="font-weight:bold;"><a name="bookmark28"></a>4 &nbsp;&nbsp;&nbsp;Conclusion</span></h2></li></ul>
<p><span class="font2">This study aims to determine the effect of using feature selection and without using feature selection for classification of liver disease and also to examine the effect of changing the number of units in the hidden layer on the results of classification of liver disease. The type of data used in this study is the Liver Disease Lab data obtained from the Kaggle Dataset. This liver disease data has a total of 483 data records. Where in comparing the results of using feature selection, it is divided into 4 scenarios that have been determined by searching for the significance value with the SPSS correlation.</span></p>
<p><span class="font2">In this study, the results show that the accuracy obtained from eliminating uncorrelated data does not really affect the accuracy results where it only has a decrease of 0.04049%, while the correlated features are more influential on the classification results obtained, where the accuracy increases by 1.64%. and 2.02%.For computation time, feature selection does not really affect the computation time obtained. In the future, it is hoped that more research on feature selection will be carried out using different data and changes in different ANN parameters so that it will get better accuracy.</span></p>
<h2><a name="bookmark29"></a><span class="font2" style="font-weight:bold;"><a name="bookmark30"></a>Reference</span></h2>
<ul style="list-style:none;"><li>
<p><span class="font2">[1] &nbsp;&nbsp;&nbsp;Solikhun, and M. Wahyudi, Jaringan Syaraf Tiruan Backpropagation Pengenalan Pola Calon Debiur, Medan, Yayasan Kita Menulis, 2020.</span></p></li>
<li>
<p><span class="font2">[2] &nbsp;&nbsp;&nbsp;R. S. Suhartanto, C. Dewi, and L. Muflikhah, “Implementasi Jaringan Syaraf Tiruan Backpropagation untuk Mendiagnosis Penyakit Kulit pada Anak” Jurnal Pengembangan Teknologi Informasi dan Ilmu Komputer, vol.1, no. 7, 2017.</span></p></li>
<li>
<p><span class="font2">[3] &nbsp;&nbsp;&nbsp;Nunik Purwaningsih, &quot;Penerapan Multilayer Perceptron Untuk Klasifikasi Jenis Kulit Sapi Tersamak&quot; Jurnal TEKNOIF, vol. 4,no 1, 2016.</span></p></li>
<li>
<p><span class="font2">[4] &nbsp;&nbsp;&nbsp;T. Astuti and T. Ferinanto, &quot;Diagnosis Penyakit Parkinson Berdasarkan Kombinasi Algoritme Data Mining Dan Seleksi Fitur,&quot; Seminar Nasional APTIKOM (SEMNASTIKOM), pp. 127-130, 2016</span></p></li>
<li>
<p><span class="font2">[5] &nbsp;&nbsp;&nbsp;A. and I. Satriadi, &quot;Implementasi Jaringan Syaraf Tiruan Dengan Multilayer Perceptron Untuk Analisa Pemberian Kredit,&quot; Jurnal Riset Komputer (JURIKOM), vol. 5, pp. 605-610, 2018.</span></p></li>
<li>
<p><span class="font2">[6] &nbsp;&nbsp;&nbsp;K. D. Prebiana and I G. S. Astawa, “Influence Optimization Feature Against Liver Disorders Diagnostic Results Using Artificial Neural Network”, Jurnal Elektronik Ilmu Komputer Udayana, vol. 8, no.3, 2020.</span></p></li></ul>
<p><span class="font2">358</span></p>