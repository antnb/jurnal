---
layout: full_article
title: "The Comparison of SVM and ANN Classifier for COVID-19 Prediction"
author: "Ditha Nurcahya Avianty, Prof. I Gede Pasek Suta Wijaya, Fitri Bimantoro"
categories: lontar
canonical_url: https://jurnal.harianregional.com/lontar/full-79732 
citation_abstract_html_url: "https://jurnal.harianregional.com/lontar/id-79732"
citation_pdf_url: "https://jurnal.harianregional.com/lontar/full-79732"  
comments: true
---

<p><span class="font1" style="font-weight:bold;">LONTAR KOMPUTER VOL. 13, NO. 2 AUGUST 2022</span></p>
<p><span class="font1" style="font-weight:bold;">DOI : 10.24843/LKJITI.2022.v13.i02.p06</span></p>
<p><span class="font1" style="font-weight:bold;">Accredited Sinta 2 by RISTEKDIKTI Decree No. 158/E/KPT/2021</span></p>
<p><span class="font1" style="font-weight:bold;">p-ISSN 2088-1541</span></p>
<p><span class="font1" style="font-weight:bold;">e-ISSN 2541-5832</span></p><a name="caption1"></a>
<h1><a name="bookmark0"></a><span class="font2" style="font-weight:bold;"><a name="bookmark1"></a>The Comparison of SVM and ANN Classifier for COVID-19 Prediction</span></h1>
<p><span class="font1">Ditha Nurcahya Avianty<sup>a1</sup></span><span class="font1" style="font-weight:bold;">, </span><span class="font1">I Gede Pasek Suta Wijaya<sup>a2</sup></span><span class="font1" style="font-weight:bold;">, </span><span class="font1">Fitri Bimantoro<sup>b3</sup></span></p>
<p><span class="font1">Dept Informatics Engineering,Faculty of Engineering, University of Mataram Jl. Majapahit No.62, Mataram, Lombok NTB - Indonesia </span><a href="mailto:1dithanurcahya55@email.com"><span class="font1"><sup>1</sup>dithanurcahya55@email.com</span></a></p>
<p><span class="font1"><sup>2,3</sup>[gpsutawijaya,bimo]@unram.ac.id</span></p>
<p><span class="font1" style="font-weight:bold;font-style:italic;">Abstract</span></p>
<p><span class="font1" style="font-style:italic;">Coronavirus 2 (SARS-CoV-2) is the cause of an acute respiratory infectious disease that can cause death, popularly known as Covid-19. Several methods have been used to detect COVID-19-positive patients, such as rapid antigen and PCR. Another method as an alternative to confirming a positive patient for COVID-19 is through a lung examination using a chest X-ray image. Our previous research used the ANN method to distinguish COVID-19 suspect, pneumonia, or expected by using a Haar filter on Discrete Wavelet Transform (DWT) combined with seven Hu Moment Invariants. This work adopted the ANN method's feature sets for the Support Vector Machine (SVM), which aim to find the best SVM model appropriate for DWT and Hu moment-based features. Both approaches demonstrate promising results, but the SVM approach has slightly better results. The SVM's performances improve accuracy to 87.84% compared to the ANN approach with 86% accuracy.</span></p>
<p><span class="font1" style="font-weight:bold;font-style:italic;">Keywords: </span><span class="font1" style="font-style:italic;">X-ray image, COVID-19, Classification, Support Vector Machine, Artificial Neural Network</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark2"></a><span class="font1" style="font-weight:bold;"><a name="bookmark3"></a>1. &nbsp;&nbsp;&nbsp;Introduction</span></h2></li></ul>
<p><span class="font1">The COVID-19 disease's first outbreak in Wuhan, China, in December 2019 [1] is a respiratory infectious disease caused by coronavirus 2 (SARS-CoV-2). This disease is highly contagious and can be transmitted through the droplet, spreading quickly and widely [2]. The PCR (Polymerase Chain Reaction) swab test is a highly recommended method for detecting COVID-19 patients [3], but it requires health personnel resources and expensive equipment, and a lengthy analysis process [4]. Another method is a rapid antigen that requires a fast time but can only detect suspected COVID-19. The delay in test outcomes and the deficiency of test kits create it challenging to determine the number of positive possibilities of COVID-19 so that the spread of the infection is more expansive and can worsen the situation [4] [5].</span></p>
<p><span class="font1">Other techniques to detect COVID-19 are examining clinical symptoms, epidemiological records, Computed Tomography (CT) images or chest X-rays, and positive pathogen tests [6]. Radiographic images obtained via X-rays can be used to examine suspected cases of COVID-19 through analysis of pneumonia. Chest X-rays were chosen for examination because they are cheaper, have minor radiation exposure, and have more comprehensive use coverage than CT scans [9][10]. Based on WHO data, that COVID-19 patients generally suffer from severe pneumonia [7]. The Ref [7] is in line with research in China, which showed that 91.1% of 1099 patients diagnosed with Covid-19 developed pneumonia [8]. The similarities between COVID-19 and pneumonia make it difficult for radiologists to distinguish between them, leading to misdiagnosis. Misdiagnosis of disease can result in delays and incorrect treatment resulting in mental and material losses.</span></p>
<p><span class="font1">Artificial Intelligence (AI) can be developed to assist doctors in diagnosing patients, such as the diagnosis of chest radiographs. One of them uses the Support Vector Machine (SVM). SVM is a learning machine that can be used for image classification of more than two classes. Multiclass SVM can currently classify data into several classes (more than two). Previous studies related to the classification of COVID-19 based on X-ray images using the Convolution Neural Network</span></p>
<p><span class="font1">(CNN) approaches succeeded in providing an accuracy of 83.4% and 93.2% [11]. While the CNN variation model called CVDNet has succeeded in classifying x-ray images into COVID-19, pneumonia, and normal categories, which has an accuracy of 96.69% [12]. Another radiographic image study based on the Artificial Neural Network (ANN) for classifying six categories was also successfully developed and gave the best accuracy of 88.5% [13].</span></p>
<p><span class="font1">The moment invariant feature of MRI image application for classifying Alzheimer's disease[14] has been successfully carried out and provides 91.4% accuracy for the KNN technique and 100% accuracy for the SVM technique. Application of features based on Discrete Wavelet Transforms (DWT) and ANN to classify brain images with an accuracy of 94.8% [15].</span></p>
<p><span class="font1">Another study that applied DWT and ANN haar filters to view cracks under the support of ScaleInvariant Feature Transformation and K-means clustering has achieved an accuracy of 93.4% [16]. Furthermore, the application of DWT feature extraction and Principal Component Analysis with ANN classifier to detect minor chronic brain hemorrhage resulted in 88.43% accuracy. Another work to classify weeds based on moment invariant features and ANN classification techniques has achieved an accuracy of 92.5%[17].</span></p>
<p><span class="font1">Based on the background outlined above, the author intends to conduct a study to create a model to predict COVID-19 by comparing the SVM and ANN methods. The comparison is made because the two calculation methods have similarities in the information to be considered, distinguishing them in the settlement process. Additionally, this study is a development of the DWT and Moment Invariant-based features of chest x-ray images[18] and Covid-19 prediction based on DWT and moment invariant features and ANN classifier[19]. The main aim of this work is to find the best SVM model appropriate for mentioned features.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark4"></a><span class="font1" style="font-weight:bold;"><a name="bookmark5"></a>2. &nbsp;&nbsp;&nbsp;Research Methods</span><br><br><span class="font1" style="font-weight:bold;"><a name="bookmark6"></a>2.1. &nbsp;&nbsp;&nbsp;Dataset and Tools</span></h2></li></ul>
<p><span class="font1">This research utilizes a dataset of chest radiography images [20] consisting of three categories, namely COVID-19, pneumonia, and normal. Each class has 1345 images with a resolution of 1024x1024 pixels and is saved in jpg format. The hardware tool used to complete the research is a computer with specifications Intel 8th Gen Core i7 processor, NVIDIA Geforce GPU, and 8 GB RAM. While the software running in this work is Windows 10 64-bit, Python 3.8.5, JupyterLab, and Visual Studio Code.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark7"></a><span class="font1" style="font-weight:bold;"><a name="bookmark8"></a>2.2. &nbsp;&nbsp;&nbsp;Research Processes</span></h2></li></ul>
<p><span class="font1">The research was completed through four main processes: literature study, data preparation, and modeling and testing. The literature study examined the primary sources of research, especially journals and proceedings related to radiographic images, DWT methods, invariant moments, and SVM. The study is in the form of analyzing the advantages and disadvantages of the methods associated with this research.</span></p>
<p><span class="font1">Data preparation is data selection for the training and testing process. The dataset is a collection of chest radiography images from a research team from Qatar University and the University of Dhaka Bangladesh and collaborators from Pakistan and Malaysia. In this case, the data were randomly selected from a dataset consisting of 15153 images [20]. Based on the query, it turns out that the number of samples of the image is not balanced per category, which can generate issues associated with the achievements of the machine learning model that was built. This issue is solved by resampling the dataset in two manners: under-sampling and over-sampling. In the case of covid classification, the primary item to remark is the number of false negatives because this fallacy is the most harmful compared to false positives. So, under-sampling is done to reduce the large class size so that the data is proportional.</span></p>
<p><span class="font1">Examples of chest radiographic images for the three classes from the data preparation process are presented in Figures 1, 2, and 3. Figures 2 and 3 show the class data for Covid-19 and Pneumonia, which have characteristic white marks on the lungs with particular intensity levels. However, the white mark intensity level on the COVID-19 chest radiograph is different in brightness. This pattern will be extracted and made into a model for its classification. While Figure</span></p>
<p><span class="font1">4 is a chest radiograph image of the normal class, which is dominated by black color in the lungs, which shows the air content in the lungs.</span></p>
<div><img src="https://jurnal.harianregional.com/media/79732-1.jpg" alt="" style="width:221pt;height:66pt;">
<p><span class="font1" style="font-weight:bold;">Figure 1. </span><span class="font1">COVID-19 image samples</span></p>
</div><br clear="all">
<div><img src="https://jurnal.harianregional.com/media/79732-2.jpg" alt="" style="width:221pt;height:67pt;">
<p><span class="font1" style="font-weight:bold;">Figure 2. </span><span class="font1">Pneumonia image samples</span></p>
</div><br clear="all">
<div><img src="https://jurnal.harianregional.com/media/79732-3.jpg" alt="" style="width:66pt;height:66pt;">
</div><br clear="all">
<div><img src="https://jurnal.harianregional.com/media/79732-4.jpg" alt="" style="width:66pt;height:66pt;">
<p><span class="font1" style="font-weight:bold;">Figure 3. </span><span class="font1">Normal image samples</span></p>
</div><br clear="all">
<div><img src="https://jurnal.harianregional.com/media/79732-5.jpg" alt="" style="width:66pt;height:66pt;">
</div><br clear="all">
<p><span class="font1">Modeling and testing require several sub-processes, such as pre-processing, feature extraction, and SVM creation, which will be explained in the following subsection.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark9"></a><span class="font1" style="font-weight:bold;"><a name="bookmark10"></a>2.3. &nbsp;&nbsp;&nbsp;Model Construction</span></h2></li></ul>
<p><span class="font1">In simple terms, there are two main processes, namely training and testing, for developing a COVID-19 prediction model, which is presented in Figure 4.</span></p>
<div><img src="https://jurnal.harianregional.com/media/79732-6.jpg" alt="" style="width:234pt;height:210pt;">
<p><span class="font1" style="font-weight:bold;">Figure 4. </span><span class="font1">Training and Testing Process</span></p>
</div><br clear="all">
<p><span class="font1">The training process's first stage is image resizing, grayscale conversion, and normalization, which aims to speed up the process and avoid data inconsistency problems. The second stage is the feature extraction process, which uses the DWT and moment invariant methods, which are then used to train SVM. The third stage is to do SVM testing using validation data taken from training data. Finally, the best training SVM model is stored for the testing data prediction process.</span></p>
<p><span class="font1">The testing process is carried out using the first and second stages of the training process for each testing image. Furthermore, the best training SVM model is used for the classification of testing image features. Confusion matrix, precision, and recall are used to assess the performance of the proposed prediction system.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark11"></a><span class="font1" style="font-weight:bold;"><a name="bookmark12"></a>2.3.1. &nbsp;&nbsp;&nbsp;Pre-processing</span></h2></li></ul>
<p><span class="font1">At this stage, the input image dataset with a resolution of 1024x1024 pixels is converted to grayscale, resized to 128x128 pixels, and finally normalized. An illustration of the pre-processing process is presented in Figure 5.</span></p>
<div><img src="https://jurnal.harianregional.com/media/79732-7.jpg" alt="" style="width:333pt;height:76pt;">
<p><span class="font1" style="font-weight:bold;">Figure 5. </span><span class="font1">Pre-processing illustration</span></p>
</div><br clear="all">
<ul style="list-style:none;"><li>
<h2><a name="bookmark13"></a><span class="font1" style="font-weight:bold;"><a name="bookmark14"></a>2.3.2. &nbsp;&nbsp;&nbsp;Feature Extraction</span></h2></li></ul>
<p><span class="font1">Each pre-processed image will have its features extracted using the DWT method and invariant moment. Feature extraction was performed using a first-order Daubechies wavelet filter (Haar). The implementation process to get four sub-image called average, detail-horizontal, detailvertical, and detail-diagonal of the input image are done by applying the &quot;PyWavelets&quot; library. Furthermore, the mean, variance, and statistical energy values were calculated from each of the approximation, horizontal, vertical, and diagonal sub-images. An illustration of the feature extraction process with DWT is given in Figure 6.</span></p>
<div><img src="https://jurnal.harianregional.com/media/79732-8.jpg" alt="" style="width:285pt;height:76pt;">
<p><span class="font1" style="font-weight:bold;">Figure 6. </span><span class="font1">The illustration of DWT's feature extraction</span></p>
</div><br clear="all">
<p><span class="font1">The moment invariant value, which represents the change in value for translational and rotational variations, is extracted from the approximation component (C_A) of the DWT results. This component was chosen because it is the most similar component to the input image. The illustration of moment invariant feature extraction is given in Figure 7.</span></p>
<div><img src="https://jurnal.harianregional.com/media/79732-9.jpg" alt="" style="width:126pt;height:71pt;">
</div><br clear="all">
<div>
<table border="1">
<tr><td style="vertical-align:top;"></td><td style="vertical-align:bottom;">
<p><span class="font4">Approximation component.png</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font4">pl</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0.16276407596556242</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font4">pl</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0.026555625477610725</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font4">Pl</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">4.28057395545598e-05</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font4">&lt;p4</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">0.0004818795427940936</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font4" style="font-style:italic;">φS</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">-6.916433479932948e-O8</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font4">φ6</span></p></td><td style="vertical-align:bottom;">
<p><span class="font4">3.6081291901626007e-06</span></p></td></tr>
<tr><td style="vertical-align:top;"></td><td style="vertical-align:top;">
<p><span class="font4">l,6752194357134434e-O8</span></p></td></tr>
</table>
</div><br clear="all">
<p><span class="font1" style="font-weight:bold;">Figure 7. </span><span class="font1">The illustration of invariant moment feature extraction.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark15"></a><span class="font1" style="font-weight:bold;"><a name="bookmark16"></a>2.3.3. &nbsp;&nbsp;&nbsp;Training</span></h2></li></ul>
<p><span class="font1">The initial process of the training stage is to load the features from the feature extraction stage. The features will be trained with the SVM method. The multiclass support is handled according to a one-vs-one scheme. The One-vs-One strategy splits a multiclass classification into one binary classification problem per each pair of classes. The training process results are stored in the form of a struct for later use in the testing process.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark17"></a><span class="font1" style="font-weight:bold;"><a name="bookmark18"></a>2.3.4. &nbsp;&nbsp;&nbsp;Testing</span></h2></li></ul>
<p><span class="font1">The confusion matrix shown in Table 1 is a tool to assess the result of the model's achievements. True COVID-19 (TC) is the actual data of the COVID-19 category correctly predicted COVID-19. False COVID-19 (FC) is pneumonia or normal category data incorrectly predicted as COVID-19. True Pneumonia (TP) is pneumonia category data correctly predicted as pneumonia. False Pneumonia (FP) is another category incorrectly predicted as pneumonia. True Normal (TN) is a normal category correctly predicted as a normal category. False Normal (FN) is another category incorrectly predicted as a normal category.</span></p>
<p><span class="font1" style="font-weight:bold;">Table 1. </span><span class="font1">Confusion matrix </span><span class="font1" style="text-decoration:underline;">tool for model evaluation</span></p>
<p><span class="font0" style="font-weight:bold;">Predicted </span><span class="font1" style="font-weight:bold;">category</span></p>
<p><span class="font0" style="font-weight:bold;">Covid-19 &nbsp;&nbsp;Pneumonia Normal</span></p>
<table border="1">
<tr><td rowspan="2" style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">Actual</span></p></td><td style="vertical-align:top;">
<p><span class="font0" style="font-weight:bold;">Covid-19</span></p></td><td style="vertical-align:top;">
<p><span class="font0">TC</span></p></td><td style="vertical-align:top;">
<p><span class="font0">FP</span></p></td><td style="vertical-align:top;">
<p><span class="font0">FN</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0" style="font-weight:bold;">Pneumonia</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">FC</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">TP</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">FN</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font1" style="font-weight:bold;">category</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0" style="font-weight:bold;">Normal</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">FC</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">FP</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">TN</span></p></td></tr>
</table>
<p><span class="font1">The Confusion matrix will calculate three quantities: accuracy, precision, and recall. Accuracy is calculated using equation 1.</span></p>
<div>
<p><span class="font7" style="font-style:italic;">accuracy =</span></p>
</div><br clear="all">
<div>
<p><span class="font5" style="font-style:italic;">(TC) + (TP) + (TN)</span></p>
<p><span class="font5" style="font-style:italic;">Total</span></p>
</div><br clear="all">
<div>
<p><span class="font6">(1)</span></p>
</div><br clear="all">
<p><span class="font1">The precision calculated using equation 2 is the level of correctness of the instance to forecast the category that matches the actual category. The accuracy is very valuable for specifying the effect of false positives. The model detects a non-covid category as COVID-19, implying that the instance lacks precision.</span></p>
<div>
<p><span class="font7" style="font-style:italic;">precision =</span></p>
</div><br clear="all">
<div>
<p><span class="font5" style="font-style:italic;text-decoration:underline;">(TC)</span></p>
<p><span class="font5" style="font-style:italic;">(TC) + (FC)</span></p>
</div><br clear="all">
<div>
<p><span class="font1">(2)</span></p>
</div><br clear="all">
<p><span class="font1">The recall calculated using equation 3 is valuable for defining the effect of false negatives. The instance incorrectly predicts COVID-19 data as non-covid, meaning recall is of low value. The Covid prediction system becomes very dangerous if the system has a low recall.</span></p>
<p><span class="font7" style="font-style:italic;">recall </span><span class="font5" style="font-style:italic;">=-----</span><span class="font3" style="font-variant:small-caps;"><sup>ctc</sup>)-----</span></p>
<div>
<p><span class="font1">(3)</span></p>
</div><br clear="all">
<p><span class="font5" style="font-style:italic;">(TC) + (FP) + (FN)</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark19"></a><span class="font1" style="font-weight:bold;"><a name="bookmark20"></a>2.3.5. &nbsp;&nbsp;&nbsp;Testing Mechanism</span></h2></li></ul>
<p><span class="font1">Testing is accomplished with several phases to obtain the best model. The first phase is to choose 1345 images randomly from the dataset. Furthermore, the selected data is split under the ratio of 80% versus 20% for the training and testing set, respectively. The SVM model is tested to find the best parameters using Grid Search:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1">1) &nbsp;&nbsp;&nbsp;C (0.1, 1, 10, 100, 1000)</span></p></li>
<li>
<p><span class="font1">2) &nbsp;&nbsp;&nbsp;Kernel (linear, polynomial, sigmoid, and radial basis function (RBF))</span></p></li>
<li>
<p><span class="font1">3) &nbsp;&nbsp;&nbsp;Gamma (1, 0.1, 0.01, 0.001, 0.0001)</span></p></li></ul>
<p><span class="font1">The initial parameters applied in the model test are the value of C=0.1, Gamma=1, and the linear kernel. The initial parameter values are selected from the first-order value of each test parameter. Finally, the best model is evaluated by k-fold cross-validation utilizing the k = 2~10 to validate and keep away bias in data sharing.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark21"></a><span class="font1" style="font-weight:bold;"><a name="bookmark22"></a>3. &nbsp;&nbsp;&nbsp;Result and Discussion</span><br><br><span class="font1" style="font-weight:bold;"><a name="bookmark23"></a>3.1. &nbsp;&nbsp;&nbsp;Testing on the value of C</span></h2></li></ul>
<p><span class="font1">This test aims to determine the best value of the C parameter of the SVM model. It is well known that the values of C and Gamma depend on the case of the image being handled. The test results for variations in the value of C are presented in Table 2.</span></p>
<table border="1">
<tr><td colspan="4" style="vertical-align:bottom;">
<p><span class="font1" style="font-weight:bold;">Table 2. </span><span class="font1">The value of C versus the performance indicator</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font1" style="font-weight:bold;">C</span></p></td><td style="vertical-align:middle;">
<p><span class="font1" style="font-weight:bold;">Accuracy</span></p></td><td style="vertical-align:middle;">
<p><span class="font1" style="font-weight:bold;">Precision</span></p></td><td style="vertical-align:middle;">
<p><span class="font1" style="font-weight:bold;">Recall</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font1" style="font-weight:bold;">0.1</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">47%</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">35%</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">48%</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font1" style="font-weight:bold;">1</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">58%</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">55%</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">56%</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font1" style="font-weight:bold;">10</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">63%</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">62%</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">62%</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font1" style="font-weight:bold;">100</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">67%</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">67%</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">66%</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font1" style="font-weight:bold;">1000</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">77%</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">77%</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">76%</span></p></td></tr>
</table>
<p><span class="font1">According to Table 4, the best achievement was obtained at the value of C=1000. The C parameter tells the SVM optimizer how much we want to avoid misclassifying each training instance. In this case, the larger the value of C, the higher the model's performance. For larger C values, the optimization will select a hyperplane with less margin if that hyperplane provides all training data classified correctly. Furthermore, the value of C=1000 will be employed in the following evaluation.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark24"></a><span class="font1" style="font-weight:bold;"><a name="bookmark25"></a>3.2. &nbsp;&nbsp;&nbsp;Testing the kernel type</span></h2></li></ul>
<p><span class="font1">A kernel is a way of adding more features to the data to make it linearly separable. The kernel variations will also produce different performances depending on the data. Polynomial, RBF, and sigmoid kernels are popular, especially for non-linear data. The achievement of each variation on the kernel type is shown in Table 3.</span></p>
<p><span class="font1" style="font-weight:bold;">Table 3. </span><span class="font1">The type of kernel versus the performance indicator</span></p>
<table border="1">
<tr><td style="vertical-align:top;">
<p><span class="font1" style="font-weight:bold;">kernel</span></p></td><td style="vertical-align:top;">
<p><span class="font1" style="font-weight:bold;">Accuracy</span></p></td><td style="vertical-align:top;">
<p><span class="font1" style="font-weight:bold;">Precision</span></p></td><td style="vertical-align:top;">
<p><span class="font1" style="font-weight:bold;">Recall</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font1" style="font-weight:bold;">linear</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">77%</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">77%</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">76%</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font1" style="font-weight:bold;">polynomial</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">86%</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">86%</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">86%</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font1" style="font-weight:bold;">RBF</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">81%</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">81%</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">81%</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font1" style="font-weight:bold;">sigmoid</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">16%</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">10%</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">15%</span></p></td></tr>
</table>
<p><span class="font1">The experimental result in Table 3 shows that the best achievement of the SVM model is given when the polynomial kernel type is applied. Furthermore, the polynomial kernel type will be employed for the next evaluation.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark26"></a><span class="font1" style="font-weight:bold;"><a name="bookmark27"></a>3.3. &nbsp;&nbsp;&nbsp;Testing on the value of Gamma</span></h2></li></ul>
<p><span class="font1">Similar to the C parameter, the variations values of Gamma will deliver different interpretations depending on the image obstacle being addressed. In this work, five Gamma variations were evaluated, and the experimental results are presented in Table 4.</span></p>
<p><span class="font1" style="font-weight:bold;text-decoration:underline;">Table 4. </span><span class="font1" style="text-decoration:underline;">The Gamma variations versus the performance indicator Gam</span><span class="font1">ma</span></p>
<table border="1">
<tr><td style="vertical-align:top;">
<p><span class="font1" style="font-weight:bold;">Gamma</span></p></td><td style="vertical-align:top;">
<p><span class="font1" style="font-weight:bold;">Accuracy</span></p></td><td style="vertical-align:top;">
<p><span class="font1" style="font-weight:bold;">Precision</span></p></td><td style="vertical-align:top;">
<p><span class="font1" style="font-weight:bold;">Recall</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font1" style="font-weight:bold;">1</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">86%</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">86%</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">86%</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font1" style="font-weight:bold;">0.1</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">72%</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">72%</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">71%</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font1" style="font-weight:bold;">0.01</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">46%</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">37%</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">47%</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font1" style="font-weight:bold;">0.001</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">30%</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">10%</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">33%</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font1" style="font-weight:bold;">0.0001</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">30%</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">10%</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">33%</span></p></td></tr>
</table>
<p><span class="font1">Table 4 shows that the Gamma=1 gives the best achievement. It can be seen that the Gamma value significantly affects the accomplishment of the SVM model. The achievement of the SVM model decreases along with the smaller Gamma value.</span></p>
<p><span class="font1">Finally, it can be concluded that the three best parameters for the SVM model are C=1000, Gamma=1, and polynomial kernel type, which provides the highest performance. Hence, the best SVM model is evaluated for the data test, and the confusion matrix in Table 5 represents the test results.</span></p>
<p><span class="font1" style="font-weight:bold;">Table 5. </span><span class="font1">The best SVM model achievements</span></p>
<p><span class="font0" style="font-weight:bold;">Predicted Class</span></p>
<table border="1">
<tr><td style="vertical-align:top;"></td><td colspan="2" style="vertical-align:bottom;">
<p><span class="font0" style="font-weight:bold;">COVID-19</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0" style="font-weight:bold;">Pneumonia</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0" style="font-weight:bold;">Normal</span></p></td></tr>
<tr><td rowspan="3" style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">Actual Class</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0" style="font-weight:bold;">COVID-19</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">257</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">15</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0">13</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">Pneumonia</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">16</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">203</span></p></td><td style="vertical-align:middle;">
<p><span class="font0">27</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font0" style="font-weight:bold;">Normal</span></p></td><td style="vertical-align:top;">
<p><span class="font0">11</span></p></td><td style="vertical-align:top;">
<p><span class="font0">32</span></p></td><td style="vertical-align:top;">
<p><span class="font0">233</span></p></td></tr>
</table>
<p><span class="font1">Based on the data in Table 5, the best model of SVM performs well for a chest radiography image prediction, indicated by 86.87% accuracy, 85.68% precision, and 85.71% recall.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark28"></a><span class="font1" style="font-weight:bold;"><a name="bookmark29"></a>3.4. &nbsp;&nbsp;&nbsp;Data Sharing Test</span></h2></li></ul>
<p><span class="font1">The next test was conducted to evaluate the variation of data splitting using k-fold cross-validation on the best SVM model. The splitting technique in the previous test data was hold-out validation which had the weakness of bias between training data and testing data because of a sharing process. Thus, testing using k-fold cross-validation, which divides the data into several k groups and ensures that each group is used as testing data, can overcome the weaknesses of the previous test.</span></p>
<p><span class="font1">Variations in the k value or fold value used in this test are 2, 3, 4, 5, 6, 7, 8, 9, and 10. For each variation in the value of k, one-fold will be taken as testing data and the rest as training data. The test results are presented in Table 6.</span></p>
<p><span class="font1" style="font-weight:bold;">T</span><span class="font1" style="font-weight:bold;text-decoration:underline;">able 6.</span><span class="font1" style="font-weight:bold;"> </span><span class="font1">The experimental result on data-splitting</span></p>
<table border="1">
<tr><td style="vertical-align:middle;">
<p><span class="font1" style="font-weight:bold;">K</span></p></td><td style="vertical-align:middle;">
<p><span class="font1" style="font-weight:bold;">Accuracy</span></p></td><td style="vertical-align:middle;">
<p><span class="font1" style="font-weight:bold;">Precision</span></p></td><td style="vertical-align:middle;">
<p><span class="font1" style="font-weight:bold;">Recall</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font1" style="font-weight:bold;">2</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">83.91%</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">83.75%</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">83.67%</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font1" style="font-weight:bold;">3</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">83.91%</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">83.98%</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">83.88%</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font1" style="font-weight:bold;">4</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">85.40%</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">85.32%</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">85.56%</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font1" style="font-weight:bold;">5</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">83.91%</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">83.85%</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">83.80%</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font1" style="font-weight:bold;">6</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">82.88%</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">83.16%</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">82.87%</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font1" style="font-weight:bold;">7</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">83.37%</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">83.28%</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">83.31%</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font1" style="font-weight:bold;">8</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">85.11%</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">85.76%</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">85.20%</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font1" style="font-weight:bold;">9</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">85.86%</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">85.87%</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">85.96%</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font1" style="font-weight:bold;">10</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">87.84%</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">87.80%</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">87.96%</span></p></td></tr>
</table>
<p><span class="font1">Table 6 shows that the k = 10 delivers the most increased accuracy, precision, and recall (87.84% accuracy rate, 87.8% precision, and 87.96% recall) when the ratio of training and testing data sharing is 9:1. It means the best model of SVM could deliver a good performance for k= 10, which is the best data sharing with low bias.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark30"></a><span class="font1" style="font-weight:bold;"><a name="bookmark31"></a>3.5. &nbsp;&nbsp;&nbsp;Model Comparison</span></h2></li></ul>
<p><span class="font1">The comparison of the model is based on the best results from the predictions proposed using SVM with the previous predictions using the method[19]. Based on the experimental results, it is known that the success of the two models is slightly different. However, the prediction model using SVM gave a slightly better performance with 87.84% accuracy, 87.8% precision, and 87.96% recall, as presented in Table 7.</span></p>
<p><span class="font1" style="font-weight:bold;">Table 7. </span><span class="font1">Model Comparison</span></p>
<table border="1">
<tr><td style="vertical-align:bottom;">
<p><span class="font1" style="font-weight:bold;">Method</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1" style="font-weight:bold;">Accuracy (%)</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1" style="font-weight:bold;">Precision (%)</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1" style="font-weight:bold;">Recall (%)</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font1" style="font-weight:bold;">SVM</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">87.84</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">87.80</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">87.96</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font1" style="font-weight:bold;">ANN</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">86.32</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">86.35</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">86.26</span></p></td></tr>
</table>
<p><span class="font1">Our proposed SVM model's accuracy, precision, and recall are slightly better than our previously reported ANN method[19]. The excellent optimization and similarity treatment of both the SVM and ANN methods allowed us to analogize these computational approaches. The SVM method slightly outperforms ANN for the chest radiographic images for our application using the current data set. The exact reason for this improvement is difficult to determine and may be due to better or varying-parameter selection and non-linear nature of the dataset, or both. It could also be because SVM converges on a global minimum and allows for better noise tolerance; therefore, it may be more robust for a large set of features [21]. Nevertheless, both ANN and SVM could be used to identify COVID-19 suspects, pneumonia, or normal from chest radiographic images. Compared to the most related method, CVDNet[12], which provided an accuracy of 96.69%, Our proposed SVM shows a lack of performance; however, the SVM model requires much fewer parameters than the commonly CNN-based method (CVDNet)[12].</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark32"></a><span class="font1" style="font-weight:bold;"><a name="bookmark33"></a>4. &nbsp;&nbsp;&nbsp;Conclusion and Future Works</span></h2></li></ul>
<p><span class="font1">The best SVM prediction model with statistical features of DWT results and moment invariance has been successfully developed with good performance, as evidenced by 86% accuracy, 86% precision rate, and 86% recall rate. The best parameters of the SVM prediction model for chest radiography image prediction are C=1000, Gamma=1, and polynomial kernel type. Based on the k-fold cross-validation test conducted to verify the model's achievement, the best accuracy rate is 87.84%, the precision level is 87.8%, and the recall rate is 87.96% for the best k value is 10. When compared to the model ANN prediction, the SVM prediction model gives slightly outperformed ANN results for the chest radiographic images for our application using the current data set.</span></p>
<p><span class="font1">Other models still need to be developed in the future, considering the performance is not yet optimal. Deep learning will likely improve predictive performance, considering that Deep-Learning assesses many features in the prediction process.</span></p>
<h2><a name="bookmark34"></a><span class="font1" style="font-weight:bold;"><a name="bookmark35"></a>References</span></h2>
<ul style="list-style:none;"><li>
<p><span class="font1">[1] &nbsp;&nbsp;&nbsp;World Health Organization, “Q&amp;A on coronaviruses (COVID-19).” .</span></p></li>
<li>
<p><span class="font1">[2] &nbsp;&nbsp;&nbsp;World Health Organization, “Pesan dan Kegiatan Utama Pencegahan dan Pengendalian COVID-19 di Sekolah,” 2020.</span></p></li>
<li>
<p><span class="font1">[3] &nbsp;&nbsp;&nbsp;A. Susilo </span><span class="font1" style="font-style:italic;">et al.</span><span class="font1">, “Coronavirus Disease 2019: Tinjauan Literatur Terkini,” </span><span class="font1" style="font-style:italic;">Jurnal Penyakit Dalam Indonesia</span><span class="font1">, vol. 7, no. 1, p. 45, 2020, doi: 10.7454/jpdi.v7i1.415.</span></p></li>
<li>
<p><span class="font1">[4] &nbsp;&nbsp;&nbsp;T. Yang, Y.-C. Wang, C.-F. Shen, and C.-M. Cheng, &quot;Point-of-Care RNA-Based Diagnostic Device for COVID-19,&quot; </span><span class="font1" style="font-style:italic;">Diagnostics</span><span class="font1">, vol. 10, no. 3. 2020, doi: 10.3390/diagnostics10030165.</span></p></li>
<li>
<p><span class="font1">[5] &nbsp;A. News, &quot;India's poor testing rate may have masked coronavirus cases,&quot; </span><span class="font1" style="font-style:italic;">2020</span><span class="font1">.</span></p></li>
<li>
<p><span class="font1">[6] &nbsp;M. E. H. Chowdhury </span><span class="font1" style="font-style:italic;">et al.</span><span class="font1">, &quot;Can AI Help in Screening Viral and COVID-19 Pneumonia?,&quot;</span></p></li></ul>
<p><span class="font1" style="font-style:italic;">IEEE Access</span><span class="font1">, vol. 8, pp. 132665–132676, 2020, doi: 10.1109/ACCESS.2020.3010287.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1">[7] &nbsp;World Health Organization, &quot;Clinical management of severe acute respiratory infection</span></p></li></ul>
<p><span class="font1">(SARI) when COVID-19 disease is suspected.&quot;.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1">[8] &nbsp;W. Guan </span><span class="font1" style="font-style:italic;">et al.</span><span class="font1">, “Clinical Characteristics of Coronavirus Disease 2019 in China,” </span><span class="font1" style="font-style:italic;">New</span></p></li></ul>
<p><span class="font1" style="font-style:italic;">England Journal of Medicine</span><span class="font1">, vol. 382, no. 18, pp. 1708–1720, Feb. 2020, doi: 10.1056/NEJMoa2002032.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1">[9] &nbsp;&nbsp;&nbsp;W. H. Self, D. M. Courtney, C. D. McNaughton, R. G. Wunderink, and J. A. Kline, &quot;High discordance of chest x-ray and computed tomography for detection of pulmonary opacities in ED patients : implications for diagnosing pneumonia,&quot; </span><span class="font1" style="font-style:italic;">The American Journal of Emergency Medicine</span><span class="font1">, vol. 31, no. 2, pp. 401–405, 2013, doi: 10.1016/j.ajem.2012.08.041.</span></p></li>
<li>
<p><span class="font1">[10] &nbsp;&nbsp;&nbsp;G. D. Rubin </span><span class="font1" style="font-style:italic;">et al.</span><span class="font1">, &quot;The Role of Chest Imaging in Patient Management During the COVID-19 Pandemic A Multinational Consensus Statement From the Fleischner Society,&quot; no. July, pp. 106–116, 2020, doi: 10.1016/j.chest.2020.04.003.</span></p></li>
<li>
<p><span class="font1">[11] &nbsp;&nbsp;&nbsp;N. Science, C. Phenomena, S. Hassantabar, M. Ahmadi, and A. Sharifi, &quot;Diagnosis and detection of infected tissue of COVID-19 patients based on lung x-ray image using convolutional neural network approaches,&quot; </span><span class="font1" style="font-style:italic;">Chaos , Solitons &amp;&nbsp;Fractals</span><span class="font1">, vol. 140, 2020, doi: 10.1016/j.chaos.2020.110170.</span></p></li>
<li>
<p><span class="font1">[12] &nbsp;&nbsp;&nbsp;C. Ouchicha, O. Ammor, and M. Meknassi, &quot;CVDNet: A novel deep learning architecture for detection of coronavirus ( Covid-19 ) from chest x-ray images,&quot; </span><span class="font1" style="font-style:italic;">Chaos , Solitons &amp;&nbsp;Fractals</span><span class="font1">, vol. 140, 2020, doi: 10.1016/j.chaos.2020.110245.</span></p></li>
<li>
<p><span class="font1">[13] &nbsp;&nbsp;&nbsp;C. Z. Basha, G. Rohini, A. V. Jayasri, and S. Anuradha, &quot;Enhanced And Effective Computerized Classification Of X-ray Images,&quot; in </span><span class="font1" style="font-style:italic;">2020 International Conference on</span></p></li></ul>
<p><span class="font1" style="font-style:italic;">Electronics and Sustainable Communication Systems (ICESC)</span><span class="font1">, 2020, pp. 86–91, doi: 10.1109/ICESC48915.2020.9155788.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1">[14] &nbsp;&nbsp;&nbsp;A. Mohammed, F. al Azzo, and M. Milanova, &quot;Classification of Alzheimer Disease based on Normalized Hu Moment Invariants and Multiclassifier,&quot; </span><span class="font1" style="font-style:italic;">International Journal of Advanced Computer Science and Applications (IJACSA)</span><span class="font1">, vol. 8, pp. &nbsp;10–18, Jan. 2017, doi:</span></p></li></ul>
<p><span class="font1">10.14569/IJACSA.2017.081102.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1">[15] &nbsp;&nbsp;&nbsp;C. M. N. Kumar, B. Ramesh, and J. Chandrika, &quot;Design and Implementation of an Efficient Level Set Segmentation and Classification for Brain MR Images,&quot; in </span><span class="font1" style="font-style:italic;">Dash S., Bhaskar M., Panigrahi B., Das S. (eds) Artificial Intelligence and Evolutionary Computations in Engineering Systems. Advances in Intelligent Systems and Computing</span><span class="font1">, Springer, New Delhi, 2016, pp. 559–568.</span></p></li>
<li>
<p><span class="font1">[16] &nbsp;&nbsp;&nbsp;C. Basha, T. Padmaja, and G. Balaji, &quot;An Effective and Reliable Computer Automated Technique for Bone Fracture Detection,&quot; </span><span class="font1" style="font-style:italic;">EAI Endorsed Transactions on Pervasive Health and Technology</span><span class="font1">, vol. 5, p. 162402, Jul. 2018, doi: 10.4108/eai.13-7-2018.162402.</span></p></li>
<li>
<p><span class="font1">[17] &nbsp;&nbsp;&nbsp;A. Bakhshipour and A. Jafari, &quot;Evaluation of support vector machine and artificial neural networks in weed detection using shape features,&quot; </span><span class="font1" style="font-style:italic;">Computers and Electronics in Agriculture</span><span class="font1">, vol. 145, pp. 153–160, 2018, doi: </span><a href="https://doi.org/10.1016/j.compag.2017.12.032"><span class="font1">https://doi.org/10.1016/j.compag.2017.12.032</span></a><span class="font1">.</span></p></li>
<li>
<p><span class="font1">[18] &nbsp;&nbsp;&nbsp;I. G. P. S. Wijaya, D. N. Avianty, F. Bimantoro, and R. Lestari, “Ekstraksi Fitur Citra Radiografi Thorax Menggunakan DWT dan Moment Invariant,” </span><span class="font1" style="font-style:italic;">Journal of Computer Science and Informatics Engineering (JCOSINE)</span><span class="font1">, vol. 5, no. 2, pp. 158–166, 2021.</span></p></li>
<li>
<p><span class="font1">[19] &nbsp;&nbsp;&nbsp;D. N. Avianty, I. G. P. S. Wijaya, F. Bimantoro, R. Lestari, and T. D. Cahyawati, &quot;COVID-19 Prediction Based on DWT and Moment Invariant Features of Radiography Image Using the Artificial Neural Network Classifier,&quot; in </span><span class="font1" style="font-style:italic;">Proceedings of the 2nd Global Health and Innovation in conjunction with 6th ORL Head and Neck Oncology Conference (ORLHN 2021)</span><span class="font1">, 2022, pp. 152–162, doi: </span><a href="https://doi.org/10.2991/ahsr.k.220206.030"><span class="font1">https://doi.org/10.2991/ahsr.k.220206.030</span></a><span class="font1">.</span></p></li>
<li>
<p><span class="font1">[20] &nbsp;&nbsp;&nbsp;T. Rahman </span><span class="font1" style="font-style:italic;">et al.</span><span class="font1">, &quot;COVID-19 Chest Radiography Database,&quot; 2020.</span></p></li>
<li>
<p><span class="font1">[21] &nbsp;&nbsp;&nbsp;H. Bisgin </span><span class="font1" style="font-style:italic;">et al.</span><span class="font1">, &quot;Comparing SVM and ANN based Machine Learning Methods for Species Identification of Food Contaminating Beetles,&quot; </span><span class="font1" style="font-style:italic;">Sci Rep</span><span class="font1">, vol. 8, no. 1, p. 6532, 2018, doi: 10.1038/s41598-018-24926-7.</span></p></li></ul>
<p><span class="font1">136</span></p>