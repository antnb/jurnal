---
layout: full_article
title: "Akurasi Klasifikasi Kualitas Wine Menggunakan Algoritma Random Forest Dengan Min-Max Normalization"
author: "Putu Putri Pratiwi, Ida Bagus Made Mahendra"
categories: jnatia
canonical_url: https://jurnal.harianregional.com/jnatia/full-102457 
citation_abstract_html_url: "https://jurnal.harianregional.com/jnatia/id-102457"
citation_pdf_url: "https://jurnal.harianregional.com/jnatia/full-102457"  
comments: true
---

<p><span class="font1">JNATIA Volume 2, Nomor 2, Februari 2024 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;p-ISSN: 2986-3929</span></p>
<p><span class="font1">Jurnal Nasional Teknologi Informasi dan Aplikasinya</span></p>
<p><span class="font2" style="font-weight:bold;">Akurasi Klasifikasi Kualitas Wine Menggunakan Algoritma Random Forest dengan Min-Max</span></p>
<p><span class="font2" style="font-weight:bold;">Normalization</span></p>
<p><span class="font1">Putu Putri Pratiwi</span><span class="font3"><sup>a1</sup></span><span class="font1" style="font-weight:bold;">, </span><span class="font1">Ida Bagus Made Mahendra</span><span class="font3"><sup>a2</sup></span></p>
<p><span class="font3"><sup>a</sup></span><span class="font1">Program Studi Informatika, Fakultas Matematika dan Ilmu Pengetahuan Alam Universitas Udayana, Bali</span></p>
<p><span class="font1">Jln. Raya Kampus UNUD, Bukit Jimbaran, Kuta Selatan, Badung, 08261, Bali, Indonesia </span><a href="mailto:1Putripratiwi720@gmail.com"><span class="font3"><sup>1</sup></span><span class="font1">Putripratiwi720@gmail.com</span></a><span class="font1"> </span><a href="mailto:ibm.mahendra@unud.ac.id"><span class="font3"><sup>2</sup></span><span class="font1" style="text-decoration:underline;">ibm.mahendra@unud.ac.id</span></a></p>
<p><span class="font1" style="font-weight:bold;font-style:italic;">Abstract</span></p>
<p><span class="font1" style="font-style:italic;">In this research, we will discuss the use of the Random Forest algorithm in classifying wine quality using Min-Max normalization. The data obtained will be subjected to data preprocessing and data normalization using Min-Max Normalization which is then applied to the Random Forest algorithm. This algorithm was chosen because it can provide good accuracy for the classification process. Data normalization and preprocessing are needed to produce a classification model with better accuracy. Min-Max normalization is used because it can improve the performance of the Random Forest algorithm in increasing accuracy.</span></p>
<p><span class="font1" style="font-weight:bold;font-style:italic;">Keywords: </span><span class="font1" style="font-style:italic;">Random Forest, Min-Max Normalization, Accuracy</span></p>
<ul style="list-style:none;"><li><a name="caption1"></a>
<h1><a name="bookmark0"></a><span class="font1" style="font-weight:bold;"><a name="bookmark1"></a>1. &nbsp;&nbsp;&nbsp;Pendahuluan</span></h1></li></ul>
<p><span class="font1">Wine merupakan minuman beralkohol yang berasal dari fermentasi buah anggur. Minuman ini banyak diminati di kalangan masyarakat. Wine biasanya disajikan pada acara-acara tertentu, baik formal maupun tidak formal. Wine juga kerap digunakan untuk menghangatkan badan di cuaca yang dingin. Banyaknya varian wine menyebabkan masyarakat menjadi bingung untuk menentukan wine mana yang akan dikonsumsi berdasarkan kualitas yang diinginkan. Klasifikasi wine dilakukan untuk memudahkan permasalahan tersebut, namun metode klasifikasi yang digunakan harus menghasilkan tingkat akurasi yang baik guna meningkatkan kinerja dan tingkat prediksi dalam klasifikasi.</span></p>
<p><span class="font1">Adapun beberapa algoritma klasifikasi yang dapat digunakan adalah Algoritma Decision Tree, Random Forest dan Support Vector Machine. Suatu penelitian di tahun 2020 yang berjudul Penerapan Algoritma Random Forest Untuk Menentukan Kualitas Anggur Merah menyatakan bahwa algoritma Random Forest mengahsilkan akurasi terbaik di antara Algoritma Decision Tree dan Support Vector Machine [3]. Penelitian tersebut membahas mengenai perbandingan tingkat akurasi yang dihasilkan antara algoritma Decision Tree, Random Forest dan Support Vector Machine dengan menggunakan metode cross validation [3]. Penelitian lain di tahun 2021 yang berjudul Peningkatan Hasil Klasifikasi pada Algoritma Random Forest untuk Deteksi Pasien Penderita Diabetes Menggunakan Metode Normalisasi, membahas tentang perbandingan metode normalisasi Min-max normalization, Z-score normalization, dan satu tanpa metode normalisasi data pada algoritma Random Forest menyatakan bahwa Min-max normalization, dapat menghasilkan akurasi terbaik pada klasifikasi deteksi pasien diabetes menggunakan algoritma Random Forest [1]. Dari hasil penelitian tersebut, penulis tertarik untuk melakukan penelitian yang berjudul “Akurasi Klasifikasi Kualitas Wine Menggunakan Algoritma Random Forest Dengan Min-Max Normalization” untuk menemukan akurasi yang lebih tinggi dalam klasifikasi kualitas wine dengan dataset wine.</span></p>
<ul style="list-style:none;"><li>
<h1><a name="bookmark2"></a><span class="font1" style="font-weight:bold;"><a name="bookmark3"></a>2. &nbsp;&nbsp;&nbsp;Metode Penelitian</span></h1></li></ul>
<p><span class="font1">Alur penelitian ini dimulai dari pengunduhan dataset skunder dari laman Kaggle, melakukan preprocessing data yang berupa data cleaning serta normalisasi data menggunakan Min-Max Normalization, kemudian penentuan hasil akurasi menggunakan algoritma Random Forest.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1" style="font-weight:bold;">2.1 &nbsp;&nbsp;&nbsp;Pengumpulan Data</span></p></li></ul>
<p><span class="font1">Data yang digunakan pada penelitian ini adalah data skunder yang berupa wine classification dataset yang diperoleh dari laman Kaggle.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1" style="font-weight:bold;">2.2 &nbsp;&nbsp;&nbsp;Preprocessing Data</span></p></li></ul>
<p><span class="font1">Preprocessing data merupakan teknik pengolahan data untuk memudahkan dalam proses data mining [1]. Permasalahan pada data seperti terlalu banyak atribut, nilai data berada di range yang sangat jauh, missing value, ataupun format data yang tidak sesuai, menyebabkan gangguan pada proses data mining [2]. Preprocessing data penting dilakukan guna membuat kualitas data yang baik, termasuk kelengkapan, konsistensi, ketepatan waktu dan meningkatkan hasil akurasi [1]. Adapun preprocessing data yang dilakukan pada penelitian ini adalah Data Cleaning dan MinMax Normalization.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1" style="font-weight:bold;">a. &nbsp;&nbsp;&nbsp;Data Cleaning</span></p></li></ul>
<p><span class="font1">Data cleaning merupakan proses menghapus atau mengisi nilai yang kosong untuk seluruh dataset dengan menggunakan rata-rata dari tiap kolom pada nilai yang kosong[1]. Berikut hasil dari proses data cleaning pada dataset wine.</span></p>
<table border="1">
<tr><td style="vertical-align:top;"></td><td style="vertical-align:bottom;">
<p><span class="font0" style="font-weight:bold;">fixed</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0" style="font-weight:bold;">volatile</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0" style="font-weight:bold;">citric</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0" style="font-weight:bold;">residual</span></p></td><td style="vertical-align:top;"></td><td style="vertical-align:bottom;">
<p><span class="font0" style="font-weight:bold;">free sulfur</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0" style="font-weight:bold;">total sulfur</span></p></td><td style="vertical-align:top;"></td><td style="vertical-align:top;"></td><td style="vertical-align:top;"></td><td style="vertical-align:top;"></td><td style="vertical-align:top;"></td><td style="vertical-align:top;"></td></tr>
<tr><td style="vertical-align:top;"></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">acidity</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">acidity</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">acid</span></p></td><td style="vertical-align:top;"></td><td style="vertical-align:top;">
<p><span class="font0" style="font-weight:bold;">chlorides</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">dioxide</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">dioxide</span></p></td><td style="vertical-align:top;">
<p><span class="font0" style="font-weight:bold;">density</span></p></td><td style="vertical-align:top;">
<p><span class="font0" style="font-weight:bold;">PH</span></p></td><td style="vertical-align:top;">
<p><span class="font0" style="font-weight:bold;">sulphates</span></p></td><td style="vertical-align:top;">
<p><span class="font0" style="font-weight:bold;">alcohol</span></p></td><td style="vertical-align:top;">
<p><span class="font0" style="font-weight:bold;">quality</span></p></td><td style="vertical-align:top;">
<p><span class="font0" style="font-weight:bold;">Id</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">O</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">7.4</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">O.7O</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">0.00</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">1.9</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">0.076</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">11.0</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">34.0</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">0.9978</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">3.51</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">0 56</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">9.4</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">5</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">0</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">1</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">7.8</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">0.88</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">0.00</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">2.6</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">0.098</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">25.0</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">67.0</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">0.9968</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">3.20</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">068</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">9.8</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">5</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">1</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">2</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">7.8</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">0.76</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">0.04</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">2.3</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">0.092</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">15.0</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">54.0</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">0.9970</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">325</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">065</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">9.8</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">5</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">2</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">3</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">11.2</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">0.28</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">0.56</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">1.9</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">0.075</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">17.0</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">60.0</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">0.9980</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">3.16</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">0.58</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">9.8</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">6</span></p></td><td style="vertical-align:middle;">
<p><span class="font0" style="font-weight:bold;">3</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font0" style="font-weight:bold;">4</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0" style="font-weight:bold;">7.4</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0" style="font-weight:bold;">0.70</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0" style="font-weight:bold;">0.00</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0" style="font-weight:bold;">1.9</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0" style="font-weight:bold;">0.078</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0" style="font-weight:bold;">11.0</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0" style="font-weight:bold;">34.0</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0" style="font-weight:bold;">0.9978</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0" style="font-weight:bold;">3 51</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0" style="font-weight:bold;">0.56</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0" style="font-weight:bold;">9.4</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0" style="font-weight:bold;">5</span></p></td><td style="vertical-align:bottom;">
<p><span class="font0" style="font-weight:bold;">4</span></p></td></tr>
</table>
<p><span class="font1" style="font-weight:bold;">Gambar 1. </span><span class="font1">Hasil Data Cleaning</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1" style="font-weight:bold;">b. &nbsp;&nbsp;&nbsp;Min-Max Normalization</span></p></li></ul>
<p><span class="font1">Normalisasi data adalah proses membuat skala nilai atribut ke dalam rentang yang lebih kecil dengan bobot yang sama [2]. Min-Max Normalization adalah suatu metode yang melakukan transformasi linear dengan menggunakan nilai minimum dan maksimum yang menghasilkan keseimbangan antara data satu dengan yang lain pada rentang yang sama [4]. Adapun formulasi dalam Min-Max Normalization adalah</span></p>
<div>
<p><span class="font4" style="font-style:italic;">(x -MinValue)*(MaxRange-MinRange) MaxValue-MinValue</span></p>
</div><br clear="all">
<div>
<p><span class="font5" style="font-style:italic;">+ MvnRange</span></p>
</div><br clear="all">
<div>
<p><span class="font1">(1)</span></p>
</div><br clear="all">
<p><span class="font1">Keterangan :</span></p>
<p><span class="font1">Data(x) &nbsp;&nbsp;&nbsp;&nbsp;: data baru dari hasil normalisasi</span></p>
<p><span class="font1">x &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;: data yang akan dinormalisasi</span></p>
<p><span class="font1">MinValue : nilai terkecil dari satu kolom baris MaxValue &nbsp;&nbsp;: nilai terbesar dari satu kolom baris</span></p>
<p><span class="font1">MinRange &nbsp;: batas nilai terkecil dari normalisasi</span></p>
<p><span class="font1">MaxRange : batas nilai terbesar dari normalisasi</span></p>
<p><span class="font1">Berikut hasil normalisasi data menggunakan Min-Max Normalization.</span></p><img src="https://jurnal.harianregional.com/media/102457-1.jpg" alt="" style="width:384pt;height:68pt;">
<p><span class="font1" style="font-weight:bold;">Gambar 2. </span><span class="font1">Hasil Normalisasi Data</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1" style="font-weight:bold;">2.3 &nbsp;&nbsp;&nbsp;Percobaan pada Algoritma Random Forest</span></p></li></ul>
<p><span class="font1">Algoritma Random Forest dikembangkan oleh Leo Bremen, algoritma ini merupakan algoritma klasifikasi yang termasuk ke dalam kelompok Supervised Learning yang terdiri dari lebih satu pohon keputusan yang setiap pohon keputusan dibentuk bergantung pada nilai-nilai vector acak sampel secara independen dan identik didistribusikan yang sama untuk semua pohon. Percobaan akan dilakukan menggunakan bahasa pemrograman Python.</span></p>
<ul style="list-style:none;"><li>
<h1><a name="bookmark4"></a><span class="font1" style="font-weight:bold;"><a name="bookmark5"></a>3. &nbsp;&nbsp;&nbsp;Hasil dan Pembahasan</span></h1></li></ul>
<p><span class="font1">Berdasarkan alur dari penelitian yang dilakukan, dataset yang diunduh dari laman Kaggle akan diproses dengan metode preprocessing data yang berupa data cleaning dan Min-Max Normalization, kemudian data akan diterapkan pada algoritma Random Forest untuk diukur akurasinya. Semua proses yang dilakukan, diuji dalam kode program Python. Berikut merupakan hasil uji coba pada kode program.</span></p>
<table border="1">
<tr><td colspan="2" style="vertical-align:top;">
<p><span class="font3">Akurasi: 0.9868995633187773</span></p></td><td rowspan="2" style="vertical-align:bottom;">
<p><span class="font3">recall</span></p></td><td rowspan="2" style="vertical-align:bottom;">
<p><span class="font3">fl-score</span></p></td><td rowspan="2" style="vertical-align:bottom;">
<p><span class="font3">support</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font3">Classification</span></p></td><td style="vertical-align:top;">
<p><span class="font3">Report: precision</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font3">4</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3">1.ΘΘ</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3">0.83</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3">0.91</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3">6</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font3">5</span></p></td><td style="vertical-align:top;">
<p><span class="font3">0.99</span></p></td><td style="vertical-align:top;">
<p><span class="font3">1.00</span></p></td><td style="vertical-align:top;">
<p><span class="font3">0.99</span></p></td><td style="vertical-align:top;">
<p><span class="font3">96</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font3">6</span></p></td><td style="vertical-align:top;">
<p><span class="font3">1.00</span></p></td><td style="vertical-align:top;">
<p><span class="font3">1.00</span></p></td><td style="vertical-align:top;">
<p><span class="font3">1.00</span></p></td><td style="vertical-align:top;">
<p><span class="font3">99</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font3">7</span></p></td><td style="vertical-align:top;">
<p><span class="font3">0.93</span></p></td><td style="vertical-align:top;">
<p><span class="font3">1.00</span></p></td><td style="vertical-align:top;">
<p><span class="font3">0.96</span></p></td><td style="vertical-align:top;">
<p><span class="font3">26</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font3">8</span></p></td><td style="vertical-align:top;">
<p><span class="font3">0.00</span></p></td><td style="vertical-align:top;">
<p><span class="font3">0.00</span></p></td><td style="vertical-align:top;">
<p><span class="font3">0.00</span></p></td><td style="vertical-align:top;">
<p><span class="font3">2</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font3">accuracy</span></p></td><td style="vertical-align:top;"></td><td style="vertical-align:top;"></td><td style="vertical-align:bottom;">
<p><span class="font3">θ.99</span></p></td><td style="vertical-align:bottom;">
<p><span class="font3">229</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font3">macro avg</span></p></td><td style="vertical-align:top;">
<p><span class="font3">0.78</span></p></td><td style="vertical-align:top;">
<p><span class="font3">0.77</span></p></td><td style="vertical-align:top;">
<p><span class="font3">0.77</span></p></td><td style="vertical-align:top;">
<p><span class="font3">229</span></p></td></tr>
<tr><td style="vertical-align:top;">
<p><span class="font3">weighted avg</span></p></td><td style="vertical-align:top;">
<p><span class="font3">0.98</span></p></td><td style="vertical-align:top;">
<p><span class="font3">0.99</span></p></td><td style="vertical-align:top;">
<p><span class="font3">0.98</span></p></td><td style="vertical-align:top;">
<p><span class="font3">229</span></p></td></tr>
</table>
<ul style="list-style:none;"><li>
<p><span class="font1" style="font-weight:bold;">Gambar 3. </span><span class="font1">Hasil Uji Coba</span></p></li></ul>
<p><span class="font1">Dari hasil pengujian, tingkat akurasi yang dihasilkan adalah 0.98, angka tersebut menunjukkan bahwa akurasi yang dihasilkan sangatlah baik. Hasil tersebut juga membuktikan bahwa algoritma Random Forest dapat menghasilkan akurasi yang tinggi. Penggunaan Min-Max Normalization juga dapat memberikan pengaruh dalam peningkatan akurasi yang dihasilkan.</span></p>
<ul style="list-style:none;"><li>
<h1><a name="bookmark6"></a><span class="font1" style="font-weight:bold;"><a name="bookmark7"></a>4. &nbsp;&nbsp;&nbsp;Kesimpulan</span></h1></li></ul>
<p><span class="font1">Berdasarkan penelitian yang telah dilakukan, akurasi yang dihasilkan sebesar 0.98. Jadi dapat disimpulkan bahwa algoritma Random Forest memiliki performa yang bagus untuk menghasilkan nilai akurasi yang tinggi. Min-Max Normalization pada preprocessing data juga berperan terhadap hasil akurasi yang dihasilkan.</span></p>
<p><span class="font1" style="font-weight:bold;">Daftar Pustaka</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1">[1] &nbsp;&nbsp;&nbsp;G. A. B. Suryanegara, Adiwijaya, and M. D. Purbolaksono, “Peningkatan Hasil Klasifikasi pada Algoritma Random Forest untuk Deteksi Pasien Penderita Diabetes Menggunakan Metode Normalisasi,” </span><span class="font1" style="font-style:italic;">Jurnal RESTI (Rekayasa Sistem Dan Teknologi Informasi)</span><span class="font1">, vol. 5, no. 1, pp. 114–122, Feb. 2021, doi: 10.29207/resti. v5i1.2880.</span></p></li>
<li>
<p><span class="font1">[2] &nbsp;&nbsp;&nbsp;Han, J., Kamber, M., and Pei, J., 2011. Data Mining Concepts and Techniques. (3rd ed.). USA: Morgan Kaufmann.</span></p></li>
<li>
<p><span class="font1">[3] &nbsp;&nbsp;&nbsp;R. Supriyadi, W. Gata, N. Maulidah, and A. Fauzi, “Penerapan Algoritma Random Forest Untuk Menentukan Kualitas Anggur Merah,” Semin. Nas. Mhs. Ilmu Komput. dan Apl., vol. 2, no. 2, pp. 260–268, 2021.</span></p></li>
<li>
<p><span class="font1">[4] &nbsp;&nbsp;&nbsp;Suyanto, 2018. Machine Learning Tingkat Dasar dan Lanjut. Bandung: Informatika Bandung.</span></p></li></ul>
<p><span class="font1">392</span></p>