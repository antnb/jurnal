---
layout: full_article
title: "Implementasi Algoritma Support Vector Machine dalam Klasifikasi Deteksi Depresi dari Postingan pada Media Sosial"
author: "Kameliya Putri, Made Agung Raharja"
categories: jnatia
canonical_url: https://jurnal.harianregional.com/jnatia/full-102526 
citation_abstract_html_url: "https://jurnal.harianregional.com/jnatia/id-102526"
citation_pdf_url: "https://jurnal.harianregional.com/jnatia/full-102526"  
comments: true
---

<p><span class="font1">JNATIA Volume 2, Nomor 1, November 2023</span></p>
<p><span class="font1">Jurnal Nasional Teknologi Informasi dan Aplikasinya</span></p>
<p><span class="font1">p-ISSN: 2986-3929</span></p>
<p><span class="font2" style="font-weight:bold;">Implementasi Algoritma </span><span class="font2" style="font-weight:bold;font-style:italic;">Support Vector Machine</span><span class="font2" style="font-weight:bold;"> dalam Klasifikasi Deteksi Depresi dari Postingan pada Media Sosial</span></p>
<p><span class="font1">Kameliya Putri<sup>a1</sup></span><span class="font1" style="font-weight:bold;">, </span><span class="font1">Made Agung Raharja<sup>a2</sup></span></p>
<p><span class="font1"><sup>a</sup>Program Studi Informatika, Fakultas Matematika dan Ilmu Pengetahuan Alam Universitas Udayana, Bali</span></p>
<p><span class="font1">Jln. Raya Kampus UNUD, Bukit Jimbaran, Kuta Selatan, Badung, 08261, Bali, Indonesia </span><a href="mailto:1kameliyaputri8748@gmail.com"><span class="font1"><sup>1</sup>kameliyaputri8748@gmail.com</span></a><span class="font1"> </span><a href="mailto:made.agung@unud.ac.id"><span class="font1"><sup>2</sup>made.agung@unud.ac.id</span></a></p>
<p><span class="font1" style="font-weight:bold;font-style:italic;">Abstract</span></p>
<p><span class="font1" style="font-style:italic;">Mental health issues, such as depression, have significant impacts on individuals and society. Early identification and detection of these conditions are crucial steps in providing appropriate interventions and supporting better recovery. With the increasing use of social media, many people have started sharing their thoughts, feelings, and experiences online. Social media provides an abundant platform for users to express themselves and interact with others. Posts on social media often reflect individuals' emotional states. Therefore, analyzing the content of these posts can provide valuable insights for monitoring and early detection of depressive symptoms. Machine learning has been widely used for automated text mining and classification tasks. A classification method that can be used to classify social media posts into depression and normal classes is the support vector machine. Based on the testing results of the Support Vector Machine algorithm in classifying posts on social media, the highest accuracy value obtained was 95.5% using a parameter value of C equal to 0.25. The Precision, recall, and F-1 score values were 96%.</span></p>
<p><span class="font1" style="font-weight:bold;font-style:italic;">Keywords: </span><span class="font1" style="font-style:italic;">Mental healt issues, Depresion, Support Vector Machine, Classification</span></p>
<ul style="list-style:none;"><li><a name="caption1"></a>
<h1><a name="bookmark0"></a><span class="font1" style="font-weight:bold;"><a name="bookmark1"></a>1. &nbsp;&nbsp;&nbsp;Pendahuluan</span></h1></li></ul>
<p><span class="font1">Masalah kesehatan mental, seperti depresi, memiliki dampak yang signifikan pada individu dan masyarakat. Dimana gangguan kesehatan mental adalah situasi di mana seseorang menghadapi kesulitan dalam beradaptasi dengan lingkungan sekitarnya dan mengalami kesulitan dalam menyelesaikan masalah, sehingga menyebabkan tingkat stres yang berlebihan [1]. Depresi adalah gangguan kesehatan mental yang menjadi alasan utama bunuh diri global. Menurut survei perhitungan beban penyakit di Indonesia pada tahun 2017, terdapat prevalensi gangguan kesehatan mental sebesar 13,4%, dimana depresi secara khusus menempati posisi teratas sebagai gangguan kesehatan mental selama tiga dekade terakhir, yaitu dari tahun 1990 hingga 2017 [2]. Identifikasi dan deteksi dini kondisi-kondisi ini merupakan langkah penting dalam memberikan intervensi yang tepat dan mendukung pemulihan yang lebih baik. Seiring dengan meningkatnya penggunaan media sosial, banyak orang mulai berbagi pikiran, perasaan, dan pengalaman mereka secara online. Menurut temuan survei &quot;We Are Social&quot; pada tahun 2017, jumlah pengguna media sosial di Indonesia mencapai 106 juta dari total populasi masyarakat yang berjumlah 262 juta [3]. Media sosial menyediakan platform yang melimpah bagi pengguna untuk mengekspresikan diri dan berinteraksi dengan orang lain. Postingan pada media sosial sering kali mencerminkan kondisi emosional individu. Oleh karena itu, analisis konten dari postingan tersebut dapat memberikan wawasan yang berharga dalam pemantauan dan klasifikasi deteksi dini gejala depresi.</span></p>
<p><span class="font1">Untuk mempermudah dalam klasifikasi deteksi depresi tentunya diperlukan teknik atau metode untuk dapat mengelompokkan dengan sebuah perhitungan yaitu dengan menggunakan metode text mining yaitu dengan klasifikasi. Klasifikasi digunakan karena klasifikasi adalah sebuah metode yang melakukan proses dalam mendapatkan suatu pola untuk menyatakan suatu teks</span></p>
<p><span class="font1">tersebut masuk pada keleompok tertentu yang telah ditentukan [4]. Salah satu algoritma yang dapat digunakan dalam </span><span class="font1" style="font-style:italic;">text mining</span><span class="font1"> khususnya pada klasisfikasi adalah </span><span class="font1" style="font-style:italic;">Support Vector Machine </span><span class="font1">(SVM). SVM merupakan suatu algoritma yang memiliki prinsip mencari </span><span class="font1" style="font-style:italic;">hyperplane</span><span class="font1"> yang memiliki margin terbesar. </span><span class="font1" style="font-style:italic;">Hyperplane</span><span class="font1"> yaitu suatu garis yang memisahkan data antar kelas atau kategori. Sedangkan margin merupakan jarak antara </span><span class="font1" style="font-style:italic;">hyperplane</span><span class="font1"> dengan data terdekat yang berada pada masing-masing kelas. Data yang paling dekat dengan </span><span class="font1" style="font-style:italic;">hyperplane</span><span class="font1"> disebut support vector [5]. Metode SVM ini memiliki tujuan utama yaitu untuk membangun OSH (Optimal Separating </span><span class="font1" style="font-style:italic;">Hyperplane</span><span class="font1">), yang membuat fungsi pemisahan optimum yang dapat digunakan untuk klasifikasi.</span></p>
<p><span class="font1">Pada penelitian sebelumnya yang terkait klasifikasi mengenai deteksi depresi yaitu penelitian dilakukan oleh Andre Budiman dkk yaitu melakukan klasifikasi konten Twitter dengan indikasi depresi dengan menggunakan metode </span><span class="font1" style="font-style:italic;">Multinomial Naïve Bayes</span><span class="font1"> (MNB) dan </span><span class="font1" style="font-style:italic;">Complement Naïve Bayes</span><span class="font1"> (CNB). Dari hasil eksperimen yang dilakukan, kombinasi metode TF-IDF dan MNB berhasil mencapai tingkat F-score sebesar 91,30%. Sementara itu, gabungan metode TF-IDF dan CNB berhasil mencapai tingkat performa sebesar 91,98% [6]. Selanjutnya penelitian yang dilakukan oleh Arianti Primadhani dkk yaitu melakukan analisis sentimen deteksi depresi pada pengguna media sosial Twitter dengan menggunakan metode KNN dengan menggunaka </span><span class="font1" style="font-style:italic;">confusion matrix </span><span class="font1">hasil akurasi yang didapatkan sebesar 78.18% [7].</span></p>
<p><span class="font1">Berdasarkan dari permasalahan yang ada dan penelitian-penelitian terdahulu yang terkait yang menjadi dasar dalam melakukan penelitian, maka penulis tertarik untuk melakukan penelitian megenai klasifikasi deteksi depresi dari postingan pada media sosial dengan menggunakan algoritma </span><span class="font1" style="font-style:italic;">Support Vector Machine</span><span class="font1">. Penelitian ini bertujuan untuk mempelajari postingan media sosial yang terindikasi mengalami gangguan depresi atau normal. Dari metode yang digunakan untuk penelitian diatas diperlukan data teks berupa cuitan dari postingan media sosial yang diperoleh datanya melalui website Kaggle. Dengan menerapkan metode </span><span class="font1" style="font-style:italic;">Support Vector Machine,</span><span class="font1"> diharapkan mampu mengahsilkan akurasi yang baik dan luaran yang dihasilkan mampu digunakan untuk mengklasifikasikan deteksi depresi dari postingan pada media sosial dengan benar.</span></p>
<ul style="list-style:none;"><li>
<h1><a name="bookmark2"></a><span class="font1" style="font-weight:bold;"><a name="bookmark3"></a>2. &nbsp;&nbsp;&nbsp;Metode Penelitian</span></h1></li></ul>
<p><span class="font1">Bagian ini akan menggambarkan secara umum langkah-langkah yang akan dilakukan dalam penelitian yang dilakukan oleh peneliti. Penelitian akan dimulai dengan mengumpulkan data teks berupa postingan pada media sosial. Setelah itu, akan dilakukan tahap preprocessing untuk mempersiapkan data tersebut. Selanjutnya, data akan diolah dengan menggunakan metode pembobotan kata menggunakan Term Frequency Inverse Document Frequency (TF-IDF). Setelah mendapatkan hasil pembobotan kata, langkah selanjutnya adalah melakukan proses klasifikasi dengan menggunakan metode Support Vector Machine. Pada tahap akhir penelitian, dilakukan pengujian dan evaluasi terhadap kinerja metode yang digunakan. Berikut adalah alur metodologi penelitian yang akan dilakukan oleh peneliti.</span></p><img src="https://jurnal.harianregional.com/media/102526-1.jpg" alt="" style="width:432pt;height:139pt;">
<p><span class="font1" style="font-weight:bold;">Gambar 1. </span><span class="font1">Alur Metode Pnelitian</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1" style="font-weight:bold;">2.1 &nbsp;&nbsp;&nbsp;Pengumpulan Data</span></p></li></ul>
<p><span class="font1">Pada proses pengumpulan data, dimana data yang akan digunakan berupa teks postingan pada sosial media yang didapatkan dari situs kaggle. Pada data tersebut terdapat lima variabel yaitu text, category, Age, Gender, Age Category. Namun variabel yang digunakan hanya variabel text dan Category. Data yang digunakan berjumlah 2454 record yang terdiri dari 2 kelas yaitu kelas 1 (Depresi) dan 0 (Normal). Distribusi antara kelas 1 (Depresi) dan 0 (Normal) masing-masing sebanyak 1227 record. Dari data tersebut digunakan data training dan data testing dengan perbandingan 80%: 20% atau sebanyak 1963 record untuk data </span><span class="font1" style="font-style:italic;">traning</span><span class="font1"> dan 491 record untuk data </span><span class="font1" style="font-style:italic;">testing</span><span class="font1">.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1" style="font-weight:bold;">2.2</span><span class="font1" style="font-weight:bold;font-style:italic;"> &nbsp;&nbsp;&nbsp;Text Preprocessing</span></p></li></ul>
<p><span class="font1" style="font-style:italic;">Text Preprocessing</span><span class="font1"> merupakan tahap awal dalam membangun sebuah model </span><span class="font1" style="font-style:italic;">machine learning </span><span class="font1">dalam </span><span class="font1" style="font-style:italic;">text mining</span><span class="font1">. Pada langkah ini, dilakukan pra-pemrosesan data teks yang telah dikumpulkan sebelumnya. </span><span class="font1" style="font-style:italic;">Preprocessing</span><span class="font1"> teks adalah suatu proses untuk mengubah data teks yang tidak terstruktur menjadi data yang terstruktur, atau dengan kata lain, mengubah teks menjadi indeks kata sesuai kebutuhan [8]. Tujuan dari proses ini adalah untuk mempersiapkan teks agar siap digunakan dan diolah. Pra-pemrosesan melibatkan serangkaian langkah, meliputi </span><span class="font1" style="font-style:italic;">cleanning, tokenization, case folding, stopwords removal, dan stemming</span><span class="font1">. Diharapkan dengan </span><span class="font1" style="font-style:italic;">preprocessing text</span><span class="font1"> dapat mengurangi informasi yang tidak relevan atau tidak berarti dalam dokumen tersebut dengan menghilangkan kata atau teks yang tidak perlu. Semua langkah ini bertujuan untuk mempermudah proses selanjutnya. Ilustrasi alur dari tahap pra-pemrosesan dapat dilihat pada Gambar 2.</span></p><img src="https://jurnal.harianregional.com/media/102526-2.jpg" alt="" style="width:414pt;height:166pt;">
<ul style="list-style:none;"><li>
<p><span class="font1" style="font-weight:bold;">Gambar 2. </span><span class="font1">Alur </span><span class="font1" style="font-style:italic;">Text Preprocessing</span></p></li></ul>
<p><span class="font1">Berdasarkan Gambar 2, tahap pra-pemrosesan terdiri dari beberapa langkah. Tahap pertama data dokumen teks postingan pada media sosial dilakukan cleaning, yang bertujuan untuk menghilangkan karakter selain huruf seperti tanda baca, emotikon, dan angka. Tahap kedua adalah case folding, yang mengubah semua kata menjadi huruf kecil. Tahap ketiga adalah tokenization, yang membagi kalimat menjadi token atau kata-kata tunggal berdasarkan tanda spasi. Tahap keempat adalah stopword removal, yaitu menghilangkan kata-kata stopword yang dianggap tidak memiliki makna. Terakhir, tahap kelima adalah stemming, yang berfungsi untuk mengubah kata-kata ke dalam bentuk dasarnya.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1" style="font-weight:bold;">2.3 &nbsp;&nbsp;&nbsp;Ekstraksi Fitur TF-IDF</span></p></li></ul>
<p><span class="font1">Setelah melalui tahap preprocessing, data akan masuk ke tahap pembobotan atau ekstraksi fitur. Dalam pengolahan teks, perlu dilakukan ekstraksi kata-kata menjadi bentuk numerik karena komputer pada dasarnya hanya dapat memproses data dalam bentuk numerik. Ekstraksi fitur digunakan untuk mengungkapkan informasi yang berpotensi dan mewakili kata-kata sebagai vektor fitur. Vektor ini kemudian digunakan sebagai input untuk metode klasifikasi pada tahap</span></p>
<p><span class="font1">selanjutnya. Salah satu teknik ekstraksi fitur yang umum digunakan adalah menggunakan metode TF-IDF (</span><span class="font1" style="font-style:italic;">Term Frequency-Inverse Document Frequency</span><span class="font1">).TF-IDF adalah metode pembobotan yang digunakan untuk mengukur pentingnya suatu kata dalam sebuah dokumen atau korpus. Metode ini menggunakan term atau kata-kata yang telah melalui proses preprocessing sebagai inputnya. Dengan menggunakan TF-IDF, kita dapat menentukan bobot atau nilai penting dari setiap kata dalam dokumen berdasarkan frekuensi kemunculannya dalam dokumen tersebut dan dalam keseluruhan korpus [9]. Hasil akhir dari ekstraksi fitur direpresentasikan dalam bentuk matriks yang berisi kata-kata unik dan nilai-nilai fitur TF-IDF dari setiap kata dalam semua data review. Berikut merupakan tahapan dari ekstrasi fitur.</span></p><img src="https://jurnal.harianregional.com/media/102526-3.jpg" alt="" style="width:354pt;height:224pt;">
<p><span class="font1" style="font-weight:bold;">Gambar 3. </span><span class="font1">Alur Ekstraksi Fitur TF-IDF</span></p>
<p><span class="font1">Berdasarkan gambar 3 tersebut, proses pembobotan TF-IDF dimulai dengan menghitung frekuensi kata atau </span><span class="font1" style="font-style:italic;">term frequency</span><span class="font1"> dalam dokumen (tf</span><span class="font0">i,j</span><span class="font1">), kemudian menghitung frekuensi dokumen yang mengandung kata tersebut atau document frequency (df), dan dilanjutkan dengan perhitungan bobot inverse document frequency dengan menggunakan persamaan (1). Terakhir menghitung bobot TF-IDF dengan menggunakan persamaan (2).</span></p>
<p><span class="font9" style="font-style:italic;">idf</span><span class="font7" style="font-style:italic;">i </span><span class="font9" style="font-style:italic;">= logφ</span><span class="font1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1)</span></p>
<p><span class="font7" style="font-style:italic;"><sup>u</sup>J </span><span class="font6" style="font-style:italic;">i</span></p>
<p><span class="font9" style="font-style:italic;">W<sub>i</sub></span><span class="font7" style="font-style:italic;">J</span><span class="font9"> = </span><span class="font9" style="font-style:italic;">tf<sub>i</sub></span><span class="font7" style="font-style:italic;">j</span><span class="font9"> × </span><span class="font9" style="font-style:italic;">idf<sub>i</sub></span><span class="font1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(2)</span></p>
<p><span class="font1">Keterangan:</span></p>
<p><span class="font1">N &nbsp;&nbsp;&nbsp;&nbsp;= jumlah dokumen secara keseluruhan</span></p>
<p><span class="font9" style="font-style:italic;">w<sub>i</sub></span><span class="font7" style="font-style:italic;">j</span><span class="font1"> &nbsp;&nbsp;&nbsp;= bobot </span><span class="font1" style="font-style:italic;">term</span><span class="font1"> t terhadap dokumen d</span></p>
<p><span class="font9" style="font-style:italic;">tf<sub>i</sub></span><span class="font7" style="font-style:italic;">j</span><span class="font1"> &nbsp;&nbsp;&nbsp;= frekuensi </span><span class="font1" style="font-style:italic;">term</span><span class="font1"> i pada dokumen j</span></p>
<p><span class="font9" style="font-style:italic;">idf<sub>i</sub></span><span class="font1"> &nbsp;&nbsp;&nbsp;&nbsp;= nilai bobot IDF </span><span class="font1" style="font-style:italic;">term</span><span class="font1"> i</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1" style="font-weight:bold;">2.4 &nbsp;&nbsp;&nbsp;Pemisahan Data</span></p></li></ul>
<p><span class="font1">Langkah berikutnya adalah memisahkan data menjadi data latih dan data uji. Dalam penelitian ini, digunakan 80% data sebagai data latih dan 20% data sebagai data uji dari total 2454 record.</span></p>
<p><span class="font11">Proporsi Data Latih dan Data Uji</span></p>
<p><span class="font8">2500</span></p><img src="https://jurnal.harianregional.com/media/102526-4.jpg" alt="" style="width:217pt;height:91pt;">
<p><span class="font8">Data Latih Data Uji</span></p>
<p><span class="font1" style="font-weight:bold;">Gambar 4. </span><span class="font1">Proporsi Data Latih dan Data Uji</span></p>
<p><span class="font1">Berdasarkan gambar 4, diperoleh 1963 data sebagai data latih dan 491 data sebagai data uji. Proses pemisahan data latih dan data uji dilakukan secara acak untuk menjaga proporsi yang seimbang antara kelas-kelas tersebut.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1" style="font-weight:bold;">2.5 &nbsp;&nbsp;&nbsp;Klasifikasi </span><span class="font1" style="font-weight:bold;font-style:italic;">Support Vector Machine</span></p></li></ul>
<p><span class="font1" style="font-style:italic;">Support Vector Machine</span><span class="font1"> (SVM) adalah salah satu metode klasifikasi dalam pembelajaran mesin (</span><span class="font1" style="font-style:italic;">supervised learning</span><span class="font1">) yang menggunakan model hasil pelatihan untuk memprediksi kelas [10]. SVM bekerja dengan mencari </span><span class="font1" style="font-style:italic;">hyperplane</span><span class="font1"> (bidang pembatas) yang memiliki margin terbesar. </span><span class="font1" style="font-style:italic;">Hyperplane</span><span class="font1"> ini adalah garis yang memisahkan data antara kelas atau kategori. Margin adalah jarak antara </span><span class="font1" style="font-style:italic;">hyperplane</span><span class="font1"> dengan data terdekat dari setiap kelas, dan data yang paling dekat dengan </span><span class="font1" style="font-style:italic;">hyperplane</span><span class="font1"> disebut support vector. SVM melakukan klasifikasi dengan mencari </span><span class="font1" style="font-style:italic;">hyperplane</span><span class="font1"> atau kernel maksimal yang dapat memisahkan dua kelas. Dalam konteks ini, kelas yang dipisahkan adalah sentimen positif (diberi label +1) dan sentimen negatif (diberi label -1). SVM menggunakan bidang pembatas paralel atau kernel untuk memisahkan kedua kelas tersebut. Berikut adalah langkah-langkah perhitungan yang terlibat dalam SVM [11]:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1">1. &nbsp;&nbsp;&nbsp;Diasumsikan bahwa kedua kelas -1 dan +1 dapat dipisahkan secara sempurna oleh </span><span class="font1" style="font-style:italic;">hyperplane</span><span class="font1"> atau bidang pembatas berdimensi d, yang didefinisikan.</span></p></li></ul>
<ul style="list-style:none;"><li>
<p><a href="#bookmark4"><span class="font9" style="font-style:italic;">w. x + b = 0</span><span class="font1">(3)</span></a></p></li></ul>
<ul style="list-style:none;"><li>
<p><span class="font1">2. &nbsp;&nbsp;&nbsp;Pattern xi yang termasuk dalam kelas -1 (kelas negatif) dapat dirumuskan sebagai pattern yang memenuhi persamaan tertentu.</span></p></li></ul>
<p><a href="#bookmark5"><span class="font9" style="font-style:italic;">w.x<sub>i</sub> + b ≤ —1</span><span class="font1">(4)</span></a></p>
<ul style="list-style:none;"><li>
<p><span class="font1">3. &nbsp;&nbsp;&nbsp;Pattern xi yang termasuk dalam kelas +1 (kelas positif) dapat dirumuskan sebagai pattern yang memenuhi persamaan tertentu.</span></p></li></ul>
<p><a href="#bookmark6"><span class="font9" style="font-style:italic;">w.x<sub>i</sub> + b≥1</span><span class="font1">(5)</span></a></p>
<ul style="list-style:none;"><li>
<p><span class="font1">4. &nbsp;&nbsp;&nbsp;Fungsi digunakan untuk mencari nilai Larangrange Multiplier α dengan syarat tertentu.</span></p></li></ul>
<p><a href="#bookmark7"><span class="font9" style="font-style:italic;">max<sub>a</sub>L<sub>β</sub> =</span><span class="font9"> ∑</span><span class="font7">p=<sub>1</sub> </span><span class="font9" style="font-style:italic;">a<sub>i</sub></span><span class="font9"> - </span><span class="font5">∣</span><span class="font9">∑</span><span class="font7">&quot;<sub>y</sub>=ι </span><span class="font9" style="font-style:italic;">a<sub>i</sub>a<sub>j</sub>y<sub>i</sub>y<sub>j</sub>K(x<sub>i</sub>,x<sub>1</sub>)</span><span class="font1">(6)</span></a></p>
<p><span class="font1">Syarat: </span><span class="font9" style="font-style:italic;">a<sub>i</sub>≥ 0(i = 1,2, ..., n)</span><span class="font1"> dan </span><span class="font9">∑</span><span class="font7">&quot;=<sub>1</sub> </span><span class="font9" style="font-style:italic;">a<sub>i</sub>y<sub>i</sub> = 0</span></p>
<p><span class="font1">Setelah nilai dari fungsi di atas ditemukan, langkah selanjutnya adalah mencari nilai w, nilai bias, dan fungsi keputusan klasifikasi sign(f(x)):</span></p>
<p><span class="font1">Jurnal Nasional Teknologi Informasi dan Aplikasinya</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1">5. &nbsp;&nbsp;&nbsp;Persamaan digunakan untuk mencari nilai w.</span></p></li></ul>
<p><a href="#bookmark8"><span class="font9" style="font-style:italic;">W</span><span class="font9"> = ∑</span><span class="font7">F=1 </span><span class="font9" style="font-style:italic;">a<sub>l</sub>y<sub>l</sub>x<sub>l</sub></span><span class="font1">(7)</span></a></p>
<ul style="list-style:none;"><li>
<p><span class="font1">6. &nbsp;&nbsp;&nbsp;Persamaan digunakan untuk mencari nilai bias.</span></p></li></ul>
<p><a href="#bookmark9"><span class="font9" style="font-style:italic;">b =-</span><span class="font7" style="font-style:italic;">1</span><span class="font9" style="font-style:italic;">(x</span><span class="font7" style="font-style:italic;">+</span><span class="font9" style="font-style:italic;">.W + x</span><span class="font7" style="font-style:italic;"><sup>-</sup></span><span class="font9" style="font-style:italic;">.W)</span><span class="font1">(8)</span></a></p>
<ul style="list-style:none;"><li>
<p><span class="font1">7. &nbsp;&nbsp;&nbsp;Persamaan digunakan untuk mencari fungsi keputusan klasifikasi sign(f(x)).</span></p></li></ul>
<p><a href="#bookmark10"><span class="font9" style="font-style:italic;">fW</span><span class="font9"> = </span><span class="font9" style="font-style:italic;">sign[∑γ<sub>j</sub></span><span class="font7" style="font-style:italic;">=ι</span><span class="font9" style="font-style:italic;">a<sub>i</sub>y<sub>i</sub>K(x,x<sub>i</sub>)</span><span class="font9"> + b]</span></a></p>
<p><span class="font1">Fungsi sign () adalah fungsi normalisasi yang memberikan nilai 1 (kelas positif) jika nilai x dalam fungsi tersebut lebih dari 0, dan memberikan nilai -1 (kelas negatif) jika nilai x dalam fungsi tersebut kurang dari 0.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1" style="font-weight:bold;">2.6 &nbsp;&nbsp;&nbsp;Pengujian dan Evaluasi</span></p></li></ul>
<p><span class="font1">Evaluasi dilakukan untuk mengukur performa dari model yang telah dibangun. Performa ini dapat diukur menggunakan tabel </span><span class="font1" style="font-style:italic;">confusion matrix</span><span class="font1">. </span><span class="font1" style="font-style:italic;">Confusion matrix</span><span class="font1"> adalah sebuah tabel yang umumnya digunakan untuk memvisualisasikan kinerja model klasifikasi pada sejumlah data uji di mana nilai sebenarnya sudah diketahui. Berikut ini adalah contoh tabel </span><span class="font1" style="font-style:italic;">confusion matrix</span><span class="font1"> untuk sebuah model klasifikasi dengan dua kelas.</span></p>
<p><span class="font1" style="font-weight:bold;">Tabel 1. </span><span class="font1">Table </span><span class="font1" style="font-style:italic;">Confusion matrix</span></p>
<p><span class="font1" style="font-weight:bold;font-style:italic;">Classifier positive classifier negative</span></p>
<p><span class="font1" style="font-style:italic;">Actual positive</span><span class="font1"> &nbsp;TP &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;FN</span></p>
<p><span class="font1" style="font-style:italic;">Actual negative</span><span class="font1"> FP &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;TN</span></p>
<p><span class="font1">Berdasarkan Tabel 1 </span><span class="font1" style="font-style:italic;">confusion matrix</span><span class="font1">, kita dapat mengukur performa </span><span class="font1" style="font-style:italic;">Precision, recall, F-1 score</span><span class="font1">, dan akurasi. </span><span class="font1" style="font-style:italic;">Precision</span><span class="font1"> yaitu mengukur sejauh mana model dapat mengidentifikasi secara akurat dokumen-dokumen yang relevan dari dokumen yang dianggap relevan oleh model [12], dan persamaannya menjadi:</span></p>
<p><a href="#bookmark11"><span class="font1" style="font-style:italic;">Precision</span><span class="font1"> = </span><span class="font4" style="font-style:italic;font-variant:small-caps;">—<sup>tp</sup>—</span></a></p>
<p><span class="font7" style="font-style:italic;">(TP+FP)</span></p>
<p><span class="font1" style="font-style:italic;">Recall</span><span class="font1"> yaitu mengukur performa dokumen yang relevan dan bernilai positif dari seluruh dokumen yang benar, dan persamaannya menjadi:</span></p>
<p><a href="#bookmark12"><span class="font1" style="font-style:italic;">Recall</span><span class="font1"> = </span><span class="font3" style="font-variant:small-caps;">—<sup>t</sup>^-</span><span class="font1">(11)</span></a></p>
<p><a href="#bookmark13"><span class="font7" style="font-style:italic;">(TP+FN) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;''</span></a></p>
<p><span class="font1" style="font-style:italic;">F-1 score</span><span class="font1"> mengukur gabungan dari </span><span class="font1" style="font-style:italic;">Precision</span><span class="font1"> dan </span><span class="font1" style="font-style:italic;">recall</span><span class="font1">, yang dimana menggabungkan kedua metrik ini menjadi satu angka untuk memberikan gambaran keseluruhan tentang performa model, dan persamaannya menjadi:</span></p>
<p><a href="#bookmark14"><span class="font1" style="font-style:italic;">F-1 score</span><span class="font1"> = </span><span class="font9">2 × </span><span class="font7" style="font-style:italic;text-decoration:line-through;">(</span><span class="font10" style="font-style:italic;text-decoration:line-through;"><sup>precision</sup></span><span class="font7" style="text-decoration:line-through;"> × </span><span class="font10" style="font-style:italic;text-decoration:line-through;"><sup>recal</sup>^</span><span class="font1">(12)</span></a></p>
<p><a href="#bookmark15"><span class="font7" style="font-style:italic;">(Precision</span><span class="font7"> + </span><span class="font7" style="font-style:italic;">recall) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'</span></a></p>
<p><span class="font1">Akurasi mengukur sejauh mana model dapat mengklasifikasikan dengan benar seluruh dokumen, baik relevan maupun tidak relevan. dan persamaannya menjadi:</span></p>
<p><span class="font7" style="font-style:italic;">(TP + TN)</span></p>
<p><a href="#bookmark16"><span class="font1">Akurasi =(13)</span></a></p>
<p><a href="#bookmark17"><span class="font7" style="font-style:italic;">(TP + TN + FP + FN) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'</span></a></p>
<ul style="list-style:none;"><li>
<h1><a name="bookmark18"></a><span class="font1" style="font-weight:bold;"><a name="bookmark19"></a>3. &nbsp;&nbsp;&nbsp;Hasil dan Pembahasan</span></h1>
<ul style="list-style:none;">
<li>
<h2><a name="bookmark20"></a><span class="font1" style="font-weight:bold;font-style:italic;"><a name="bookmark21"></a>3.1.</span><span class="font1" style="font-weight:bold;"> &nbsp;Hasil </span><span class="font1" style="font-weight:bold;font-style:italic;">Prepocessing</span></h2></li></ul></li></ul>
<p><span class="font1">Hasil dari seluruh proses preprocessing pada dataset disajikan dalam bentuk tabel yang dapat ditemukan pada Tabel 2. Di bawah ini adalah beberapa contoh kalimat yang diambil dari dataset.</span></p>
<p><span class="font1" style="font-weight:bold;">Tabel 2. </span><span class="font1">Hasil </span><span class="font1" style="font-style:italic;">Preprocessing</span></p>
<table border="1">
<tr><td colspan="2" style="vertical-align:bottom;">
<p><span class="font1" style="font-weight:bold;">Tahap Preprocessing Teks Postingan Media Sosial</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font1">Tanpa Prepocessing</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">I hate being alive when I feel so dead inside.</span></p></td></tr>
<tr><td style="vertical-align:bottom;">
<p><span class="font1">Cleanning</span></p></td><td style="vertical-align:bottom;">
<p><span class="font1">I hate being alive when I feel so dead inside</span></p></td></tr>
<tr><td style="vertical-align:middle;">
<p><span class="font1">Case Folding Tokenisasi Stopword Removal Stemming</span></p></td><td style="vertical-align:middle;">
<p><span class="font1">I hate being alive when I feel so dead inside.</span></p>
<p><span class="font1">[‘i’, ‘hate’, ‘being’, ‘alive’, ‘when’, ‘i’, ‘feel’, ‘so’, ‘dead’, ‘inside’] [‘hate’, ‘alive’, ‘feel’, ‘dead’, ‘inside’]</span></p>
<p><span class="font1">hate alive feel dead inside</span></p></td></tr>
</table>
<ul style="list-style:none;"><li>
<h2><a name="bookmark22"></a><span class="font1" style="font-weight:bold;"><a name="bookmark23"></a>3.2. &nbsp;&nbsp;&nbsp;Hasil Pembobotan TF-IDF</span></h2></li></ul>
<p><span class="font1">Dalam penelitian ini, digunakan pembobotan TF-IDF untuk menghasilkan representasi vektor dari data teks. Vektorisasi adalah proses mengubah data teks menjadi data numerik, di mana setiap angka dalam vektor merepresentasikan kemunculan kata dalam dokumen. Pembobotan ini penting karena komputer hanya dapat memahami dan memproses data dalam bentuk numerik.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark24"></a><span class="font1" style="font-weight:bold;"><a name="bookmark25"></a>3.3. &nbsp;&nbsp;&nbsp;Hasil Klasifikasi SVM</span></h2></li></ul>
<p><span class="font1">Pada klasifikasi menggunakan SVM dengan kernel linear, dilakukan percobaan dengan beberapa nilai parameter C yang berbeda. Nilai C digunakan untuk mengontrol </span><span class="font1" style="font-style:italic;">trade-off</span><span class="font1"> antara margin dan jumlah kesalahan klasifikasi. Berikut adalah hasil dari percobaan tersebut:</span></p>
<p><span class="font1" style="font-weight:bold;">Tabel 3. </span><span class="font1">Percobaan dengan Beberapa Nilai Parameter C</span></p>
<p><span class="font1" style="font-weight:bold;">C Akurasi</span></p>
<p><span class="font1">0.01 90,8%</span></p>
<p><span class="font1">0.05 94,3%</span></p>
<p><span class="font1">0.25 95,9%</span></p>
<p><span class="font1">0.5 &nbsp;95,5%</span></p>
<p><span class="font1">1 &nbsp;&nbsp;&nbsp;95,1%</span></p>
<p><span class="font1">Berdasarkan tabel 3 tersebut, hasil pengujian menunjukkan bahwa penggunaan parameter C mempengaruhi akurasi klasifikasi. Ketika menggunakan parameter C = 0.01, diperoleh akurasi sebesar 90,8%, kemudian, dengan nilai C = 0.05, akurasi meningkat menjadi 94,3%, menunjukkan peningkatan performa. Penggunaan parameter C = 0.25 menghasilkan akurasi sebesar 95,9%, menunjukkan peningkatan signifikan dalam performa klasifikasi. Meskipun akurasi turun sedikit, dengan C = 0.5 dengan akurasi 95,5% dan C = 1, yaitu 95,1%, model SVM tetap memberikan performa yang baik. Nilai C yang lebih tinggi cenderung memberikan performa yang lebih baik, tetapi perlu diingat bahwa peningkatan yang signifikan juga bisa berdampak pada </span><span class="font1" style="font-style:italic;">overfitting</span><span class="font1"> atau kompleksitas model yang lebih tinggi. Oleh karena itu, pemilihan nilai C yang optimal perlu mempertimbangkan </span><span class="font1" style="font-style:italic;">trade-off</span><span class="font1"> antara akurasi dan kompleksitas model. Sehingga untuk nilai C yang digunakan dalam penelitian ini yaitu dengan parameter C = 0.25.</span></p>
<ul style="list-style:none;"><li>
<h2><a name="bookmark26"></a><span class="font1" style="font-weight:bold;"><a name="bookmark27"></a>3.4. &nbsp;&nbsp;&nbsp;Evaluasi</span></h2></li></ul>
<p><span class="font1">Evaluasi dilakukan menggunakan </span><span class="font1" style="font-style:italic;">Confusion matrix</span><span class="font1"> untuk mengukur akurasi yang diperoleh dari metode yang digunakan. Pada pemodelan menggunakan </span><span class="font1" style="font-style:italic;">Support Vector Machine</span><span class="font1"> (SVM), diperoleh akurasi yang tinggi pada tahap pelatihan dan pengujian. Informasi evaluasi yang lebih rinci disajikan dalam Tabel 4 dan Gambar 5.</span></p>
<p><span class="font1" style="font-weight:bold;">Tabel 4. </span><span class="font1">Hasil Evaluasi</span></p>
<p><span class="font1" style="font-weight:bold;font-style:italic;">Precision Recall</span><span class="font1" style="font-weight:bold;"> &nbsp;F-1 Score Akurasi</span></p>
<p><span class="font1">depresi 96% &nbsp;&nbsp;&nbsp;&nbsp;96% &nbsp;&nbsp;96% &nbsp;&nbsp;&nbsp;&nbsp;96%</span></p>
<p><span class="font1">normal &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;95,9%</span></p><img src="https://jurnal.harianregional.com/media/102526-5.jpg" alt="" style="width:212pt;height:118pt;">
<p><span class="font1" style="font-weight:bold;">Gambar 5. </span><span class="font1" style="font-style:italic;">Confusion matrix</span><span class="font1"> SVM</span></p>
<p><span class="font1">Dalam evaluasi yang menggunakan parameter C = 0.25, yang menghasilkan akurasi terbaik sebesar 96%, juga dilakukan perhitungan nilai </span><span class="font1" style="font-style:italic;">Precision</span><span class="font1">, </span><span class="font1" style="font-style:italic;">recall</span><span class="font1">, dan F-1 score. Hasil evaluasi menunjukkan bahwa model klasifikasi SVM memiliki kinerja yang sangat baik dalam mengklasifikasikan data. </span><span class="font1" style="font-style:italic;">Precision</span><span class="font1"> yang mencapai 96% menunjukkan tingkat ketepatan yang tinggi dalam mengidentifikasi dokumen-dokumen yang relevan dan bernilai positif. </span><span class="font1" style="font-style:italic;">Recall</span><span class="font1"> sebesar 96% menunjukkan bahwa model mampu mengenali sebagian besar dokumen yang sebenarnya relevan. Selain itu, nilai </span><span class="font1" style="font-style:italic;">F-1 score</span><span class="font1"> sebesar 96% menunjukkan keseimbangan yang baik antara </span><span class="font1" style="font-style:italic;">Precision</span><span class="font1"> dan </span><span class="font1" style="font-style:italic;">recall</span><span class="font1">. Dengan demikian, dapat disimpulkan bahwa penggunaan parameter C = 0.25 pada SVM memberikan kinerja yang optimal dalam mengklasifikasikan data, dengan akurasi, </span><span class="font1" style="font-style:italic;">Precision</span><span class="font1">, </span><span class="font1" style="font-style:italic;">recall</span><span class="font1">, dan </span><span class="font1" style="font-style:italic;">F-1 score</span><span class="font1"> yang sangat memuaskan. Model ini dapat diandalkan dalam mengidentifikasi dokumen-dokumen yang relevan dan memberikan hasil prediksi yang akurat.</span></p>
<ul style="list-style:none;"><li>
<h1><a name="bookmark28"></a><span class="font1" style="font-weight:bold;"><a name="bookmark29"></a>4. &nbsp;&nbsp;&nbsp;Kesimpulan</span></h1></li></ul>
<p><span class="font1">Berdasarkan penelitian ini, deteksi depresi dari postingan pada media sosial dilakukan dengan menggunakan metode klasifikasi </span><span class="font1" style="font-style:italic;">Support Vector Machine</span><span class="font1"> (SVM) dengan kernel linear. Dataset terdiri dari dua kelas, yaitu depresi dan normal. Hasil evaluasi menunjukkan bahwa penggunaan SVM dengan nilai parameter C sebesar 0.25 menghasilkan akurasi terbaik sebesar 95.5%. Selain itu, </span><span class="font1" style="font-style:italic;">Precision</span><span class="font1">, </span><span class="font1" style="font-style:italic;">recall</span><span class="font1">, dan </span><span class="font1" style="font-style:italic;">F-1 score</span><span class="font1"> juga mencapai nilai yang tinggi, yaitu sebesar 96%. Penelitian ini menunjukkan bahwa metode SVM dengan kernel linear sangat efektif dalam mengklasifikasikan postingan pada media sosial menjadi kategori depresi atau normal. Penggunaan nilai parameter C sebesar 0.25 memberikan kinerja optimal dengan tingkat akurasi yang tinggi. </span><span class="font1" style="font-style:italic;">Precision</span><span class="font1">, </span><span class="font1" style="font-style:italic;">recall</span><span class="font1">, dan </span><span class="font1" style="font-style:italic;">F-1 score</span><span class="font1"> yang tinggi menunjukkan bahwa model ini mampu mengenali dengan baik postingan-postingan yang relevan dengan kondisi depresi dan normal.</span></p>
<p><span class="font1" style="font-weight:bold;">Daftar Pustaka</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1">[1] &nbsp;&nbsp;&nbsp;Putri, A. W., Wibhawa, B. dan Gutama, A. S. 2015. Kesehatan Mental Masyarakat Indonesia (Pengetahuan, Dan Keterbukaan Masyarakat Terhadap Gangguan Kesehatan Mental). Prosiding Penelitian dan Pengabdian Kepada Masyarakat. 2, 2, 252–258. doi:</span></p></li></ul>
<p><span class="font1">10.24198/jppm. v2i2.13535</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1">[2] &nbsp;&nbsp;&nbsp;Indrayani, Y.A., Wahyudi, T. 2019. Situasi Kesehatan Jiwa di Indonesia. InfoDatin Pusat Data dan Informasi Kementerian Kesehatan RI. 1-12</span></p></li>
<li>
<p><span class="font1">[3] &nbsp;&nbsp;&nbsp;J. Degenhard, “Forecast of the number of Twitter users in Indonesia from 2017 to 2026,” Statista.com, 2020.</span></p></li></ul>
<p><a href="https://www.statista.com/forecasts/1145550/twitter-users-in-indonesia"><span class="font1" style="text-decoration:underline;">https://www.statista.com/forecasts/1145550/twitter-users-in-indonesia</span><span class="font1">.</span></a></p>
<ul style="list-style:none;"><li>
<p><span class="font1">[4] &nbsp;&nbsp;&nbsp;Setio, P. B. N., Saputro, D. R. S., and Winarno. B., “Klasifikasi Dengan Pohon Keputusan Berbasis Algoritme C4.5,” Prism. Pros. Semin. Nas. Mat., vol. 3, pp. 64–71, 2020.</span></p></li>
<li>
<p><span class="font1">[5] &nbsp;&nbsp;&nbsp;Irmanda, H.N. and Astriratma, R. (2020). Klasifikasi Jenis Pantun dengan Metode Support Vector Machines (SVM). Jurnal RESTI (Rekayasa Sistem dan Teknologi Informasi), 4(5), pp.915–922.</span></p></li>
<li>
<p><span class="font1">[6] &nbsp;&nbsp;&nbsp;A. Budiman, A. Suryadibrata, and J. Young, “Implementasi Algoritma Naïve Bayes untuk Klasifikasi Konten Twitter dengan Indikasi Depresi,” </span><span class="font1" style="font-style:italic;">Julnal Informatika: Jurnal Pengembangan IT</span><span class="font1">, vol. 6, no. 1, 2021.</span></p></li>
<li>
<p><span class="font1">[7] &nbsp;&nbsp;&nbsp;A.P.Tirtopangarsa and W. Maharani, “Sentiment Analysis of Depression Detection on Twitter Social Media Users Using the K-Nearest Neighbor Method,” 2021. In </span><span class="font1" style="font-style:italic;">Seminar Nasional Informatika (SEMNASIF)</span><span class="font1"> (Vol. 1, No. 1, pp. 247-258).</span></p></li>
<li>
<p><span class="font1">[8] &nbsp;&nbsp;&nbsp;E. Indrayuni. “Klasifikasi Text Mining Review Produk Kosmetik Untuk Teks Bahasa</span></p></li></ul>
<p><span class="font1">Indonesia Menggunakan Algoritma Naive Bayes.” vol. VII, no. 1, pp. 29-36, 2019.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1">[9] &nbsp;&nbsp;P. M. Prihatini, “Implementasi Ekstraksi Fitur Pada Pengolahan Dokumen Berbahasa</span></p></li></ul>
<p><span class="font1">Indonesia,” Matrix J. Manaj. Teknol. dan Inform., vol. 6, no. 3, pp. 174–178, 2017.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1">[10] &nbsp;R. Maulana &amp;&nbsp;S. Redjeki. (2017). Analisis Sentimen Pengguna Twitter Menggunakan</span></p></li></ul>
<p><span class="font1">Metode </span><span class="font1" style="font-style:italic;">Support Vector Machine</span><span class="font1"> Berbasis Cloud Computing. Jurnal TAM, 6, 23-28.</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1">[11] &nbsp;&nbsp;&nbsp;A. S. Nugroho, A. B. Wiarto, &amp;&nbsp;D. Handoko. (2003). </span><span class="font1" style="font-style:italic;">Support Vector Machine.</span><span class="font1"> Proceesing </span><span class="font1" style="font-style:italic;">Indones. Sci. Meetiting Cent. Japan.</span></p></li>
<li>
<p><span class="font1">[12] &nbsp;&nbsp;&nbsp;Zizka, Jan., Darena, Frantisek., and Svoboda, Arnost. 2020. </span><span class="font1" style="font-style:italic;">Text Mining with Machine Learning Principles and Techniques.</span><span class="font1"> CRC Press. New York.</span></p></li></ul>
<p><span class="font1">Halaman ini sengaja dibiarkan kosong</span></p>
<p><span class="font1">202</span></p>